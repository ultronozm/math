<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Notes on Lie Groups</title>
  <link rel="stylesheet" href="tex.css">
  <style>
      .my-links-container {
        position: absolute;
        top: 0;
        right: 0;
        padding-right: 20px;
        padding-top: 10px;
      }
      .my-link {
        margin-left: 10px;
      }
      .my-links-container-2 { /* new CSS class for the second row */
        position: absolute;
        top: 40px; /* adjust this value based on the height of your links */
        right: 0;
        padding-right: 20px;
      }
      .my-link-2 {
        margin-left: 10px;
      }

    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    div.abstract {
      margin: 2em 2em 2em 2em;
      text-align: left;
      font-size: 85%;
    }
    div.abstract-title {
      font-weight: bold;
      text-align: center;
      padding: 0;
      margin-bottom: 0.5em;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
    <div class="my-links-container">
2024-03-08 17:44:43
      <a href="20240308T151221--fall-2016-lie-groups__course.tex" class="my-link">tex</a>
      <a href="20240308T151221--fall-2016-lie-groups__course.pdf" class="my-link">pdf</a>
      <a href="https://github.com/ultronozm/math/commits/main/20240308T151221--fall-2016-lie-groups__course.tex" class="my-link">history</a>
      <a href="." class="my-link">home</a>
    </div>
<header id="title-block-header">
<h1 class="title">Notes on Lie Groups</h1>
<div class="abstract">
<div class="abstract-title">Abstract</div>
<p>Notes from a Lie groups course given at ETH Zurich, Fall 2016,
unedited</p>
</div>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#sec:org8827c4a" id="toc-sec:org8827c4a">Disclaimers<span
id="sec:disclaimers" label="sec:disclaimers"></span></a></li>
<li><a href="#sec:orgeacc8f6" id="toc-sec:orgeacc8f6">Summary of classes
and homework assignments</a>
<ul>
<li><a href="#sec:org5df22f0" id="toc-sec:org5df22f0">9/20: The
definition of a Lie group</a></li>
<li><a href="#sec:org254d9af" id="toc-sec:org254d9af">9/22: The
connected component</a></li>
<li><a href="#sec:orge89327d" id="toc-sec:orge89327d">9/27:
One-parameter subgroups and the exponential map</a></li>
<li><a href="#sec:org102c8ed" id="toc-sec:org102c8ed">9/29: The Lie
algebra of a Lie group</a></li>
<li><a href="#sec:org04627a1" id="toc-sec:org04627a1">10/4
(half-lecture) and 10/6: Representations of <span
class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span></a></li>
<li><a href="#sec:orgc4f94de" id="toc-sec:orgc4f94de">10/11
(half-lecture) and 10/13: The unitary trick</a></li>
<li><a href="#sec:org019e4bd" id="toc-sec:org019e4bd">10/18
(half-lecture): The adjoint representation</a></li>
<li><a href="#sec:org7c4df3a" id="toc-sec:org7c4df3a">10/20 (first
half): Character theory for <span
class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span>
(algebraic)</a></li>
<li><a href="#sec:org5473899" id="toc-sec:org5473899">10/20 (second
half): Maurer-Cartan equations; lifting morphisms of Lie
algebras</a></li>
<li><a href="#sec:org37094a7" id="toc-sec:org37094a7">10/25
(half-lecture): universal covering group</a></li>
<li><a href="#sec:org6e185d7" id="toc-sec:org6e185d7">10/27: Fundamental
groups of Lie groups</a></li>
<li><a href="#sec:orged45fdb" id="toc-sec:orged45fdb">11/1: The
Baker–Campbell–Hausdorff(–Dynkin) formula</a></li>
<li><a href="#sec:org3214742" id="toc-sec:org3214742">11/3: Closed
subgroups are Lie; virtual subgroups vs. Lie subalgebras</a></li>
<li><a href="#sec:org6225804" id="toc-sec:org6225804">11/8: Simplicity
of Lie groups and Lie algebras</a></li>
<li><a href="#sec:orgf1075d9" id="toc-sec:orgf1075d9">11/10: Simplicity
of the special linear Lie algebra</a></li>
<li><a href="#sec:org808d1e4" id="toc-sec:org808d1e4">11/22, 11/24: How
to classify classical simple complex Lie algebras</a></li>
<li><a href="#sec:org6f2526e" id="toc-sec:org6f2526e">11/29: 11/31: Why
simple Lie algebras give rise to root systems</a></li>
<li><a href="#sec:orge92c104" id="toc-sec:orge92c104">12/6: Complex
reductive vs. compact real</a></li>
<li><a href="#sec:org291b534" id="toc-sec:org291b534">12/8: Compact Lie
groups: center, fundamental group</a></li>
<li><a href="#sec:org070bbf1" id="toc-sec:org070bbf1">12/13 Maximal tori
in compact Lie groups</a></li>
</ul></li>
<li><a href="#sec:org814ace2" id="toc-sec:org814ace2">Selected homework
solutions</a></li>
<li><a href="#sec:org8f383a2" id="toc-sec:org8f383a2">Some notation</a>
<ul>
<li><a href="#sec:orgafcf8b3" id="toc-sec:orgafcf8b3">Local maps<span
id="sec:notation-partial-functions"
label="sec:notation-partial-functions"></span></a>
<ul>
<li><a href="#sec:org37c609c"
id="toc-sec:org37c609c">Motivation</a></li>
<li><a href="#sec:org4f4ed31"
id="toc-sec:org4f4ed31">Definition</a></li>
<li><a href="#sec:orgcfbef67"
id="toc-sec:orgcfbef67">Equivalence</a></li>
<li><a href="#sec:orgf825d0e" id="toc-sec:orgf825d0e">Images<span
id="sec:partial-map-images"
label="sec:partial-map-images"></span></a></li>
<li><a href="#sec:org7f9108b"
id="toc-sec:org7f9108b">Composition</a></li>
<li><a href="#sec:orga0b7c1f" id="toc-sec:orga0b7c1f">Inverses</a></li>
</ul></li>
</ul></li>
<li><a href="#sec:org2f1e843" id="toc-sec:org2f1e843">Some review of
calculus</a>
<ul>
<li><a href="#sec:org428341e" id="toc-sec:org428341e">One-variable
derivatives</a></li>
<li><a href="#sec:org2290879" id="toc-sec:org2290879">Multi-variable
total and partial derivatives<span id="sec:calc-multi"
label="sec:calc-multi"></span></a></li>
<li><a href="#sec:org56f7558" id="toc-sec:org56f7558">The chain
rule</a></li>
<li><a href="#sec:org81b78cb" id="toc-sec:org81b78cb">Inverse function
theorem<span id="sec:calc-inv-func-thm"
label="sec:calc-inv-func-thm"></span></a></li>
<li><a href="#sec:orgc7b25df" id="toc-sec:orgc7b25df">Implicit function
theorem<span id="sec:calc-impl-func-thm"
label="sec:calc-impl-func-thm"></span></a></li>
</ul></li>
<li><a href="#sec:org53eb85b" id="toc-sec:org53eb85b">Some review of
differential geometry</a>
<ul>
<li><a href="#sec:org8cf0641" id="toc-sec:org8cf0641">Charts</a></li>
<li><a href="#sec:orgdbe668d" id="toc-sec:orgdbe668d">Manifolds</a></li>
<li><a href="#sec:org92b178d" id="toc-sec:org92b178d">Smooth
maps</a></li>
<li><a href="#sec:org9cf6a98" id="toc-sec:org9cf6a98">Coordinate
systems</a></li>
<li><a href="#sec:orgd99d069" id="toc-sec:orgd99d069">Tangent
spaces<span id="sec:diff-geom-tangent-spaces"
label="sec:diff-geom-tangent-spaces"></span></a></li>
<li><a href="#sec:org3a5d387"
id="toc-sec:org3a5d387">Derivatives</a></li>
<li><a href="#sec:org9589e79" id="toc-sec:org9589e79">Jacobians</a></li>
<li><a href="#sec:org63376d9" id="toc-sec:org63376d9">Inverse function
theorem<span id="sec:diff-geom-inv-func-thm"
label="sec:diff-geom-inv-func-thm"></span></a></li>
<li><a href="#sec:org7d02d39" id="toc-sec:org7d02d39">Local
linearization of smooth maps</a>
<ul>
<li><a href="#sec:org7f15f91" id="toc-sec:org7f15f91">Linear maps in
terms of coordinates</a></li>
<li><a href="#sec:org52585b3" id="toc-sec:org52585b3">The constant rank
theorem</a></li>
<li><a href="#sec:org6479c62" id="toc-sec:org6479c62">The case of
maximal rank<span id="sec:linearization-subimm"
label="sec:linearization-subimm"></span></a></li>
</ul></li>
<li><a href="#sec:orgde0d03e" id="toc-sec:orgde0d03e">Submanifolds<span
id="sec:submflds" label="sec:submflds"></span></a></li>
<li><a href="#sec:org6e7a46d" id="toc-sec:org6e7a46d">A criterion for
being a submanifold</a></li>
<li><a href="#sec:orgcf4ffee" id="toc-sec:orgcf4ffee">Computing tangent
spaces of submanifolds<span id="sec:tangent-space-submfld"
label="sec:tangent-space-submfld"></span></a></li>
<li><a href="#sec:org75b7188" id="toc-sec:org75b7188">Summary of how to
work with submanifolds</a></li>
</ul></li>
<li><a href="#sec:orgec9f688" id="toc-sec:orgec9f688">Some review of
differential equations<span id="sec:diffeq"
label="sec:diffeq"></span></a></li>
<li><a href="#sec:orgaef96e9" id="toc-sec:orgaef96e9">Some review of
group theory</a>
<ul>
<li><a href="#sec:orgd7903af" id="toc-sec:orgd7903af">Basic
definition</a></li>
<li><a href="#sec:orgcf966cd" id="toc-sec:orgcf966cd">Permutation
groups</a></li>
<li><a href="#sec:orgaff9727" id="toc-sec:orgaff9727">Topological
groups</a></li>
</ul></li>
<li><a href="#sec:org66cd91a" id="toc-sec:org66cd91a">Some review of
functional analysis</a>
<ul>
<li><a href="#sec:org3082d00" id="toc-sec:org3082d00">Definitions and
elementary properties of operators on Hilbert spaces</a></li>
<li><a href="#sec:org816b98f" id="toc-sec:org816b98f">Compact
self-adjoint operators on nonzero Hilbert spaces have
eigenvectors</a></li>
<li><a href="#sec:orgaec3806" id="toc-sec:orgaec3806">Spectral theorem
for compact self-adjoint operators on a Hilbert space</a></li>
<li><a href="#sec:org14df4a0" id="toc-sec:org14df4a0">Basics on matrix
coefficients</a></li>
<li><a href="#sec:org39a802e" id="toc-sec:org39a802e">Finite functions
on a compact group are dense<span id="sec:finite-functions-dense"
label="sec:finite-functions-dense"></span></a></li>
<li><a href="#sec:orga60f514" id="toc-sec:orga60f514">Schur
orthogonality relations</a></li>
<li><a href="#sec:org9fd6b0d" id="toc-sec:org9fd6b0d">Peter–Weyl
theorem</a></li>
</ul></li>
<li><a href="#sec:org22598a8" id="toc-sec:org22598a8">Some facts
concerning invariant measures<span id="sec:inv-measures"
label="sec:inv-measures"></span></a>
<ul>
<li><a href="#sec:org171fce1" id="toc-sec:org171fce1">Definition of Haar
measures</a></li>
<li><a href="#sec:orga3b0a45" id="toc-sec:orga3b0a45">Existence
theorem</a></li>
<li><a href="#sec:org720d559" id="toc-sec:org720d559">Unimodularity of
compact groups</a></li>
<li><a href="#sec:orgb26c793" id="toc-sec:orgb26c793">Direct
construction for Lie groups<span id="sec:inv-measure-lie"
label="sec:inv-measure-lie"></span></a></li>
<li><a href="#sec:org02a337d" id="toc-sec:org02a337d">Some
exercises</a></li>
<li><a href="#sec:org0bc8f8b" id="toc-sec:org0bc8f8b">Construction of a
Haar measure on a compact group via averaging<span
id="sec:haar-compact-gp-via-avg"
label="sec:haar-compact-gp-via-avg"></span></a></li>
</ul></li>
<li><a href="#sec:orgfa95dc3" id="toc-sec:orgfa95dc3">Definition and
basic properties of Lie groups</a>
<ul>
<li><a href="#sec:org11b4fd5" id="toc-sec:org11b4fd5">Lie groups:
definition</a></li>
<li><a href="#sec:org7a9cd32" id="toc-sec:org7a9cd32">Basic
examples</a></li>
<li><a href="#sec:orgc7b7f1f" id="toc-sec:orgc7b7f1f">Lie subgroups:
definition</a></li>
<li><a href="#sec:orgd63ace1" id="toc-sec:orgd63ace1">A handy criterion
for being a Lie subgroup</a></li>
<li><a href="#sec:orgc0ef6df" id="toc-sec:orgc0ef6df">Lie subgroups are
closed<span id="sec:lie-subgroups-are-closed"
label="sec:lie-subgroups-are-closed"></span></a></li>
<li><a href="#sec:org89c17c6" id="toc-sec:org89c17c6">Translation of
tangent spaces by group elements<span
id="sec:translate-tangent-spaces-gp-elts"
label="sec:translate-tangent-spaces-gp-elts"></span></a></li>
</ul></li>
<li><a href="#sec:orgf603676" id="toc-sec:orgf603676">The connected
component</a>
<ul>
<li><a href="#sec:org948d2a7"
id="toc-sec:org948d2a7">Generalities</a></li>
<li><a href="#sec:orgdc3e70e" id="toc-sec:orgdc3e70e">Some examples<span
id="sec:connectedness-examples"
label="sec:connectedness-examples"></span></a></li>
<li><a href="#sec:orga8ac11a" id="toc-sec:orga8ac11a">Connectedness of
<span class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span></a></li>
</ul></li>
<li><a href="#sec:org77618cc" id="toc-sec:org77618cc">Basics on the
exponential map<span id="sec:exp-map" label="sec:exp-map"></span></a>
<ul>
<li><a href="#sec:orgd602cac" id="toc-sec:orgd602cac">Review of the
matrix exponential<span id="sec:matrix-exp"
label="sec:matrix-exp"></span></a></li>
<li><a href="#sec:org964bb98" id="toc-sec:org964bb98">One-parameter
subgroups<span id="sec:one-param-subgps"
label="sec:one-param-subgps"></span></a></li>
<li><a href="#sec:org1d85865" id="toc-sec:org1d85865">Definition and
basic properties of exponential map</a></li>
<li><a href="#sec:org4b91333" id="toc-sec:org4b91333">Application to
detecting invariance by a connected Lie group<span
id="sec:appl-inv-by-connected"
label="sec:appl-inv-by-connected"></span></a></li>
<li><a href="#sec:org51d5203" id="toc-sec:org51d5203">Connected Lie
subgroups are determined by their Lie algebras</a></li>
<li><a href="#sec:org45e312b" id="toc-sec:org45e312b">The exponential
map commutes with morphisms<span id="sec:exp-commutes-with-morphisms"
label="sec:exp-commutes-with-morphisms"></span></a></li>
<li><a href="#sec:org84c10f5" id="toc-sec:org84c10f5">Morphisms out of a
connected Lie group are determined by their differentials</a></li>
</ul></li>
<li><a href="#sec:org03a946d" id="toc-sec:org03a946d">Putting the
“algebra” in “Lie algebra”</a>
<ul>
<li><a href="#sec:org3a6e4da" id="toc-sec:org3a6e4da">The commutator of
small group elements</a></li>
<li><a href="#sec:org166886b" id="toc-sec:org166886b">The Lie bracket as
an infinitesimal commutator</a></li>
<li><a href="#sec:org0f4ac0a" id="toc-sec:org0f4ac0a">Lie
algebras</a></li>
<li><a href="#sec:org96fd5c4" id="toc-sec:org96fd5c4">The Lie bracket
commutes with differentials of morphisms<span
id="sec:diff-morphism-is-morphism"
label="sec:diff-morphism-is-morphism"></span></a></li>
</ul></li>
<li><a href="#sec:org7275cd0" id="toc-sec:org7275cd0">How pretend that
every Lie group is a matrix group and survive<span
id="sec:pretend-lie-groups-are-matrix-groups"
label="sec:pretend-lie-groups-are-matrix-groups"></span></a></li>
<li><a href="#sec:orgf4f0402" id="toc-sec:orgf4f0402">Something about
representations, mostly <span
class="math inline">\({\mathop{\mathrm{SL}}}_2\)</span></a>
<ul>
<li><a href="#sec:org2880980" id="toc-sec:org2880980">Some
preliminaries</a></li>
<li><a href="#sec:org959bbb9"
id="toc-sec:org959bbb9">Definition</a></li>
<li><a href="#sec:org601ff7d" id="toc-sec:org601ff7d">Matrix
multiplication</a></li>
<li><a href="#sec:orgfac8ca7" id="toc-sec:orgfac8ca7">Invariant
subspaces and irreducibility<span id="sec:stability-subspaces"
label="sec:stability-subspaces"></span></a></li>
<li><a href="#sec:orgb2dd983" id="toc-sec:orgb2dd983">Polynomial
representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span></a></li>
<li><a href="#sec:orgbd19a70" id="toc-sec:orgbd19a70">Classifying
finite-dimensional irreducible representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span></a></li>
<li><a href="#sec:orgf4dbdd0" id="toc-sec:orgf4dbdd0">Complete
reducibility<span id="sec:compl-red"
label="sec:compl-red"></span></a></li>
<li><a href="#sec:org7d9bd5a" id="toc-sec:org7d9bd5a">Linear reductivity
of compact groups<span id="sec:linear-reductivity-compact-groups"
label="sec:linear-reductivity-compact-groups"></span></a></li>
<li><a href="#sec:orgfb8c0e1" id="toc-sec:orgfb8c0e1">Constructing new
representations from old ones</a>
<ul>
<li><a href="#sec:org3c4515a" id="toc-sec:org3c4515a">Direct
sum</a></li>
<li><a href="#sec:orgb0fcad8" id="toc-sec:orgb0fcad8">Tensor
product</a></li>
<li><a href="#sec:org4d627e9" id="toc-sec:org4d627e9">Symmetric power
representations<span id="sec:constructing-sym-power"
label="sec:constructing-sym-power"></span></a></li>
</ul></li>
<li><a href="#sec:orgc5f3d81"
id="toc-sec:orgc5f3d81">Characters</a></li>
</ul></li>
<li><a href="#sec:orgb4bc044" id="toc-sec:orgb4bc044">The unitary
trick<span id="sec:unitary-trick"
label="sec:unitary-trick"></span></a></li>
<li><a href="#sec:orga45c298" id="toc-sec:orga45c298">Ad and ad</a>
<ul>
<li><a href="#sec:org7eda827" id="toc-sec:org7eda827">Basic
definitions</a></li>
<li><a href="#sec:orgeaeefa5" id="toc-sec:orgeaeefa5">Relationship
between <span class="math inline">\(\mathop{\mathrm{Ad}}\)</span> and
<span class="math inline">\(\mathop{\mathrm{ad}}\)</span></a></li>
<li><a href="#sec:orgeedd74d" id="toc-sec:orgeedd74d">Interpretation of
the Jacobi identity</a></li>
<li><a href="#sec:orgcb8cdaf" id="toc-sec:orgcb8cdaf"><span
class="math inline">\(\mathop{\mathrm{Ad}},
\mathop{\mathrm{ad}}\)</span> are intertwined by the exponential
map<span id="sec:Ad-ad-intertwined-exp"
label="sec:Ad-ad-intertwined-exp"></span></a></li>
<li><a href="#sec:orgcb7a112" id="toc-sec:orgcb7a112">Some low-rank
exceptional isomorphisms induced by the adjoint representation<span
id="sec:low-rank-exceptional-isomorphisms"
label="sec:low-rank-exceptional-isomorphisms"></span></a></li>
</ul></li>
<li><a href="#sec:org6e14ee2" id="toc-sec:org6e14ee2">Maurer–Cartan
equations and applications</a>
<ul>
<li><a href="#sec:org61f279c" id="toc-sec:org61f279c">The equations<span
id="sec:cartan-maurer-eqn"
label="sec:cartan-maurer-eqn"></span></a></li>
<li><a href="#sec:org6f964c7" id="toc-sec:org6f964c7">Lifting morphisms
of Lie algebras</a></li>
</ul></li>
<li><a href="#sec:org1f9aec4" id="toc-sec:org1f9aec4">The universal
covering group</a></li>
<li><a href="#sec:org1288635" id="toc-sec:org1288635">Quotients of Lie
groups</a></li>
<li><a href="#sec:org245e5dc" id="toc-sec:org245e5dc">Homotopy exact
sequence</a></li>
<li><a href="#sec:org167c08b" id="toc-sec:org167c08b">Cartan
decomposition<span id="sec:cartan-decmop"
label="sec:cartan-decmop"></span></a></li>
<li><a href="#sec:orgc67fbf4" id="toc-sec:orgc67fbf4">BCHD</a></li>
<li><a href="#sec:orgdccc169" id="toc-sec:orgdccc169">Some more ways to
produce and detect Lie groups</a>
<ul>
<li><a href="#sec:org1d479ae" id="toc-sec:org1d479ae">Summary</a></li>
<li><a href="#sec:orgd737096" id="toc-sec:orgd737096">Closed subgroups
of real Lie groups</a>
<ul>
<li><a href="#sec:org018f0b5" id="toc-sec:org018f0b5">Statement of the
key result</a></li>
<li><a href="#sec:org3cf56ab" id="toc-sec:org3cf56ab">A toy
example</a></li>
<li><a href="#sec:org5574bc9" id="toc-sec:org5574bc9">Proof of the key
result</a></li>
</ul></li>
<li><a href="#sec:orgca48d81" id="toc-sec:orgca48d81">Stabilizers<span
id="sec:detect-lie-stabilizers"
label="sec:detect-lie-stabilizers"></span></a>
<ul>
<li><a href="#sec:org9ced8a6" id="toc-sec:org9ced8a6">The basic
result<span id="sec:stab-basic-result"
label="sec:stab-basic-result"></span></a></li>
<li><a href="#sec:org93667ef" id="toc-sec:org93667ef">Application to
kernels</a></li>
<li><a href="#sec:org79033ad" id="toc-sec:org79033ad">Application to
preimages<span id="sec:stab-appl-preimages"
label="sec:stab-appl-preimages"></span></a></li>
<li><a href="#sec:org60c2f88" id="toc-sec:org60c2f88">Application to
intersections</a></li>
<li><a href="#sec:orgc9b1def" id="toc-sec:orgc9b1def">Application to
stabilizers of vectors or subspaces in representations</a></li>
</ul></li>
<li><a href="#sec:orge98ecbb" id="toc-sec:orge98ecbb">Commutator
subgroups</a></li>
</ul></li>
<li><a href="#sec:org1df5b23" id="toc-sec:org1df5b23">Immersed Lie
subgroups</a></li>
<li><a href="#sec:org0fe80c3" id="toc-sec:org0fe80c3">Simple Lie
groups</a></li>
<li><a href="#sec:org0a0c43a" id="toc-sec:org0a0c43a">Simplicity of the
special linear group<span id="sec:simplicity-sln"
label="sec:simplicity-sln"></span></a>
<ul>
<li><a href="#sec:orge7b7a5c" id="toc-sec:orge7b7a5c">Some linear
algebra<span id="sec:some-lin-alg"
label="sec:some-lin-alg"></span></a></li>
<li><a href="#sec:org77c4374" id="toc-sec:org77c4374">Recap on <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span></a></li>
<li><a href="#sec:org67e3030" id="toc-sec:org67e3030">Reformulation in
terms of representations of abelian Lie algebras</a></li>
<li><a href="#sec:orgccb748c" id="toc-sec:orgccb748c">Roots of an
abelian subalgebra<span id="sec:roots-of-abelian-subalgebra"
label="sec:roots-of-abelian-subalgebra"></span></a></li>
<li><a href="#sec:orgca2a787" id="toc-sec:orgca2a787">The roots of the
special linear Lie algebra<span id="sec:roots-sln"
label="sec:roots-sln"></span></a></li>
<li><a href="#sec:org952f7d3" id="toc-sec:org952f7d3">The simplicity of
<span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span></a></li>
<li><a href="#sec:orgd32f640" id="toc-sec:orgd32f640">The proof given in
lecture</a></li>
</ul></li>
<li><a href="#sec:orgdbcaaaf" id="toc-sec:orgdbcaaaf">Classification of
the classical simple complex Lie algebras<span
id="sec:classify-classical-simple-algebras"
label="sec:classify-classical-simple-algebras"></span></a>
<ul>
<li><a href="#sec:org4260801" id="toc-sec:org4260801">Recap<span
id="sec:recap-classification-includes-better-defn-of-orthogonal-gp"
label="sec:recap-classification-includes-better-defn-of-orthogonal-gp"></span></a></li>
<li><a href="#sec:org617bb1c" id="toc-sec:org617bb1c">Classical simple
complex Lie algebras</a></li>
<li><a href="#sec:orgaf78e16" id="toc-sec:orgaf78e16">How to classify
them (without worrying about why it works)<span id="sec:how-to-classify"
label="sec:how-to-classify"></span></a></li>
<li><a href="#sec:orga54764a" id="toc-sec:orga54764a">Dynkin diagrams of
classical simple Lie algebras<span
id="sec:dynkin-diagrams-classical-examples"
label="sec:dynkin-diagrams-classical-examples"></span></a></li>
<li><a href="#sec:org395e74a" id="toc-sec:org395e74a">Classical algebras
come with faithful representations and are cut out by
anti-involutions<span id="sec:classical-action"
label="sec:classical-action"></span></a></li>
<li><a href="#sec:org67896e3" id="toc-sec:org67896e3">Diagonalization in
classical Lie algebras<span id="sec:classical-lie-alg-diagonalization"
label="sec:classical-lie-alg-diagonalization"></span></a></li>
<li><a href="#sec:org00974ae" id="toc-sec:org00974ae">Semisimplicity of
elements of classical Lie algebras</a></li>
<li><a href="#sec:orgf4e7f31" id="toc-sec:orgf4e7f31">Conjugacy of
Cartan subalgebras</a></li>
<li><a href="#sec:org8b90669" id="toc-sec:org8b90669">Interpretation of
Cartan matrix in terms of inner products<span
id="sec:cartan-via-inner-products"
label="sec:cartan-via-inner-products"></span></a></li>
<li><a href="#sec:orgecfb737" id="toc-sec:orgecfb737">Independence with
respect to the choice of simple system</a></li>
</ul></li>
<li><a href="#sec:orgbc4b3b3" id="toc-sec:orgbc4b3b3">Why simple Lie
algebras give rise to root systems</a>
<ul>
<li><a href="#sec:orgca704ad" id="toc-sec:orgca704ad">Overview<span
id="sec:overview:simple-lie-alg-induce-root-systems"
label="sec:overview:simple-lie-alg-induce-root-systems"></span></a></li>
<li><a href="#sec:org60618cb" id="toc-sec:org60618cb">The basic theorem
on Cartan subalgebras</a></li>
<li><a href="#sec:orgc2613cc" id="toc-sec:orgc2613cc">Abstract root
systems</a></li>
<li><a href="#sec:org44a29a8" id="toc-sec:org44a29a8">Illustration of
the root system axioms</a></li>
<li><a href="#sec:orgfacc967" id="toc-sec:orgfacc967">Simple Lie
algebras give rise to root systems<span
id="sec:simple-lie-alg-give-roots"
label="sec:simple-lie-alg-give-roots"></span></a></li>
<li><a href="#sec:org3ce571d" id="toc-sec:org3ce571d">Some stuff about
scalar products and inner products<span
id="sec:some-stuff-about-scalar-products"
label="sec:some-stuff-about-scalar-products"></span></a></li>
<li><a href="#sec:org573a7f4" id="toc-sec:org573a7f4">Some recap on
<span class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span></a></li>
<li><a href="#sec:orgfd608b2" id="toc-sec:orgfd608b2">Proof of Theorem
233</a></li>
</ul></li>
<li><a href="#sec:org96d3081" id="toc-sec:org96d3081">Serre relations
and applications</a>
<ul>
<li><a href="#sec:orgd6370a3" id="toc-sec:orgd6370a3">Generators and
relations for simple complex Lie algebras</a></li>
<li><a href="#sec:org051a3bb" id="toc-sec:org051a3bb">Semisimple complex
Lie algebras</a></li>
<li><a href="#sec:orgdfba908" id="toc-sec:orgdfba908">Reductive complex
Lie algebras</a></li>
<li><a href="#sec:orgdfd4c01" id="toc-sec:orgdfd4c01">Compact complex
Lie groups</a></li>
<li><a href="#sec:orgc85f06b" id="toc-sec:orgc85f06b">Compact real Lie
algebras</a></li>
<li><a href="#sec:org00eed09" id="toc-sec:org00eed09">Complex reductive
vs. compact real Lie algebras</a></li>
</ul></li>
<li><a href="#sec:orge2e02c5" id="toc-sec:orge2e02c5">The center and
fundamental group of a compact Lie group<span
id="sec:center-pi1-compact"
label="sec:center-pi1-compact"></span></a></li>
<li><a href="#sec:orga4a1522" id="toc-sec:orga4a1522">Tori in compact
Lie groups<span id="sec:tori-compact-lie-gps"
label="sec:tori-compact-lie-gps"></span></a>
<ul>
<li><a href="#sec:org2b9a950" id="toc-sec:org2b9a950">Basic
definitions</a></li>
<li><a href="#sec:org56989a6" id="toc-sec:org56989a6">Characters of
tori</a></li>
<li><a href="#sec:org00a6b97" id="toc-sec:org00a6b97">Topologies on
character groups<span id="sec:tops-on-char-gps"
label="sec:tops-on-char-gps"></span></a></li>
<li><a href="#sec:org1044d7f" id="toc-sec:org1044d7f">Maximal tori give
rise to Cartan subalgebras</a></li>
<li><a href="#sec:org822bc0f" id="toc-sec:org822bc0f">Some notation
involving roots<span
id="sec:notationinvolvingroots-for-amxl-tori-section"
label="sec:notationinvolvingroots-for-amxl-tori-section"></span></a></li>
<li><a href="#sec:orgc0705cb" id="toc-sec:orgc0705cb">The automorphism
group of a compact torus<span id="sec:aut-gp-compact-torus"
label="sec:aut-gp-compact-torus"></span></a></li>
<li><a href="#sec:orga53673f" id="toc-sec:orga53673f">Generators<span
id="sec:gens-tori" label="sec:gens-tori"></span></a></li>
<li><a href="#sec:org8429097" id="toc-sec:org8429097">A maximal torus is
the connected component of its normalizer</a></li>
<li><a href="#sec:orgb02c776" id="toc-sec:orgb02c776">Conjugacy of
maximal tori</a></li>
<li><a href="#sec:org3dd568d" id="toc-sec:org3dd568d">Basic consequences
of the conjugacy theorem.</a></li>
</ul></li>
<li><a href="#sec:orgf4996f8" id="toc-sec:orgf4996f8">Regular and
singular elements</a>
<ul>
<li><a href="#sec:orgedf2662" id="toc-sec:orgedf2662">Definitions and
basic properties</a></li>
<li><a href="#sec:org776dd5b" id="toc-sec:org776dd5b">Singular elements
have codimension at least three</a></li>
<li><a href="#sec:org8a0ef0a" id="toc-sec:org8a0ef0a">The key covering
morphism<span id="sec:key-cov-morph"
label="sec:key-cov-morph"></span></a></li>
<li><a href="#sec:org8dfce1f" id="toc-sec:org8dfce1f">The affine Weyl
group and the components of the set of regular elements<span
id="sec:affine-weyl-gp" label="sec:affine-weyl-gp"></span></a></li>
</ul></li>
<li><a href="#sec:org25cd375" id="toc-sec:org25cd375">The distinguished
<span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>’s<span
id="sec:distinguished-su2"
label="sec:distinguished-su2"></span></a></li>
<li><a href="#sec:org1822737" id="toc-sec:org1822737">Proofs regarding
the basic homomorphism describnig fundamental groups of compact Lie
groups</a>
<ul>
<li><a href="#sec:org1514b4c"
id="toc-sec:org1514b4c">Definition</a></li>
<li><a href="#sec:orgddabaf2" id="toc-sec:orgddabaf2">The basic
homomorphism: checking that it’s a homomorphism</a></li>
<li><a href="#sec:org9527204" id="toc-sec:org9527204">Checking that some
stuff is in its kernel</a></li>
<li><a href="#sec:orgea26b3f" id="toc-sec:orgea26b3f">The basic
homomorphism: checking that it’s surjective</a></li>
<li><a href="#sec:org8c8e428" id="toc-sec:org8c8e428">The basic
homomorphism: pinning down the kernel</a></li>
</ul></li>
</ul>
</nav>
<h1 id="sec:org8827c4a">§1. Disclaimers<span id="sec:disclaimers"
label="sec:disclaimers"></span></h1>
<p>The notes recorded here are intended to <em>supplement</em> the
lectures, but I have included more material here than is necessary for
the course. You are <em>not</em> expected to read these notes, but I
hope that providing them as a reference may be helpful. For example,
although I have recorded here a fair bit of background from differential
geometry, it should not be necessary for the purposes of the course.</p>
<p>A principal aim of the lectures is that after attending them, you
should be able to do the homework problems given below their
summaries.</p>
<p>It is very likely that the notes and exercises will contain some
mistakes; any corrections would be much appreciated.</p>
<h1 id="sec:orgeacc8f6">§2. Summary of classes and homework assignments</h1>
<h2 id="sec:org5df22f0">§2.1. 9/20: The definition of a Lie group</h2>
<p><strong>Objectives.</strong> You should be able to explain the
definition of "Lie group" and to prove that basic examples (e.g.,
orthogonal groups) are in fact Lie groups.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>review of one-variable calculus and how it relates global
properties of functions (e.g., monotonicity) to infinitesimal ones
(e.g., positivity of derivative)</p></li>
<li><p>review of multivariable calculus:</p>
<ol>
<li><p>partial and total derivatives of a function</p></li>
<li><p>inverse function theorem</p></li>
<li><p>implicit function theorem</p></li>
</ol></li>
<li><p>very brief review of differential geometry:</p>
<ol>
<li><p>the definition of submanifolds of open subsets of Euclidean
spaces</p></li>
<li><p>how (in practice) to check that a subset is a
submanifold</p></li>
<li><p>how (in practice) to compute tangent spaces of
submanifolds</p></li>
<li><p>immersions, embeddings, submersions</p></li>
</ol></li>
<li><p>review of group theory:</p>
<ol>
<li><p>functorial definition of "group" in terms of multiplication and
inversion maps</p></li>
<li><p>permutation groups; Cayley’s theorem</p></li>
<li><p>definition of topological group</p></li>
</ol></li>
<li><p>basic Lie-theoretic definitions:</p>
<ol>
<li><p>Lie group (without recalling what a "manifold" is, other than to
note that open subsets of Euclidean space and submanifolds thereof are
examples of manifolds)</p></li>
<li><p>Lie subgroup</p></li>
<li><p>immersed Lie subgroup (e.g., irrational winding of the
2-torus)</p></li>
<li><p>the Lie algebra of a Lie group (without justifying the "algebra"
in "Lie algebra")</p></li>
<li><p>linear Lie group</p></li>
</ol></li>
<li><p>how to compute Lie algebras of Lie groups in practice; examples
of <span class="math inline">\({\mathop{\mathrm{GL}}}_n,
{\mathop{\mathrm{SL}}}_n, O_n\)</span></p></li>
</ol>
<div class="homework">
<p><strong>Homework 1</strong> (Due Oct 4). Write down the definitions
of “Lie group” and “Lie subgroup”. Using some lemmas from class, prove
that <span class="math inline">\(\operatorname{O}(n) := \{g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{R}) : g g^t = 1\}\)</span> is a Lie
subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span> of
dimension <span class="math inline">\(n(n-1)/2\)</span> with Lie algebra
<span class="math inline">\(\mathfrak{o}(n) :=
\mathop{\mathrm{Lie}}(\operatorname{O}(n))\)</span> given by the space
<span class="math inline">\(\{ X \in M_n(\mathbb{R}) : X + X^t = 0
\}\)</span> of skew-symmetric matrices.</p>
</div>
<h2 id="sec:org254d9af">§2.2. 9/22: The connected component</h2>
<p><strong>Objectives.</strong> You should be able to define the
"connected component" of a Lie group, explain its importance, and
determine it in some basic examples (such as linear, orthogonal or
unitary groups).</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>review of the general topological notion of connected components
of a topological space, and how it specializes when the space is a
manifold</p></li>
<li><p>basics on the connected component of the identity <span
class="math inline">\(G^0\)</span> in a Lie group <span
class="math inline">\(G\)</span>:</p>
<ol>
<li><p>it is a normal Lie subgroup whose cosets are the connected
components of <span class="math inline">\(G\)</span></p></li>
<li><p><span class="math inline">\(G^0\)</span> (and more generally, any
connected topological group) is generated by any neighborhood of the
identity</p></li>
</ol></li>
<li><p>most of the classical groups were introduced and their number of
connected components described, with some cases proved (<span
class="math inline">\({\mathop{\mathrm{SL}}}_n, {\mathop{\mathrm{GL}}}_n,
\operatorname{O}(n), \mathop{\mathrm{SO}}(n),
\mathop{\mathrm{U}}(n)\)</span>) and others left as exercises (<span
class="math inline">\(\operatorname{O}(p,q)\)</span>, …); a large part
of the class consisted of filling in and explaining the entries in the
three-column table depicted in §<a href="#sec:connectedness-examples"
data-reference-type="ref"
data-reference="sec:connectedness-examples">12.2</a></p></li>
<li><p>review on the matrix exponential, as in §<a
href="#sec:matrix-exp" data-reference-type="ref"
data-reference="sec:matrix-exp">13.1</a></p></li>
</ol>
<div id="hw:2" class="homework">
<p><strong>Homework 2</strong> (Due Oct 4). Let <span
class="math inline">\(p, q \geq 1\)</span> and <span
class="math inline">\(n := p + q\)</span>. Recall that <span
class="math display">\[\begin{align}
    \operatorname{O}(p,q) &amp;:= \{g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{R}) : Q(g v) = Q(v)
              \text{ for all } v \in \mathbb{R}^n\} \\
            &amp;=
              \{g \in {\mathop{\mathrm{GL}}}_n(\mathbb{R}): g^t J g = J
\},
  
\end{align}\]</span> where <span class="math inline">\(Q(v) := v_1^2 +
\dotsb + v_p^2 - v_{p+1}^2 - \dotsb - v_n^2\)</span> and <span
class="math inline">\(J :=
\mathop{\mathrm{diag}}(1,\dotsc,1,-1,\dotsc,-1)\)</span>, and that <span
class="math inline">\(\mathop{\mathrm{SO}}(p,q) :=
{\mathop{\mathrm{SL}}}_n(\mathbb{R}) \cap \operatorname{O}(p,q)\)</span>.
For <span class="math inline">\(a \in \mathbb{R}\)</span>, set <span
class="math inline">\(V_a := \{v \in \mathbb{R}^n : Q(v) = a\}\)</span>.
Denote by <span class="math inline">\(e_1,\dotsc,e_n\)</span> the
standard basis vectors for <span
class="math inline">\(\mathbb{R}^n\)</span>.</p>
<ol>
<li><p>Suppose <span class="math inline">\(p = q = 1\)</span>, so that
<span class="math inline">\(n = 2\)</span>.</p>
<ol>
<li><p>Show that every matrix of the form <span id="eq:elements-o-1-1" class="math display">\[\label{eq:elements-o-1-1}\tag{1}
        g =
        \begin{pmatrix}
          \varepsilon_1 &amp;  \\
                 &amp; \varepsilon_2
        \end{pmatrix}
        \begin{pmatrix}
          \cosh(t) &amp; \sinh(t) \\
          \sinh(t) &amp; \cosh(t)
        \end{pmatrix}\]</span> with <span
class="math inline">\(\varepsilon_1,\varepsilon_2 \in \{\pm
1\}\)</span>, <span class="math inline">\(t \in \mathbb{R}\)</span>
belongs to <span class="math inline">\(\operatorname{O}(1,1)\)</span>.
Show that <span class="math display">\[\begin{pmatrix}
          \cosh(t) &amp; \sinh(t) \\
          \sinh(t) &amp; \cosh(t)
        \end{pmatrix}
        = \exp (t
\begin{pmatrix}
          0 &amp; 1 \\
          1 &amp; 0
        \end{pmatrix}
).\]</span> Show that if <span class="math inline">\(\varepsilon_1 =
\varepsilon_2 = 1\)</span>, then <span class="math inline">\(g \in
\operatorname{O}(1,1)^0\)</span>.</p></li>
<li><p>Show that for each <span class="math inline">\(v \in V_1\)</span>
with <span class="math inline">\(v_1 &gt; 0\)</span> there is an element
<span class="math inline">\(g \in \operatorname{O}(1,1)^0\)</span> so
that <span class="math inline">\(g e_1 = v\)</span>.</p></li>
<li><p>Show that every <span class="math inline">\(g \in
\operatorname{O}(1,1)\)</span> with <span class="math inline">\(g e_1 =
e_1\)</span> is of the form <a href="#eq:elements-o-1-1"
data-reference-type="eqref"
data-reference="eq:elements-o-1-1">\((1)\)</a> with <span
class="math inline">\(\varepsilon_1 = 1, \varepsilon_2 = \pm 1\)</span>
and <span class="math inline">\(t = 0\)</span>.</p></li>
<li><p>Show for <span class="math inline">\(a = \pm 1\)</span> that the
space <span class="math inline">\(V_a\)</span> has two connected
components and that <span
class="math inline">\(\operatorname{O}(1,1)\)</span> acts transitively
on <span class="math inline">\(V_a\)</span>. Determine the orbit of
<span class="math inline">\(e_1\)</span> under <span
class="math inline">\(\mathop{\mathrm{SO}}(1,1)\)</span>.</p></li>
<li><p>Using some of the previous steps (or direct calculation), show
that every element of <span
class="math inline">\(\operatorname{O}(1,1)\)</span> is of the form <a
href="#eq:elements-o-1-1" data-reference-type="eqref"
data-reference="eq:elements-o-1-1">\((1)\)</a> and that
<span class="math inline">\(\operatorname{O}(1,1)\)</span> has four
connected components.</p></li>
</ol></li>
<li><p>Suppose now that <span class="math inline">\(p = 1, q = 2, n =
3\)</span>.</p>
<ol>
<li><p>Observe (by drawing a picture, say) that <span
class="math inline">\(V_{-1}\)</span> is connected, that <span
class="math inline">\(V_{1}\)</span> has two connected components, and
that <span class="math inline">\(e_1 \in V_{1}\)</span>. Denote by <span
class="math inline">\(V_{1}^0\)</span> the connected component of <span
class="math inline">\(V_{1}\)</span> containing <span
class="math inline">\(e_1\)</span>. Show that for each <span
class="math inline">\(v \in V_{1}^0\)</span> there exists an <span
class="math inline">\(h \in \mathop{\mathrm{SO}}(1,2)^0\)</span> so that
<span class="math inline">\(h v = e_1\)</span>. [Hint: one can reduce to
part (b) of the previous exercise.]</p></li>
<li><p>Show that the stabilizer of <span
class="math inline">\(e_1\)</span> in <span
class="math inline">\(\mathop{\mathrm{SO}}(1,2)\)</span> is isomorphic
to <span class="math inline">\(\mathop{\mathrm{SO}}(2)\)</span>, hence
is connected.</p></li>
<li><p>Show that any <span class="math inline">\(g \in
\mathop{\mathrm{SO}}(1,2)\)</span> for which <span
class="math inline">\(g e_1 \in V_{1}^0\)</span> belongs to the
connected component <span
class="math inline">\(\mathop{\mathrm{SO}}(1,2)^0\)</span>.</p></li>
<li><p>Deduce that <span
class="math inline">\(\mathop{\mathrm{SO}}(1,2)\)</span> has two
connected components.</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:orge89327d">§2.3. 9/27: One-parameter subgroups and the
exponential map</h2>
<p><strong>Objectives.</strong> You should be able to define
one-parameter subgroups and apply their basic uniqueness theorem. You
should be able to define and characterize the exponential map on a Lie
group in a few different ways, and be able to apply these
characterizations. You should be able to apply the exponential map to
relate global symmetries to infinitesimal ones (as in the example from
lecture or the homework problem below). You should be able to apply the
fact that the image of the exponential map contains a neighborhood of
the identity, which in turn generates the connected component.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>Review of the matrix exponential and its various
characterizations:</p>
<ol>
<li><p>as a series <span class="math inline">\(\exp(X) = \sum
X^n/n!\)</span></p></li>
<li><p>as a limit <span class="math inline">\(\exp(X) = \lim (1 +
X/n)^n\)</span>, or more generally, <span class="math inline">\(\exp(X)
= \lim \gamma(1/n)^n\)</span> for any curve with basepoint <span
class="math inline">\(\gamma(0) = 1\)</span> and initial velocity <span
class="math inline">\(\gamma&#39;(0) = X\)</span></p></li>
<li><p>by requiring that for each <span
class="math inline">\(X\)</span>, the function <span
class="math inline">\(\Phi_X(t) = \exp(t X)\)</span> is the unique
solution to the ODE <span class="math inline">\(\Phi&#39;(t) = X
\Phi(t)\)</span> with initial condition <span
class="math inline">\(\Phi(0) = 1\)</span></p></li>
<li><p>by requiring that for each <span
class="math inline">\(X\)</span>, the function <span
class="math inline">\(\Phi_X(t)\)</span> as above is the unique smooth
group homomorphism with initial velocity <span
class="math inline">\(\Phi_X&#39;(0) = X\)</span>.</p></li>
</ol></li>
<li><p>We explained how the above generalizes to any Lie group. The key
was the existence/uniqueness of one-parameter subgroups.</p>
<ol>
<li><p>The uniqueness was reduced to uniqueness theorems for
ODE’s.</p></li>
<li><p>We gave a direct proof of the existence of one-parameter
subgroups for <span
class="math inline">\({\mathop{\mathrm{GL}}}_n\)</span>, deduced it for
linear Lie groups via the second characterization above, and indicated
how it follows for general <span class="math inline">\(G\)</span> by
solving some ODE’s and extending their solutions.</p></li>
</ol></li>
<li><p>As a basic application we explained how to characterize the
rotation-invariant functions on <span
class="math inline">\(\mathbb{R}^n\)</span> as the solutions to a finite
system of homogeneous linear differential equations.</p></li>
</ol>
<div id="hw:3-lie-first" class="homework">
<p><strong>Homework 3</strong> (Due Oct 4).  </p>
<ol>
<li><p>Use Lie’s first theorem (Theorem <a href="#thm:exp-local-diffeo"
data-reference-type="ref" data-reference="thm:exp-local-diffeo">81</a>)
and the results of Homework <a href="#hw:2" data-reference-type="ref"
data-reference="hw:2">2</a> to show that the following are equivalent
for a smooth function <span class="math inline">\(f : \mathbb{R}^3
\rightarrow \mathbb{R}\)</span>:</p>
<ol>
<li><p><span class="math inline">\(f\)</span> is constant on each
connected component of <span class="math inline">\(\{(x,y,z) \in
\mathbb{R}^3 : z^2 - x^2 - y^2 = 1\}\)</span>.</p></li>
<li><p><span class="math inline">\(f\)</span> satisfies the differential
equations <span class="math display">\[x \frac{\partial f }{\partial y }
- y \frac{\partial f}{ \partial x} = 0,\]</span> <span
class="math display">\[z \frac{\partial f }{\partial x } + x
\frac{\partial f}{ \partial z} = 0,\]</span> <span
class="math display">\[z \frac{\partial f }{\partial y } + y
\frac{\partial f}{ \partial z} = 0\]</span> on <span
class="math inline">\(\{(x,y,z) \in \mathbb{R}^3 : z^2 - x^2 - y^2 =
1\}\)</span>.</p></li>
</ol></li>
<li><p>Let <span class="math inline">\(G\)</span> be a topological group
and <span class="math inline">\(H \leq G\)</span> a subgroup with the
property that there is a neighborhood <span
class="math inline">\(U\)</span> in <span
class="math inline">\(G\)</span> of the identity element so that <span
class="math inline">\(U \cap H = \{1\}\)</span>. Show that <span
class="math inline">\(H\)</span> is a discrete subgroup of <span
class="math inline">\(G\)</span>.</p></li>
<li><p>Let <span class="math inline">\(G\)</span> be a connected
commutative Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Show that <span
class="math inline">\(\exp : \mathfrak{g} \rightarrow G\)</span> is a
surjective homomorphism and with discrete kernel.</p></li>
</ol>
</div>
<h2 id="sec:org102c8ed">§2.4. 9/29: The Lie algebra of a Lie group</h2>
<p><strong>Objectives.</strong> You should be able to explain how the
Lie bracket arises as an infinitesimal commutator of group elements. You
should be able to explain the meaning of the sentence "the differential
of a morphism of Lie groups is a morphism of Lie algebras"; in
particular, you should be able to define all of its terms. Given a
fairly explicit morphism of Lie groups (such as the representations on
polynomials discussed in lecture or in the homework below), you should
be able to compute the induced infinitesimal action of the Lie
algebra.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>tying up loose ends on application of exponential map:</p>
<ol>
<li><p>connected Lie subgroups are determined by their Lie
algebras</p></li>
<li><p>the exponential map intertwines morphisms of Lie groups with
their differentials</p></li>
<li><p>morphisms of Lie groups with connected domain are characterized
by their differentials</p></li>
</ol></li>
<li><p>the commutator of infinitesimal elements on the general linear
group compared with the commutator bracket <span
class="math inline">\([X,Y] := X Y - Y X\)</span> on the matrix algebra;
generalization to arbitrary Lie groups</p></li>
<li><p>definition of Lie algebra and morphism of Lie algebra</p></li>
<li><p>examples of Lie algebras:</p>
<ol>
<li><p><span class="math inline">\(\mathop{\mathrm{Lie}}(G)\)</span> for
<span class="math inline">\(G\)</span> a Lie group</p></li>
<li><p><span class="math inline">\(\mathop{\mathrm{End}}(V)\)</span> for
<span class="math inline">\(V\)</span> a vector space</p></li>
<li><p><span class="math inline">\(\mathop{\mathrm{Der}}(A)\)</span> for
<span class="math inline">\(A\)</span> an algebra</p></li>
<li><p><span class="math inline">\(\operatorname{Vect}(M) =
\mathop{\mathrm{Der}}(C^\infty(M))\)</span> for <span
class="math inline">\(M\)</span> a manifold</p></li>
</ol></li>
<li><p>proof that morphisms of Lie groups induce morphisms of Lie
algebras</p></li>
<li><p>definition of a representation of a Lie group, matrix
coefficients with respect to a basis; example involving trigonometric
functions and their addition law</p></li>
</ol>
<div id="hw:sl2-rep-verify-commutator" class="homework">
<p><strong>Homework 4</strong> (Due Oct 4).   Let <span
class="math inline">\(G\)</span> be the Lie group <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>, <span
class="math inline">\(\mathfrak{g} := \mathop{\mathrm{Lie}}(G) =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>, and
let <span class="math inline">\(n\)</span> be a positive integer. Let
<span class="math inline">\(V \leq \mathbb{C}[x,y]\)</span> be the <span
class="math inline">\((n+1)\)</span>-dimensional vector space consisting
of homogeneous polynomials of degree <span
class="math inline">\(n\)</span> in the variables <span
class="math inline">\(x,y\)</span>, so that a basis of <span
class="math inline">\(V\)</span> is given by the set of monomials <span
class="math display">\[\mathcal{B} := \{x^n, x^{n-1} y, \dotsc, x
y^{n-1}, y^n\}.\]</span> Let <span class="math inline">\(R : G
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> be the map given for <span
class="math inline">\(\phi \in V\)</span> by <span
class="math display">\[(R(g) \phi)(x,y) := \phi((x,y) g),\]</span> where
<span class="math inline">\((x,y) g\)</span> denotes matrix
multiplication, so that more explicitly <span class="math display">\[(R(
\begin{pmatrix}
      a &amp; b \\
      c &amp; d
    \end{pmatrix}
)
    \phi)(x,y)
    =
    \phi (a x + c y, b x + d y).\]</span></p>
<ol>
<li><p>Verify that <span class="math inline">\(R\)</span> defines a
representation of <span class="math inline">\(G\)</span> on <span
class="math inline">\(V\)</span>, hence (by a general theorem from
class) that <span class="math inline">\(d R : \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> is a morphism of Lie
algebras.</p></li>
<li><p>Verify that the basis elements <span class="math display">\[H :=
\begin{pmatrix}
        1 &amp; 0 \\
        0 &amp; -1
      \end{pmatrix}
,
      \quad
      X :=
      \begin{pmatrix}
        0 &amp; 1 \\
        0 &amp; 0
      \end{pmatrix}
      \quad Y :=
      \begin{pmatrix}
        0 &amp; 0 \\
        1 &amp; 0
      \end{pmatrix}\]</span> of <span
class="math inline">\(\mathfrak{g}\)</span> satisfy <span
class="math inline">\([X,Y] = H\)</span>.</p></li>
<li><p>Compute the actions of <span class="math inline">\(d R(H), d
R(X), d R(Y)\in \mathop{\mathrm{End}}(V)\)</span> explicitly with
respect to the basis <span class="math inline">\(\mathcal{B}\)</span> of
<span class="math inline">\(V\)</span> and verify directly (without
appeal to the general theorem from class) that <span
class="math inline">\([d R(X), d R(Y)] = d R(H)\)</span>. [See §<a
href="#sec:stability-subspaces" data-reference-type="ref"
data-reference="sec:stability-subspaces">16.4</a>
if the definition of <span class="math inline">\(d R(X)\)</span> is
unclear.]</p></li>
</ol>
</div>
<h2 id="sec:org04627a1">§2.5. 10/4 (half-lecture) and 10/6: Representations of
<span class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span></h2>
<p><strong>Objectives.</strong> You should be able to analyze
(finite-dimensional) representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> by
differentiating them to obtain representations of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>,
breaking the latter up into weight spaces, and studying how the weight
spaces are permuted by raising and lowering operators.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>definition of representations of Lie groups and algebras</p></li>
<li><p>example of polynomial representations of linear Lie groups;
explicit calculation of the induced representation on the Lie
algebra</p></li>
<li><p>discussion of the action of the standard basis of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> on the
$(n+1)$-dimensional representation <span
class="math inline">\(W_n\)</span> from Homework <a
href="#hw:sl2-rep-verify-commutator" data-reference-type="ref"
data-reference="hw:sl2-rep-verify-commutator">4</a></p></li>
<li><p>definition of invariant subspaces, irreducibility</p></li>
<li><p><span class="math inline">\(W_n\)</span> is irreducible</p></li>
<li><p>every irreducible finite-dimensional representation of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> is
isomorphic to some <span class="math inline">\(W_n\)</span></p></li>
</ol>
<div class="homework">
<p><strong>Homework 5</strong> (Due Oct 11).   Let <span
class="math inline">\(G\)</span> be the Lie group <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>. Let
<span class="math inline">\(H,X,Y\)</span> be the basis of <span
class="math inline">\(\mathfrak{g} := \mathop{\mathrm{Lie}}(G)\)</span>
as in Homework <a href="#hw:sl2-rep-verify-commutator"
data-reference-type="ref"
data-reference="hw:sl2-rep-verify-commutator">4</a>.</p>
<ol>
<li><p>For <span class="math inline">\(\lambda \in \mathbb{C}\)</span>,
let <span class="math inline">\(V_\lambda\)</span> be the vector space
with basis <span class="math inline">\((v_k)_{k \in \mathbb{Z}_{\geq
0}}\)</span>. Show that the action <span
class="math display">\[\begin{align}
      H v_k &amp;= (\lambda - 2 k) v_k \\
      X v_k &amp;= k ( \lambda - k + 1) v_{k-1}
              \quad (v_{-1} := 0) \\
      Y v_k &amp;= v_{k+1}
    
\end{align}\]</span> defines a Lie algebra representation <span
class="math inline">\(\mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(V_{\lambda})\)</span>. Determine the invariant
subspaces of <span class="math inline">\(V_\lambda\)</span>.</p></li>
<li><p>Same question, but for the spaces <span
class="math inline">\(U_\nu\)</span> (<span class="math inline">\(\nu
\in \mathbb{C}\)</span>) with basis <span class="math inline">\((v_k)_{k
\in \mathbb{Z}}\)</span> and action <span
class="math display">\[\begin{align}
      H v_k &amp;= 2 k v_k \\
      X v_k &amp;= (\nu + k) v_{k+1} \\
      Y v_k &amp;= (\nu - k) v_{k-1}.
    
\end{align}\]</span></p></li>
<li><p>Let <span class="math inline">\(\mathfrak{b} \leq
\mathfrak{g}\)</span> be the subspace spanned by <span
class="math inline">\(H,X\)</span>. Verify that <span
class="math inline">\(\mathfrak{b}\)</span> is a Lie subalgebra. Let
<span class="math inline">\(\rho : \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> be a finite-dimensional
representation. Show that the following are equivalent for <span
class="math inline">\(v \in V\)</span>:</p>
<ol>
<li><p><span class="math inline">\(v\)</span> is an eigenvector for
every element of <span
class="math inline">\(\mathfrak{b}\)</span>.</p></li>
<li><p><span class="math inline">\(v\)</span> is an eigenvector of <span
class="math inline">\(H\)</span> and satisfies <span
class="math inline">\(X v = 0\)</span>.</p></li>
</ol></li>
<li><p>Let <span class="math inline">\(V\)</span> be a
finite-dimensional representation of <span
class="math inline">\(G\)</span>. Let <span class="math inline">\(v \in
V\)</span> be a nonzero element satisfying <span class="math inline">\(H
v = \lambda v\)</span> for some integer <span
class="math inline">\(\lambda \in \mathbb{Z}\)</span>. Define <span
class="math inline">\(v&#39; \in V\)</span> by <span
class="math display">\[v&#39; :=
      \begin{cases}
        Y^\lambda v &amp; \lambda \geq 0
        \\
        X^{-\lambda} v &amp; \lambda \leq 0.
      \end{cases}\]</span></p>
<ol>
<li><p>Verify that <span class="math inline">\(H v&#39; = - \lambda
v&#39;\)</span>.</p></li>
<li><p>Prove that <span class="math inline">\(v&#39; \neq 0\)</span>.
[Hint: Use the classification theorem for <span
class="math inline">\(V\)</span> proved in lecture.]</p></li>
</ol></li>
<li><p>(Optional) The <span class="math inline">\(n\)</span>th Legendre
polynomial <span class="math inline">\(P_n\)</span> may be defined
(perhaps up to a sign) by <span class="math display">\[P_n(x) :=
\sum_{k=0}^n {\binom{n}{k}}^2 \left( \frac{x-1}{2} \right)^{n-k} \left(
\frac{x+1}{2} \right)^{k}.\]</span> The purpose of the exercise is to
establish the formula <span id="eq:legendre-composition" class="math display">\[\label{eq:legendre-composition}\tag{2}
      P_n(\cos \theta_1) P_n(\cos \theta_2)
      = \int_{\phi = -\pi}^{\pi}
      P_n(\cos(\theta_1) \cos(\theta_2) - \sin(\theta_2)
      \sin(\theta_2) \cos(\phi))
      \,
      \frac{d \phi }{2 \pi }.\]</span> The geometric interpretation of
the argument in the integrand is that if one fixes a point <span
class="math inline">\(O \in S^2\)</span> at spherical distance <span
class="math inline">\(\theta_1\)</span> from the north pole <span
class="math inline">\(N\)</span>, then <span
class="math inline">\(\cos(\theta_1) \cos(\theta_2) - \sin(\theta_2)
\sin(\theta_2) \cos(\phi)\)</span> is the vertical coordinate of the
point <span class="math inline">\(P \in S^2\)</span> at spherical
distance <span class="math inline">\(\theta_2\)</span> from <span
class="math inline">\(O\)</span> for which the angle between the arcs
<span class="math inline">\(O N\)</span> and <span
class="math inline">\(O P\)</span> is <span
class="math inline">\(\phi\)</span>. [You might wish first to attempt to
prove <a href="#eq:legendre-composition" data-reference-type="eqref"
data-reference="eq:legendre-composition">\((2)\)</a>
directly.]</p>
<ol>
<li><p>Let <span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> be the <span class="math inline">\((2
n+1)\)</span>-dimensional representation <span class="math inline">\(V
:= W_{2 n}\)</span> defined in the lectures. Let <span
class="math inline">\((v_k)_{k=-n..n}\)</span> be the basis of <span
class="math inline">\(V\)</span> given by <span
class="math inline">\(v_k := x^{n+k} y^{n-k}\)</span>. For <span
class="math inline">\(i,j \in \{-n..n\}\)</span>, let <span
class="math inline">\(R_{i j}(g)\)</span> denote the matrix entry of
<span class="math inline">\(g \in G\)</span> with respect to this basis,
i.e., the coefficient of <span class="math inline">\(v_i\)</span> in
<span class="math inline">\(R(g) v_j\)</span>. For <span
class="math inline">\(\theta,\phi \in \mathbb{R}\)</span>, set <span
class="math display">\[\kappa(\theta) :=
\begin{pmatrix}
          \cos (\theta/2)  &amp; i\sin (\theta/2)  \\
          i\sin (\theta/2) &amp; \cos (\theta /2)
        \end{pmatrix}
,
        \quad
        \delta(\phi) :=
        \begin{pmatrix}
          e^{i \phi/2}  &amp;  \\
                     &amp; e^{-i \phi/2}
        \end{pmatrix}
.\]</span> Verify that <span class="math display">\[R_{0 0}(
\begin{pmatrix}
          a &amp; b \\
          c &amp; d
        \end{pmatrix}
)
        = \sum_{k=0}^n
        {\binom{n}{k}}^2
        (a d)^k (c y)^{n-k}.\]</span> Deduce that <span
class="math display">\[P_n(\cos(\theta)) = R_{0
0}(\kappa(\theta)).\]</span></p></li>
<li><p>Show that for each <span
class="math inline">\(\theta_1,\theta_2,\phi\)</span> there exist <span
class="math inline">\(\phi_1,\phi_2,\theta\)</span> so that <span
class="math display">\[\kappa(\theta_1) \delta(\phi) \kappa(\theta_2) =
\delta(\phi_1) \kappa(\theta) \delta(\phi_2)\]</span> and moreover <span
class="math display">\[\cos(\theta) = \cos(\theta_1) \cos(\theta_2) -
\sin(\theta_1) \sin(\theta_2) \cos(\phi).\]</span> This can be proved
directly via the geometric interpretation mentioned after <a
href="#eq:legendre-composition" data-reference-type="eqref"
data-reference="eq:legendre-composition">\((2)\)</a>
using the map <span class="math inline">\(\mathop{\mathrm{SU}}(2)
\rightarrow \mathop{\mathrm{SO}}(3)\)</span> to be discussed next week;
if one wishes to attempt an algebraic proof, it may help to note
that</p>
<ol>
<li><p><em>every</em> element of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> may be decomposed
as <span class="math inline">\(\delta(\phi_1) \kappa(\theta)
\delta(\phi_2)\)</span>,</p></li>
<li><p>the function <span class="math display">\[f :
\mathop{\mathrm{SU}}(2) \rightarrow \mathbb{R}\]</span> given by <span
class="math display">\[f(
\begin{pmatrix}
            \alpha  &amp; \beta  \\
            - \overline{\beta } &amp; \overline{\alpha }
          \end{pmatrix}
          ) := 2 |\alpha|^2 - 1\]</span> satisfies <span
class="math inline">\(f(\delta(\phi_1) g \delta(\phi_2)) = f(g)\)</span>
and <span class="math inline">\(f(\kappa(\theta)) =
\cos(\theta)\)</span>.</p></li>
</ol>
<p>It may also help to treat first the case <span
class="math inline">\(\phi = 0\)</span>.</p></li>
<li><p>Verify that <span class="math inline">\(R_{k l}(\delta(\phi_1) g
\delta(\phi_2)) = e^{i(-k \phi_1 + l \phi_2)}\)</span> for all relevant
indices and arguments.</p></li>
<li><p>Prove <a href="#eq:legendre-composition"
data-reference-type="eqref"
data-reference="eq:legendre-composition">\((2)\)</a>
by taking the <span class="math inline">\((0,0)\)</span>th matrix
coefficient of the identity <span class="math display">\[R(g_1 g_2) =
R(g_1) R(g_2)\]</span> with <span class="math display">\[g_1 :=
\kappa(\theta_1) \delta(\phi),\]</span> <span class="math display">\[g_2
:= \kappa(\theta_2)\]</span> and integrating over <span
class="math inline">\(\phi\)</span>. [It may be helpful to recall the
Fourier inversion formula <span class="math display">\[\int_{\phi =
-\pi}^{\pi} e^{i k \phi} \, \frac{d \phi }{2 \pi } =
\begin{cases}
          1 &amp; k = 0 \\
          0 &amp; k \neq 0
        \end{cases}\]</span> for <span class="math inline">\(k \in
\mathbb{Z}\)</span>.]</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:orgc4f94de">§2.6. 10/11 (half-lecture) and 10/13: The unitary
trick</h2>
<p><strong>Objectives.</strong> Given a real form of a complex Lie
algebras, you should be able to relate representations of the two. You
should be able to verify that the classical complex Lie groups have
compact real forms and apply this fact to deduce their linear
reductivity. You should know the definitions of <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span> and <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span> and be able to apply
the fact that they are morphisms.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>introduction to and overview of the "unitary trick"</p></li>
<li><p>defn of real form of a complex Lie algebra, comparison between
representations</p></li>
<li><p>defn of real form of a connected complex Lie group</p></li>
<li><p>example of a representation that is not completely
reducible</p></li>
<li><p>lemma: complete reducibility is the same as invariant subspaces
having invariant complements</p></li>
<li><p>stated theorems that the following classes of groups are linearly
reductive:</p>
<ol>
<li><p>finite groups</p></li>
<li><p>(more generally) compact groups</p></li>
<li><p>complex connected Lie groups with a compact real form</p></li>
</ol></li>
<li><p>(Thursday onwards) we proved the above theorems.</p></li>
<li><p>along the way, we proved the useful fact that any
finite-dimensional representation of a compact group is unitarizable,
i.e., admits an invariant inner product.</p></li>
<li><p>we spent some time talking about examples of real forms and
complexifications.</p></li>
<li><p>we introduced Ad and ad. we related them, proved some of their
basic properties, and interpreted the Jacobi identity in terms of
properties of ad.</p></li>
</ol>
<div id="hw:all-about-Ad" class="homework">
<p><strong>Homework 6</strong> (Due Oct 18).  </p>
<ol>
<li><p>Prove that if <span class="math inline">\(f : G \rightarrow
H\)</span> is a Lie group morphism, then <span class="math inline">\(d
f(\mathop{\mathrm{Ad}}(g) X) = \mathop{\mathrm{Ad}}(f(g)) d
f(X)\)</span>.</p></li>
<li><p>Do Exercise <a href="#exe:complexifications"
data-reference-type="ref"
data-reference="exe:complexifications">20</a>.</p></li>
<li><p>Let <span class="math inline">\(G :=
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>; it is a three-dimensional
complex Lie group. Regard <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\)</span> as a three-dimensional
holomorphic representation of <span class="math inline">\(G\)</span>.
Write down an explicit isomorphism between <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span> and the
representation <span class="math inline">\(W_2 = \mathbb{C} x^2 \oplus
\mathbb{C} x y \oplus \mathbb{C} y^2\)</span> discussed in
lecture.</p></li>
<li><p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a Lie
algebra (the case <span class="math inline">\(\mathfrak{g} =
\mathop{\mathrm{End}}(V)\)</span> is already interesting), let <span
class="math inline">\(n \geq 1\)</span>, and let <span
class="math display">\[M = [Z_1,[Z_2,\dotsc,[Z_{n-1},Z_n] \dotsb ] =
\mathop{\mathrm{ad}}(Z_1) \mathop{\mathrm{ad}}(Z_2) \dotsb
\mathop{\mathrm{ad}}(Z_{n-1}) Z_n\]</span> be an <span
class="math inline">\(n\)</span>-fold iterated commutator of elements
<span class="math inline">\(Z_1,\dotsc,Z_n \in \mathfrak{g}\)</span>.
Let <span class="math inline">\(M&#39; \in \mathfrak{g}\)</span> be the
result of formally expanding <span class="math inline">\(M\)</span> as a
sum of degree <span class="math inline">\(n\)</span> monomials <span
class="math inline">\(Z_{i_1} \dotsb Z_{i_n}\)</span> and replacing each
such monomial by the corresponding commutator <span
class="math inline">\(\mathop{\mathrm{ad}}(Z_{i_1}) \dotsb
\mathop{\mathrm{ad}}(Z_{i_{n-1}}) Z_{i_n}\)</span>. For example:</p>
<ol>
<li><p>If <span class="math inline">\(M = [X,Y]\)</span>, then we expand
and set <span class="math display">\[\begin{align}
        M &amp;= X Y - Y X,\\
        M&#39; &amp;:= [X,Y] - [Y,X]
      
\end{align}\]</span> and obtain <span class="math inline">\(M&#39; = 2
[X,Y]\)</span> after some simplification.</p></li>
<li><p>If <span class="math inline">\(M = [X,[Y,X]]\)</span>, then we
expand and set <span class="math display">\[\begin{align}
        M &amp;= X Y X - X X Y - Y X X + X Y X, \\
        M&#39; &amp;:= [X,[Y,X]] - [X,[X,Y]] - [Y,[X,X]] + [X,[Y,X]]
      
\end{align}\]</span> and obtain <span class="math inline">\(M &#39; =
3 [X,[Y,X]]\)</span> after some simplification.</p></li>
</ol>
<p>Show that <span class="math inline">\(M&#39; = n M\)</span>. [Hint:
induct on <span class="math inline">\(n\)</span>. Use the consequence
<span class="math inline">\([\mathop{\mathrm{ad}}(Z_{i_1}),
[\mathop{\mathrm{ad}}(Z_{i_2}), \dotsc,
[{\mathop{\mathrm{ad}}}_{Z_{i_{n-1}}}, {\mathop{\mathrm{ad}}}_{Z_{i_n}}]]] =
\mathop{\mathrm{ad}}([Z_{i_1},[Z_{i_2}, \dotsc, [Z_{i_{n-1}},
Z_{i_n}]]])\)</span> of iterated application of the Jacobi identity in
the form <span class="math inline">\(\mathop{\mathrm{ad}}([X,Y]) =
[\mathop{\mathrm{ad}}(X),\mathop{\mathrm{ad}}(Y)]\)</span>.]</p></li>
</ol>
</div>
<h2 id="sec:org019e4bd">§2.7. 10/18 (half-lecture): The adjoint
representation</h2>
<p><strong>Objectives.</strong> You should be able to use the adjoint
representation to describe some low-dimensional exceptional isomorphisms
and to relate representations of the involved Lie groups and Lie
algebras.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>recap of what we’ve shown about representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> and
<span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></p></li>
<li><p>the exceptional isomorphisms <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})/ \{\pm 1\}
\cong {\mathop{\mathrm{SO}}}_3(\mathbb{C})\)</span>, <span
class="math inline">\(\mathop{\mathrm{SU}}(2) / \{\pm 1\} \cong
\mathop{\mathrm{SO}}(3)\)</span>, <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{R})/ \{\pm 1\}
\cong \mathop{\mathrm{SO}}(1,2)^0\)</span>, (plus some generalities on
quadratic spaces)</p></li>
</ol>
<div class="homework">
<p><strong>Homework 7</strong> (Due Oct 25).  </p>
<ol>
<li><p>Write down a careful proof that the adjoint representation <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\)</span> of the group <span
class="math inline">\(G := {\mathop{\mathrm{SL}}}_2(\mathbb{R})\)</span>
induces an isomorphism of Lie groups <span class="math inline">\(f :
{\mathop{\mathrm{PSL}}}_2(\mathbb{R}) \xrightarrow{\cong}
\mathop{\mathrm{SO}}(1,2)^0\)</span>. Give an explicit isomorphism of
Lie algebras <span class="math inline">\(d f :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{R})
\xrightarrow{\cong }
\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(1,2)\)</span>.</p></li>
<li><p>Explain why the adjoint representation of <span
class="math inline">\(G = {\mathop{\mathrm{GL}}}_2(\mathbb{C})\)</span>
does <em>not</em> induce an isomorphism between <span
class="math inline">\(G\)</span> and <span
class="math inline">\({\mathop{\mathrm{SO}}}_4(\mathbb{C})\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\mathbb{H}\)</span> denote
Hamilton’s quaternion algebra over <span
class="math inline">\(\mathbb{R}\)</span>, realized as the subalgebra of
<span class="math inline">\(M_2(\mathbb{C})\)</span> given by <span
class="math display">\[\mathbb{H} := \left\{
        \begin{pmatrix}
          z &amp; w \\
          -\overline{w} &amp; \overline{z}
        \end{pmatrix}
        :z,w \in \mathbb{C} \right\}.\]</span> Set <span
class="math display">\[\mathbb{H}^{(1)} := \left\{ g \in
\mathbb{H}^\times : \det(g) = 1 \right\}\]</span> and <span
class="math display">\[\mathbb{H}_0 := \left\{ v \in \mathbb{H} :
\mathop{\mathrm{trace}}(v) = 0 \right\}.\]</span></p>
<ol>
<li><p>Verify that <span class="math inline">\(\mathbb{H}^{(1)} =
\mathop{\mathrm{SU}}(2)\)</span>. Deduce in particular via the embedding
<span class="math inline">\((z,w) \hookrightarrow \mathbb{C}^2
\hookrightarrow \mathbb{R}^4\)</span> that <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> is diffeomorphic
to the three-dimensional sphere <span
class="math inline">\(S^3\)</span>.</p></li>
<li><p>Show that <span
class="math inline">\((\mathbb{H}_0,\det)\)</span> is a quadratic space
over <span class="math inline">\(\mathbb{R}\)</span> of signature <span
class="math inline">\((3,0)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\alpha : \mathbb{H}^\times
\rightarrow \mathop{\mathrm{GL}}(\mathbb{H}_0)\)</span> be the
conjugation action <span class="math inline">\(\alpha(g)(v) := g v
g^{-1}\)</span> (<span class="math inline">\(g \in \mathbb{H}^\times, v
\in \mathbb{H}_0\)</span>). Show that <span
class="math inline">\(\alpha(\mathbb{H}^{(1)}) =
\mathop{\mathrm{SO}}(\mathbb{H}_0,\det) \cong
\mathop{\mathrm{SO}}(3)\)</span> and that <span
class="math inline">\(\{g \in \mathbb{H}^{(1)} : \alpha(g) = 1\} = \{\pm
E\}\)</span> where <span class="math inline">\(E := \left(
        \begin{smallmatrix}
          1&amp;\\
           &amp;1
        \end{smallmatrix}
      \right)\)</span>. Deduce that <span
class="math display">\[\mathbb{H}^\times / \mathbb{R}^\times \cong
\mathbb{H}^{(1)} / \{\pm 1\} \cong \mathop{\mathrm{SO}}(3).\]</span>
[Use the connectedness of <span
class="math inline">\(\mathop{\mathrm{SO}}(3)\)</span> to reduce the
problem to one involving Lie algebras.]</p></li>
<li><p>Deduce that <span class="math inline">\(\alpha\)</span> induces
an isomorphism <span class="math inline">\(\mathop{\mathrm{SU}}(2) /
\{\pm 1\} \cong \mathop{\mathrm{SO}}(3)\)</span>. Compare with the proof
given in class by showing that one has <span
class="math inline">\(\mathop{\mathrm{Lie}}(\mathbb{H}^{(1)}) =
\mathbb{H}_0\)</span> under the natural identification <span
class="math inline">\(\mathop{\mathrm{Lie}}(\mathbb{H}^{\times}) =
\mathbb{H}\)</span>.</p></li>
</ol></li>
<li><p>(Optional) Here we understand how the map <span
class="math inline">\(\mathop{\mathrm{SU}}(2) \rightarrow
\mathop{\mathrm{SO}}(3)\)</span> may be defined by comparing the
standard actions <span class="math inline">\(\mathbb{P}^1(\mathbb{C})
\circlearrowleft \mathop{\mathrm{SU}}(2)\)</span> and <span
class="math inline">\(S^2 \circlearrowleft
\mathop{\mathrm{SO}}(3)\)</span> under the identification <span
class="math inline">\(\mathbb{P}^1(\mathbb{C}) \cong S^2\)</span> given
by stereographic projection:</p>
<ol>
<li><p>Let <span class="math inline">\(\mathbb{P}^1(\mathbb{C})\)</span>
be the complex projective line, that is, the set of equivalence classes
<span class="math inline">\([z:w]\)</span> of row vectors <span
class="math inline">\((z,w) \in \mathbb{C}^2 - \{0\}\)</span> under the
equivalence relation <span class="math inline">\((z,w) \simeq (\lambda
z,\lambda w)\)</span> for all <span class="math inline">\(\lambda \in
\mathbb{C}^\times\)</span>. Verify that <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> acts on <span
class="math inline">\(\mathbb{P}^1(\mathbb{C})\)</span> via <span
class="math display">\[\cdot g := [a \xi + c \eta : b \xi + d \eta ]
\text{ for } g =
        \begin{pmatrix}
          a &amp; b \\
          c &amp; d
        \end{pmatrix}
        \in \mathop{\mathrm{SU}}(2).\]</span></p></li>
<li><p>Let <span class="math inline">\(S^2 := \{(x,y,z) : x^2 + y^2 +
z^2\} \subseteq \mathbb{R}^3\)</span> be the standard two-dimensional
sphere. Let <span class="math inline">\(\mathop{\mathrm{SO}}(3)\)</span>
act on <span class="math inline">\(S^2\)</span> in the usual way: for
<span class="math inline">\(v \in S^2\)</span> and <span
class="math inline">\(g \in G\)</span>, <span class="math inline">\(v
\cdot g\)</span> is given by matrix multiplication. Verify that an
element of <span class="math inline">\(\mathop{\mathrm{SO}}(3)\)</span>
is determined by its action on <span
class="math inline">\(S^2\)</span>.</p></li>
<li><p>Let <span class="math inline">\(p := (0,0,-1) \in S^2\)</span>
denote the “south pole” and let <span class="math inline">\(P :=
\{(u,v,0) : u,v \in \mathbb{R}\} \subseteq \mathbb{R}^3\)</span> denote
the “equatorial plane.” Let <span class="math inline">\(\pi : S^2 -
\{p\} \rightarrow P\)</span> denote the result of stereographic
projection from <span class="math inline">\(p\)</span>, thus <span
class="math inline">\(\pi(x,y,z) = (u,v,0)\)</span> means that the
points <span class="math inline">\((0,0,-1)\)</span>, <span
class="math inline">\((u,v,0)\)</span>, <span
class="math inline">\((x,y,z)\)</span> are collinear. Let <span
class="math inline">\(\rho : P \hookrightarrow
\mathbb{P}^1(\mathbb{C})\)</span> be the map <span
class="math inline">\(\rho(u,v,0) := [u+i v : 1]\)</span>. Verify that
the composition <span class="math inline">\(\rho \circ \pi : S^2 -
\{p\}\)</span> extends to a homeomorphism <span
class="math display">\[\iota : S^2 \rightarrow
\mathbb{P}^1(\mathbb{C})\]</span> for which <span
class="math inline">\(\iota(p) = [1:0]\)</span>.</p></li>
<li><p>Show that for each <span class="math inline">\(g \in
\mathop{\mathrm{SU}}(2)\)</span> there is a unique <span
class="math inline">\(\alpha(g) \in \mathop{\mathrm{SO}}(3)\)</span> so
that for all <span class="math inline">\(s \in S^2\)</span>, one has
<span class="math inline">\(\iota(s \cdot \alpha(g)) = \iota(s) \cdot
g\)</span>. Show that the map <span class="math inline">\(\alpha :
\mathop{\mathrm{SU}}(2) \rightarrow \mathop{\mathrm{SO}}(3)\)</span> is
a surjective morphism of Lie groups.</p></li>
<li><p>Read about the “Hopf fibration” somewhere and understand its
relevance.</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:org7c4df3a">§2.8. 10/20 (first half): Character theory for <span
class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span> (algebraic)</h2>
<p><strong>Objectives.</strong> Given a (reasonably explicit)
representation <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> or
some closely related group, you should be able to determine its
reduction into irreducibles by computing its character and multiplying
by the Weyl denominator.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>definitions of direct sum and tensor product of representations
of Lie groups and Lie algebras</p></li>
<li><p>characters of representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> as
Laurent polynomials in one variable <span
class="math inline">\(z\)</span></p></li>
<li><p>compatibility with direct sum and direct product</p></li>
<li><p>the characters of the irreducibles</p></li>
<li><p>the Weyl denominator <span class="math inline">\(z -
1/z\)</span></p></li>
<li><p>Clebsch–Gordon decomposition</p></li>
</ol>
<div id="hw:characters-sl2" class="homework">
<p><strong>Homework 8</strong> (Due Oct 25).  </p>
<ol>
<li><p>Verify that if <span class="math inline">\(\rho_j : \mathfrak{g}
\rightarrow \mathop{\mathrm{End}}(V_j)\)</span> (<span
class="math inline">\(j=1,2\)</span>) are representations of a Lie
algebra, then the map <span class="math inline">\(\rho_1 \otimes \rho_2
: \mathfrak{g} \rightarrow \mathop{\mathrm{End}}(V_1 \otimes
V_2)\)</span>, defined as in class by linear extension of its definition
on pure tensors <span class="math inline">\(v_1 \otimes v_2 \in V_1
\otimes V_2\)</span> by <span class="math display">\[((\rho_1 \otimes
\rho_2)(X))(v_1 \otimes v_2) := \rho_1(X) v_1 \otimes v_2 + v_1 \otimes
\rho_2(X) v_2,\]</span> or in abbreviated form simply by <span
class="math display">\[X(v_1 \otimes v_2) := X v_1 \otimes v_2
    + v_1 \otimes X v_2,\]</span> defines a representation of Lie
algebras.</p></li>
<li><p>Verify that the map <span class="math inline">\(W_2 \oplus W_0
\rightarrow W_1 \otimes W_1\)</span> defined in class is an isomorphism
of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>-representations.</p></li>
<li><p>Show that there does <em>not</em> exist a representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> whose
weight spaces <span class="math inline">\(V[m] := \{ v \in V : H v = m v
\}\)</span> (<span class="math inline">\(m \in \mathbb{Z}\)</span>) have
dimensions given by <span class="math display">\[\dim V[m] =
\begin{cases}
        1 &amp; m \in \{-7,-6,-5,5,6,7\}, \\
        0 &amp; \text{otherwise.}
      \end{cases}\]</span> More generally, for which functions <span
class="math inline">\(\nu : \mathbb{Z} \rightarrow \mathbb{Z}_{\geq
0}\)</span> does there exist a finite-dimensional representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> with
<span class="math inline">\(\dim V[n] = \nu(n)\)</span> for all <span
class="math inline">\(n\)</span>? [Hint: write <span
class="math inline">\(V \cong \oplus W_m^{\oplus \mu(m)}\)</span> and
apply <span class="math inline">\(D \cdot \operatorname{ch}(.)\)</span>
to both sides.]</p></li>
<li><p>(Optional) Given <span class="math inline">\(k \in
\mathbb{Z}_{\geq 0}\)</span> and a representation <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
of a Lie group <span class="math inline">\(G\)</span>, one obtains a
symmetric power representation <span
class="math inline">\({\mathop{\mathrm{Sym}}}^k(R) : G \rightarrow
\mathop{\mathrm{GL}}({\mathop{\mathrm{Sym}}}^k(V))\)</span> on the
symmetric power vector space <span
class="math inline">\({\mathop{\mathrm{Sym}}}^k(V)\)</span>; see §<a
href="#sec:constructing-sym-power" data-reference-type="ref"
data-reference="sec:constructing-sym-power">16.9.3</a>
or Google for some details. The purpose of this exercise is to relate
the character of <span
class="math inline">\({\mathop{\mathrm{Sym}}}^k(V)\)</span> to that of
<span class="math inline">\(V\)</span>. We restrict to the case <span
class="math inline">\(G := {\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>,
although the arguments are somewhat more general. Let <span
class="math inline">\(A := \mathbb{Z}[z,z^{-1}]\)</span> be as in
lecture.</p>
<ol>
<li><p>Define <span class="math inline">\(\sigma(V)\)</span> to be the
element of the formal power series ring <span
class="math inline">\(A[[T]]\)</span> in the variable <span
class="math inline">\(T\)</span> with coefficients in <span
class="math inline">\(A\)</span> given by the formula <span
class="math display">\[\sigma(V) := \sum_{k \in \mathbb{Z}_{\geq 0}}
      \operatorname{ch}({\mathop{\mathrm{Sym}}}^k V) T^k.\]</span> Show
that <span class="math display">\[\sigma(V) = \exp \sum _{k \geq 1}
      \frac{\Psi^k(\operatorname{ch}(V)) T^k}{k }\]</span> where <span
class="math inline">\(\Psi^k\)</span> is defined via the substitution
<span class="math inline">\(z \mapsto z^k\)</span>, i.e., by setting
<span class="math inline">\(\Psi^k(\chi)(z) := \chi(z^k)\)</span> for
<span class="math inline">\(\chi \in A\)</span>. [Hint: the identity
<span class="math display">\[\exp \sum_{k \geq 1}
      \frac{x^k}{k}
      =
      \frac{1}{1-x}
      = \sum_{k \geq 0}
      x^k\]</span> is relevant.]</p></li>
<li><p>Deduce the recursion relation <span class="math display">\[n
\operatorname{ch}({\mathop{\mathrm{Sym}}}^k (V)) = \sum_{k = 1}^n
      \Psi^k(\operatorname{ch}(V))
      \operatorname{ch}({\mathop{\mathrm{Sym}}}^{n-k}(V)).\]</span> Check
that this is consistent with the isomorphisms <span
class="math inline">\({\mathop{\mathrm{Sym}}}^n(W_1) \cong
W_n\)</span>.</p></li>
<li><p>Specialize the above relation to the case <span
class="math inline">\(n = 2\)</span> to obtain <span
class="math display">\[\operatorname{ch}({\mathop{\mathrm{Sym}}}^2(V))
      = \frac{\operatorname{ch}(V)^2 -
\Psi^2(\operatorname{ch}(V))}{2}.\]</span> For each irreducible
representation <span class="math inline">\(W_m\)</span> of <span
class="math inline">\(G\)</span>, compute <span
class="math inline">\(\operatorname{ch}({\mathop{\mathrm{Sym}}}^2(W_m))\)</span>
by the above formula and use it to derive the decomposition <span
class="math display">\[{\mathop{\mathrm{Sym}}}^2(W_m)
      \cong
      W_{2 m} \oplus W_{2 m - 4} \oplus \dotsb
      = \oplus _{\substack{
          0 \leq j \leq 2 m : \\
          j \equiv 2 m (4)
        }}
      W_j.\]</span> of <span
class="math inline">\({\mathop{\mathrm{Sym}}}^2(W_m)\)</span> into
irreducibles. (It is also instructive, and not difficult, to derive this
decomposition directly.) Write down an explicit isomorphism <span
class="math inline">\({\mathop{\mathrm{Sym}}}^2(W_2) \cong W_4 \oplus
W_0\)</span>.</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:org5473899">§2.9. 10/20 (second half): Maurer-Cartan equations;
lifting morphisms of Lie algebras</h2>
<p><strong>Objectives.</strong> You should know that <span
class="math inline">\(\mathop{\mathrm{Hom}}(G,H) \rightarrow
\mathop{\mathrm{Hom}}(\mathfrak{g},\mathfrak{h})\)</span> is injective
when <span class="math inline">\(G\)</span> is connected and surjective
when <span class="math inline">\(G\)</span> is simply-connected and be
able to give some basic counter-examples indicating the necessity of
such conditions. You should be able to describe the role played by the
Maurer–Cartan equations in establishing surjectivity in the
simply-connected case. Given hints, you should be able to apply the
Maurer–Cartan equation to related problems.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>statement of main theorem on lifts of Lie algebra
morphisms</p></li>
<li><p>proof via paths and Maurer–Cartan equation</p></li>
</ol>
<div id="hw:diff-exp" class="homework">
<p><strong>Homework 9</strong> (Due Oct 25).  </p>
<ol>
<li><p>For a smooth scalar-valued function <span class="math inline">\(f
: \mathbb{R} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbb{R}\)</span>, the chain rule implies that <span id="eq:exp-path-abelian-case" class="math display">\[\label{eq:exp-path-abelian-case}\tag{3}
            \frac{d}{d t} \exp(f(t))
      = \exp(f(t)) f&#39;(t).\]</span> The purpose of this exercise is
to generalize the above identity as an application of a technique
introduced in lecture. Let <span class="math inline">\(G\)</span> be a
real Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>; the problem is already
interesting when <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span>, so feel free to assume
that. Prove that for a smooth function <span class="math inline">\(f :
\mathbb{R} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\)</span>, one has <span id="eq:derivative-exponential-path" class="math display">\[\label{eq:derivative-exponential-path}\tag{4}
      \frac{d}{d t} \exp(f(t))
      =
      \exp(f(t))
      \sum_{n=1}^{\infty}
      \frac{
        (- {\mathop{\mathrm{ad}}}_{f(t)})^{n-1} f&#39;(t)
      }{n!}\]</span> where we may write more explicitly <span
class="math display">\[(- {\mathop{\mathrm{ad}}}_{f(t)})^{n-1} f&#39;(t)
      = [[[f&#39;(t), f(t)], f(t)], \dotsc, f(t)].\]</span> Observe that
<a href="#eq:derivative-exponential-path" data-reference-type="eqref"
data-reference="eq:derivative-exponential-path">\((4)\)</a>
specializes to <a href="#eq:exp-path-abelian-case"
data-reference-type="eqref"
data-reference="eq:exp-path-abelian-case">\((3)\)</a>
when <span class="math inline">\(G\)</span> is abelian, so that <span
class="math inline">\({\mathop{\mathrm{ad}}}_{f(t)} = 0\)</span>.</p>
<p>[Hint: Consider the map <span class="math inline">\(g : \mathbb{R}^2
%
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
G\)</span> given by <span class="math display">\[g(s,t) := \exp(s
f(t)).\]</span> Define <span class="math inline">\(\xi : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\)</span> by <span class="math inline">\(\frac{\partial
g}{\partial t} = g \xi\)</span>, so that <span
class="math inline">\(\frac{d}{d t} \exp(f(t))
    = \exp(f(t)) \xi(t,1)\)</span>. Apply the Maurer–Cartan equation
(§<a href="#sec:cartan-maurer-eqn" data-reference-type="ref"
data-reference="sec:cartan-maurer-eqn">19.1</a>) to
characterize <span class="math inline">\(\xi\)</span> as the unique
solution <span class="math inline">\(F\)</span> to the differential
equation <span class="math display">\[\frac{\partial F}{\partial s}(t,s)
      = f&#39;(t)
      + [F(t,s), f(t)]\]</span> with initial condition <span
class="math inline">\(F(t,0) = 0\)</span>. On the other hand, verify
that such a solution may be given explicitly by <span
class="math display">\[F(t,s) :=
      \sum_{n=1}^{\infty}
      s^n
      \frac{
        (- {\mathop{\mathrm{ad}}}_{f(t)})^{n-1} f&#39;(t)
      }{n!}\]</span> and set <span class="math inline">\(s := 1\)</span>
to conclude.]</p></li>
</ol>
</div>
<h2 id="sec:org37094a7">§2.10. 10/25 (half-lecture): universal covering
group</h2>
<p><strong>Objectives.</strong> You should be able to classify the Lie
groups having a given Lie algebra in terms of discrete central subgroups
of a simply-connected group. You should be able to describe some basic
examples of covering morphisms and use them to determine the fundamental
groups of some Lie groups.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>The main theorem was that for any connected Lie group <span
class="math inline">\(G\)</span> there exists a simply-connected Lie
group <span class="math inline">\(\tilde{G}\)</span> and a covering
morphism <span class="math inline">\(p : \tilde{G} \rightarrow
G\)</span> whose kernel <span class="math inline">\(N = \ker(p)\)</span>
is a discrete subgroup of the center of <span
class="math inline">\(\tilde{G}\)</span>, with <span
class="math inline">\((\tilde{G},N)\)</span> uniquely determined up to
isomorphism. Moreover, <span class="math inline">\(\pi_1(G) \cong
N\)</span>.</p></li>
<li><p>We gave several examples to which this applies. Some further
examples are given on the homework.</p></li>
<li><p>We stated without proof that every finite-dimensional Lie algebra
arises from some Lie group.</p></li>
<li><p>By combining with a result from last time, we deduced that the
category of simply-connected Lie groups is equivalent to the category of
finite-dimensional Lie algebras.</p></li>
<li><p>We recalled the definition of "cover" (locally trivial fiber
bundle with discrete fiber). We briefly recalled the construction of the
universal cover of a connected manifold and stated its universal
property (existence of unique lifts of paths). We defined the group
structure on the simply-connected cover of a Lie group.</p></li>
<li><p>We reduced the remainder of the proof of the main theorem to some
lemmas left mostly as exercises.</p></li>
</ol>
<div id="hw:universal-covering-group" class="homework">
<p><strong>Homework 10</strong> (Due Nov 1).  </p>
<ol>
<li><p>Let <span class="math inline">\(n \geq 1\)</span>. For the
purposes of this exercise, you may use without proof that <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> and
<span class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span> are
simply-connected.</p>
<ol>
<li><p>Show that <span
class="math inline">\(\pi_1({\mathop{\mathrm{PGL}}}_n(\mathbb{C})) \cong
\mathbb{Z}/n\)</span>. [Hint: show that the natural map <span
class="math inline">\(p : {\mathop{\mathrm{SL}}}_n(\mathbb{C}) \rightarrow
      {\mathop{\mathrm{PGL}}}_n(\mathbb{C})\)</span> is a covering
morphism, determine the kernel of <span
class="math inline">\(p\)</span>, and appeal to the theorem from
lecture.]</p></li>
<li><p>Set <span class="math inline">\(\mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>.
Determine the connected Lie groups <span
class="math inline">\(G\)</span> (up to isomorphism, and over either the
real or complex numbers – it doesn’t matter) having Lie algebra
(isomorphic to) <span class="math inline">\(\mathfrak{g}\)</span>, and
describe their fundamental groups <span
class="math inline">\(\pi_1(G)\)</span>. [Hint: start by determining the
center of <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span>.]
Interpret “determine” as you wish. For instance, you should be able to
answer the following question: How many isomorphism classes of connected
Lie groups have Lie algebra isomorphic to <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_{12}(\mathbb{C})\)</span>?</p></li>
<li><p>Same question but for <span class="math inline">\(\mathfrak{g} :=
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(n)\)</span>.</p></li>
</ol></li>
<li><p>Verify that (at least one or two of) the following maps are
covering morphisms of Lie groups and determine their kernels. [Hint: the
lemma from lecture characterizing covering morphisms may help.]</p>
<ol>
<li><p>The morphism of complex Lie groups <span
class="math display">\[\mathbb{C} \xrightarrow{\exp}
\mathbb{C}^\times.\]</span></p></li>
<li><p>The morphism of complex Lie groups <span
class="math display">\[{\mathop{\mathrm{SL}}}_2(\mathbb{C})
\xrightarrow{\mathop{\mathrm{Ad}}}
        \mathop{\mathrm{SO}}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}),\det)
        \cong
        {\mathop{\mathrm{SO}}}_3(\mathbb{C}).\]</span></p></li>
<li><p>The morphism of real Lie groups <span
class="math display">\[\mathop{\mathrm{SU}}(2)
\xrightarrow{\mathop{\mathrm{Ad}}}
        \mathop{\mathrm{SO}}(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2),\det)
        \cong
        \mathop{\mathrm{SO}}(3).\]</span></p></li>
<li><p>The morphism of real Lie groups <span
class="math display">\[{\mathop{\mathrm{SL}}}_2(\mathbb{R})
\xrightarrow{\mathop{\mathrm{Ad}}}
        \mathop{\mathrm{SO}}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{R}),\det)^0
        \cong
        \mathop{\mathrm{SO}}(1,2)^0.\]</span></p></li>
<li><p>The morphism of complex Lie groups <span
class="math display">\[{\mathop{\mathrm{SL}}}_2(\mathbb{C}) \times
{\mathop{\mathrm{SL}}}_2(\mathbb{C}) \rightarrow
        \mathop{\mathrm{SO}}(M_2(\mathbb{C}),\det)
        \cong {\mathop{\mathrm{SO}}}_4(\mathbb{C}),\]</span> <span
class="math display">\[(g,h) \mapsto [x \mapsto g x
h^{-1}].\]</span></p></li>
<li><p>The morphism of real Lie groups <span
class="math display">\[\mathop{\mathrm{SU}}(2) \times
\mathop{\mathrm{SU}}(2)
        \rightarrow
        \mathop{\mathrm{SO}}(\mathbb{H},\det)
        \cong \mathop{\mathrm{SO}}(4),\]</span> <span
class="math display">\[(g,h) \mapsto [x \mapsto g x h^{-1}],\]</span>
where <span class="math inline">\(\mathbb{H} = \left\{
\begin{pmatrix}
          z &amp; w \\
          -\overline{w} &amp; \overline{z}
        \end{pmatrix}
\right\}\subseteq M_2(\mathbb{C})\)</span> denotes Hamilton’s quaternion
algebra as considered on previous homeworks.</p></li>
<li><p>The morphism of <em>real</em> Lie groups <span
class="math display">\[{\mathop{\mathrm{SL}}}_2(\mathbb{C})
        \rightarrow
        \mathop{\mathrm{SO}}(V,\det)^0
        \cong \mathop{\mathrm{SO}}(1,3)^0,\]</span> <span
class="math display">\[g \mapsto [x \mapsto g x
\overline{g}^t],\]</span> where <span class="math inline">\(V
      := \left\{ X \in M_2(\mathbb{C}) : \overline{X} = X^t
      \right\}
      =
      \left\{
\begin{pmatrix}
          x &amp;  z \\
          \overline{z} &amp; y
        \end{pmatrix}
: x,y \in \mathbb{R}, z \in \mathbb{C}
      \right\}\)</span> is the space of <span class="math inline">\(2
\times 2\)</span> hermitian matrices.</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:org6e185d7">§2.11. 10/27: Fundamental groups of Lie groups</h2>
<p><strong>Objectives</strong>. You should be able to analyze the
topology of Lie groups by</p>
<ul>
<li><p>applying the homotopy exact sequence to their transitive actions,
and</p></li>
<li><p>via the Cartan decomposition.</p></li>
</ul>
<p><strong>Summary</strong></p>
<ol>
<li><p>Description, without proof, of the fundamental groups of the
classical groups; empirical observation that complex Lie groups and
their compact real forms (if they exist) have the same fundamental
groups</p></li>
<li><p>Homotopy exact sequence and its consequences; proofs of some of
the descriptions of fundamental groups given before (most were left as
exercises). For example, we showed inductively that <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> is
simply-connected.</p></li>
<li><p>Quotient groups (abstract, topological, Lie), quotient manifolds,
transitive action theorem; sketch of construction of smooth structure on
the quotient</p></li>
<li><p>Statement of Cartan decomposition; application to comparing
homotopy groups, recap on the unitary trick</p></li>
</ol>
<div class="homework">
<p><strong>Homework 11</strong> (Due Nov 1).  </p>
<ol>
<li><p>Let <span class="math inline">\(p,q \geq 1\)</span>. Set <span
class="math inline">\(G := \operatorname{O}(p,q)\)</span>, realized as
usual as a subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_{p+q}(\mathbb{R})\)</span>.
Let <span class="math inline">\(\Theta\)</span> be given by <span
class="math inline">\(\Theta(g) := {}^t
    \overline{g}^{-1}\)</span>.</p>
<ol>
<li><p>Show that the subgroup <span class="math inline">\(K := \{g \in G
: \Theta(g) = g\}\)</span> fixed by <span
class="math inline">\(G\)</span> identifies with <span
class="math inline">\(\operatorname{O}(p) \times
\operatorname{O}(q)\)</span>.</p></li>
<li><p>Use (without proof) the Cartan decomposition (§<a
href="#sec:cartan-decmop" data-reference-type="ref"
data-reference="sec:cartan-decmop">23</a>) <span
class="math display">\[K \times \mathfrak{p} \cong G\]</span> <span
class="math display">\[(k,Y) \mapsto k \exp(Y)\]</span> to show that
<span class="math inline">\(G\)</span> has four connected
components.</p></li>
<li><p>Describe the Cartan decomposition explicitly in the special case
<span class="math inline">\(p := 1, q := 1\)</span>, and compare with
the related problem on Homework <a href="#hw:2"
data-reference-type="ref" data-reference="hw:2">2</a>.</p></li>
</ol></li>
<li><p>(Optional) Let <span class="math display">\[G :=
{\mathop{\mathrm{SL}}}_2(\mathbb{R}).\]</span> Denote by <span
class="math inline">\(\mathbb{H} := \{x + i y : x,y \in \mathbb{R}, y
&gt;
    0\} \subseteq \mathbb{C}\)</span> the upper half-plane. The group
<span class="math inline">\(G\)</span> acts smoothly on <span
class="math inline">\(\mathbb{H}\)</span> by fractional linear
transformations: <span class="math display">\[g z := \frac{a z + b}{c z
+ d}
      \text{ if }
      g =
\begin{pmatrix}
        a &amp; b \\
        c &amp; d
      \end{pmatrix}
\in G,
      \quad z \in \mathbb{H}.\]</span> Denote by <span
class="math inline">\(\tilde{G}\)</span> the set of all pairs <span
class="math inline">\((g,\phi)\)</span>, where</p>
<ul>
<li><p><span class="math inline">\(g \in G\)</span>, and</p></li>
<li><p><span class="math inline">\(\phi : \mathbb{H} \rightarrow
\mathbb{C}\)</span> is a holomorphic function with the property that
<span class="math display">\[\exp(\phi(z))
        =
        c z + d
        \text{ if we write }
        g =
\begin{pmatrix}
          a &amp; b \\
          c &amp; d
        \end{pmatrix}
.\]</span></p></li>
</ul>
<p>In other words, <span class="math inline">\(\phi\)</span> is a branch
of <span class="math inline">\(\log(c z + d)\)</span>; it is determined
by <span class="math inline">\(g\)</span> and any of its values, say
<span class="math inline">\(\phi(i)\)</span>. We may define on <span
class="math inline">\(\tilde{G}\)</span> a smooth structure by regarding
it as a submanifold of <span class="math inline">\(G \times
\mathbb{C}\)</span> via the embedding <span
class="math inline">\((g,\phi) \mapsto (g,\phi(i))\)</span>. We define
on <span class="math inline">\(\tilde{G}\)</span> a group structure by
the law <span class="math display">\[(g_1,\phi_1) \cdot (g_2,\phi_2)
      :=
      (g_1 g_2, \phi_1^{g_2} \phi_2)
      \text{ where }
      (\phi_1^{g_2} \phi_2)(z)
      :=
      \phi_1(g_2 z) \phi_2(z).\]</span> This group operation is then
associative and smooth, and defines on <span
class="math inline">\(\tilde{G}\)</span> the structure of a Lie group.
The natural map <span class="math display">\[\pi : \tilde{G} \rightarrow
G\]</span> given by <span class="math inline">\(\pi((g,\phi)) :=
g\)</span>, is smooth and surjective. The group <span
class="math inline">\(\tilde{G}\)</span> inherits from <span
class="math inline">\(G\)</span> an action on <span
class="math inline">\(\mathbb{H}\)</span>: <span
class="math inline">\((g,\phi) \cdot z := g z\)</span>. The map <span
class="math display">\[\kappa : \mathbb{R} \rightarrow
\tilde{G}\]</span> given by <span class="math display">\[\kappa(\theta)
:=
      (
      \begin{pmatrix}
        \cos(\theta) &amp; \sin(\theta) \\
        -\sin(\theta) &amp; \cos(\theta)
      \end{pmatrix}
,
      \phi_\theta),\]</span> where <span
class="math inline">\(\phi_\theta(z)\)</span> is the unique branch of
<span class="math inline">\(\log(-\sin(\theta) z +
\cos(\theta))\)</span> for which <span
class="math inline">\(\phi_\theta(i)
    = - i \theta\)</span>, is a morphism of Lie groups. [For the
purposes of this exercise, all of the assertions just made may be
regarded as sufficiently self-evident as not to require proof.]</p>
<ol>
<li><p>Write down an isomorphism <span class="math inline">\(N \cong
\mathbb{Z}\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(\tilde{G}\)</span> is
connected. [Hint: use <span class="math inline">\(\kappa\)</span> to
show that <span class="math inline">\(N \subseteq \tilde{G}^0\)</span>,
and use that <span class="math inline">\(G\)</span> is
connected.]</p></li>
<li><p>Let <span class="math inline">\(H \leq \tilde{G}\)</span> denote
the image of <span class="math inline">\(\kappa\)</span>. Show that
<span class="math inline">\(H\)</span> is the stabilizer in <span
class="math inline">\(\tilde{G}\)</span> of the point <span
class="math inline">\(i \in \mathbb{H}\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(\tilde{G}\)</span> is
simply-connected. [The homotopy exact sequence gives one way to do this;
alternatively, one can find a diffeomorphism <span
class="math inline">\(\tilde{G} \cong \mathbb{H} \times
\mathbb{R}\)</span>.]</p></li>
</ol>
<p>In summary, <span class="math inline">\(\tilde{G}\)</span> is the
simply-connected covering group of <span
class="math inline">\(G\)</span>, and <span
class="math inline">\(\pi_1(G) \cong N \cong
\mathbb{Z}\)</span>.</p></li>
</ol>
</div>
<h2 id="sec:orged45fdb">§2.12. 11/1: The Baker–Campbell–Hausdorff(–Dynkin)
formula</h2>
<p><strong>Objectives.</strong> You should be able to describe the BCH
formula (qualitatively), specialize it to the case of $2$-step nilpotent
groups, and apply it to derive asymptotic expansions in local
exponential coordinates of products in a Lie group.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>We defined what it means for a pair of Lie groups to be locally
isomorphic, and explained how the lifting theorem for simply-connected
Lie groups and the existence of the universal cover of a given Lie group
imply that two Lie groups are locally isomorphic if and only if their
Lie algebras are isomorphic.</p></li>
<li><p>Motivated by a “local” proof of this assertion, we initiated a
study of the <span class="math inline">\(x \ast y := \log(\exp(x)
\exp(y))\)</span> for a pair of matrices <span
class="math inline">\(x,y\)</span>.</p></li>
<li><p>We verified empirically that the first couple homogeneous
components <span class="math inline">\(z_n\)</span> in the series
expansion of <span class="math inline">\(x \ast y\)</span> are Lie
polynomials, i.e., linear combinations of iterated Lie commutators
involving <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>. We stated the BCH theorem, which says
that this empirical observation holds for all <span
class="math inline">\(n\)</span>.</p></li>
<li><p>We stated Dynkin’s formula and indicated briefly how it follows
from the BCH theorem together with an earlier homework problem on
iterated commutators.</p></li>
<li><p>We proved the BCH theorem in its qualitative form using the
homework problem on the derivative of the exponential map.</p></li>
</ol>
<div id="hw:bch-consequences" class="homework">
<p><strong>Homework 12</strong> (Due Nov 8).  </p>
<ol>
<li><p>Let <span class="math inline">\(s \in \mathbb{Z}_{\geq
0}\)</span>. A group <span class="math inline">\(G\)</span> is said to
be <em><span class="math inline">\(s\)</span>-step nilpotent</em> if all
for all <span class="math inline">\(x_1,\dotsc,x_{s+1} \in G\)</span>,
the iterated commutator <span
class="math inline">\((x_1,(x_2,\dotsc,(x_{s},x_{s+1})))\)</span> is the
identity element. Here <span class="math inline">\((x,y) := x y x^{-1}
y^{-1}\)</span>. For example, <span class="math inline">\(G\)</span> is
<span class="math inline">\(1\)</span>-step nilpotent if and only if it
is abelian.</p>
<p>Similarly, a Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> is said to be <em><span
class="math inline">\(s\)</span>-step nilpotent</em> if <span
class="math inline">\([x_1,[x_2,\dotsc,[x_{s},x_{s+1}]]] = 0\)</span>
for all <span class="math inline">\(x_1,\dotsc,x_{s+1} \in
\mathfrak{g}\)</span>. We call <span
class="math inline">\(\mathfrak{g}\)</span> abelian if it is <span
class="math inline">\(1\)</span>-step nilpotent, or equivalently, if the
commutator bracket vanishes identity.</p>
<ol>
<li><p>Verify that the Lie group <span class="math inline">\(G \leq
{\mathop{\mathrm{SL}}}_{s+1}(\mathbb{R})\)</span> consisting of strictly
upper-triangular matrices is <span class="math inline">\(s\)</span>-step
nilpotent.</p></li>
<li><p>Let <span class="math inline">\(G\)</span> be a connected Lie
group with adjoint representation <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\)</span>. Show that <span
class="math inline">\(\ker(\mathop{\mathrm{Ad}})\)</span> is the center
of <span class="math inline">\(G\)</span>.</p></li>
<li><p>Let <span class="math inline">\(G\)</span> be a connected Lie
group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Show for <span
class="math inline">\(s \leq 2\)</span> that <span
class="math inline">\(G\)</span> is <span
class="math inline">\(s\)</span>-step nilpotent if and only if <span
class="math inline">\(\mathfrak{g}\)</span> is <span
class="math inline">\(s\)</span>-step nilpotent. (The same conclusion
holds for all <span class="math inline">\(s\)</span>, and can be proved
similarly; the assumption <span class="math inline">\(s \leq 2\)</span>
is just to simplify the homework problem.)</p></li>
<li><p>If <span class="math inline">\(G\)</span> is <span
class="math inline">\(2\)</span>-step nilpotent, show that the BCH
formula takes the simple form <span id="eq:bchd-2-step" class="math display">\[\label{eq:bchd-2-step}\tag{5}
        x \ast y = x + y + \frac{1}{2} [x,y]\]</span> for small enough
<span class="math inline">\(x,y \in \mathfrak{g}\)</span>. Show that the
quantities <span id="eq:lie-algebra-elements-that-are-similar" class="math display">\[\label{eq:lie-algebra-elements-that-are-similar}\tag{6}
        x \ast (y-x),
        \quad
        y + \frac{1}{2} [x,y],
        \quad
        \frac{x}{2} \ast y
        \ast (\frac{-x}{2})\]</span> coincide.</p></li>
<li><p>Let <span class="math inline">\(G \leq
{\mathop{\mathrm{SL}}}_3(\mathbb{R})\)</span> be the three-dimensional Lie
group consisting of strictly upper-triangular matrices; we have seen
already that it is <span class="math inline">\(2\)</span>-step
nilpotent. Establish the formula <span class="math display">\[\exp (
\begin{pmatrix}
          &amp; x &amp; 0 \\
          &amp;  &amp; 0 \\
          &amp;  &amp;
        \end{pmatrix}
)
        \exp (
\begin{pmatrix}
          &amp; 0 &amp; 0 \\
          &amp;  &amp; y \\
          &amp;  &amp;
        \end{pmatrix}
)
        =
        \exp (
\begin{pmatrix}
          &amp; x &amp; xy/2 \\
          &amp;  &amp; y \\
          &amp;  &amp;
        \end{pmatrix}
)\]</span> in two ways:</p>
<ol>
<li><p>By direct calculation with power series.</p></li>
<li><p>By application of the BCHD formula to <span
class="math display">\[X :=
\begin{pmatrix}
            &amp; x &amp;  \\
            &amp;  &amp;  \\
            &amp;  &amp;
          \end{pmatrix}
,
          \quad
          Y :=
\begin{pmatrix}
            &amp;  &amp;  \\
            &amp;  &amp; y \\
            &amp;  &amp;
          \end{pmatrix}
.\]</span></p></li>
</ol></li>
</ol></li>
<li><p>Let <span class="math inline">\(G\)</span> be a Lie group. Equip
its Lie algebra <span class="math inline">\(\mathfrak{g}\)</span> with
some norm <span class="math inline">\(|.|\)</span>. Use the BCHD formula
(or part of its proof) to show that for small enough <span
class="math inline">\(x,y \in \mathfrak{g}\)</span>, <span id="eq:bchd-cons-0" class="math display">\[\label{eq:bchd-cons-0}\tag{7}
      x \ast y \ast (-x)
      =
      \exp({\mathop{\mathrm{ad}}}_x) y
      =
      y + [x,y]
      + \frac{[x,[x,y]]}{2}
      + \dotsb,\]</span> <span id="eq:bchd-cons-1" class="math display">\[\label{eq:bchd-cons-1}\tag{8}
      x \ast y
      =
      x +
      F_1({\mathop{\mathrm{ad}}}_x) y + O(|y|^2),
      \quad
      F_1(z) :=
      \frac{z}{1 - \exp(-z)}
      =
      1 + \frac{z}{2} + \dotsb,\]</span> <span id="eq:bchd-cons-2" class="math display">\[\label{eq:bchd-cons-2}\tag{9}
      x \ast (y-x)
      =
      F_2({\mathop{\mathrm{ad}}}_x) y + O(|y|^2),
      \quad
      F_2(z) :=
      \frac{\exp(z) - 1}{z}
      =
      1 + \frac{z}{2} + \dotsb.\]</span> Deduce that the quantities <a
href="#eq:lie-algebra-elements-that-are-similar"
data-reference-type="eqref"
data-reference="eq:lie-algebra-elements-that-are-similar">\((6)\)</a>
coincide up to a possible error of size <span
class="math inline">\(O(|x|^2 |y| + |y|^2)\)</span>. [Hint: For <a
href="#eq:bchd-cons-1" data-reference-type="eqref"
data-reference="eq:bchd-cons-1">\((8)\)</a> and <a
href="#eq:bchd-cons-2" data-reference-type="eqref"
data-reference="eq:bchd-cons-2">\((9)\)</a>, one can specialize
the BCHD formula directly. Alternatively, let <span
class="math inline">\(t \in \mathbb{R}\)</span> be small and let <span
class="math inline">\(f(t)\)</span> denote one of the expressions <span
class="math inline">\(x \ast t y\)</span> or <span
class="math inline">\(x \ast (t y - x)\)</span>. Then the BCH formula in
its qualitative form, together with Taylor’s theorem, reduces the
problem to computing <span class="math inline">\(f(0)\)</span> and <span
class="math inline">\(f&#39;(0)\)</span>. For this, Homework <a
href="#hw:diff-exp" data-reference-type="ref"
data-reference="hw:diff-exp">9</a> and <a href="#eq:diff-exp"
data-reference-type="eqref"
data-reference="eq:diff-exp">\((86)\)</a> may be helpful.]</p></li>
</ol>
</div>
<h2 id="sec:org3214742">§2.13. 11/3: Closed subgroups are Lie; virtual
subgroups vs. Lie subalgebras</h2>
<p><strong>Objectives.</strong> You should know the following trivia,
and some of their basic consequences:</p>
<ol>
<li><p>closed subgroups of a Lie group are the same as Lie
subgroups.</p></li>
<li><p>connected immersed Lie subgroups of a given Lie group correspond
to the Lie subalgebras of its Lie algebra.</p></li>
</ol>
<p><strong>Summary.</strong></p>
<ol>
<li><p>I explained how the BCH formula implies directly that
isomorphisms of Lie algebras lift to local isomorphisms of Lie groups,
and how Lie theory is the same whether one starts with "smooth
manifolds" or "analytic manifolds".</p></li>
<li><p>I stated the theorem that closed subgroups of Lie groups are Lie
subgroups, and indicated briefly how it implies that continuous
homomorphisms between Lie groups are automatically smooth (hence, by
BCH, analytic with respect to exponential coordinates). I then proved
that theorem.</p></li>
<li><p>I explained the correspondence between Lie subalgebras and
immersed Lie subgroups and briefly mentioned some ideas of the
proof.</p></li>
</ol>
<div id="hw:including-symplectic-group-etc" class="homework">
<p><strong>Homework 13</strong> (Due Nov 8).  </p>
<ol>
<li><p>Following the sketch indicated in lecture, write down a careful
proof that a continuous homomorphism of Lie groups <span
class="math inline">\(G \rightarrow H\)</span> is automatically
smooth.</p></li>
<li><p>Let <span class="math inline">\(n \geq 1\)</span>. Denote by
<span class="math inline">\(1_n\)</span> the <span
class="math inline">\(n \times n\)</span> identity matrix. Set <span
class="math inline">\(J :=
\begin{pmatrix}
      &amp; 1_n \\
      -1_n &amp;
    \end{pmatrix}\)</span>; it is a <span class="math inline">\(2 n
\times 2 n\)</span> matrix. Set <span
class="math display">\[{\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C})
      :=
      \{g \in {\mathop{\mathrm{SL}}}_{2n}(\mathbb{C}):
      g^t J g = J
      \}\]</span> <span
class="math display">\[{\mathop{\mathrm{Sp}}}_{2n}(\mathbb{R})
      :=
      {\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C}) \cap
{\mathop{\mathrm{SL}}}_{2n}(\mathbb{R})
      \}\]</span> and <span
class="math display">\[\mathop{\mathrm{Sp}}(2 n)
      := U(2 n) \cap {\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C}).\]</span> (In
practice, one alternates between writing <span
class="math inline">\(\mathop{\mathrm{Sp}}(2n)\)</span> and <span
class="math inline">\(\mathop{\mathrm{Sp}}(n)\)</span> to mean the same
thing. Beware conventions.) Check that this definition is the same as
what we gave earlier using quaternions. Show that <span
class="math inline">\(\mathop{\mathrm{Sp}}(2 n)\)</span> is a compact
real form of <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C})\)</span> and
that <span class="math display">\[\mathfrak{s}\mathfrak{p}_{2
n}(\mathbb{C}) := \mathop{\mathrm{Lie}}({\mathop{\mathrm{Sp}}}_{2
n}(\mathbb{C}))
      = \left\{
        \begin{pmatrix}
          a &amp; b \\
          c &amp; d
        \end{pmatrix}
: a,b,c,d \in M_n(\mathbb{C}),
        d = - a^t,
        b^t = b, c^t = c\right\}.\]</span> Show for <span
class="math inline">\(\mathbf{k} = \mathbb{R}, \mathbb{C}\)</span> and
<span class="math inline">\(a \in
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> and <span
class="math inline">\(b \in M_n(\mathbf{k})\)</span> with <span
class="math inline">\(b^t = b\)</span> that <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbf{k})\)</span>
contains the matrices <span class="math display">\[\begin{pmatrix}
        0_n &amp; 1_n \\
        -1_n &amp; 0_n
      \end{pmatrix}
,
      \quad
      \begin{pmatrix}
        a &amp;  \\
         &amp; {}^t a^{-1}
       \end{pmatrix}
,
       \quad
       \begin{pmatrix}
         1_n &amp; b \\
          &amp; 1_n
       \end{pmatrix}
.\]</span> Show that <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C})\)</span> and
<span class="math inline">\(\mathop{\mathrm{Sp}}(2 n)\)</span> are
connected and simply-connected. Show that <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{R})\)</span> is
connected, that <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{R}) \cap
\mathop{\mathrm{U}}(2n)\)</span> is isomorphic to <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>, and that <span
class="math inline">\(\pi_1({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{R})) \cong
\mathbb{Z}\)</span>. [Hint: one way is as follows. Study <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C})\)</span>
inductively on <span class="math inline">\(n\)</span> by considering the
natural action on <span class="math inline">\(\mathbb{C}^{2 n} -
\{0\}\)</span>, analyzing stabilizers, and using the homotopy exact
sequence. Study <span class="math inline">\(\mathop{\mathrm{Sp}}(2
n)\)</span> using the Cartan decomposition. Study <span
class="math inline">\({\mathop{\mathrm{Sp}}}_{2n}(\mathbb{R})\)</span>
using either the Cartan decomposition or the homotopy exact
sequence.]</p></li>
</ol>
</div>
<h2 id="sec:org6225804">§2.14. 11/8: Simplicity of Lie groups and Lie
algebras</h2>
<p><strong>Objectives.</strong> You should be able to explain what it
means for a Lie group to be “simple as a Lie group” and how this differs
from being simple as an abstract group.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>I defined what it means for Lie algebras and Lie groups to be
simple and proved the equivalence of the following assertions concerning
a connected Lie group:</p>
<ol>
<li><p>It is simple (no nontrivial proper normal connected virtual Lie
subgroups).</p></li>
<li><p>Its Lie algebra is simple (no nonzero proper ideals).</p></li>
<li><p>Its proper normal subgroups are discrete.</p></li>
</ol></li>
<li><p>I recalled the classical groups (complex forms, compact real
forms, Lie algebras) and stated as a motivating goal the theorem
describing when they are simple and what are the exceptional
isomorphisms between them.</p></li>
</ol>
<div class="homework">
<p><strong>Homework 14</strong> (Due Nov 15).  </p>
<ol>
<li><p>Check carefully that the following are equivalent for a connected
Lie group <span class="math inline">\(G\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> and connected virtual Lie
subgroup <span class="math inline">\(H\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span>:</p>
<ol>
<li><p><span class="math inline">\(H\)</span> is a normal subgroup of
<span class="math inline">\(G\)</span>.</p></li>
<li><p><span class="math inline">\(\mathop{\mathrm{Ad}}(G) \mathfrak{h}
\subseteq \mathfrak{h}\)</span></p></li>
<li><p><span class="math inline">\(\mathfrak{h}\)</span> is an ideal of
<span class="math inline">\(\mathfrak{g}\)</span>.</p></li>
</ol>
<p>[Hint: Exercise <a
href="#exercise:conjugation-and-Ad-are-intertwined-by-exponential"
data-reference-type="ref"
data-reference="exercise:conjugation-and-Ad-are-intertwined-by-exponential">22</a>
may be useful.]</p></li>
<li><ol>
<li><p>Prove by hand that <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
is simple.</p></li>
<li><p>Complete the following sentence: “a Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> is simple if and only if its
adjoint representation <span class="math inline">\(\mathop{\mathrm{ad}}:
\mathfrak{g} \rightarrow \mathop{\mathrm{GL}}(\mathfrak{g})\)</span> is
(...).” Explain then how we have already secretly proven that <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
is simple.</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:orgf1075d9">§2.15. 11/10: Simplicity of the special linear Lie
algebra</h2>
<p><strong>Objectives.</strong> You should be to analyze ideals in
classical Lie algebras by decomposing them into root spaces.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>We recalled briefly some facts we established long ago concerning
<span class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span>.</p></li>
<li><p>We recalled, with sketch of proof, the theorem from linear
algebra that commuting diagonalizable operators are simultaneously
diagonalizable. We then reformulated this result in terms of
representations of abelian Lie algebras.</p></li>
<li><p>We defined the set of weights of a semisimple representation of
an abelian Lie algebra, and illustrated the definition in the basic case
of the standard representation of the diagonal subalgebra of the matrix
algebra.</p></li>
<li><p>We defined the set of roots for the diagonal subalgebra of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
and described the root spaces and their commutation relations
explicitly.</p></li>
<li><p>We proved that <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
is simple by splitting any nonzero ideal as a sum of root spaces and
applying suitable commutators.</p></li>
</ol>
<div class="homework">
<p><strong>Homework 15</strong> (Due Nov 17).   Set <span
class="math inline">\(\mathfrak{g} :=
\mathfrak{s}\mathfrak{p}_{2n}(\mathbb{C})\)</span>. The main purpose of
this exercise is to carry out the analogue for <span
class="math inline">\(\mathfrak{g}\)</span> of what was done in lecture
for <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>.
We include some additional computations of independent interest; they
are straightforward but (I think) instructive.</p>
<ol>
<li><p>Recall the description of <span
class="math inline">\(\mathfrak{g}\)</span> from Homework <a
href="#hw:including-symplectic-group-etc" data-reference-type="ref"
data-reference="hw:including-symplectic-group-etc">13</a>. Verify that
<span class="math inline">\(\dim(\mathfrak{g}) = 2 n^2 + n\)</span>. For
<span class="math inline">\(1 \leq j, k \leq 2 n\)</span>, let <span
class="math inline">\(E_{j k} \in M_{2 n}(\mathbb{C})\)</span> denote
the elementary matrix with <span class="math inline">\(1\)</span> in the
<span class="math inline">\((i,j)\)</span>th entry and <span
class="math inline">\(0\)</span> elsewhere, thus <span
class="math inline">\(E_{j k} e_k = e_j\)</span> and <span
class="math inline">\(e_{j k} e_l = 0\)</span> for <span
class="math inline">\(l \neq k\)</span>, where <span
class="math inline">\(e_1,\dotsc,e_{2 n}\)</span> denotes the standard
basis of <span class="math inline">\(\mathbb{C}^{2 n}\)</span>. Verify
that a basis for <span class="math inline">\(\mathfrak{g}\)</span> is
given by elements of the following form, where <span
class="math inline">\(1 \leq j, k \leq n\)</span>:</p>
<ul>
<li><p><span class="math inline">\(E_{j j} -
E_{n+j,n+j}\)</span></p></li>
<li><p><span class="math inline">\(E_{j, k} - E_{n+k, n+j}\)</span> for
<span class="math inline">\(j \neq k\)</span></p></li>
<li><p><span class="math inline">\(E_{j,n+k} + E_{k,n+j}\)</span> for
<span class="math inline">\(j \leq k\)</span></p></li>
<li><p><span class="math inline">\(E_{n+j,k} + E_{n+k,j}\)</span> for
<span class="math inline">\(j \leq k\)</span></p></li>
</ul>
<p>Write all these elements out explicitly when <span
class="math inline">\(n = 2\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\mathfrak{h} \leq
\mathfrak{g}\)</span> denote the subalgebra of diagonal matrices. Then
<span class="math inline">\(\dim(\mathfrak{h}) = n\)</span>. Explicitly,
<span class="math inline">\(\mathfrak{h}\)</span> has the basis <span
class="math inline">\(E_{j j} - E_{n+j,n+j}\)</span> (<span
class="math inline">\(j=1,\dotsc,n\)</span>) and consists of of matrices
of the form <span id="eq:cartan-in-sp2n" class="math display">\[\label{eq:cartan-in-sp2n}\tag{10}
      H =
\begin{pmatrix}
        \lambda_1(H) &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; \dotsb &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; \lambda_n(H) &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; -\lambda_1(H) &amp; 0 &amp; 0\\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; \dotsb &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -\lambda_n(H)
      \end{pmatrix}
.\]</span> A basis for the dual space <span
class="math inline">\(\mathfrak{h}^*\)</span> consists of the elements
<span class="math inline">\(\lambda_1,\dotsc,\lambda_n\)</span> defined
by <a href="#eq:cartan-in-sp2n" data-reference-type="eqref"
data-reference="eq:cartan-in-sp2n">\((10)\)</a>, or
equivalently, by <span class="math inline">\(\lambda_k(E_{j j} -
E_{n+j,n+j}) := \delta_{j k}\)</span>.</p>
<p>Let <span class="math inline">\(R\)</span> denote the set of
<em>roots</em> for the pair <span
class="math inline">\((\mathfrak{g},\mathfrak{h})\)</span>, defined
exactly as in the case of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
to consist of all nonzero elements <span class="math inline">\(\alpha
\in \mathfrak{h}^*\)</span> for which the eigenspace <span
class="math display">\[\mathfrak{g}^\alpha := \left\{ X \in \mathfrak{g}
: [H,X]
        = \alpha(H) X \text{ for all }  H \in
\mathfrak{h}\right\}\]</span> is nonzero. The same argument as in
lecture shows that <span class="math display">\[\mathfrak{g} =
\mathfrak{h} \oplus (\oplus_{\alpha \in R}
\mathfrak{g}^\alpha).\]</span></p>
<p>Show that <span class="math display">\[R = \left\{ \pm (\lambda_j \pm
\lambda_k) : j &lt; k \right\} \cup \{ \pm 2 \lambda_k \},\]</span>
where the signs <span class="math inline">\(\pm\)</span> vary
independently. Verify that <span class="math inline">\(R\)</span> spans
<span class="math inline">\(\mathfrak{h}^*\)</span>.</p></li>
<li><p>For each <span class="math inline">\(\alpha \in R\)</span>:</p>
<ol>
<li><p>Verify that <span class="math inline">\(\{n \in \mathbb{Z} : n
\alpha \in R\} = \{\pm 1\}\)</span>.</p></li>
<li><p>Verify that <span class="math inline">\(\dim(\mathfrak{g}^\alpha)
= 1\)</span>.</p></li>
<li><p>Find an explicit basis element <span
class="math inline">\(X_\alpha \in
      \mathfrak{g}^\alpha\)</span>.</p></li>
<li><p>Show that there exists <span class="math inline">\(Y_\alpha \in
      \mathfrak{g}^{-\alpha}\)</span> so that the element <span
class="math inline">\(H_\alpha := [X_\alpha,Y_\alpha]\)</span> of <span
class="math inline">\(\mathfrak{h}\)</span> satisfies <span
class="math inline">\(\alpha(H_\alpha) = 2\)</span>; write down <span
class="math inline">\(H_\alpha\)</span> explicitly.</p></li>
<li><p>Verify that for all <span class="math inline">\(\alpha,\beta \in
R\)</span>, <span class="math display">\[=
\begin{cases}
        \mathfrak{g}^{\alpha + \beta} &amp; \text{ if } \alpha + \beta
\in R \\
        \mathbb{C} H_\alpha  &amp; \text{ if } \alpha + \beta = 0 \\
        0 &amp; \text{ otherwise.}
      \end{cases}\]</span></p></li>
<li><p>(Optional) Show that the subspace <span
class="math inline">\(\mathbb{C} H_\alpha \oplus \mathbb{C} X_\alpha
      \oplus \mathbb{C} Y_\alpha\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> is a Lie subalgebra that is
isomorphic to <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>.</p></li>
</ol></li>
<li><p>(Optional) Set <span class="math inline">\(S := \{\lambda_1 -
\lambda_2, \lambda_2 - \lambda_3,
    \dotsc,
    \lambda_{n-1} - \lambda_n, 2 \lambda_n \} \subseteq R\)</span>.
Verify that <span class="math inline">\(S\)</span> is a basis for <span
class="math inline">\(\mathfrak{h}^*\)</span> and that every <span
class="math inline">\(\beta \in R\)</span> may be written in the form
<span class="math inline">\(\beta = \sum_{\alpha \in S}
    m_\alpha \alpha\)</span>, where the <span
class="math inline">\(m_\alpha\)</span> are integers which are either
all <span class="math inline">\(\geq 0\)</span> or all <span
class="math inline">\(\leq 0\)</span>. Let <span
class="math inline">\(C\)</span> denote the set of all <span
class="math inline">\(\lambda \in \mathfrak{h}^*\)</span> for which
<span class="math inline">\(\lambda(H_\alpha) \geq 0\)</span> for all
<span class="math inline">\(\alpha \in S\)</span>. Verify that <span
class="math inline">\(C = \{l_1 \lambda_1 + \dotsb + l_n \lambda_n :
  l_1 \geq l_2 \geq \dotsb \geq l_{n-1} \geq |l_n|
  \}\)</span>.</p></li>
<li><p>By adapting the argument given in lecture for <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>,
prove that <span class="math inline">\(\mathfrak{g}\)</span> is simple.
[This is the only part of this homework that is not a straightforward
computation. The same argument as in lecture shows that no nonzero ideal
is contained in <span class="math inline">\(\mathfrak{h}\)</span>. The
key point is then to show that if an ideal contains one root space, then
it contains every other root space. For this, one can certainly imitate
the proof given in lecture, but it may be simpler to show that Lemma <a
href="#lemma:clean-way-to-get-simplicity" data-reference-type="ref"
data-reference="lemma:clean-way-to-get-simplicity">202</a> applies also
to <span
class="math inline">\(\mathfrak{s}\mathfrak{p}_{2n}(\mathbb{C})\)</span>
with <span class="math inline">\(\lambda_{\max} := 2 \lambda_1\)</span>;
the rest of the proof then goes through unmodified.]</p></li>
</ol>
</div>
<h2 id="sec:org808d1e4">§2.16. 11/22, 11/24: How to classify classical simple
complex Lie algebras</h2>
<p><strong>Objectives.</strong> You should be to classify classical
simple complex Lie algebras by computing their Dynkin diagrams. You
should be able to explain why this process is well-defined. You should
develop some intuition for the following important concepts by reference
to the classical examples: Cartan subalgebras, roots, simple roots,
positive roots, Cartan matrix, root reflections, Weyl group, Weyl
chambers and their relation with simple systems</p>
<p><strong>Summary.</strong> (Tuesday.) We recalled the classical simple
complex Lie algebras, explained (mechanically) how to compute their
Dynkin diagrams (by reference to the handout copied in §<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>),
and started explaining why the process of doing so is well-defined
(i.e., depends only upon the isomorphism class of the Lie algebra);
namely, we briefly discussed why Cartan subalgebras of classical simple
algebras are conjugate.</p>
<p>(Thursday.) We started explaining why the Cartan matrix (hence the
Dynkin diagram) is independent of the choice of simple root system. We
divided the proof into three parts:</p>
<ol>
<li><p>The definition of root reflections and the observation that each
root reflection stabilizes the set of roots.</p></li>
<li><p>The interpretation of root reflections as geometric reflections
with respect to the "obvious" inner product on the real span of the
roots.</p></li>
<li><p>The claim that the Weyl group, i.e., the group generated by the
root reflections, acts transitively on the sets of simple
systems.</p></li>
</ol>
<p>We explained how these points imply that the Cartan matrix is
independent of the simple system.</p>
<p>We did not explain why points 1,2 hold (other than by brute-force
inspection of the handout, §<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>);
we will return to them later. We started explaining point 3 by
introducing the real span of the roots, the regular subset of that span,
the Weyl chambers, the dominant Weyl chamber for a given simple system.
For each classical example, we described the root reflections, the Weyl
groups, the regular elements, and the dominant Weyl chambers explicitly.
For the low-dimensional families B<sub>2</sub> = C<sub>2</sub>,
A<sub>1</sub> and A<sub>2</sub>, we drew pictures of the root systems,
indicating the simple roots, the irregular hyperplanes, the Weyl
chambers, the dominant Weyl chamber, etc. We observed that the number of
Weyl chambers is the same as the order of the Weyl group in those
examples. We stated the theorem that simple systems and Weyl chambers
are in natural bijection with each other, equivariantly for the action
of the Weyl group, and that the Weyl group acts simply transitively on
the set of Weyl chambers. We described both directions of the bijection
between simple systems and Weyl chambers, without yet proving that we
get well-defined bijections in this way; we explicated the bijection in
the case of A<sub>2</sub>. We explained how these facts imply that the
Weyl group acts simply-transitively on the set of simple systems.</p>
<div class="homework">
<p><strong>Homework 16</strong> (Due Nov 29).  </p>
<ol>
<li><p>(Optional, but highly recommended) Carefully study the
computation of the Cartan matrices <span
class="math inline">\(N\)</span> on the handout, §<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>.
Check that all entries are as they should be; report to me any errors
that you find. (I worked them out by hand; it might be a healthy
exercise to redo them.) Verify by inspection that the formula <span
class="math display">\[\alpha(H_\beta)
    = 2 \frac{(\alpha,\beta)}{(\beta,\beta)}.\]</span> holds (see §<a
href="#sec:cartan-via-inner-products" data-reference-type="ref"
data-reference="sec:cartan-via-inner-products">29.9</a>
for details).</p></li>
<li><p>Let <span class="math inline">\(X :=
\begin{pmatrix}
      0 &amp; 1 \\
      0 &amp; 0
    \end{pmatrix}
\in \mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>. Show
that <span class="math inline">\({\mathop{\mathrm{ad}}}_X\)</span> is not
semisimple (i.e., diagonalizable). Show that <span
class="math inline">\(\mathbb{C} X\)</span> is a maximal abelian
subalgebra of <span class="math inline">\(\mathfrak{g}\)</span> (i.e.,
that if <span class="math inline">\(\mathfrak{h}\)</span> is an abelian
subalgebra of <span class="math inline">\(\mathfrak{g}\)</span> that
contains <span class="math inline">\(\mathbb{C} X\)</span>, then <span
class="math inline">\(\mathfrak{h} = \mathbb{C} X\)</span>.</p></li>
<li><p>Which of the classical simple complex Lie algebras have the
property that there exists an element <span
class="math inline">\(w\)</span> of the Weyl group for which <span
class="math inline">\(w(\alpha) = -\alpha\)</span> for all roots <span
class="math inline">\(\alpha\)</span>?</p></li>
<li><p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a
classical simple complex Lie algebra with Weyl group <span
class="math inline">\(W\)</span>. Equip <span
class="math inline">\(\mathfrak{g}\)</span> with the scalar product
<span class="math inline">\((,)\)</span> as in lecture or as in §<a
href="#sec:cartan-via-inner-products" data-reference-type="ref"
data-reference="sec:cartan-via-inner-products">29.9</a>.</p>
<ol>
<li><p>Suppose <span class="math inline">\(\mathfrak{g} = A_n\)</span>
or <span class="math inline">\(D_n\)</span>. Verify (by inspecting the
handout (§<a href="#sec:dynkin-diagrams-classical-examples"
data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>),
say) that <span class="math inline">\((\alpha,\alpha) = 2\)</span> for
all roots <span class="math inline">\(\alpha \in R\)</span>. Verify that
<span class="math inline">\(W\)</span> acts transitively on <span
class="math inline">\(R\)</span>.</p></li>
<li><p>Suppose <span class="math inline">\(\mathfrak{g} = B_n\)</span>
or <span class="math inline">\(C_n\)</span>. Observe that <span
class="math inline">\((\alpha,\alpha)\)</span> takes two distinct values
as <span class="math inline">\(\alpha\)</span> traverses <span
class="math inline">\(R\)</span>; call <span
class="math inline">\(\alpha\)</span> <em>long</em> or <em>short</em>
according as it takes the larger or the smaller of these values.</p>
<ol>
<li><p>Verify (by inspecting the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>))
that <span class="math inline">\(W\)</span> acts transitively on the set
of long roots and also on the set of short roots.</p></li>
<li><p>Verify that for each root <span
class="math inline">\(\alpha\)</span> there is a root <span
class="math inline">\(\beta\)</span> so that <span
class="math inline">\(\gamma := \alpha + \beta\)</span> is a root and
<span class="math inline">\((\alpha,\alpha) \neq
(\gamma,\gamma)\)</span>.</p></li>
</ol></li>
</ol>
<p>Remark: we may explain next week how these observations yield new
proofs of the simplicity of <span
class="math inline">\(\mathfrak{g}\)</span>, “simpler” than the proofs
we gave earlier; the key point will be to explain why the Weyl group
<span class="math inline">\(W\)</span> permutes the root spaces
belonging to any ideal.</p></li>
<li><p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a
classical simple complex Lie algebra, and let notation be otherwise as
usual; in particular, <span class="math inline">\(S \subset R\)</span>
is the “standard” simple system, <span
class="math inline">\(R^+\)</span> the associated set of positive roots,
and <span class="math inline">\((,)\)</span> the standard inner
product.</p>
<ol>
<li><p>Verify that if <span class="math inline">\(\alpha,\beta \in
S\)</span> are distinct simple roots, then <span
class="math inline">\((\alpha,\beta) \leq 0\)</span>, or equivalently,
<span class="math inline">\(\alpha(H_\beta), \beta(H_\alpha) \leq
0\)</span>. [The intention here is to observe that this holds in every
example; we will explain “why” next week.]</p></li>
<li><p>Verify that if <span class="math inline">\(\alpha \in S\)</span>
is a simple root, then the root reflection <span
class="math inline">\(s_\alpha\)</span> stabilizes the set <span
class="math inline">\(R^+ - \{\alpha \}\)</span> consisting of all
positive roots other than <span class="math inline">\(\alpha\)</span>.
[This can be verified by inspection; alternatively, use the previous
part of this exercise and appeal to the definition of “simple system”
and the observation that <span class="math inline">\(\{n \in \mathbb{Z}
: n \alpha \in R\} = \{\pm 1\}\)</span>.]</p></li>
<li><p>Let <span class="math inline">\(\rho := (1/2) \sum_{\alpha \in
R^+} \alpha \in
      \mathfrak{h}^*\)</span> denote the half-sum of positive roots.
Compute that <span id="eqn:explicit-rho-half-sum-computation-classical-families" class="math display">\[\label{eqn:explicit-rho-half-sum-computation-classical-families}\tag{11}
        \rho
        =
\begin{cases}
          \sum_{j=1}^n
          \frac{n + 1 - 2 j}{2} \lambda_j
           &amp; \mathfrak{g} = A_{n-1} \\
           \sum_{j=1}^n
           (n + \frac{1}{2} - j) \lambda_j
           &amp; \mathfrak{g} = B_n \\
           \sum_{j=1}^n
           (n + 1 - j) \lambda_j
           &amp; \mathfrak{g} = C_n \\
           \sum_{j=1}^n
           (n-j) \lambda_j
           &amp; \mathfrak{g} = D_n.
        \end{cases}\]</span> Show for each <span
class="math inline">\(\alpha \in S\)</span> that <span id="eqn:explicit-rho-half-sum-computation-classical-families-consequence-1" class="math display">\[\label{eqn:explicit-rho-half-sum-computation-classical-families-consequence-1}\tag{12}
        s_\alpha \rho = \rho - \alpha,\]</span> or equivalently, that
<span id="eqn:explicit-rho-half-sum-computation-classical-families-consequence-2" class="math display">\[\label{eqn:explicit-rho-half-sum-computation-classical-families-consequence-2}\tag{13}
        \rho(H_\alpha) = 1.\]</span> [The two assertions are obviously
equivalent. The first assertion <a
href="#eqn:explicit-rho-half-sum-computation-classical-families-consequence-1"
data-reference-type="eqref"
data-reference="eqn:explicit-rho-half-sum-computation-classical-families-consequence-1">\((12)\)</a>
can be deduced from the previous part. The second assertion <a
href="#eqn:explicit-rho-half-sum-computation-classical-families-consequence-2"
data-reference-type="eqref"
data-reference="eqn:explicit-rho-half-sum-computation-classical-families-consequence-2">\((13)\)</a>
may be compared with <a
href="#eqn:explicit-rho-half-sum-computation-classical-families"
data-reference-type="eqref"
data-reference="eqn:explicit-rho-half-sum-computation-classical-families">\((11)\)</a>.]</p></li>
<li><p>Verify that if <span class="math inline">\(\alpha \in R^+ -
S\)</span> is a positive root that is not simple, then there exist
positive roots <span class="math inline">\(\beta, \gamma \in
R^+\)</span> such that <span class="math inline">\(\alpha = \beta +
\gamma\)</span>. [This is unrelated to the previous parts of this
exercise; the intention is to observe that it holds in all
examples.]</p></li>
<li><p>Let <span class="math inline">\(\lambda \in
\mathfrak{h}^*_\mathbb{R}\)</span> be a regular element. Verify that
<span class="math inline">\(\{w \in W : w (\lambda) = \lambda \} =
      \{1\}\)</span>. [This is again unrelated to the previous parts of
this exercise; the intent is that you verify it using the explicit
description of <span class="math inline">\(W\)</span>.]</p></li>
</ol></li>
<li><p>(Optional) The exceptional isomorphisms between classical complex
simple Lie algebras that we have not already seen are the following:</p>
<ol>
<li><p><span class="math inline">\(A_3 \cong D_3\)</span>, i.e., <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_4(\mathbb{C})
\cong
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{6}(\mathbb{C})\)</span>. On
the group level, denote by <span class="math display">\[V := \Lambda^2
\mathbb{C}^4
      = \oplus_{i &lt; j} \mathbb{C} e_i \wedge e_j\]</span> the
six-dimensional vector space given by the exterior square of <span
class="math inline">\(\mathbb{C}^4\)</span>. Equip it with the quadratic
form <span class="math inline">\(Q : V \rightarrow \mathbb{C}\)</span>
defined by requiring that <span class="math inline">\(v \wedge v = Q(v)
e_1 \wedge e_2 \wedge e_3 \wedge e_4\)</span>. Then <span
class="math inline">\((V,Q)\)</span> is a quadratic space (see §<a
href="#sec:low-rank-exceptional-isomorphisms" data-reference-type="ref"
data-reference="sec:low-rank-exceptional-isomorphisms">18.5</a>)
and the natural map <span class="math inline">\(\Lambda^2 :
{\mathop{\mathrm{SL}}}_4(\mathbb{C}) \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> given by <span
class="math inline">\(\Lambda^2(g) (v_1 \wedge v_2)
      := g v_1 \wedge g v_2\)</span> defines a covering morphism <span
class="math inline">\(\Lambda^2 : {\mathop{\mathrm{SL}}}_4(\mathbb{C})
\rightarrow \mathop{\mathrm{SO}}(V) \cong
{\mathop{\mathrm{SO}}}_6(\mathbb{C})\)</span>.</p></li>
<li><p><span class="math inline">\(C_2 \cong B_2\)</span>, i.e., <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{p}}}}_4(\mathbb{C})
\cong
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{5}(\mathbb{C})\)</span>.
[Restrict the map <span
class="math inline">\({\mathop{\mathrm{SL}}}_4(\mathbb{C}) \rightarrow
      {\mathop{\mathrm{SO}}}_6(\mathbb{C})\)</span> to <span
class="math inline">\({\mathop{\mathrm{Sp}}}_4(\mathbb{C})\)</span>; show
that its image is the stabilizer of a one-dimensional subspace <span
class="math inline">\(L\)</span> of <span
class="math inline">\(V\)</span>, hence identifies with the orthogonal
group of the orthogonal complement <span
class="math inline">\(L^\perp\)</span>. One can read off <span
class="math inline">\(L\)</span> from the definition of <span
class="math inline">\({\mathop{\mathrm{Sp}}}_4(\mathbb{C})\)</span>.]</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:org6f2526e">§2.17. 11/29: 11/31: Why simple Lie algebras give rise
to root systems</h2>
<p><strong>Objectives.</strong> You should be able to use <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}\textsubscript{2}\)</span>-triples
to explain why simple complex Lie algebras (which contain Cartan
subalgebras satisfying the expected properties) give rise to root
systems.</p>
<p><strong>Summary.</strong> (Tuesday.)</p>
<ol>
<li><p>We finished the proof from last time that the Weyl group of a
classical simple complex Lie algebra acts transitively on the simple
systems; this was deduced by choosing an element that maximizes the
inner product of a pair of elements of the corresponding Weyl chambers
and verifying that the map from simple systems to Weyl chambers is
one-to-one.</p></li>
<li><p>We stated the definition of a Cartan subalgebra of a simple
complex Lie algebra and the theorem concerning the existence and
uniqueness of such subalgebras; we included in this theorem also</p>
<ul>
<li><p>the existence of a real form of the Cartan subalgebra on which
the roots are real-valued, and</p></li>
<li><p>the existence of a scalar product on the ambient Lie algebra
(i.e., a non-degenerate symmetric bilinear form) whose restriction to
the real form of the Cartan subalgebra is positive-definite.</p></li>
</ul>
<p>We observed that the conclusion of this theorem holds for the
classical families "by inspection" and gave a reference for the general
case; discussing its proof would take us too far afield from (what I
think are) more interesting topics to present in a first course on Lie
groups.</p></li>
<li><p>We stated the definition of a (reduced) root system: it is a
finite subset of a real inner product space that satisfies some axioms
that we had observed empirically last week.</p></li>
<li><p>We stated the theorem that simple complex Lie algebras
(satisfying the conclusion of the "Cartan subalgebra theorem") give rise
to root systems. Our aim next time is to prove this theorem.</p></li>
</ol>
<p>(Thursday.) We explained in detail how <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}\textsubscript{2}\)</span>-triples
allow us to prove that simple Lie algebras possessing Cartan subalgebras
give rise to root systems that satisfy the various properties we had
observed for the classical families.</p>
<div id="hw:Falphaz" class="homework">
<p><strong>Homework 17</strong> (Due Dec 6). The main purposes of the
lectures this week were to demystify last week’s observations concerning
root systems for the classical Lie algebras and to demonstrate the power
of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
in proving results about more general Lie algebras. This week there is
one multipart exercise whose purpose is to complement that discussion by
showing how one might instead use <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> to
establish such properties.</p>
<p>Thus, let <span class="math inline">\(\mathfrak{g}\)</span> be a
simple Lie algebra over <span class="math inline">\(\mathbb{C}\)</span>,
let <span class="math inline">\(\mathfrak{h} \leq \mathfrak{g}\)</span>
be a Cartan subalgebra with real form <span
class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span> so that the set
<span class="math inline">\(R\)</span> of roots of <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{h}
  \rightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span> satisfies
<span class="math inline">\(R \subseteq \mathfrak{h}_\mathbb{R}^*  =
  {\mathop{\mathrm{Hom}}}_\mathbb{R}(\mathfrak{h}_\mathbb{R},\mathbb{R})
  \cong \{\lambda \in \mathfrak{h}^* : \lambda(\mathfrak{h}_\mathbb{R})
\subseteq \mathbb{R} \}\)</span>. Fix <span class="math inline">\(\alpha
\in R\)</span>. Assume given nonzero elements <span
class="math inline">\(X_\alpha \in
  \mathfrak{g}^\alpha,
  Y_\alpha \in \mathfrak{g}^{-\alpha}, H_\alpha \in
  \mathfrak{h}_\mathbb{R}\)</span> satisfying the relations indicated
just before the statement of Lemma <a
href="#lem:root-spaces-one-dimensional" data-reference-type="ref"
data-reference="lem:root-spaces-one-dimensional">240</a>, so that the
map <span class="math display">\[\phi_\alpha :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
  \rightarrow \mathfrak{s}_\alpha  := \mathbb{C} X_\alpha
  \oplus \mathbb{C} H_\alpha \oplus \mathbb{C} Y_\alpha
  \subseteq \mathfrak{g}\]</span> given by <span
class="math inline">\(X,Y,H \mapsto X_\alpha,Y_\alpha,H_\alpha\)</span>
is an isomorphism of Lie algebras. Finally, fix a complex Lie group
<span class="math inline">\(G\)</span> so that <span
class="math inline">\(\mathfrak{g} =
\mathop{\mathrm{Lie}}(G)\)</span>.</p>
<p>Our aim here is to give alternative proofs (using Lie group methods
rather than Lie algebra methods) of the first part of Lemma <a
href="#lem:alpha-string-thru-beta-description" data-reference-type="ref"
data-reference="lem:alpha-string-thru-beta-description">242</a>. Thus,
it would be best not to invoke the statement of that lemma in the
arguments to follow.</p>
<ol>
<li><p>Show that there is a morphism of complex Lie groups <span
class="math inline">\(F_\alpha : {\mathop{\mathrm{SL}}}_2(\mathbb{C})
\rightarrow G\)</span> so that <span class="math inline">\(d F_\alpha =
\phi_\alpha\)</span>.</p>
<p>For an element <span class="math inline">\(t\)</span> of any complex
vector space on which <span class="math inline">\(\exp\)</span> is
defined (e.g., <span class="math inline">\(t\)</span> can be a complex
scalar or an element of a Lie algebra over <span
class="math inline">\(\mathbb{C}\)</span>), introduce the abbreviation
<span class="math inline">\(e(t) := \exp(2 \pi i t)\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(e(H) = 1\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(e(H_\alpha) =
1\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\beta \in R\)</span>. Show for
<span class="math inline">\(t \in \mathbb{C}\)</span> and <span
class="math inline">\(v \in \mathfrak{g}^\beta\)</span> that <span
class="math inline">\(\mathop{\mathrm{Ad}}(e(t H_\alpha)) v = e(t
\beta(H_\alpha)) v\)</span>.</p></li>
<li><p>Deduce that <span class="math inline">\(e(\beta(H_\alpha)) =
1\)</span>, hence that <span class="math inline">\(\beta(H_\alpha) \in
\mathbb{Z}\)</span>.</p></li>
<li><p>Set <span class="math inline">\(w :=
\begin{pmatrix}
      0 &amp; 1 \\
      -1 &amp; 0
    \end{pmatrix}
\in {\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>. Verify that <span
class="math inline">\(w = e^X e^{-Y} e^X\)</span> and that <span
class="math inline">\(\mathop{\mathrm{Ad}}(w) H = - H\)</span>.</p></li>
<li><p>Set <span class="math inline">\(w_\alpha := F_\alpha(w) \in
G\)</span>. Show that <span
class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha) H_\alpha = -
H_\alpha\)</span> and that <span
class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha)^2 =
1\)</span>.</p></li>
<li><p>Suppose <span class="math inline">\(H \in \mathfrak{h}\)</span>
satisfies <span class="math inline">\(\alpha(H) = 0\)</span>.</p>
<ol>
<li><p>Show that <span class="math inline">\([x,H] = 0\)</span> for all
<span class="math inline">\(x \in
      \mathfrak{s}_\alpha\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(\mathop{\mathrm{Ad}}(g) H =
H\)</span> for all <span class="math inline">\(g\)</span> in the image
of <span class="math inline">\(F_\alpha\)</span>. Deduce in particular
that <span class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha) H =
H\)</span>.</p></li>
</ol></li>
<li><p>Deduce that <span
class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha) \mathfrak{h} =
\mathfrak{h}\)</span>.</p></li>
<li><p>Recall that for <span class="math inline">\(\lambda \in
\mathfrak{h}^*\)</span>, we set <span class="math inline">\(s_\alpha
\lambda := \lambda - \lambda(H_\alpha)
    \alpha\)</span>. Show that for all <span class="math inline">\(H \in
\mathfrak{h}\)</span>, one has <span
class="math display">\[\lambda(\mathop{\mathrm{Ad}}(w_\alpha) H) =
(s_\alpha \lambda)(H).\]</span></p></li>
<li><p>For any <span class="math inline">\(\lambda \in
\mathfrak{h}^*\)</span>, set <span
class="math inline">\(\mathfrak{g}^\lambda := \{v \in \mathfrak{g} :
[H,v] =
    \lambda(H) v \text{ for all } H \in \mathfrak{h}\}\)</span>. Show
that <span class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha)\)</span>
induces a well-defined isomorphism <span
class="math display">\[\mathop{\mathrm{Ad}}(w_\alpha) :
\mathfrak{g}^{\lambda} \rightarrow
\mathfrak{g}^{s_\alpha(\lambda)}.\]</span></p></li>
<li><p>Deduce in particular that if <span class="math inline">\(\beta
\in R\)</span>, then <span class="math inline">\(s_\alpha(\beta) \in
R\)</span>.</p></li>
</ol>
</div>
<h2 id="sec:orge92c104">§2.18. 12/6: Complex reductive vs. compact real</h2>
<p><strong>Objectives.</strong> You should be able to explain the
relationships between complex simple Lie algebras, complex semisimple
Lie algebras, complex reductive Lie algebras, and compact real Lie
algebras.</p>
<p><strong>Summary.</strong></p>
<ol>
<li><p>We explained that the association constructed in previous weeks
from</p>
<ol>
<li><p>simple complex Lie algebras to</p></li>
<li><p>irreducible reduced root systems to</p></li>
<li><p>connected Dynkin diagrams</p></li>
</ol>
<p>is bijective, and indicated briefly how the Serre relations explain
this (without proving them).</p></li>
<li><p>We defined semisimple and reductive Lie algebras and indicated
how the above bijection generalizes to them.</p></li>
<li><p>We defined compact real Lie algebras and explained why the Lie
algebra of any compact real Lie group is compact; we stated the theorem
that every compact real Lie algebra arises in this way.</p></li>
<li><p>We stated the theorem that compact real Lie algebras and complex
reductive Lie algebras are in natural bijection. We gave a proof using
the unitary trick and the Serre relations.</p></li>
</ol>
<h2 id="sec:org291b534">§2.19. 12/8: Compact Lie groups: center, fundamental
group</h2>
<p><strong>Objectives.</strong> You should be able to describe the
center and fundamental group of a copmact Lie group in terms of its
root/weight lattices and the kernel of the exponential map.</p>
<p><strong>Summary.</strong> We defined the root, weight, coroot and
coweight lattices of a semisimple Lie algebra as well as the lattices of
integral elements attached to a compact Lie group. We explained how the
center and fundamental group are described in terms of these, and
illustrate with the examples of tori and <span
class="math inline">\({\mathop{\mathrm{SL}}}_n\)</span>.</p>
<div class="homework">
<p><strong>Homework 18</strong> (Due Dec 13).   Let <span
class="math inline">\(K\)</span> be a compact Lie group with finite
center. Let other notation be as in §<a href="#sec:center-pi1-compact"
data-reference-type="ref"
data-reference="sec:center-pi1-compact">32</a>.
Thus <span class="math inline">\(\mathfrak{h}\)</span> be a Cartan
subalgebra of a complex semisimple Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Let <span
class="math inline">\(R\)</span> be the set of roots and <span
class="math inline">\(S \subseteq R\)</span> a base. Let <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span> denote the span
of <span class="math inline">\(R\)</span> and <span
class="math inline">\(\mathfrak{h}_\mathbb{R} := \{H \in \mathfrak{h} :
    \alpha(H) \in \mathbb{R}
    \text{ for all } \alpha \in R\}\)</span>, as usual.</p>
<ol>
<li><p>Verify that the Weyl group <span class="math inline">\(W\)</span>
(generated by the <span class="math inline">\(s_\alpha\)</span> for
<span class="math inline">\(\alpha \in R\)</span>, as usual) acts on the
root and weight lattices. Verify that the transposes of elements of the
Weyl group act on the coroot and coweight lattices. One can thus form
the semidirect product <span class="math inline">\(W \ltimes \mathbb{Z}
R^\wedge\)</span>.</p></li>
<li><p>Let <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}} =
\{H \in
    \mathfrak{h}_\mathbb{R} : \alpha(H) \notin \mathbb{Z} \text{
      for all } \alpha\in R \}\)</span>.</p>
<ol>
<li><p>Verify that <span class="math inline">\(W\)</span> acts on <span
class="math inline">\(\mathfrak{h}_{\mathbb{R}}^{\mathop{\mathrm{sreg}}}\)</span>.</p></li>
<li><p>Verify that <span class="math inline">\(\mathbb{Z}
R^\wedge\)</span> acts on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>
(by translation).</p></li>
<li><p>Verify that the actions of <span class="math inline">\(W\)</span>
and <span class="math inline">\(\mathbb{Z} R^\wedge\)</span> on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span> induce an action
of their semidirect product <span class="math inline">\(W \ltimes
      \mathbb{Z} R^\wedge\)</span> on <span
class="math inline">\(\mathfrak{h}_{\mathbb{R}}\)</span>, preserving
<span
class="math inline">\(\mathfrak{h}_{\mathbb{R}}^{\mathop{\mathrm{sreg}}}\)</span>.
Let <span class="math inline">\(T \leq
\mathop{\mathrm{GL}}(\mathfrak{h}_{\mathbb{R}})\)</span> denote the
image of <span class="math inline">\(W \ltimes \mathbb{Z}
      R^\wedge\)</span>.</p></li>
<li><p>Let <span class="math inline">\(n \in \mathbb{Z}\)</span>, <span
class="math inline">\(\alpha \in R\)</span>. Let <span
class="math inline">\(s_{\alpha,n} : \mathfrak{h}_{\mathbb{R}}
\rightarrow
      \mathfrak{h}_{\mathbb{R}}\)</span> be the reflection in the
hyperplane <span class="math inline">\(\alpha(H) = n\)</span>, thus
<span class="math inline">\(s_{\alpha,n}(H) = H - (\alpha(H) - n)
H_\alpha\)</span>. Show that <span
class="math inline">\(s_{\alpha,n}\)</span> belongs to <span
class="math inline">\(T\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(T\)</span> is generated by
the <span class="math inline">\(s_{\alpha,n}\)</span>.</p></li>
</ol></li>
<li><p>Choose an enumeration <span class="math inline">\(S =
\{\alpha_1,\dotsc,\alpha_l\}\)</span>.</p>
<ol>
<li><p>Show that the <span
class="math inline">\(\mathbb{Z}\)</span>-span <span
class="math inline">\(\mathbb{Z} R\)</span> is has basis <span
class="math inline">\(S\)</span> in the sense that <span
class="math inline">\(\mathbb{Z} R = \mathbb{Z} \alpha_1 \oplus
      \dotsb \oplus \mathbb{Z} \alpha_l\)</span>.</p></li>
<li><p>Show that there exist unique elements <span
class="math inline">\(\pi_1,\dotsc,\pi_l \in
\mathfrak{h}_\mathbb{R}\)</span> so that <span
class="math inline">\(H_{\alpha_i}(\pi_j) = \delta_{i j}\)</span> for
all <span class="math inline">\(i,j
      \in \{1..l\}\)</span>. (These are called the <em>fundamental
weights</em>.)</p></li>
<li><p>Show that <span class="math inline">\((\mathbb{Z} R^\wedge)^* =
\mathbb{Z} \pi_1
      \oplus
      \dotsb \oplus \mathbb{Z} \pi_l\)</span>.</p></li>
<li><p>Show that matrix <span class="math inline">\((a_{i j})\)</span>
for which <span class="math inline">\(\alpha_i = \sum_j a_{i j}
\pi_j\)</span> is given by the Cartan matrix.</p></li>
<li><p>(Optional) Compute <span class="math inline">\(\pi_1, \dotsc,
\pi_l\)</span> for the classical families. (This can be done by hand, or
by inverting the Cartan matrix.)</p></li>
</ol></li>
</ol>
</div>
<h2 id="sec:org070bbf1">§2.20. 12/13 Maximal tori in compact Lie groups</h2>
<p><strong>Objectives.</strong> You should be able to explain the role
played by maximal tori in the study of compact connected Lie groups.</p>
<p><strong>Summary.</strong> (Tuesday) See §<a
href="#sec:tori-compact-lie-gps" data-reference-type="ref"
data-reference="sec:tori-compact-lie-gps">33</a>
for details. Throughout, let <span class="math inline">\(K\)</span> be a
compact connected Lie group.</p>
<ol>
<li><p>We defined tori, and characterized them as compact connected
abelian Lie groups.</p></li>
<li><p>We defined maximal tori in <span class="math inline">\(K\)</span>
and characterized them as closed connected subgroups whose Lie algebras
are maximal abelian subalgebras.</p></li>
<li><p>We recorded that closed connected abelian subgroups of <span
class="math inline">\(K\)</span> are tori.</p></li>
<li><p>As an example of the latter, we gave the connected components of
closures of subgroups generated by individual elements.</p></li>
<li><p>We indicated why the Lie algebras of maximal tori give rise to
Cartan subalgebras after taking complexifications.</p></li>
<li><p>We stated (without proof yet) the big theorem that <span
class="math inline">\(K\)</span> is the union of the conjugates of any
one of its maximal tori.</p></li>
<li><p>We derived from this the consequence that the center of <span
class="math inline">\(K\)</span> is the intersection of all (maximal)
tori and indicated briefly how this implies the description given last
time of the center in terms of roots.</p></li>
</ol>
<p>(Thursday) See §<a href="#sec:tori-compact-lie-gps"
data-reference-type="ref"
data-reference="sec:tori-compact-lie-gps">33</a>
for details.</p>
<ol>
<li><p><span
class="math inline">\(\mathop{\mathrm{Aut}}(T)\)</span></p></li>
<li><p><span class="math inline">\(N(T)_0\)</span></p></li>
<li><p><span class="math inline">\(\Lambda(f)\)</span></p></li>
<li><p>Proof.</p></li>
<li><p><span class="math inline">\(T_1, T_2\)</span></p></li>
<li><p><span class="math inline">\(Z(T) = T\)</span></p></li>
</ol>
<h1 id="sec:org814ace2">§3. Selected homework solutions</h1>
<ul>
<li><p>Homework <a href="#hw:2" data-reference-type="ref"
data-reference="hw:2">2</a>, 2d. Here is a quick and fairly intuitive
way to see that <span class="math inline">\(G :=
\mathop{\mathrm{SO}}(1,2)\)</span> has two connected components. (We’ve
seen later in the course that this is established more efficiently using
the Cartan decomposition.) We realize <span
class="math inline">\(G\)</span> as a subgroup of <span
class="math inline">\({\mathop{\mathrm{SL}}}_3(\mathbb{R})\)</span> in the
evident way. It contains the subgroups <span class="math display">\[H_1
:=
  \left\{
    \begin{pmatrix}
      a &amp; b &amp; 0 \\
      c &amp; d &amp; 0 \\
      0 &amp; 0 &amp; 1
    \end{pmatrix}
:
    \begin{pmatrix}
      a &amp; b \\
      c &amp; d
    \end{pmatrix}
\in \operatorname{O}(1,1)
  \right\}\]</span> and <span class="math display">\[H_2 :=
  \left\{
    \begin{pmatrix}
      1 &amp; 0 &amp; 0 \\
      0 &amp; a &amp; b \\
      0 &amp; c &amp; d
    \end{pmatrix}
    :
    \begin{pmatrix}
      a &amp; b \\
      c &amp; d
    \end{pmatrix}
\in \mathop{\mathrm{SO}}(2)
  \right\}.\]</span> Note that <span class="math inline">\(H_2\)</span>
is connected, so <span class="math inline">\(H_2 \subseteq
G^0\)</span>.</p>
<p>Let <span class="math inline">\(V_1\)</span> be as in the homework
problem. Let <span class="math inline">\(V_1^+\)</span> denote the
connected component containing <span class="math inline">\(e_1\)</span>,
and <span class="math inline">\(V_1^-\)</span> the other component.
(Thus <span class="math inline">\(V_1^+ = V_1^0\)</span> in the notation
of the homework problem.) We now make the following observations:</p>
<ol>
<li><p>Since <span class="math inline">\(V_1^{\pm}\)</span> is connected
and <span class="math inline">\(G\)</span> acts on <span
class="math inline">\(V_1 = \cup_{\pm} V_1^{\pm}\)</span>, for each
<span class="math inline">\(g \in G\)</span> we have either <span
class="math inline">\(g V_1^+ \subseteq V_1^+\)</span> or <span
class="math inline">\(g V_1^+ \subseteq V_1^-\)</span>. It follows that
<span class="math inline">\(G\)</span> permutes the two connected
components <span class="math inline">\(V_1^{\pm}\)</span> of <span
class="math inline">\(V_1\)</span>, and so the subgroup <span
class="math inline">\(\{g \in G : g V_1^+ \subseteq V_1^+\}\)</span> of
<span class="math inline">\(G\)</span> has index at most <span
class="math inline">\(2\)</span>.</p></li>
<li><p>There exist elements <span class="math inline">\(g \in G\)</span>
which map <span class="math inline">\(V_1^+\)</span> to <span
class="math inline">\(V_1^-\)</span>, and vice-versa. For instance, one
can take <span class="math inline">\(g :=
\mathop{\mathrm{diag}}(-1,-1,1)\)</span>. The subgroup <span
class="math inline">\(\{g \in G : g V_1^+ \subseteq V_1^+\}\)</span> of
<span class="math inline">\(G\)</span> thus has index exactly <span
class="math inline">\(2\)</span>.</p></li>
<li><p>Since <span class="math inline">\(V_1^+\)</span> is connected, we
have <span class="math inline">\(G^0 \subseteq \{g \in G : g V_1^+
\subseteq V_1^+\}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(v \in V_1^+\)</span>. It is of
the form <span class="math inline">\(v = (x,y,z)\)</span> with <span
class="math inline">\(x^2 - y^2 - z^2 = 1\)</span>. Choose an element
<span class="math inline">\(h_2 \in H_2\)</span> so that <span
class="math inline">\(h_2 v = (x,r,0)\)</span>, where <span
class="math inline">\(r = \sqrt{y^2 + z^2}\)</span>. By part 1b of the
same homework, we can then find <span class="math inline">\(h_1 \in
H_1^0\)</span> so that <span class="math inline">\(h_2 v = h_1
e_1\)</span>. Consequently <span class="math inline">\(v = g
e_1\)</span> where <span class="math inline">\(g := h_2^{-1} h_1 \in
G^0\)</span>.</p></li>
<li><p>Now let <span class="math inline">\(g \in G\)</span> with <span
class="math inline">\(g V_1^+ \subseteq V_1^+\)</span>. Then <span
class="math inline">\(g e_1 \in V_1^+\)</span>. By what was shown in the
previous item, we can find <span class="math inline">\(g_0 \in
G^0\)</span> so that <span class="math inline">\(g e_1 = g_0
e_1\)</span>, thus <span class="math inline">\(g \in g_0 H_2 \subseteq
G^0\)</span>. Thus, <span class="math inline">\(G^0 \supseteq \{g \in G
: g V_1^+ \subseteq V_1^+\}\)</span>.</p></li>
<li><p>We have seen that <span class="math inline">\(G^0 = \{g \in G : g
V_1^+ \subseteq V_1^+\}\)</span> and that <span
class="math inline">\(\{g \in G : g V_1^+ \subseteq V_1^+\}\)</span> has
index <span class="math inline">\(2\)</span> in <span
class="math inline">\(G\)</span>. Therefore <span
class="math inline">\(G\)</span> has two connected components.</p></li>
</ol>
<p>One can tidy this discussion up a bit with some lemmas from
lecture.</p></li>
<li><p>Homework <a href="#hw:3-lie-first" data-reference-type="ref"
data-reference="hw:3-lie-first">3</a>, part 1. Let <span
class="math inline">\(G := \mathop{\mathrm{SO}}(2,1)\)</span>. It acts
on <span class="math inline">\(M := V_1 := \{(x,y,z) : z^2 - x^2 - y^2 =
1\}\)</span> as well as its connected components <span
class="math inline">\(V_1^{\pm}\)</span>. Let us realize <span
class="math inline">\(M\)</span> as a space of row vectors, so that
<span class="math inline">\(G\)</span> acts on <span
class="math inline">\(M\)</span> by right matrix multiplication: <span
class="math inline">\(m \mapsto m g\)</span>. The group <span
class="math inline">\(G\)</span> then acts on smooth functions <span
class="math inline">\(f : M \rightarrow \mathbb{R}\)</span> by the
formula: for <span class="math inline">\(g \in G\)</span>, <span
class="math inline">\(m \in M\)</span>, <span class="math display">\[g
f(m) :=
  f(m g).\]</span> We saw in an earlier homework problem that <span
class="math inline">\(G\)</span> acts transitively on the connected
components of <span class="math inline">\(M\)</span>, hence <span
class="math inline">\(f\)</span> is constant on each such component if
and only if <span id="eq:f-invariant-by-group-for-so-1-2-hw-problem" class="math display">\[\label{eq:f-invariant-by-group-for-so-1-2-hw-problem}\tag{16}
    g f = f \text{ for all } g \in G.\]</span></p>
<p>Set <span class="math inline">\(\mathfrak{g} :=
\mathop{\mathrm{Lie}}(G)\)</span>. We may differentiate the action of
<span class="math inline">\(G\)</span> on <span
class="math inline">\(C^\infty(M)\)</span> to the action of <span
class="math inline">\(\mathfrak{g}\)</span> on <span
class="math inline">\(C^\infty(M)\)</span> given for <span
class="math inline">\(X \in \mathfrak{g}\)</span> by <span
class="math display">\[X f(m) :=
  \partial_{t=0} f(m \exp(t X)).\]</span> Explicitly, the Lie algebra
<span class="math inline">\(\mathfrak{g}\)</span> consists of matrices
<span class="math inline">\(X \in M_3(\mathbb{R})\)</span> satisfying
<span class="math inline">\({}^t X J + J X = 0\)</span>, where <span
class="math inline">\(J := \mathop{\mathrm{diag}}(1,1,-1)\)</span>; an
explicit basis for <span class="math inline">\(\mathfrak{g}\)</span> is
given by the matrices <span class="math display">\[X_1
  :=
  \begin{pmatrix}
    0 &amp; 1 &amp; 0 \\
    -1 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0
  \end{pmatrix}
,
  \quad
  X_2
  :=
  \begin{pmatrix}
    0 &amp; 0 &amp; 1 \\
    0 &amp; 0 &amp; 0 \\
    1 &amp; 0 &amp; 0
  \end{pmatrix}
,
  X_3
  :=
  \begin{pmatrix}
    0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 1 \\
    0 &amp; 1 &amp; 0
  \end{pmatrix}
.\]</span> Using that <span class="math display">\[(x,y,z) X_1
  =
  x e_2
  - y e_1,\]</span> <span class="math display">\[(x,y,z) X_2
  =
  z e_1
  + x e_3,\]</span> <span class="math display">\[(x,y,z) X_3
  =
  z e_2
  + y e_3,\]</span> we obtain <span class="math display">\[X_1 f(x,y,z)
  =
  (x \partial_y - y \partial_x) f(x,y,z),\]</span> <span
class="math display">\[X_2 f(x,y,z)
  =
  (z \partial_x + x \partial_z) f(x,y,z),\]</span> <span
class="math display">\[X_3 f(x,y,z)
  =
  (z \partial_y + y \partial_z) f(x,y,z).\]</span> Therefore assertion
(b) in the homework problem is equivalent to saying that <span
class="math inline">\(X_i f = 0\)</span> for <span
class="math inline">\(i=1,2,3\)</span>, or equivalently, that <span id="eq:f-invariant-by-algebra-for-so-1-2-hw-problem" class="math display">\[\label{eq:f-invariant-by-algebra-for-so-1-2-hw-problem}\tag{17}
    X f = 0 \text{ for all }X \in \mathfrak{g}.\]</span></p>
<p>It remains only to verify that <a
href="#eq:f-invariant-by-group-for-so-1-2-hw-problem"
data-reference-type="eqref"
data-reference="eq:f-invariant-by-group-for-so-1-2-hw-problem">\((16)\)</a>
and <a href="#eq:f-invariant-by-algebra-for-so-1-2-hw-problem"
data-reference-type="eqref"
data-reference="eq:f-invariant-by-algebra-for-so-1-2-hw-problem">\((17)\)</a>
are equivalent. This follows from the connectedness of <span
class="math inline">\(G\)</span> by the same argument (the
“exponentiation/differentiation trick”) as in §<a
href="#sec:appl-inv-by-connected" data-reference-type="ref"
data-reference="sec:appl-inv-by-connected">13.4</a>.</p></li>
<li><p>Homework <a href="#hw:all-about-Ad" data-reference-type="ref"
data-reference="hw:all-about-Ad">6</a>, part 1. We want to show for
<span class="math inline">\(f : G \rightarrow H\)</span> that <span
class="math inline">\(d f(\mathop{\mathrm{Ad}}(g) X) =
\mathop{\mathrm{Ad}}(f(g)) d f(X)\)</span>. The curve <span
class="math inline">\(t \mapsto \exp(t \mathop{\mathrm{Ad}}(g) X) =
\exp(\mathop{\mathrm{Ad}}(g) t X)\)</span> in <span
class="math inline">\(G\)</span> has initial velocity <span
class="math inline">\(\mathop{\mathrm{Ad}}(g) X\)</span>, hence <span id="eqn:proving-ad-df-compatibility-1" class="math display">\[\label{eqn:proving-ad-df-compatibility-1}\tag{18}
    d f(\mathop{\mathrm{Ad}}(g) X)
    = \partial_{t=0} f(\exp(\mathop{\mathrm{Ad}}(g) t X)).\]</span> In
particular, <span id="eqn:proving-ad-df-compatibility-2" class="math display">\[\label{eqn:proving-ad-df-compatibility-2}\tag{19}
    d f(X)
    = \partial_{t=0} f(\exp(t X)).\]</span> By Exercise <a
href="#exercise:conjugation-and-Ad-are-intertwined-by-exponential"
data-reference-type="ref"
data-reference="exercise:conjugation-and-Ad-are-intertwined-by-exponential">22</a>,
we have <span class="math inline">\(\exp(\mathop{\mathrm{Ad}}(g) t X))
  = g \exp(t X) g^{-1}\)</span>; since <span
class="math inline">\(f\)</span> is a group homomorphism, it follows
that <span id="eqn:proving-ad-df-compatibility-3" class="math display">\[\label{eqn:proving-ad-df-compatibility-3}\tag{20}
    d f(\mathop{\mathrm{Ad}}(g) X)
    =
    \partial_{t=0}
    f(g)g
    f(\exp(t X)) f(g)^{-1}
    =
    \mathop{\mathrm{Ad}}(f(g))
    \partial_{t=0}
    f(\exp(t X))\]</span> Combining <a
href="#eqn:proving-ad-df-compatibility-2" data-reference-type="eqref"
data-reference="eqn:proving-ad-df-compatibility-2">\((19)\)</a>
with <a href="#eqn:proving-ad-df-compatibility-3"
data-reference-type="eqref"
data-reference="eqn:proving-ad-df-compatibility-3">\((20)\)</a>
gives the required identity.</p></li>
<li><p>Homework <a href="#hw:all-about-Ad" data-reference-type="ref"
data-reference="hw:all-about-Ad">6</a>, part 2. We want to determine the
complexifications of <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{H}),
  \mathop{\mathrm{SU}}(p,q)\)</span>, and <span
class="math inline">\({\mathop{\mathrm{U}}}_m(\mathbb{H})\)</span>. (!!!
to be written)</p></li>
<li><p>Homework <a href="#hw:characters-sl2" data-reference-type="ref"
data-reference="hw:characters-sl2">8</a>, part 3. The answer is: those
functions <span class="math inline">\(\nu : \mathbb{Z} \rightarrow
\mathbb{Z}_{\geq
    0}\)</span> for which</p>
<ol>
<li><p><span class="math inline">\(\nu(n) = 0\)</span> for all but
finitely many <span class="math inline">\(n\)</span>,</p></li>
<li><p><span class="math inline">\(\nu(n) = \nu(-n)\)</span> for all
<span class="math inline">\(n \in \mathbb{Z}_{\geq 0}\)</span>,</p></li>
<li><p><span class="math inline">\(\nu(0) \geq \nu(2) \geq \nu(4) \geq
\nu(6) \geq \dotsb\)</span>, and</p></li>
<li><p><span class="math inline">\(\nu(1) \geq \nu(3) \geq \nu(5) \geq
\nu(7) \geq \dotsb\)</span>.</p></li>
</ol>
<p>Given such a seuqence, we can define <span class="math inline">\(\mu
: \mathbb{Z}_{\geq 0} \rightarrow \mathbb{Z}_{\geq 0}\)</span> by <span
class="math inline">\(\mu(m) := \nu(m) - \nu(m + 2)\)</span> and set
<span class="math display">\[V := \oplus_{\substack{
      m \in \mathbb{Z}_{\geq 0}
    }
  }
  W_m^{\oplus \mu(m)}.\]</span> Conversely, the claimed inequalities are
clearly satisfied for <span class="math inline">\(V\)</span> of this
form (by the hint suggested in the homework problem, or by directly
writing out the characters).</p></li>
<li><p>Homework <a href="#hw:universal-covering-group"
data-reference-type="ref"
data-reference="hw:universal-covering-group">10</a>, part 1: It is easy
to see (by considering elementary matrices) that the center of <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> is the
subgroup <span class="math inline">\(\mu_n\)</span> of scalar matrices
<span
class="math inline">\(\mathop{\mathrm{diag}}(z,z,\dotsc,z)\)</span>
whose entries <span class="math inline">\(z\)</span> are <span
class="math inline">\(n\)</span>th roots of unity. We have <span
class="math inline">\(\mathbb{Z}/n \cong \mu^n\)</span> via the map
<span class="math inline">\(x \mapsto e^{2 \pi i x}\)</span>.</p>
<p>The inclusion <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C}) \rightarrow
  {\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> has differential given by
the inclusion <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})
\rightarrow \mathfrak{g}\mathfrak{l}_n(\mathbb{C})\)</span> from the
space of traceless matrices to the space of all matrices. The group
<span class="math inline">\({\mathop{\mathrm{PGL}}}_n(\mathbb{C})\)</span>
is the quotient of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> by the
normal subgroup <span class="math inline">\(Z\)</span> of scalar
matrices <span
class="math inline">\(\mathop{\mathrm{diag}}(z,z,\dotsc,z)\)</span>
(<span class="math inline">\(z \in \mathbb{C}^\times\)</span>). Thus (by
some theorem from lecture) the surjective quotient map <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C}) \rightarrow
{\mathop{\mathrm{PGL}}}_n(\mathbb{C})\)</span> has differential given by
the surjective linear map <span
class="math display">\[\mathfrak{g}\mathfrak{l}_n(\mathbb{C})
\rightarrow \mathfrak{p}\mathfrak{g}\mathfrak{l}_n(\mathbb{C}),\]</span>
where <span
class="math inline">\(\mathfrak{p}\mathfrak{g}\mathfrak{l}_n(\mathbb{C})\)</span>
denotes the quotient of <span
class="math inline">\(\mathfrak{g}\mathfrak{l}_n(\mathbb{C})\)</span> by
the subgroup of diagonal scalar matrices of the form <span
class="math inline">\(\mathop{\mathrm{diag}}(Z,Z,\dotsc,Z)\)</span>
(<span class="math inline">\(Z \in \mathbb{C}\)</span>). The composite
map <span
class="math display">\[{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})
\rightarrow \mathfrak{g}\mathfrak{l}_n(\mathbb{C})
  \twoheadrightarrow
  \mathfrak{p}\mathfrak{g}\mathfrak{l}_n(\mathbb{C})\]</span> is an
isomorphism (indeed, one may invert it by sending an element of <span
class="math inline">\(\mathfrak{p}\mathfrak{g}\mathfrak{l}_n(\mathbb{C})\)</span>
to its unique traceless representative) so we may identify <span
class="math inline">\(\mathfrak{p}\mathfrak{g}\mathfrak{l}_n(\mathbb{C})
= {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>. The
map <span class="math inline">\(p : {\mathop{\mathrm{SL}}}_n(\mathbb{C})
\rightarrow {\mathop{\mathrm{PGL}}}_n(\mathbb{C})\)</span> is a morphism
between connected Lie groups whose differential <span
class="math inline">\(d p\)</span> is then the “identity map” on <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>;
in particular, <span class="math inline">\(d p\)</span> is an
isomorphism. Thus <span class="math inline">\(p\)</span> is a covering
morphism. We have seen that <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> is
simply-connected. By the homotopy exact sequence (or the uniqueness of
the discrete central subgroup “<span class="math inline">\(N\)</span>”
appearing in the theorem on the universal covering group), it follows
that <span
class="math inline">\(\pi_1({\mathop{\mathrm{PGL}}}_n(\mathbb{C})) \cong
\ker(p) =
  \mu_n \cong \mathbb{Z}/n\)</span>, as required.</p>
<p>An identical argument works for <span class="math inline">\(G =
\mathop{\mathrm{SU}}(n)\)</span>.</p>
<p>The connected Lie groups having Lie algebra isomorphic to <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
are in bijection with the discrete central subgroups of the
simply-connected Lie group <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> having
that Lie algebra; since the center of that group is <span
class="math inline">\(\mu_n \cong \mathbb{Z}/n \mathbb{Z}\)</span> and
since all subgroups of the latter are uniquely of the form <span
class="math inline">\(d \mathbb{Z} / n \mathbb{Z} \cong \mathbb{Z} /
(n/d) \mathbb{Z}\)</span> for some positive divisor <span
class="math inline">\(d\)</span> of <span
class="math inline">\(n\)</span>, we obtain a bijection between the
isomorphism classes of such Lie groups <span
class="math inline">\(G\)</span> and the positive divisors <span
class="math inline">\(d\)</span> of <span
class="math inline">\(n\)</span>, where <span
class="math inline">\(\pi_1(G) \cong \mathbb{Z} / (n/d)
\mathbb{Z}\)</span>.</p></li>
<li><p>Homework <a href="#hw:bch-consequences" data-reference-type="ref"
data-reference="hw:bch-consequences">12</a>, 1a. Let <span
class="math inline">\(G \leq
{\mathop{\mathrm{SL}}}_{n}(\mathbb{R})\)</span> be the group of unipotent
upper-triangular matrices; for <span class="math inline">\(n =
3\)</span>, one has <span class="math display">\[G =
\begin{pmatrix}
    1 &amp; \ast &amp; \ast \\
    &amp; 1 &amp; \ast \\
    &amp;  &amp; 1
  \end{pmatrix}
.\]</span> For subgroups <span class="math inline">\(A,B\)</span> of
<span class="math inline">\(G\)</span>, let <span
class="math inline">\((A,B)\)</span> denote the subgroup of <span
class="math inline">\(G\)</span> generated by all commutators <span
class="math inline">\((a,b) := a b a^{-1} b^{-1}\)</span> with <span
class="math inline">\(a \in A, b \in B\)</span>. In the special case
that <span class="math inline">\(B\)</span> is a normal subgroup of
<span class="math inline">\(A\)</span>, we may interpret <span
class="math inline">\(B/(A,B)\)</span> as the <em>maximal quotient of
<span class="math inline">\(B\)</span> on which <span
class="math inline">\(A\)</span> acts trivially by conjugation</em>: if
<span class="math inline">\(\phi : B \rightarrow K\)</span> is a
surjective group homomorphism with the property that <span
class="math inline">\(\phi(a b a^{-1}) = \phi(b)\)</span> for all <span
class="math inline">\(a \in A, b \in B\)</span>, then <span
class="math inline">\(\phi\)</span> factors uniquely as a composition
<span class="math inline">\(B \twoheadrightarrow B/(A,B)
\xrightarrow{\psi} K\)</span>.</p>
<p>For <span class="math inline">\(k \in \mathbb{Z}_{\geq 1}\)</span>,
define <span class="math inline">\(G_k\)</span> inductively by <span
class="math inline">\(G_1 := G\)</span> and <span
class="math inline">\(G_{k+1} := (G,G_k)\)</span>. The problem is to
show that <span class="math inline">\(G_{n} = \{1\}\)</span>.</p>
<p>We will establish the stronger assertion that <span
class="math inline">\(G_k = U_k\)</span>, where <span
class="math display">\[U_k := \{a \in G : a_{i j} = 0 \text{ if } i &lt;
j &lt; i + k\}.\]</span> For example, if <span class="math inline">\(n =
4\)</span>, then <span class="math display">\[U_1 =
\begin{pmatrix}
    1 &amp; \ast &amp; \ast &amp; \ast \\
    &amp; 1 &amp; \ast &amp; \ast  \\
    &amp;  &amp; 1 &amp; \ast \\
    &amp; &amp; &amp; 1
  \end{pmatrix}
,
  \quad
  U_2 =
\begin{pmatrix}
    1 &amp; 0 &amp; \ast &amp; \ast \\
    &amp; 1 &amp; 0 &amp; \ast  \\
    &amp;  &amp; 1 &amp; 0 \\
    &amp; &amp; &amp; 1
  \end{pmatrix}
,\]</span> <span class="math display">\[U_3 =
\begin{pmatrix}
    1 &amp; 0 &amp; 0 &amp; \ast \\
    &amp; 1 &amp; 0 &amp; 0  \\
    &amp;  &amp; 1 &amp; 0 \\
    &amp; &amp; &amp; 1
  \end{pmatrix}
,
  \quad
  U_4 =
\begin{pmatrix}
    1 &amp; 0 &amp; 0 &amp; 0 \\
    &amp; 1 &amp; 0 &amp; 0  \\
    &amp;  &amp; 1 &amp; 0 \\
    &amp; &amp; &amp; 1
  \end{pmatrix}
  = \{1\}.\]</span> For notational convenience, set <span
class="math inline">\(U_m := \{1\}\)</span> if <span
class="math inline">\(m \geq n\)</span>.</p>
<p>To show that <span class="math inline">\(G_k = U_k\)</span>, it
suffices (since <span class="math inline">\(G_1 = U_1\)</span> and <span
class="math inline">\(G_{k+1} = (G,G_k)\)</span>) to show that <span
class="math display">\[(U,U_k) = U_{k+1}.\]</span></p>
<p>For <span class="math inline">\(i, j \in \{1..n\}\)</span> with <span
class="math inline">\(i &lt; j\)</span>, let <span
class="math inline">\(E_{i j} \in G\)</span> denote the “elementary
matrix” that has a <span class="math inline">\(1\)</span> in the <span
class="math inline">\((i,j)\)</span>th entry and vanishes on all other
off-diagonal entries. For example, if <span class="math inline">\(n =
3\)</span>, then <span class="math display">\[E_{12}
  =
\begin{pmatrix}
    1 &amp; 1 &amp; 0 \\
    &amp; 1 &amp; 0 \\
    &amp;  &amp; 1
  \end{pmatrix}
,
  \quad
  E_{13}
  =
\begin{pmatrix}
    1 &amp; 0  &amp; 1 \\
    &amp; 1 &amp; 0 \\
    &amp;  &amp; 1
  \end{pmatrix}
,
  \quad
  E_{23}
  =
\begin{pmatrix}
    1 &amp; 0  &amp; 0 \\
    &amp; 1 &amp; 1 \\
    &amp;  &amp; 1
  \end{pmatrix}
.\]</span> By matrix multiplication, one has the commutation relations
<span class="math display">\[= E_{i k},
  \quad
  [E_{ij},E_{k l}] = 0 \text{ if } j \neq k.\]</span></p>
<p>By Gaussian elimination, <span class="math inline">\(G\)</span> is
generated by the elements <span class="math inline">\(E_{i j}\)</span>
taken over all <span class="math inline">\(i &lt; j\)</span>. Similarly,
<span class="math inline">\(U_k\)</span> is generated by those <span
class="math inline">\(E_{i j}\)</span> for which <span
class="math inline">\(j \geq i + k\)</span>. It follows from this
observation and the commutation relations that</p>
<ol>
<li><p><span class="math inline">\(U_k\)</span> is normal in <span
class="math inline">\(U_1\)</span> for all <span
class="math inline">\(k\)</span>,</p></li>
<li><p>the conjugation action of <span
class="math inline">\(U_1\)</span> on the quotient <span
class="math inline">\(U_k / U_{k+1}\)</span> is trivial, and</p></li>
<li><p><span class="math inline">\((U_1,U_k) \geq U_{k+1}\)</span> for
all <span class="math inline">\(k\)</span>.</p></li>
</ol>
<p>On the other hand, <span class="math inline">\(U_k /
(U_1,U_k)\)</span> is the <em>maximal</em> quotient of <span
class="math inline">\(U_k\)</span> on which <span
class="math inline">\(U_1\)</span> acts trivially by conjugation, hence
<span class="math inline">\((U_1,U_k) \leq U_{k+1}\)</span> and
therefore <span class="math inline">\((U_1,U_k) = U_{k+1}\)</span>. This
completes the proof.</p>
<p>Remark: One can alternatively argue using the matrix
logarithm/exponential. The series defining the logarithm converges
everywhere on <span class="math inline">\(G\)</span> because <span
class="math inline">\(g-1\)</span> is nilpotent for <span
class="math inline">\(g \in G\)</span>, hence the series is actually
finite; similarly, the exponential series <span
class="math inline">\(\mathfrak{g} \rightarrow G\)</span> is actually a
polynomial.</p>
<p>Remark: One can formulate the definition of <span
class="math inline">\(U_k\)</span> more geometrically in terms of the
standard complete flag <span class="math inline">\(\mathbb{R}^n = V_0
\supset V_1 \supset \dotsb \supset V_n
  = \{0\}\)</span>, where <span class="math inline">\(V_k\)</span>
denotes the span of the first <span class="math inline">\(k\)</span>
standard basis vectors <span
class="math inline">\(e_1,\dotsc,e_k\)</span>. Then <span
class="math inline">\(U_k = \{g  \in {\mathop{\mathrm{GL}}}_n(\mathbb{R})
:
  (g - 1) V_i \subseteq V_{i + k} \text{ for all } i\}\)</span>, where
<span class="math inline">\(V_m := \{0\}\)</span> for <span
class="math inline">\(m \geq n\)</span>.</p></li>
<li><p>Homework <a href="#hw:bch-consequences" data-reference-type="ref"
data-reference="hw:bch-consequences">12</a>, 2. In what follows, <span
class="math inline">\(x,y\)</span> denote small enough elements of <span
class="math inline">\(\mathfrak{g}\)</span>, while <span
class="math inline">\(g\)</span> denotes an element of the group <span
class="math inline">\(G\)</span>.</p>
<ol>
<li><p>Recall (from Exercise <a
href="#exercise:conjugation-and-Ad-are-intertwined-by-exponential"
data-reference-type="ref"
data-reference="exercise:conjugation-and-Ad-are-intertwined-by-exponential">22</a>)
the general identity <span
class="math inline">\(\exp(\mathop{\mathrm{Ad}}(g) x) = g \exp(x)
g^{-1}\)</span>. Recall also (from §<a href="#sec:Ad-ad-intertwined-exp"
data-reference-type="ref"
data-reference="sec:Ad-ad-intertwined-exp">18.4</a>)
that <span class="math inline">\(\mathop{\mathrm{Ad}}(\exp(x)) =
\exp({\mathop{\mathrm{ad}}}_x)\)</span>. From these identities it follows
that <span class="math display">\[\exp(x \ast y \ast (-x))
      = \exp(x) \exp(y) \exp(-x)
      = \exp(\mathop{\mathrm{Ad}}(\exp(x)) y)\]</span> and thus <span
class="math display">\[x \ast y \ast (-x) =
\mathop{\mathrm{Ad}}(\exp(x)) y
      = \exp({\mathop{\mathrm{ad}}}_x) y,\]</span> as required.</p></li>
<li><p>Set <span class="math inline">\(f(t) := x \ast t y\)</span>. By
BCH, <span class="math inline">\(f\)</span> is analytic near <span
class="math inline">\(0\)</span>. We have <span
class="math inline">\(f(0) = x\)</span>. We have <span
class="math display">\[\exp(f(t)) =  \exp(x) \exp(t y)\]</span> and thus
<span class="math display">\[\exp(-f(0))
      \partial_{t=0}
      \exp(f(t))
      = y.\]</span> On the other hand, by Homework <a
href="#hw:diff-exp" data-reference-type="ref"
data-reference="hw:diff-exp">9</a>, <span id="eqn:consequence-of-maurer-cartan-for-computing-exp-dfdfd" class="math display">\[\label{eqn:consequence-of-maurer-cartan-for-computing-exp-dfdfd}\tag{26}
      \exp(-f(0))
      \partial_{t=0}
      \exp(f(t))
      =
      \Psi({\mathop{\mathrm{ad}}}_x)
      f&#39;(0)\]</span> where <span class="math display">\[\Psi(z)
      = \sum_{n=1}^{\infty}
      \frac{(-z)^{n-1}}{n!}
      = \frac{1 - \exp(-z)}{z}.\]</span> It follows that <span
class="math inline">\(f&#39;(0) = \Psi({\mathop{\mathrm{ad}}}_x)^{-1}
y\)</span>, or more verbosely, that <span
class="math display">\[f&#39;(0)
      =
      \frac{{\mathop{\mathrm{ad}}}_x}{1 - \exp(-{\mathop{\mathrm{ad}}}_x)}
      y
      =
      \sum_{n \geq 0}
      c_n {\mathop{\mathrm{ad}}}_x^n y
      =
      y + \frac{[x,y]}{2} + \dotsb\]</span> for some explicit
coefficients <span class="math inline">\(c_n\)</span> (Bernoulli
numbers). Since <span class="math inline">\(f\)</span> is analytic, we
deduce (upon setting <span class="math inline">\(t := 1\)</span>, taking
<span class="math inline">\(x,y\)</span> small enough and appealing to
Taylor’s theorem) that <span class="math display">\[x \ast y
      = x
      + \frac{{\mathop{\mathrm{ad}}}_x}{1 - \exp(-{\mathop{\mathrm{ad}}}_x)}
y + O(|y|^2).\]</span></p></li>
<li><p>Take <span class="math inline">\(f(t) := x \ast (t y  -
x)\)</span>. Then <span class="math inline">\(\exp(f(t)) = \exp(x)
\exp(t y - x)\)</span> and <span class="math inline">\(f(0) =
0\)</span>; we want to compute <span
class="math inline">\(f&#39;(0)\)</span>. To that end, we compute the
quantity <span class="math display">\[Q := \exp(-f(0)) \partial_{t=0}
\exp(f(t))
      =
      \partial_{t=0}
      \exp(x) \exp(t y - x).\]</span> in two ways. First, by the
rearrangement <span class="math display">\[Q =
      \exp(x)
      \partial_{t=0}
      \exp(t y - x)\]</span> and the formula <a href="#eq:diff-exp"
data-reference-type="eqref"
data-reference="eq:diff-exp">\((86)\)</a>, we have <span
class="math display">\[Q
      = \Psi(-{\mathop{\mathrm{ad}}}_x) y\]</span> with <span
class="math inline">\(\Psi\)</span> as above. On the other hand, by
direct application of <a
href="#eqn:consequence-of-maurer-cartan-for-computing-exp-dfdfd"
data-reference-type="eqref"
data-reference="eqn:consequence-of-maurer-cartan-for-computing-exp-dfdfd">\((26)\)</a>
(which remains valid in this context), <span class="math display">\[Q =
\Psi({\mathop{\mathrm{ad}}}_{f(0)}) f&#39;(0) = f&#39;(0),\]</span> since
<span class="math inline">\(f(0) = 0\)</span>. Therefore <span
class="math display">\[f&#39;(0) = \Psi(-{\mathop{\mathrm{ad}}}_x) y
      =
      \frac{1 - \exp({\mathop{\mathrm{ad}}}_x)}{- {\mathop{\mathrm{ad}}}_x}
y
      =
      \frac{\exp({\mathop{\mathrm{ad}}}_x)-1}{{\mathop{\mathrm{ad}}}_x} y
      = y + \frac{[x,y]}{2} + \dotsb.\]</span> The asymptotic formula
<span class="math display">\[x \ast (y- x)
      = \frac{\exp({\mathop{\mathrm{ad}}}_x) - 1}{{\mathop{\mathrm{ad}}}_x}
y + O(|y|)^2\]</span> for small enough <span
class="math inline">\(x,y\)</span> follows as in the previous part of
the problem.</p></li>
<li><p>In particular, since <span
class="math inline">\(|{\mathop{\mathrm{ad}}}_x^n y| = O(|x|^n
|y|)\)</span>, we see by Taylor’s theorem that <span
class="math display">\[\frac{x}{2} \ast y
      \ast \frac{-x}{2}
      = x + \frac{[x,y]}{2} + O(|x|^2 |y| + |y|^2),\]</span> <span
class="math display">\[x \ast (y - x)
      = x + \frac{[x,y]}{2} + O(|x|^2 |y| + |y|^2).\]</span></p></li>
</ol></li>
</ul>
<h1 id="sec:org8f383a2">§4. Some notation</h1>
<h2 id="sec:orgafcf8b3">§4.1. Local maps<span
id="sec:notation-partial-functions"
label="sec:notation-partial-functions"></span></h2>
<h3 id="sec:org37c609c">§4.1.1. Motivation</h3>
<p>We shall often have occasion to consider continuous maps defined on
open subsets of topological spaces for which the precise choice of
domain is unimportant (other than, perhaps, in that it contains a
specific point). This circumstance motivates introducing the notation
and terminology to follow.</p>
<h3 id="sec:org4f4ed31">§4.1.2. Definition</h3>
<p>Let <span class="math inline">\(X\)</span>, <span
class="math inline">\(Y\)</span> be topological spaces. By a <em>map
<span class="math inline">\(f\)</span> from <span
class="math inline">\(X\)</span> to <span
class="math inline">\(Y\)</span></em>, denoted <span
class="math inline">\(f : X \rightarrow Y\)</span>, we shall mean a
continuous function. By a <em>local map <span
class="math inline">\(f\)</span> from <span
class="math inline">\(X\)</span> to <span
class="math inline">\(Y\)</span></em>, denoted<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
<span class="math display">\[f : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Y,\]</span> we shall mean more precisely a pair <span
class="math inline">\((U,f)\)</span>, where:</p>
<ul>
<li><p><span class="math inline">\(U\)</span> is an open subset of <span
class="math inline">\(X\)</span>, called the <em>domain of
definition</em> or simply the <em>domain</em> of <span
class="math inline">\(f\)</span> and denoted <span
class="math inline">\(U =: \mathop{\mathrm{dom}}(f)\)</span>,
and</p></li>
<li><p><span class="math inline">\(f : U \rightarrow Y\)</span> is
continuous.</p></li>
</ul>
<p>We say that <span class="math inline">\(f : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Y\)</span> is <em>defined</em> at a point <span class="math inline">\(p
\in X\)</span> if <span class="math inline">\(p\)</span> belongs to the
domain of <span class="math inline">\(f\)</span>.</p>
<div class="example">
<p><strong>Example 1</strong>. Let <span class="math inline">\(X := Y :=
\mathbf{k}\)</span>. The pair <span
class="math inline">\((U,f)\)</span>, where <span
class="math inline">\(U := \mathbf{k}^\times\)</span> and <span
class="math inline">\(f(x) := 1/x\)</span>, is a local map <span
class="math inline">\(f : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span>.</p>
</div>
<h3 id="sec:orgcfbef67">§4.1.3. Equivalence</h3>
<p>Two local maps <span class="math inline">\(f_1, f_2  : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Y\)</span> will be called <em>equivalent</em> if they coincide on the
intersection of their domains of definition.</p>
<h3 id="sec:orgf825d0e">§4.1.4. Images<span id="sec:partial-map-images"
label="sec:partial-map-images"></span></h3>
<p>Given a local map <span class="math inline">\(f : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Y\)</span> and a subset <span class="math inline">\(S\)</span> of <span
class="math inline">\(X\)</span>, we denote by <span
class="math inline">\(f(S)\)</span> the image of the intersection of
<span class="math inline">\(S\)</span> with the domain of <span
class="math inline">\(f\)</span>, i.e., if <span class="math inline">\(U
= \mathop{\mathrm{dom}}(f)\)</span>, then <span
class="math inline">\(f(S) := f(U \cap S)\)</span>.</p>
<h3 id="sec:org7f9108b">§4.1.5. Composition</h3>
<p>Given local maps <span class="math inline">\(f : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Y\)</span> and <span class="math inline">\(g : Y %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Z\)</span>, we may define their composition to be the local map <span
class="math display">\[g \circ f : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Z\]</span> with <span class="math inline">\(\mathop{\mathrm{dom}}(g
\circ f) := \mathop{\mathrm{dom}}(f) \cap
f^{-1}(\mathop{\mathrm{dom}}(g))\)</span> given as usual by <span
class="math inline">\((g \circ f)(x) := g(f(x))\)</span>. It can happen
that <span class="math inline">\(\mathop{\mathrm{dom}}(g \circ f) =
\emptyset\)</span>.</p>
<h3 id="sec:orga0b7c1f">§4.1.6. Inverses</h3>
<p>A local map <span class="math inline">\(f : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
Y\)</span> with domain <span class="math inline">\(U :=
\mathop{\mathrm{dom}}(f)\)</span> will be called <em>invertible</em> if
<span class="math inline">\(f(U)\)</span> is open and the induced map
<span class="math inline">\(f : U \rightarrow f(U)\)</span> is a
homeomorphism. In that case, the <em>inverse</em> of <span
class="math inline">\(f\)</span> is defined to be the local map <span
class="math display">\[f^{-1} : Y %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
X\]</span> with <span
class="math inline">\(\mathop{\mathrm{dom}}(f^{-1}) := f(U)\)</span>
given as usual by <span class="math inline">\(f^{-1}(y) := x\)</span> if
<span class="math inline">\(y = f(x)\)</span>.</p>
<h1 id="sec:org2f1e843">§5. Some review of calculus</h1>
<p>To explain what will happen in this course, it will help to recall
some background from calculus. Let <span
class="math inline">\(\mathbf{k}\)</span> denote either of the fields
<span class="math inline">\(\mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span>.</p>
<h2 id="sec:org428341e">§5.1. One-variable derivatives</h2>
<p>We say that <span class="math inline">\(f : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> is <em>smooth</em> if all of its derivatives (of
arbitrary order) exist at all points in the domain of definition. The
first derivative <span class="math inline">\(f&#39; : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> may be characterized by the relation <span
class="math display">\[f(p + v) = f(p) + f&#39;(p) v + o(|v|)\]</span>
holding for each fixed point <span class="math inline">\(p\)</span> as
<span class="math inline">\(|v| \rightarrow 0\)</span>. In a
single-variable calculus course, one learns to relate (apparently
complicated) <em>global</em> properties of a function to simpler
<em>local</em> (or <em>infinitesimal</em>) properties involving its
derivatives. For example, when <span class="math inline">\(\mathbf{k} =
\mathbb{R}\)</span>, one learns that the following are equivalent:</p>
<ul>
<li><p><span class="math inline">\(f\)</span> is increasing (an
ostensibly <em>global</em> property, as it requires one to check that
<span class="math inline">\(f(x) &lt; f(y)\)</span> for every pair of
points with <span class="math inline">\(x &lt; y\)</span>, and such
points might be quite far apart!);</p></li>
<li><p><span class="math inline">\(f&#39;\)</span> is positive (a
<em>local</em> property, as it only requires one to check that <span
class="math inline">\(f&#39;(x) &gt; 0\)</span> for each point <span
class="math inline">\(x\)</span>).</p></li>
</ul>
<p>This test and others (concerning the second derivative, for instance)
often suffice to piece together an approximate portrait of the global
shape of a function from the local behavior of its derivatives at the
critical points.</p>
<h2 id="sec:org2290879">§5.2. Multi-variable total and partial
derivatives<span id="sec:calc-multi" label="sec:calc-multi"></span></h2>
<p>We say that <span class="math inline">\(f : \mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> is <em>smooth</em> if all of its partial
derivatives exist at all points in the domain of definition. For each
<span class="math inline">\(p\)</span> in the domain of <span
class="math inline">\(f\)</span>, the total derivative <span
class="math inline">\(T_p f\)</span> is a <em>linear</em> map <span
class="math inline">\(T_p f : \mathbf{k}^m
\rightarrow \mathbf{k}^n\)</span> that may be characterized as above by
the relation <span class="math display">\[f(p+v) = f(p) + (T_p f)(v) +
o(|v|)\]</span> holding for each fixed <span
class="math inline">\(p\)</span> as <span class="math inline">\(|v|
\rightarrow 0\)</span>. One can express <span class="math inline">\(T_p
f\)</span> in matrix form <span class="math display">\[T_p f
  =
\begin{pmatrix}
    \frac{\partial f_1}{\partial x_1}(p) &amp; \dotsb  &amp;
\frac{\partial f_1}{\partial x_m}(p) \\
    \dotsb  &amp; \dotsb  &amp; \dotsb  \\
    \frac{\partial f_n}{\partial x_1}(p) &amp; \dotsb  &amp;
\frac{\partial f_n}{\partial x_m}(p)
  \end{pmatrix}\]</span> where the function <span
class="math inline">\(f\)</span> is expressed as a tuple <span
class="math inline">\(f =  (f_1,\dotsc,f_n)\)</span> of components <span
class="math inline">\(f_i : \mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

\mathbf{k}\)</span>, elements <span class="math inline">\(x \in
\mathbf{k}^m\)</span> are equipped with the standard coordinates <span
class="math inline">\(x =
(x_1,\dotsc,x_n)\)</span>, and the partial derivatives are characterized
by <span class="math display">\[f_i(p + t e_j)
  =
  f_i(p)
  +
  \frac{\partial f_i}{\partial x_j}(p)
  t +
  o(|t|)\]</span> for <span class="math inline">\(t \in
\mathbf{k}\)</span> with <span class="math inline">\(|t| \rightarrow
0\)</span>, where <span class="math inline">\(e_j\)</span> denotes the
standard <span class="math inline">\(j\)</span>th basis element of <span
class="math inline">\(\mathbf{k}^m\)</span> dual to the coordinate <span
class="math inline">\(x_j\)</span>; for a vector <span
class="math inline">\(v = (v_1,\dotsc,v_m) \in \mathbf{k}^m\)</span> and
a coordinate index <span class="math inline">\(i = 1,\dotsc,n\)</span>,
one then has <span class="math display">\[((T_p f) v)_i
=
\sum_{j=1}^m
\frac{\partial f_i}{\partial x_j}(p)
v_j.\]</span> As in single-variable calculus, one learns various ways to
relate the global behavior of a <span class="math inline">\(f\)</span>
to the local behavior of its total derivative <span
class="math inline">\(T_p f\)</span> at various critical points <span
class="math inline">\(p\)</span> (Hessian test, etc). A basic case to
keep in mind is that of a linear function <span class="math inline">\(A
: \mathbf{k}^m \rightarrow \mathbf{k}^n\)</span>, for which one has
<span class="math inline">\(T_p A = A\)</span> for all <span
class="math inline">\(p \in \mathbf{k}^m\)</span>.</p>
<p>When <span class="math inline">\(m = 1\)</span>, so that <span
class="math inline">\(f = (f_1,\dotsc,f_n)\)</span> may be thought of as
an <span class="math inline">\(n\)</span>-tuple of functions <span
class="math inline">\(f_i : \mathbf{k} \rightarrow \mathbf{k}\)</span>,
the total derivative <span class="math inline">\(T_p f\)</span> is then
a linear transformation <span class="math inline">\(\mathbf{k}
\rightarrow \mathbf{k}^n\)</span> and so may be identified with the
vector <span class="math display">\[f&#39;(p) = (f_1&#39;(p), \dotsc,
f_n&#39;(p)) \in \mathbf{k}^n\]</span> characterized by the same
relation as in the one-variable case.</p>
<h2 id="sec:org56f7558">§5.3. The chain rule</h2>
<p>Given a pair of smooth functions <span class="math inline">\(f :
\mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> and <span class="math inline">\(g : \mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^l\)</span>, one can form the composition <span
class="math inline">\(h := g \circ f : \mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^l\)</span>, which is smooth. One knows the chain rule: at a
point <span class="math inline">\(p \in \mathbf{k}^m\)</span> at which
<span class="math inline">\(h\)</span> is defined, the derivative of the
composition <span class="math inline">\(h\)</span> is the linear map
<span class="math inline">\(T_p h  : \mathbf{k}^m \rightarrow
\mathbf{k}^l\)</span> given by the composition <span
class="math display">\[T_p h = T_{f(p)} g \circ T_p f\]</span> of the
derivatives of <span class="math inline">\(f,g\)</span>. Expanding out
in terms of matrices and using standard coordinates <span
class="math inline">\(x_1,\dotsc,x_m\)</span> on <span
class="math inline">\(\mathbf{k}^m\)</span> and <span
class="math inline">\(y_1,\dotsc,y_n\)</span> on <span
class="math inline">\(\mathbf{k}^n\)</span>, the chain rule reads: for
<span class="math inline">\(i \in \{1..l\}\)</span> and <span
class="math inline">\(k \in \{1..m\}\)</span>, <span
class="math display">\[\frac{\partial h_i}{\partial x_k }(p)
=
\sum_{j=1}^n
\frac{\partial g_i}{\partial y_j}(f(p))
\frac{\partial f_j}{\partial x_k}(p).\]</span> Specialized to the case
<span class="math inline">\(m=1\)</span>, the chain rule reads <span
class="math inline">\(h&#39;(p) = (T_{f(p)} g) f&#39;(p)\)</span>, or
expanding out further in terms in terms of components, as <span
class="math inline">\(h_i&#39;(p)
= \sum_{j=1}^n
\frac{\partial h_i}{\partial y_j}(f(p))
f_j(p)\)</span>.</p>
<h2 id="sec:org81b78cb">§5.4. Inverse function theorem<span
id="sec:calc-inv-func-thm" label="sec:calc-inv-func-thm"></span></h2>
<p>The <em>inverse function theorem</em> is a fundamental tool for
controlling the local behavior of a function <span
class="math inline">\(f\)</span> <em>near</em> a point <span
class="math inline">\(p\)</span> in terms of <em>linear algebraic</em>
properties of the derivative <span class="math inline">\(T_p
f\)</span>.</p>
<div id="thm:inverse-function-theorem-euclidean" class="theorem">
<p><strong>Theorem 2</strong>. <em>Let <span class="math inline">\(f :
\mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> be smooth and defined at <span
class="math inline">\(p\)</span>. The following are equivalent:</em></p>
<ol>
<li><p><em>The map <span class="math inline">\(T_p f : \mathbf{k}^n
\rightarrow
    \mathbf{k}^n\)</span> is a linear isomorphism of vector spaces, or
equivalently, has nonzero Jacobian determinant <span
class="math inline">\(\det(T_p
    f)\)</span>.</em></p></li>
<li><p><em>There is an open neighborhood <span
class="math inline">\(U\)</span> of <span
class="math inline">\(p\)</span>, contained in the domain of <span
class="math inline">\(f\)</span>, so that <span class="math inline">\(V
:= f(U)\)</span> is open and the induced map <span
class="math inline">\(f : U \rightarrow V\)</span> is a diffeomorphism,
i.e., admits a smooth two-sided inverse <span class="math inline">\(g :
V \rightarrow U\)</span>.</em></p></li>
</ol>
</div>
<h2 id="sec:orgc7b25df">§5.5. Implicit function theorem<span
id="sec:calc-impl-func-thm" label="sec:calc-impl-func-thm"></span></h2>
<p>We state it here rather verbosely, saving a tidier formulation for
the generalization to manifolds given below in §<a
href="#sec:diff-geom-inv-func-thm" data-reference-type="ref"
data-reference="sec:diff-geom-inv-func-thm">6.8</a>.</p>
<div id="thm:implicit-function-thm-euclidean" class="theorem">
<p><strong>Theorem 3</strong>. <em>Let <span
class="math inline">\(n,m,d\)</span> be nonnegative integers with <span
class="math inline">\(n = m + d\)</span>. Suppose given a point <span
class="math inline">\(p \in \mathbf{k}^n\)</span> and smooth maps <span
class="math inline">\(f_1,\dotsc,f_m : \mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> defined at <span class="math inline">\(p =
(p_1,\dotsc,p_n)\)</span> satisfying either of the following evidently
equivalent properties:</em></p>
<ol>
<li><p><em>The <span class="math inline">\(m \times n\)</span> matrix of
partial derivatives <span class="math inline">\(\frac{\partial
f_i}{\partial x_j}(p)\)</span> (<span class="math inline">\(i=1..m, j =
1..n\)</span>) has rank <span
class="math inline">\(m\)</span>.</em></p></li>
<li><p><em>The function <span class="math inline">\(f :=
(f_1,\dotsc,f_m) : \mathbf{k}^n
    %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m\)</span> has the property that its total derivative <span
class="math inline">\(T_p f : \mathbf{k}^n
    \rightarrow \mathbf{k}^m\)</span> at <span
class="math inline">\(p\)</span> is surjective.</em></p></li>
<li><p><em><span class="math inline">\(\dim \ker(T_p f) =
d\)</span>.</em></p></li>
<li><p><em>The space of solutions <span class="math inline">\((d
x_1,\dotsc, d x_n) \in \mathbf{k}^n\)</span> to the system of
homogeneous linear equations <span class="math inline">\(\sum_{j=1}^n
\frac{\partial f_i}{\partial x_j} (p) d x _j = 0\)</span> (<span
class="math inline">\(i=1,\dotsc,m\)</span>) is <span
class="math inline">\(d\)</span>-dimensional.</em></p></li>
</ol>
<p><em>Then after suitably reordering the coordinates indices, one can
find smooth functions <span class="math inline">\(\psi_{d+1}, \dotsc,
\psi_{n} : \mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

  \mathbf{k}\)</span> defined at <span
class="math inline">\((p_1,\dotsc,p_d,f_1(p),\dotsc,f_m(p))\)</span> so
for any point <span class="math inline">\(x = (x_1,\dotsc,x_n)\)</span>
close enough to <span class="math inline">\(p\)</span>, one has <span
class="math display">\[x_j
  =
  \psi_j(x_1,\dotsc,x_d,f_1(x),\dotsc,f_m(x))
  \quad \text{ for } j = d+1,\dotsc,n.\]</span> In particular, if we
suppose moreover that <span class="math inline">\(f_1(p) = \dotsb =
f_m(p) = 0\)</span>, then the following are equivalent for <span
class="math inline">\(x\)</span> close enough to <span
class="math inline">\(p\)</span>:</em></p>
<ol>
<li><p><em><span class="math inline">\(f_1(x) = \dotsb = f_m(x) =
0\)</span></em></p></li>
<li><p><em><span class="math inline">\(x_j =
\psi_j(x_1,\dotsc,x_d,0,\dotsc,0)\)</span> for <span
class="math inline">\(j = d+1, \dotsc, n\)</span>.</em></p></li>
</ol>
<p><em>Consequently the map <span class="math display">\[\Psi :
\mathbf{k}^d %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\]</span> <span class="math display">\[\Psi(x_1,\dotsc,x_d)
:=
  (x_1,\dotsc,x_d,\psi_{d+1}(x_1,\dotsc,x_d,0,\dotsc,0),
  \dotsc,
  \psi_{n}(x_1,\dotsc,x_d,0,\dotsc,0))\]</span> parametrizes the set
<span class="math inline">\(\{ x : f_1(x) = \dotsb = f_m(x) =
0\}\)</span> near <span class="math inline">\(p\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Suppose after suitably relabeling indices that the
rightmost <span class="math inline">\(m \times m\)</span> minor of the
matrix <span class="math inline">\(T_p f\)</span> is nonsingular.
Consider then the map <span class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> defined near <span
class="math inline">\(p\)</span> by the formula <span
class="math inline">\(\phi(x) :=
(x_1,\dotsc,x_d,f_1(x),\dotsc,f_m(x))\)</span>. The total derivative
<span class="math inline">\(T_p \phi\)</span> is then given by the
matrix <span class="math display">\[\begin{pmatrix}
    1 &amp; 0 &amp; \dotsb &amp; 0 &amp; 0 &amp; \dotsb &amp; 0 \\
    0 &amp; 1 &amp; \dotsb &amp; 0 &amp; 0 &amp; \dotsb &amp; 0 \\
    \dotsb &amp; \dotsb &amp; \dotsb &amp; \dotsb &amp; \dotsb &amp;
\dotsb &amp; 0 \\
    0 &amp; 0 &amp; \dotsb &amp; 1 &amp; 0 &amp; \dotsb &amp; 0 \\
    \frac{\partial f_1}{\partial x_{1}}(p)  &amp;   \frac{\partial
f_1}{\partial x_{2}}(p) &amp; \dotsb &amp; \frac{\partial f_1}{\partial
x_d}(p) &amp; \frac{\partial f_1}{\partial x_{d+1}}(p) &amp; \dotsb
&amp; \frac{\partial f_1}{\partial x_{n}}(p) \\
    \dotsb &amp; \dotsb &amp; \dotsb &amp; \dotsb &amp; \dotsb &amp;
\dotsb &amp; \dotsb \\
    \frac{\partial f_m}{\partial x_{1}}(p)  &amp;   \frac{\partial
f_m}{\partial x_{2}}(p) &amp; \dotsb &amp; \frac{\partial f_m}{\partial
x_d}(p) &amp; \frac{\partial f_m}{\partial x_{d+1}}(p) &amp; \dotsb
&amp; \frac{\partial f_m}{\partial x_{n}}(p)
  \end{pmatrix}\]</span> By our assumption on <span
class="math inline">\(T_p f\)</span>, it follows that <span
class="math inline">\(T_p \phi\)</span> is nonsingular. By the inverse
function theorem, we can find a local inverse <span
class="math inline">\(\psi = (\psi_1,\dotsc,\psi_n) : \mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

  \mathbf{k}^n\)</span> to <span class="math inline">\(\phi\)</span>
defined at <span class="math inline">\(\phi(p)\)</span>. By
construction, <span class="math inline">\(\psi_i(x) = x_i\)</span> for
<span class="math inline">\(i=1,\dotsc,d\)</span>, while the <span
class="math inline">\(\psi_i\)</span> for <span class="math inline">\(i
&gt; d\)</span> satisfy the requirements of the conclusion. ◻</p>
</span></div>
<h1 id="sec:org53eb85b">§6. Some review of differential geometry</h1>
<p>As indicated already in §<a href="#sec:disclaimers"
data-reference-type="ref"
data-reference="sec:disclaimers">1</a>, this section is
intended to be used mainly as a reference. I don’t plan to use much
differential geometry in the actual course.</p>
<h2 id="sec:org8cf0641">§6.1. Charts</h2>
<p>Recall the notation and terminology of §<a
href="#sec:notation-partial-functions" data-reference-type="ref"
data-reference="sec:notation-partial-functions">4.1</a>.
By a <em>topological chart</em> on a topological space <span
class="math inline">\(X\)</span> we shall mean a pair <span
class="math inline">\((\phi,n)\)</span>, where <span
class="math inline">\(n\)</span> is a nonnegative integer and <span
class="math display">\[\phi : X %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\]</span> is an invertible local map. More verbosely, this
means that a topological chart is a triple <span
class="math inline">\((U,\phi,n)\)</span>, where <span
class="math inline">\(n\)</span> is a nonnegative integer, <span
class="math inline">\(U\)</span> is an open subset of <span
class="math inline">\(X\)</span>, and <span class="math inline">\(\phi :
U \rightarrow \mathbf{k}^n\)</span> is a continuous map for which <span
class="math inline">\(\phi(U)\)</span> is open and <span
class="math inline">\(\phi : U \rightarrow \phi(U)\)</span> is a
homeomorphism onto its image.</p>
<h2 id="sec:orgdbe668d">§6.2. Manifolds</h2>
<p>For us, an <em><span class="math inline">\(n\)</span>-manifold</em>
(over the field <span class="math inline">\(\mathbf{k}\)</span>) is a
triple <span class="math inline">\((M,n,\mathcal{A})\)</span>, often
abbreviated simply as <span class="math inline">\(M\)</span> when the
data <span class="math inline">\(n, \mathcal{A}\)</span> are understood
by context, where:</p>
<ol>
<li><p><span class="math inline">\(M\)</span> is a topological space
(which we assume to be Hausdorff and second-countable, hence
metrizable),</p></li>
<li><p><span class="math inline">\(n\)</span> is a nonnegative
integer,</p></li>
<li><p><span class="math inline">\(\mathcal{A}\)</span> is an
<em>maximal smooth atlas</em>, that is to say, a collection of
topological charts <span class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> whose domains cover <span
class="math inline">\(M\)</span> and which are <em>smoothly
compatible</em> in the sense that for each pair <span
class="math inline">\(\phi, \psi\)</span> of charts in <span
class="math inline">\(\mathcal{A}\)</span>, the compositions <span
class="math display">\[\phi \circ \psi^{-1}, \psi \circ \phi^{-1} :
\mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

  \mathbf{k}^n\]</span> are smooth on their respective domains of
definition. “Maximal” means that <span
class="math inline">\(\mathcal{A}\)</span> contains every chart on <span
class="math inline">\(M\)</span> that is compatible with every chart in
<span class="math inline">\(\mathcal{A}\)</span>. By a <em>smooth
chart</em> on <span class="math inline">\(M\)</span> we then mean an
element of <span class="math inline">\(\mathcal{A}\)</span>.</p></li>
</ol>
<p>A <em>manifold</em> is an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(M\)</span> for some <span
class="math inline">\(n\)</span>, which is called the <em>dimension</em>
of <span class="math inline">\(M\)</span> and denoted <span
class="math inline">\(n = \dim(M)\)</span>.</p>
<div class="example">
<p><strong>Example 4</strong>. An open subset subset <span
class="math inline">\(M\)</span> of <span
class="math inline">\(\mathbf{k}^n\)</span> is a <span
class="math inline">\(n\)</span>-manifold if we take for <span
class="math inline">\(\mathcal{A}\)</span> the set of all charts <span
class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> which are smooth and have smooth inverses in the
ordinary sense of §<a href="#sec:calc-multi" data-reference-type="ref"
data-reference="sec:calc-multi">5.2</a>. In particular,
<span class="math inline">\(\mathbf{k}^n\)</span> is an <span
class="math inline">\(n\)</span>-manifold. More generally, any open
subset <span class="math inline">\(U\)</span> of an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(M\)</span> has the natural structure of an <span
class="math inline">\(n\)</span>-manifold: if <span
class="math inline">\(\mathcal{A}\)</span> is a maximal smooth atlas on
<span class="math inline">\(M\)</span>, then <span
class="math inline">\(\{ \phi \in \mathcal{A} :
\mathop{\mathrm{dom}}(\phi) \subseteq U \}\)</span> is a maximal smooth
atlas on <span class="math inline">\(U\)</span>.</p>
</div>
<div class="remark">
<p><strong>Remark 5</strong>.  </p>
<ol>
<li><p>One could also work with manifolds having multiple components of
varying dimension, but we will not have occasion to do so.</p></li>
<li><p>One can show that the dimension of a manifold is determined by
its topological structure, making the inclusion of <span
class="math inline">\(n\)</span> in the definition redundant, but this
fact is not important for our purposes.</p></li>
</ol>
</div>
<h2 id="sec:org92b178d">§6.3. Smooth maps</h2>
<p>Given manifolds <span class="math inline">\(M\)</span>, <span
class="math inline">\(N\)</span>, a local map <span
class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> is <em>smooth</em> if it is smooth with respect to
every pair of charts <span class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k} ^m\)</span>, <span class="math inline">\(\psi : N %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k} ^n\)</span> in the sense that the composition <span
class="math display">\[\mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{\phi^{-1}}{}\mathchar&quot;0\hexnumber@\symAMSa
4B {\,}{}}{}%
  }%

M
%
  \mathrel{%
    \mathpalette{\da@xarrow{}{f}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

N
%
  \mathrel{%
    \mathpalette{\da@xarrow{}{\psi}{}\mathchar&quot;0\hexnumber@\symAMSa
4B {\,}{}}{}%
  }%

\mathbf{k}^n\]</span> is smooth in the sense of §<a
href="#sec:calc-multi" data-reference-type="ref"
data-reference="sec:calc-multi">5.2</a>. When <span
class="math inline">\(M, N\)</span> are open subsets of Euclidean space,
this notion generalizes the earlier one.</p>
<h2 id="sec:org9cf6a98">§6.4. Coordinate systems</h2>
<p>Let <span class="math inline">\(M\)</span> be an <span
class="math inline">\(m\)</span>-manifold and let <span
class="math inline">\(p \in M\)</span> be a point. By a <em>coordinate
system for <span class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span></em>, or more simply a <em>coordinate
system at <span class="math inline">\(p\)</span></em> or <em>local
coordinates at <span class="math inline">\(p\)</span></em> when the
ambient manifold <span class="math inline">\(M\)</span> is clear from
context, we shall mean a tuple of smooth maps <span
class="math inline">\(x_1,\dotsc,x_m : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> arising as the components of a smooth chart <span
class="math inline">\(\phi = (x_1,\dotsc,x_m) : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m\)</span> on <span class="math inline">\(M\)</span> defined
at <span class="math inline">\(p\)</span>. Such a coordinate system
allows us to identify points <span class="math inline">\(x \in
M\)</span> near <span class="math inline">\(p\)</span> with tuples <span
class="math inline">\(x = (x_1,\dotsc,x_m)\)</span> and smooth functions
<span class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> defined near <span class="math inline">\(p\)</span>
with smooth functions <span
class="math inline">\(f(x_1,\dotsc,x_m)\)</span> of the local
coordinates <span class="math inline">\(x_1,\dotsc,x_m\)</span>. In
particular, it makes sense to define partial derivatives <span
class="math inline">\(\partial f /\partial x_j \in \mathbf{k}\)</span>
in this setting. For example, if <span class="math inline">\(M\)</span>
is an open subset of <span class="math inline">\(\mathbf{k}^m\)</span>,
then the standard coordinate functions <span
class="math inline">\(x_1,\dotsc,x_m : M
\rightarrow \mathbf{k}\)</span> form a coordinate system at every point
<span class="math inline">\(p \in M\)</span>.</p>
<p>Given an <span class="math inline">\(m\)</span>-manifold <span
class="math inline">\(M\)</span>, an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(N\)</span>, a smooth map <span
class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> and a point <span class="math inline">\(p \in M\)</span> at
which <span class="math inline">\(f\)</span> is defined, one can choose
local coordinates <span class="math inline">\(x_1,\dotsc,x_m\)</span> at
<span class="math inline">\(p\)</span> and <span
class="math inline">\(y_1,\dotsc,y_n\)</span> at <span
class="math inline">\(f(p)\)</span>. With respect to such coordinates,
the smooth map <span class="math inline">\(f\)</span> identifies with a
smooth map <span class="math inline">\((f_1,\dotsc,f_n) : \mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> defined at <span
class="math inline">\((x_1(p),\dotsc,x_m(p))\)</span> and <span
class="math inline">\(T_p f\)</span> identifies with the matrix of
partial derivatives <span class="math inline">\(\partial f_i/ \partial
x_j\)</span> as in §<a href="#sec:calc-multi" data-reference-type="ref"
data-reference="sec:calc-multi">5.2</a>.</p>
<h2 id="sec:orgd99d069">§6.5. Tangent spaces<span
id="sec:diff-geom-tangent-spaces"
label="sec:diff-geom-tangent-spaces"></span></h2>
<p>Let <span class="math inline">\(M\)</span> be an open subset of <span
class="math inline">\(\mathbf{k}^m\)</span>. A <em>curve on <span
class="math inline">\(M\)</span></em> is a smooth map <span
class="math inline">\(\gamma : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
M\)</span> whose domain is connected and contains <span
class="math inline">\(0\)</span>; the point <span
class="math inline">\(p := \gamma(0) \in M\)</span> is referred to as
its <em>basepoint</em> and the vector <span class="math inline">\(v :=
\gamma&#39;(0) \in \mathbf{k}^m\)</span> as its <em>initial
velocity</em>. Given an open subset <span class="math inline">\(N
\subseteq \mathbf{k} ^n\)</span> and a smooth map <span
class="math inline">\(f : M \rightarrow N\)</span>, the composition
<span class="math inline">\(f \circ \gamma : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> is then a curve on <span class="math inline">\(N\)</span>
with basepoint <span class="math inline">\(f(p)\)</span>; thanks to the
chain rule, its initial velocity is the image <span
class="math inline">\((f \circ \gamma)&#39;(0) = (T_{p} f) v\)</span> of
that of the original curve <span class="math inline">\(\gamma\)</span>
under the derivative of the map <span class="math inline">\(f\)</span>
at the basepoint of the original curve.</p>
<div id="rmk:lots-of-curves" class="remark">
<p><strong>Remark 6</strong>. Observe also that for each point <span
class="math inline">\(p \in M\)</span> and vector <span
class="math inline">\(v \in \mathbf{k}^m\)</span> there exists a curve
<span class="math inline">\(\gamma\)</span> with basepoint <span
class="math inline">\(p\)</span> and initial velocity <span
class="math inline">\(v\)</span>; for example, one can set <span
class="math inline">\(\gamma(t) := p + t v\)</span> and take for the
domain of <span class="math inline">\(\gamma\)</span> any sufficiently
small neighborhood of <span class="math inline">\(0\)</span>.</p>
</div>
<p>We now recall the generalization of the above notion to an arbitrary
<span class="math inline">\(n\)</span>-manifold <span
class="math inline">\(M\)</span>:</p>
<div class="definition">
<p><strong>Definition 7</strong>. Let <span
class="math inline">\(M\)</span> be a manifold. A <em>curve on <span
class="math inline">\(M\)</span></em> is defined as above to be a smooth
map <span class="math inline">\(\gamma : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
M\)</span> whose domain is connected and contains <span
class="math inline">\(0\)</span>.</p>
</div>
<p>We continue to refer to the point <span class="math inline">\(p :=
\gamma(0) \in M\)</span> as the <em>basepoint</em> of <span
class="math inline">\(\gamma\)</span>. If one now ponders how to define
“the initial velocity <span
class="math inline">\(\gamma&#39;(0)\)</span>” (e.g., to which space
should it belong?), one is eventually led to introduce the <em>tangent
space</em> <span class="math inline">\(T_p M\)</span> to the manifold
<span class="math inline">\(M\)</span> at the point <span
class="math inline">\(p\)</span>. To motivate the definition, note first
that for any smooth chart <span class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> defined at <span class="math inline">\(p\)</span>,
the composition <span class="math inline">\(\phi \circ \gamma :
\mathbf{k}  %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

\mathbf{k}^n\)</span> is (after suitably shrinking its domain so as to
be connected) a curve on <span
class="math inline">\(\mathbf{k}^n\)</span> with basepoint <span
class="math inline">\(\phi(p)\)</span> and initial velocity <span id="eq:velocity-of-curve-in-chart" class="math display">\[\label{eq:velocity-of-curve-in-chart}\tag{38}
  v_\phi := (\phi \circ \gamma)&#39;(0)\]</span> in the Euclidean sense
defined previously. Moreover, for any other smooth chart <span
class="math inline">\(\psi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> defined at <span class="math inline">\(p\)</span>,
we can use the chain rule in the form <span class="math display">\[T_0
(\psi \circ \gamma)
=
T_0 (\psi \circ \phi^{-1} \circ \phi \circ  \gamma)
=
T_{\phi(p)} (\psi \circ \phi^{-1}) \circ T_{0}(\phi
\circ  \gamma)\]</span> to read off the initial velocity <span
class="math inline">\(v_{\psi}\)</span> of the curve <span
class="math inline">\(\psi \circ \gamma\)</span> from that of <span
class="math inline">\(\phi \circ \gamma\)</span>: <span id="eq:consistency-tangent-vectors-in-charts" class="math display">\[\label{eq:consistency-tangent-vectors-in-charts}\tag{39}
  v_\psi = T_{\phi(p)}(\psi \circ \phi^{-1}) v_\phi.\]</span> This
observation suggests the following definition:</p>
<div class="definition">
<p><strong>Definition 8</strong>. The <em>tangent space <span
class="math inline">\(T_p M\)</span> to <span
class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span></em> is the set of all tuples <span
class="math inline">\(v = (v_\phi)_{\phi}\)</span>, where <span
class="math inline">\(\phi\)</span> traverses the set of smooth charts
defined at <span class="math inline">\(p\)</span> and the <span
class="math inline">\(v_\phi\)</span> are elements of <span
class="math inline">\(\mathbf{k}^n\)</span> satisfying the consistency
condition <a href="#eq:consistency-tangent-vectors-in-charts"
data-reference-type="eqref"
data-reference="eq:consistency-tangent-vectors-in-charts">\((39)\)</a>.</p>
</div>
<p>Since the consistency condition is linear, it is clear that <span
class="math inline">\(T_p M\)</span> is a vector space. We can also now
define, for each curve <span class="math inline">\(\gamma\)</span> on
<span class="math inline">\(M\)</span> with basepoint <span
class="math inline">\(p = \gamma(0)\)</span>, the initial velocity of
<span class="math inline">\(\gamma\)</span> to be the vector <span
class="math inline">\(\gamma &#39;(0) \in T_p M\)</span> given by <span
class="math inline">\(v = (v_\phi)_\phi\)</span>, where the components
<span class="math inline">\(v_\phi\)</span> are as in <a
href="#eq:velocity-of-curve-in-chart" data-reference-type="eqref"
data-reference="eq:velocity-of-curve-in-chart">\((38)\)</a>.
We have moreover the following:</p>
<div id="lem:describe-tangent-space" class="lemma">
<p><strong>Lemma 9</strong>. For any smooth chart <span
class="math inline">\(\chi\)</span> on <span
class="math inline">\(M\)</span> defined at <span
class="math inline">\(p\)</span>, the map <span class="math inline">\(v
\mapsto v_\chi\)</span> defines a linear isomorphism <span
class="math inline">\(T_p M \cong \mathbf{k}^n\)</span>. In particular,
<span class="math inline">\(\dim T_p M = \dim M\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The consistency condition <a
href="#eq:consistency-tangent-vectors-in-charts"
data-reference-type="eqref"
data-reference="eq:consistency-tangent-vectors-in-charts">\((39)\)</a>
implies that <span class="math inline">\(v\)</span> is determined by any
one of its components <span class="math inline">\(v_\chi\)</span>, so
the map in question is clearly injective. Conversely, given any element
<span class="math inline">\(u \in \mathbf{k}^n\)</span>, we may define a
tuple <span class="math inline">\(v = (v_\phi)_\phi\)</span> by the rule
<span class="math inline">\(v_\phi := T_{\chi(p)}(\phi \circ \chi^{-1})
u\)</span>. An application of the chain rule to the composition <span
class="math inline">\((\psi \circ \phi^{-1}) \circ (\phi
\circ  \chi^{-1})\)</span> implies for any smooth charts <span
class="math inline">\(\phi,\psi\)</span> defined at <span
class="math inline">\(p\)</span> that <a
href="#eq:consistency-tangent-vectors-in-charts"
data-reference-type="eqref"
data-reference="eq:consistency-tangent-vectors-in-charts">\((39)\)</a>
is satisfied, and so <span class="math inline">\(v\)</span> belongs to
<span class="math inline">\(T_p M\)</span>. Since <span
class="math inline">\(v_\chi = u\)</span> and <span
class="math inline">\(u\)</span> was arbitrary, we deduce that the map
in question is surjective. ◻</p>
</span></div>
<div id="example:tangent-space-open-subset-euclidean-space"
class="example">
<p><strong>Example 10</strong>. If <span
class="math inline">\(M\)</span> is an open subset of <span
class="math inline">\(\mathbf{k}^n\)</span>, then the inclusion <span
class="math inline">\(\phi : M \rightarrow \mathbf{k}^n\)</span> is a
smooth chart defined at all points of <span
class="math inline">\(M\)</span>, and the lemma gives a natural
identification <span class="math inline">\(T_p M \cong
  \mathbf{k}^n\)</span> for all <span class="math inline">\(p \in
M\)</span>. The two senses in which we have defined the initial velocity
<span class="math inline">\(\gamma&#39;(0)\)</span> of a curve <span
class="math inline">\(\gamma\)</span> on <span
class="math inline">\(M\)</span> with basepoint <span
class="math inline">\(p\)</span> (first as the ordinary derivative <span
class="math inline">\(\frac{d }{d t}
  \gamma(t)|_{t=0}\)</span>, then later as a tuple <span
class="math inline">\((v_\phi)_\phi\)</span>) are compatible under this
identification.</p>
</div>
<div id="rmk:tangent-vectors-via-curves" class="remark">
<p><strong>Remark 11</strong>. A more customary definition is that <span
class="math inline">\(T_p M\)</span> is the space of equivalence classes
<span class="math inline">\([\gamma]\)</span> of curves <span
class="math inline">\(\gamma\)</span> on <span
class="math inline">\(M\)</span> with basepoint <span
class="math inline">\(p\)</span>, with two curves <span
class="math inline">\(\gamma_1, \gamma_2\)</span> declared equivalent
precisely when <span class="math inline">\((\phi \circ \gamma_1)&#39;(0)
= (\phi \circ \gamma_2)&#39;(0)\)</span> for all charts <span
class="math inline">\(\phi\)</span> on <span
class="math inline">\(M\)</span> defined at <span
class="math inline">\(p\)</span>. That definition is isomorphic to the
one we’ve used. An isomorphism from the former to the latter may be
given by <span class="math inline">\([\gamma] \mapsto
(v_\phi)_\phi\)</span> with <span class="math inline">\(v_\phi\)</span>
as in <a href="#eq:velocity-of-curve-in-chart"
data-reference-type="eqref"
data-reference="eq:velocity-of-curve-in-chart">\((38)\)</a>;
this map is well-defined by <a
href="#eq:consistency-tangent-vectors-in-charts"
data-reference-type="eqref"
data-reference="eq:consistency-tangent-vectors-in-charts">\((39)\)</a>,
injective by definition of the equivalence relation defining <span
class="math inline">\([\gamma]\)</span>, and surjective by Lemma <a
href="#lem:describe-tangent-space" data-reference-type="ref"
data-reference="lem:describe-tangent-space">9</a> and Remark <a
href="#rmk:lots-of-curves" data-reference-type="ref"
data-reference="rmk:lots-of-curves">6</a>.</p>
</div>
<h2 id="sec:org3a5d387">§6.6. Derivatives</h2>
<p>Given a smooth map <span class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> of manifolds a point <span class="math inline">\(p \in
M\)</span> at which <span class="math inline">\(f\)</span> is defined, a
chart <span class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k} ^m\)</span> at <span class="math inline">\(p\)</span> and a
chart <span class="math inline">\(\psi : N %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k} ^n\)</span> at <span class="math inline">\(f(p)\)</span>, we
can form the smooth map <span class="math display">\[f_{\phi \psi} :=
\psi \circ f \circ \phi ^{-1} :
\mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\]</span> and consider its total derivative in the sense of
§<a href="#sec:calc-multi" data-reference-type="ref"
data-reference="sec:calc-multi">5.2</a>, which is a linear
map <span class="math display">\[T_{\phi(p)}(f_{\phi \psi})
:
\mathbf{k}^m %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n.\]</span> We can piece these linear maps together to form a
linear map <span class="math display">\[T_p f : T_p M \rightarrow
T_{f(p)} N,\]</span> called the <em>derivative of <span
class="math inline">\(f\)</span></em>, by setting, for <span
class="math inline">\(v = (v_\phi)_\phi \in T_p M\)</span>, <span id="eq:defn-derivative-manifolds" class="math display">\[\label{eq:defn-derivative-manifolds}\tag{40}
  (T_p f(v))_\psi
  :=
  T_{\phi(p)} (f_{\phi \psi}) v_\phi.\]</span> An application of the
chain rule confirms that the RHS of <a
href="#eq:defn-derivative-manifolds" data-reference-type="eqref"
data-reference="eq:defn-derivative-manifolds">\((40)\)</a>
is independent of <span class="math inline">\(\phi\)</span> and that the
the tuple <span class="math inline">\(T_p f(v)\)</span> defined
componentwise above actually belongs to <span
class="math inline">\(T_{f(p)} N\)</span>; moreover, for a composition
<span class="math inline">\(L %
  \mathrel{%
    \mathpalette{\da@xarrow{}{g}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{f}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> defined at a point <span class="math inline">\(p \in
L\)</span>, one has again <span id="eqn:chain-rule-general" class="math display">\[\label{eqn:chain-rule-general}\tag{41}
T_p (f \circ g)
=
T_{g(p)} f \circ T_p g.\]</span></p>
<div class="remark">
<p><strong>Remark 12</strong>. </p>
<ol>
<li><p>If <span class="math inline">\(M \subseteq \mathbf{k}^m, N
\subseteq \mathbf{k}^n\)</span> are open and we identify <span
class="math inline">\(T_p M \cong \mathbf{k}^m, T_{f(p)} N \cong
    \mathbf{k}^n\)</span>, then the derivative <span
class="math inline">\(T_p f : T_p M \rightarrow T_{f(p)} N\)</span>
defined just now identifies the derivative <span
class="math inline">\(T_p f : \mathbf{k}^m \rightarrow
\mathbf{k}^n\)</span> as in §<a href="#sec:calc-multi"
data-reference-type="ref"
data-reference="sec:calc-multi">5.2</a>.</p></li>
<li><p>If <span class="math inline">\(M\)</span> is an <span
class="math inline">\(n\)</span>-manifold, <span class="math inline">\(p
\in M\)</span> is a point, and <span class="math inline">\(\phi\)</span>
is a chart on <span class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span>, then the map <span
class="math inline">\(T_\phi : T_p M \rightarrow T_{\phi(p)}
\mathbf{k}^n \cong  \mathbf{k}^n\)</span> is just the projection <span
class="math inline">\(v \mapsto v_\phi\)</span>.</p></li>
<li><p>If we had instead defined tangent spaces using equivalence
classes of smooth curves as in Remark <a
href="#rmk:tangent-vectors-via-curves" data-reference-type="ref"
data-reference="rmk:tangent-vectors-via-curves">11</a>, then the
definition of the derivative of <span class="math inline">\(f\)</span>
would look like: for a curve <span class="math inline">\(\gamma\)</span>
on <span class="math inline">\(M\)</span> with basepoint <span
class="math inline">\(p\)</span> and equivalence class <span
class="math inline">\([\gamma]\)</span>, <span
class="math display">\[T_p f([\gamma]) := [f \circ \gamma].\]</span> As
noted earlier in the Euclidean case, one has the following identity of
elements of <span class="math inline">\(T_{f(p)} N\)</span>: <span
class="math display">\[(T_p f) \gamma&#39;(0)
    =
    (f \circ \gamma)&#39;(0).\]</span></p></li>
</ol>
</div>
<p>It is occasionally notationally cumbersome to refer explicitly to the
basepoint <span class="math inline">\(p\)</span> in the total derivative
<span class="math inline">\(T_p f : T_p M \rightarrow T_{f(p)}
N\)</span>; when that is the case, we might denote the latter as simply
<span class="math display">\[d f : T_p M \rightarrow T_{f(p)}
N,\]</span> with the point <span class="math inline">\(p\)</span>
understood by context as the domain of any vector <span
class="math inline">\(v\)</span> to which we apply <span
class="math inline">\(d f\)</span>. To illustrate, consider a
composition of smooth maps of manifolds <span
class="math display">\[\phi : K \xrightarrow{h} L \xrightarrow{g} M
\xrightarrow{f} N.\]</span> For a point <span class="math inline">\(p
\in K\)</span> and a tangent vector <span class="math inline">\(v \in
T_p K\)</span>, the chain rule <a href="#eqn:chain-rule-general"
data-reference-type="eqref"
data-reference="eqn:chain-rule-general">\((41)\)</a>
gives the slightly unwieldly formula <span class="math display">\[T_p
\phi(v)
=
T_{g(h(p))} f
(
T_{h(p)} g(
T_p h (v)
)
)\]</span> which we abbreviate to simply <span class="math display">\[d
\phi(v)
= d f (d g( d h(v))).\]</span></p>
<h2 id="sec:org9589e79">§6.7. Jacobians</h2>
<p>Given an <span class="math inline">\(n\)</span>-dimensional vector
space <span class="math inline">\(V\)</span>, we denote by <span
class="math inline">\(\det (V) := \Lambda^n V\)</span> its highest wedge
power. It is a one-dimensional vector space. Given a pair <span
class="math inline">\(V,W\)</span> of <span
class="math inline">\(n\)</span>-dimensional vector spaces and a linear
map <span class="math inline">\(f : V \rightarrow W\)</span>, one
obtains an induced map <span class="math inline">\(\det(f) : \det(V)
\rightarrow \det(W)\)</span>. If <span class="math inline">\(W =
V\)</span>, then <span class="math inline">\(\det(f) : \det(V)
\rightarrow \det(V)\)</span> acts on the one-dimensional space <span
class="math inline">\(\det(V)\)</span> via multiplication by the
determinant of <span class="math inline">\(f\)</span> in the sense of a
first course on linear algebra.</p>
<p>In particular, given a manifold <span
class="math inline">\(M\)</span>, we obtain for each point <span
class="math inline">\(p \in M\)</span> a one-dimensional vector space
<span class="math inline">\(\det T_p M\)</span>. Given a pair of
manifolds <span class="math inline">\(M,N\)</span> of the same
dimension, a smooth map <span class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> between them, and a point <span
class="math inline">\(p\)</span> at which <span
class="math inline">\(f\)</span> is defined, we obtain a linear map
<span class="math inline">\(\det(T_p f) : \det(T_p M) \rightarrow
\det(T_{f(p)} N)\)</span> between one-dimensional spaces, called the
<em>Jacobian determinant</em> of <span class="math inline">\(f\)</span>.
In the special case that <span class="math inline">\(M,N\)</span> are
open subsets of <span class="math inline">\(\mathbf{k}^n\)</span>, we
may identify <span class="math inline">\(T_p M, T_{f(p)} N\)</span> with
<span class="math inline">\(\mathbf{k}^n\)</span> and the Jacobian
determinant with the linear map <span
class="math inline">\(\det(\mathbf{k}^n) \rightarrow
\det(\mathbf{k}^n)\)</span> given by multiplication by the determinant
of the Jacobian matrix describing the total derivative <span
class="math inline">\(T_p f : \mathbf{k}^n \rightarrow
\mathbf{k}^n\)</span>. In general, one has <span
class="math inline">\(\det(T_p f) \neq 0\)</span> if and only if <span
class="math inline">\(T_p f\)</span> is a linear isomorphism.</p>
<h2 id="sec:org63376d9">§6.8. Inverse function theorem<span
id="sec:diff-geom-inv-func-thm"
label="sec:diff-geom-inv-func-thm"></span></h2>
<p>We record the generalization of what was given earlier in the
Euclidean case.</p>
<div class="definition">
<p><strong>Definition 13</strong>. A smooth map <span
class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> between <span class="math inline">\(n\)</span>-manifolds is
said to be a <em>local diffeomorphism</em> at a point <span
class="math inline">\(p \in M\)</span> if <span
class="math inline">\(f\)</span> is equivalent to an invertible local
map defined at <span class="math inline">\(p\)</span> with smooth
inverse, or more verbosely, if there is an open neighborhood <span
class="math inline">\(U\)</span> of <span
class="math inline">\(p\)</span> in the domain of <span
class="math inline">\(f\)</span> so that <span
class="math inline">\(f(U)\)</span> is open and the induced map <span
class="math inline">\(f : U \rightarrow f(U)\)</span> is a
diffeomorphism. In that case, there are coordinate systems <span
class="math inline">\(x_1,\dotsc,x_n\)</span> on <span
class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span> and <span class="math inline">\(y =
(y_1,\dotsc,y_n)\)</span> on <span class="math inline">\(N\)</span> at
<span class="math inline">\(f(p)\)</span> with respect to which <span
class="math inline">\(p\)</span> is the origin and so that <span
class="math inline">\(f\)</span> is given near <span
class="math inline">\(p\)</span> in these coordinates by the identity
map <span class="math inline">\(f : (x_1,\dotsc,x_n) \mapsto
(x_1,\dotsc,x_n)\)</span>.</p>
</div>
<p>For example, if <span class="math inline">\(M\)</span> is an <span
class="math inline">\(n\)</span>-manifold, then a map <span
class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{\mathbf}{}\mathchar&quot;0\hexnumber@\symAMSa
4B {\,}{}}{}%
  }%
{k}^n\)</span> is a local diffeomorphism at <span
class="math inline">\(p\)</span> if and only if it is equivalent to a
smooth chart at <span class="math inline">\(p\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 14</strong>. <em>Let <span class="math inline">\(f :
M \rightarrow N\)</span> be a smooth map of manifolds of the same
dimension. The following are equivalent:</em></p>
<ol>
<li><p><em><span class="math inline">\(T_p f : T_p M \rightarrow
T_{f(p)} N\)</span> is a <em>linear isomorphism</em> of vector spaces,
or equivalently, has nonzero Jacobian determinant <span
class="math inline">\(\det(T_p f)\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(f\)</span> is a local
diffeomorphism near <span
class="math inline">\(p\)</span>.</em></p></li>
</ol>
</div>
<p>The problem is local, so it suffices to consider the case that <span
class="math inline">\(M,N\)</span> are open subsets <span
class="math inline">\(\mathbf{k}^n\)</span>, in which case the theorem
reduces to special case given above in §<a href="#sec:calc-inv-func-thm"
data-reference-type="ref"
data-reference="sec:calc-inv-func-thm">5.4</a>.</p>
<p>Here is a particularly useful consequence:</p>
<div class="corollary">
<p><strong>Corollary 15</strong>. <em>Let <span
class="math inline">\(M\)</span> be an <span
class="math inline">\(n\)</span>-manifold and <span
class="math inline">\(p \in M\)</span>. Let <span
class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> be a smooth map defined at <span
class="math inline">\(p\)</span>. Suppose that <span
class="math inline">\(\det(T_p \phi) \neq 0\)</span>. Then <span
class="math inline">\(\phi\)</span> is equivalent to a smooth chart on
<span class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span>; in other words, there is a
neighborhood <span class="math inline">\(p \in U \subseteq M\)</span> so
that if we write <span class="math inline">\(\phi|_U =
(x_1,\dotsc,x_n)\)</span> for some component functions <span
class="math inline">\(x_i : U \rightarrow \mathbf{k}\)</span>, then
<span class="math inline">\(x_1,\dotsc,x_n\)</span> defines a coordinate
system at <span class="math inline">\(p\)</span>.</em></p>
</div>
<h2 id="sec:org7d02d39">§6.9. Local linearization of smooth maps</h2>
<h3 id="sec:org7f15f91">§6.9.1. Linear maps in terms of coordinates</h3>
<p>Suppose given an <span class="math inline">\(m\)</span>-dimensional
vector space <span class="math inline">\(V\)</span> an <span
class="math inline">\(n\)</span>-dimensional vector <span
class="math inline">\(W\)</span> and a linear map <span
class="math inline">\(f : V \rightarrow W\)</span> between them. Recall
that the <em>rank</em> of <span class="math inline">\(f\)</span> is the
dimension of its image, or equivalently, the codimension of its kernel.
Denote by <span class="math inline">\(k\)</span> the rank of <span
class="math inline">\(f\)</span>. Then <span class="math inline">\(k
\leq m\)</span> and <span class="math inline">\(k \leq n\)</span>. One
can always find bases <span
class="math inline">\(e_1,\dotsc,e_m\)</span> of <span
class="math inline">\(V\)</span> and <span
class="math inline">\(\varepsilon_1,\dotsc,\varepsilon_n\)</span> of
<span class="math inline">\(W\)</span> so that <span
class="math inline">\(f(\sum_{i=1}^m x_i e_i)
= \sum_{i=1}^k x_i \varepsilon_i\)</span>; in coordinates, <span
class="math inline">\(f\)</span> takes the form <span
class="math inline">\((x_1,\dotsc,x_m) \mapsto
(x_1,\dotsc,x_k,0,\dotsc,0)\)</span>.</p>
<h3 id="sec:org52585b3">§6.9.2. The constant rank theorem</h3>
<p>Suppose now given an <span class="math inline">\(m\)</span>-manifold
<span class="math inline">\(M\)</span>, an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(N\)</span>, a smooth map <span
class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> and a point <span class="math inline">\(p\)</span> in the
domain of <span class="math inline">\(f\)</span>.</p>
<div class="definition">
<p><strong>Definition 16</strong>. We say that <span
class="math inline">\(f\)</span> is <em>linearizable</em> at <span
class="math inline">\(p\)</span> if there are local coordinates at <span
class="math inline">\(p\)</span> with respect to which <span
class="math inline">\(f\)</span> is given by a linear map. The
<em>rank</em> of <span class="math inline">\(f\)</span> at <span
class="math inline">\(p\)</span> is then the rank of that linear
map.</p>
</div>
<p>Since any linear map is its own derivative, the rank of <span
class="math inline">\(f\)</span> at <span
class="math inline">\(p\)</span> is the same as the rank of <span
class="math inline">\(T_p f\)</span>. Denoting that rank by <span
class="math inline">\(k\)</span> (necessarily <span
class="math inline">\(k \leq \min(m,n)\)</span>), one can find local
coordinates <span class="math inline">\(x_1,\dotsc,x_m\)</span> at <span
class="math inline">\(p\)</span> and <span
class="math inline">\(y_1,\dotsc,y_n\)</span> at <span
class="math inline">\(f(p)\)</span>, putting both <span
class="math inline">\(p\)</span> and <span
class="math inline">\(f(p)\)</span> at the origin, so that <span
class="math inline">\(f\)</span> is given in the particularly concrete
form <span class="math display">\[f : (x_1,\dotsc,x_m) \mapsto
(x_1,\dotsc,x_k,0,\dotsc,0).\]</span> Since a linear map has constant
rank, an obvious necessary condition for <span
class="math inline">\(f\)</span> to be linearizable is the
following:</p>
<div class="definition">
<p><strong>Definition 17</strong>. We say that <span
class="math inline">\(f\)</span> has <em>constant rank</em> at <span
class="math inline">\(p\)</span> if the rank of <span
class="math inline">\(T_x f\)</span> takes some constant value in a
neighborhood of <span class="math inline">\(p\)</span>.</p>
</div>
<p>In fact, the two conditions are equivalent:</p>
<div id="thm:constant-rank" class="theorem">
<p><strong>Theorem 18</strong>. <em><span
class="math inline">\(f\)</span> is linearizable at <span
class="math inline">\(p\)</span> if and only if <span
class="math inline">\(f\)</span> has constant rank at <span
class="math inline">\(p\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The interesting direction (showing that if <span
class="math inline">\(f\)</span> has constant rank, then it is
linearizable) reduces to the rank theorem from multivariable calculus,
whose proof is similar to that of the implicit function theorem given in
§<a href="#sec:calc-impl-func-thm" data-reference-type="ref"
data-reference="sec:calc-impl-func-thm">5.5</a>. ◻</p>
</span></div>
<h3 id="sec:org6479c62">§6.9.3. The case of maximal rank<span
id="sec:linearization-subimm"
label="sec:linearization-subimm"></span></h3>
<p>Given <span class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> as above, the function <span class="math inline">\(x \mapsto
\mathop{\mathrm{rank}}(T_x f)\)</span> is <em>lower semicontinuous</em>,
i.e., has the property that <span class="math inline">\(\{x :
\mathop{\mathrm{rank}}(T_x f) \geq k\}\)</span> is open for all <span
class="math inline">\(k\)</span>. This is because the condition <span
class="math inline">\(\mathop{\mathrm{rank}}(T_x f) \geq k\)</span> is
detected by the nonvanishing of any <span class="math inline">\(k \times
k\)</span> minor, which is an open condition. In other words, as <span
class="math inline">\(x\)</span> varies, the rank can only “jump”
downwards.</p>
<p>The quantity <span class="math inline">\(k_0 := \min(m,n)\)</span> is
the largest possible value for the rank of <span
class="math inline">\(f\)</span> at any point, i.e., one has <span
class="math inline">\(\mathop{\mathrm{rank}}(T_x f) \leq k_0\)</span>
for all <span class="math inline">\(x\)</span>. It follows from the
lower semicontinuity noted above that the set <span
class="math inline">\(\{x : \mathop{\mathrm{rank}}(T_x f) = k_0
\}\)</span> of points at which <span class="math inline">\(f\)</span>
attains its maximal rank is <em>open</em>: if <span
class="math inline">\(f\)</span> has rank <span
class="math inline">\(k_0\)</span> at some point at some <span
class="math inline">\(p\)</span>, it automatically has rank <span
class="math inline">\(k_0\)</span> in some small neighborhood of <span
class="math inline">\(p\)</span>. This observation motivates the utility
of the following definition:</p>
<div class="definition">
<p><strong>Definition 19</strong>. For <span class="math inline">\(m
\geq n\)</span>, we say that <span class="math inline">\(f\)</span> is
<em>submersive</em> at <span class="math inline">\(p\)</span> if it
satisfies any of the following equivalent conditions:</p>
<ol>
<li><p><span class="math inline">\(\mathop{\mathrm{rank}}(T_p f) =
n\)</span>.</p></li>
<li><p><span class="math inline">\(T_p f\)</span> is
surjective.</p></li>
<li><p><span class="math inline">\(\dim \ker(T_p f) = m -
n\)</span>.</p></li>
</ol>
<p>For <span class="math inline">\(m \leq n\)</span>, we say that <span
class="math inline">\(f\)</span> is <em>immersive</em> at <span
class="math inline">\(p\)</span> if it satisfies any of the following
equivalent conditions:</p>
<ol>
<li><p><span class="math inline">\(\mathop{\mathrm{rank}}(T_p f) =
m\)</span>.</p></li>
<li><p><span class="math inline">\(T_p f\)</span> is injective.</p></li>
<li><p><span class="math inline">\(\dim \mathop{\mathrm{coker}}(T_p f) =
n-m\)</span>, where <span
class="math inline">\(\mathop{\mathrm{coker}}(T_p f) :=
T_{f(p)}N/\mathop{\mathrm{image}}(T_p f)\)</span>.</p></li>
</ol>
<p>We say that <span class="math inline">\(f\)</span> is a submersion
(resp. immersion) if it is submersive (resp. immersive) at all points
<span class="math inline">\(p\)</span>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 20</strong>. <em>Suppose <span
class="math inline">\(f : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> as above is submersive at <span
class="math inline">\(p\)</span>. Then there are coordinate systems at
<span class="math inline">\(p\)</span> with respect to which <span
class="math inline">\(f\)</span> is given by a surjective linear map.
For instance, there are coordinate systems <span
class="math inline">\(x_1,\dotsc,x_m\)</span> on <span
class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span> and <span
class="math inline">\(y_1,\dotsc,y_n\)</span> on <span
class="math inline">\(N\)</span> at <span
class="math inline">\(f(p)\)</span>, putting both <span
class="math inline">\(p\)</span> and <span
class="math inline">\(f(p)\)</span> at the origin, so that <span
class="math inline">\(f\)</span> is given by <span
class="math inline">\(f : (x_1,\dotsc,x_m) \mapsto
(x_1,\dotsc,x_n)\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The statement is local, and reduces to that of §<a
href="#sec:calc-impl-func-thm" data-reference-type="ref"
data-reference="sec:calc-impl-func-thm">5.5</a>. ◻</p>
</span></div>
<div class="theorem">
<p><strong>Theorem 21</strong>. <em>If <span
class="math inline">\(f\)</span> as above is immersive at <span
class="math inline">\(p\)</span>, then there are coordinate systems at
<span class="math inline">\(p\)</span> with respect to which <span
class="math inline">\(f\)</span> is given by an injective linear map.
For instance, there are coordinates <span
class="math inline">\(x_1,\dotsc,x_m\)</span> on <span
class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span> and <span
class="math inline">\(y_1,\dotsc,y_n\)</span> on <span
class="math inline">\(N\)</span> at <span
class="math inline">\(f(p)\)</span>, putting both <span
class="math inline">\(p\)</span> and <span
class="math inline">\(f(p)\)</span> at the origin, so that <span
class="math inline">\(f\)</span> is given by <span
class="math inline">\((x_1,\dotsc,x_m) \mapsto
(x_1,\dotsc,x_m,0,\dotsc,0)\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This reduces to a local statement which can be proved
as in §<a href="#sec:calc-impl-func-thm" data-reference-type="ref"
data-reference="sec:calc-impl-func-thm">5.5</a>
using the inverse function theorem. ◻</p>
</span></div>
<div id="cor:checking-smoothness-via-immersions" class="corollary">
<p><strong>Corollary 22</strong>. <em>Let <span
class="math inline">\(K\)</span> be a <span
class="math inline">\(k\)</span>-manifold, let <span
class="math inline">\(g : K %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
M\)</span> be a continuous map, and let <span class="math inline">\(f :
M  %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\)</span> be an immersion whose domain contains the image of <span
class="math inline">\(g\)</span>. Suppose that the composition <span
class="math display">\[K %
  \mathrel{%
    \mathpalette{\da@xarrow{}{g}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{f}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
N\]</span> is smooth. Then <span class="math inline">\(g\)</span> is
smooth.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Smoothness can be checked locally, so we may suppose
that <span class="math inline">\(K\)</span> is an open subset of <span
class="math inline">\(\mathbf{k}^k\)</span>. By the local description of
<span class="math inline">\(f\)</span> given the previous result, we may
assume that <span class="math inline">\(N = \mathbf{k}^n\)</span> and
<span class="math inline">\(M = \mathbf{k}^m \cong \mathbf{k}^m  \times
\{0\}  \subseteq \mathbf{k}^n\)</span>. We are then given a continuous
map <span class="math inline">\(\mathbf{k}^k %
  \mathrel{%
    \mathpalette{\da@xarrow{}{g}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m\)</span> with the property that the composition <span
class="math inline">\(\mathbf{k}^k %
  \mathrel{%
    \mathpalette{\da@xarrow{}{g}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m \hookrightarrow
  \mathbf{k}^n\)</span> is smooth (i.e., all partials exist). We want to
deduce that <span class="math inline">\(\mathbf{k}^k %
  \mathrel{%
    \mathpalette{\da@xarrow{}{g}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m\)</span> is smooth (i.e., all partials exist). What we want
follows immediately from the definition. ◻</p>
</span></div>
<h2 id="sec:orgde0d03e">§6.10. Submanifolds<span id="sec:submflds"
label="sec:submflds"></span></h2>
<p>Submanifolds<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> are subsets of manifolds that look
like vector subspaces up to a local diffeomorphism. More precisely:</p>
<div class="definition">
<p><strong>Definition 23</strong>. Given an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(M\)</span>, a subset <span
class="math inline">\(S\)</span> of <span
class="math inline">\(M\)</span> is said to be a <em><span
class="math inline">\(d\)</span>-dimensional submanifold</em> if for
each <span class="math inline">\(p \in S\)</span>, there is a smooth
chart <span class="math inline">\(\phi : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\)</span> at <span class="math inline">\(p\)</span> so that
<span class="math inline">\(\phi(S) = \phi(M) \cap \mathbf{k}^d \times
\{0\} \subseteq \mathbf{k}^n\)</span> (as defined in §<a
href="#sec:partial-map-images" data-reference-type="ref"
data-reference="sec:partial-map-images">4.1.4</a>);
said another way, there is a coordinate system <span
class="math inline">\(x_1,\dotsc,x_n\)</span> on <span
class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span> with respect to which <span
class="math inline">\(S\)</span> is given near <span
class="math inline">\(p\)</span> by the equation <span
class="math inline">\(x_{d+1} = \dotsb  = x_n = 0\)</span>.</p>
</div>
<p>The appropriateness of the term “submanifold” requires some
justification:</p>
<div id="thm:characterize-submanifold-smooth-structure" class="theorem">
<p><strong>Theorem 24</strong>. <em>Let <span
class="math inline">\(S\)</span> be a <span
class="math inline">\(d\)</span>-dimensional submanifold of an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(M\)</span>, regarded as a topological space with
the induced topology. Then <span class="math inline">\(S\)</span>
possess a unique structure of a smooth <span
class="math inline">\(d\)</span>-manifold (i.e., a unique maximal smooth
atlas) for which the inclusion map <span class="math inline">\(\iota : S
\rightarrow M\)</span> is immersive.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The uniqueness follows from Corollary <a
href="#cor:checking-smoothness-via-immersions" data-reference-type="ref"
data-reference="cor:checking-smoothness-via-immersions">22</a>: if <span
class="math inline">\(\mathcal{A}_1, \mathcal{A}_2\)</span> are two
maximal smooth atlases on <span class="math inline">\(S\)</span> with
the property that <span
class="math inline">\((S,d,\mathcal{A}_1)\)</span> and <span
class="math inline">\((S,d,\mathcal{A}_2)\)</span> are <span
class="math inline">\(d\)</span>-manifolds for which <span
class="math inline">\(\iota\)</span> is immersive, then each of the
inclusions <span class="math inline">\((S,d,\mathcal{A}_i)
\hookrightarrow M\)</span> is smooth, so by Corollary <a
href="#cor:checking-smoothness-via-immersions" data-reference-type="ref"
data-reference="cor:checking-smoothness-via-immersions">22</a>, the
identity maps <span class="math inline">\((S,d,\mathcal{A}_1)
\rightarrow (S,d,\mathcal{A}_2),
  (S,d,\mathcal{A}_2) \rightarrow (S,d,\mathcal{A}_1)\)</span> are
smooth two-sided inverses of each other; this shows that any smooth
chart for <span class="math inline">\(\mathcal{A}_1\)</span> is also a
smooth chart for <span class="math inline">\(\mathcal{A}_2\)</span>, and
vice-versa, so we may conclude by the maximality of <span
class="math inline">\(\mathcal{A}_1\)</span> and <span
class="math inline">\(\mathcal{A}_2\)</span> that they coincide. For the
existence, we can use the local coordinates afforded by the definition
of “submanifold” to define for each <span class="math inline">\(p \in
S\)</span> a smooth atlas <span
class="math inline">\(\mathcal{A}_p\)</span> in some neighborhood <span
class="math inline">\(U\)</span> of <span
class="math inline">\(p\)</span> for which <span class="math inline">\(U
\hookrightarrow M\)</span> is an immersion; as <span
class="math inline">\(p\)</span> varies, the atlases <span
class="math inline">\(\mathcal{A}_p\)</span> are compatible with one
another thanks to the uniqueness assertion shown before, hence their
union extends to a maximal smooth atlas on <span
class="math inline">\(S\)</span> with the required property. ◻</p>
</span></div>
<p>By Corollary <a href="#cor:checking-smoothness-via-immersions"
data-reference-type="ref"
data-reference="cor:checking-smoothness-via-immersions">22</a>, we
immediately obtain:</p>
<div id="prop:smoothness-preserved-codomain-pass-to-submfld"
class="proposition">
<p><strong>Proposition 25</strong>. <em>Let <span
class="math inline">\(f : M \rightarrow N\)</span> be a smooth map of
manifolds whose image is contained in some submanifold <span
class="math inline">\(S \subseteq N\)</span>. Then the induced map <span
class="math inline">\(f : M \rightarrow S\)</span> is also
smooth.</em></p>
</div>
<div id="rmk:submfld-locally-closed" class="remark">
<p><strong>Remark 26</strong>. A submanifold need not be open (think
<span class="math inline">\(\mathbf{k}^1
  \hookrightarrow \mathbf{k}^2\)</span>) and need not be closed (think
<span class="math inline">\((0,1) \hookrightarrow \mathbb{R}\)</span>),
but is always <em>locally closed</em> in the following equivalent senses
(as follows immediately from its local description):</p>
<ol>
<li><p><span class="math inline">\(S\)</span> is open in its closure in
<span class="math inline">\(M\)</span>.</p></li>
<li><p><span class="math inline">\(S\)</span> is the intersection of a
closed subset of <span class="math inline">\(M\)</span> and an open
subset of <span class="math inline">\(M\)</span>.</p></li>
<li><p>For each <span class="math inline">\(p \in S\)</span> there is an
open neighborhood <span class="math inline">\(p \in
    U \subseteq M\)</span> so that <span class="math inline">\(S \cap
U\)</span> is closed in <span class="math inline">\(U\)</span>.</p></li>
</ol>
</div>
<div class="exercise">
<p><strong>Exercise 1</strong>. Let <span
class="math inline">\(S,M\)</span> be manifolds and let <span
class="math inline">\(\iota : S \rightarrow M\)</span> be an injective
immersion with the property:</p>
<ul>
<li><p>for each <span class="math inline">\(x \in M\)</span> and each
open <span class="math inline">\(x \in U_1 \subseteq M\)</span>, there
exists an open <span class="math inline">\(x \in U \subseteq U_1
\subseteq M\)</span> so that the open subset <span
class="math inline">\(\iota^{-1}(U)\)</span> of <span
class="math inline">\(S\)</span> is connected.</p></li>
</ul>
<p>Show that <span class="math inline">\(\iota(S)\)</span> is a
submanifold of <span class="math inline">\(M\)</span> and that <span
class="math inline">\(\iota\)</span> is a diffeomorphism onto its
image.</p>
</div>
<h2 id="sec:org6e7a46d">§6.11. A criterion for being a submanifold</h2>
<p>In this section we record a handy criterion for determining when a
subset is actually a submanifold. It amounts to the implicit function
theorem from multivariable calculus.</p>
<div id="prop:submfld-criterion" class="proposition">
<p><strong>Proposition 27</strong>. <em>Suppose given an <span
class="math inline">\(n\)</span>-manifold <span
class="math inline">\(M\)</span> and a natural number <span
class="math inline">\(d \leq n\)</span>. Let <span
class="math inline">\(S \subseteq M\)</span> be a subset with the
property that for each <span class="math inline">\(p \in S\)</span>
there are <span class="math inline">\(m := n - d\)</span> smooth
functions <span class="math inline">\(f_1,\dotsc,f_m : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span>, defined at <span class="math inline">\(p\)</span>,
so that</em></p>
<ol>
<li><p><em><span class="math inline">\(S\)</span> is given near <span
class="math inline">\(p\)</span> by the equation <span
class="math inline">\(f_1 = \dotsb = f_m = 0\)</span> (cf. §<a
href="#sec:submflds" data-reference-type="ref"
data-reference="sec:submflds">6.10</a>), and</em></p></li>
<li><p><em><span class="math inline">\((f_1,\dotsc,f_m) : M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m\)</span> is submersive at <span
class="math inline">\(p\)</span>.</em></p></li>
</ol>
<p><em>Then <span class="math inline">\(S\)</span> is a <span
class="math inline">\(d\)</span>-dimensional submanifold of <span
class="math inline">\(M\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This is immediate from the local description of
submersive maps given in §<a href="#sec:linearization-subimm"
data-reference-type="ref"
data-reference="sec:linearization-subimm">6.9.3</a>. ◻</p>
</span></div>
<div class="remark">
<p><strong>Remark 28</strong>. The proposition is not an “if and only
if.” For example, consider <span class="math inline">\(S := \{0\}
\subseteq M := \mathbf{k}\)</span>. Clearly <span
class="math inline">\(S\)</span> is a <span
class="math inline">\(0\)</span>-dimensional submanifold. On the other
hand, one can (unwisely) define <span class="math inline">\(S\)</span>
inside <span class="math inline">\(M\)</span> by the equation <span
class="math inline">\(f_1 = 0\)</span>, where <span
class="math inline">\(f_1(x) := x^2\)</span>. For this choice, the
hypotheses of Proposition <a href="#prop:submfld-criterion"
data-reference-type="ref" data-reference="prop:submfld-criterion">27</a>
fail because <span class="math inline">\(f_1\)</span> is not submersive
at <span class="math inline">\(0\)</span>: its derivative <span
class="math inline">\(2 x\)</span> vanishes there.</p>
</div>
<h2 id="sec:orgcf4ffee">§6.12. Computing tangent spaces of submanifolds<span
id="sec:tangent-space-submfld"
label="sec:tangent-space-submfld"></span></h2>
<p>Let <span class="math inline">\(M\)</span> be an <span
class="math inline">\(n\)</span>-manifold and <span
class="math inline">\(S \subseteq M\)</span> a <span
class="math inline">\(d\)</span>-dimensional submanifold. For each <span
class="math inline">\(p \in S\)</span>, the tangent space <span
class="math inline">\(T_p S\)</span> then identifies with a <span
class="math inline">\(d\)</span>-dimensional vector subspace of the
<span class="math inline">\(n\)</span>-dimensional vector space <span
class="math inline">\(T_p M\)</span>. The following is computationally
helpful:</p>
<div id="prop:compute-tangent-space-submfld" class="proposition">
<p><strong>Proposition 29</strong>. <em>Suppose <span
class="math inline">\(S\)</span> is given near <span
class="math inline">\(p \in S\)</span> by a system of smooth equations
<span id="eq:tangent-computation-original-system" class="math display">\[\label{eq:tangent-computation-original-system}\tag{42}
    f_1 = \dotsb = f_m = 0,\]</span> where <span class="math inline">\(m
:= n-d\)</span> and <span class="math inline">\(f := (f_1,\dotsc,f_m) :
M %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

  \mathbf{k}^m\)</span> is defined and submersive at <span
class="math inline">\(p\)</span>. Then <span
class="math inline">\(T_p(S)\)</span> coincides with the space <span
class="math inline">\(\ker(T_p f)\)</span> of solutions to the system of
linear equations obtained by differentiating <a
href="#eq:tangent-computation-original-system"
data-reference-type="eqref"
data-reference="eq:tangent-computation-original-system">\((42)\)</a>.
Thus in local coordinates <span
class="math inline">\(x_1,\dotsc,x_n\)</span> at <span
class="math inline">\(p\)</span>, <span id="eq:tangent-space-as-solutions-to-linear-eqns" class="math display">\[\label{eq:tangent-space-as-solutions-to-linear-eqns}\tag{43}
    T_p(S)
    =
    \left\{  (d x_1, \dotsc, d x_n) \in \mathbf{k}^n :
      \sum_{j=1}^{n}
      \frac{\partial f_i}{\partial x_j}(p) d x_j
      = 0 \text{ for } i=1..m
    \right\}.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This is again immediate from the local description of
submersive maps. ◻</p>
</span></div>
<h2 id="sec:org75b7188">§6.13. Summary of how to work with submanifolds</h2>
<p>Let <span class="math inline">\(M\)</span> be an <span
class="math inline">\(n\)</span>-manifold and <span
class="math inline">\(S\)</span> a subset that one expects is a <span
class="math inline">\(d\)</span>-dimensional submanifold. Let’s take a
moment to explain how in practice one goes about verifying this and
computing tangent spaces. First of all, the problem is local, so for
each point <span class="math inline">\(p \in S\)</span>, one fixes local
coordinates <span class="math inline">\(x_1,\dotsc,x_n\)</span> for
<span class="math inline">\(M\)</span> at <span
class="math inline">\(p\)</span>. (If <span
class="math inline">\(M\)</span> is an open subset of <span
class="math inline">\(\mathbf{k}^n\)</span>, then one can just use the
default global coordinates.) Next, one expresses <span
class="math inline">\(S\)</span> near <span
class="math inline">\(p\)</span> as the solution set of some smooth
system <span class="math inline">\(f_1 = \dotsb = f_m = 0\)</span>,
where <span class="math inline">\(m := n - d\)</span>. Next, one
computes by hand the space <span class="math inline">\(V\)</span> of
solutions to the system of linear equations arising in <a
href="#eq:tangent-space-as-solutions-to-linear-eqns"
data-reference-type="eqref"
data-reference="eq:tangent-space-as-solutions-to-linear-eqns">\((43)\)</a>.
If it happens that <span class="math inline">\(\dim(V) = d\)</span>,
then it follows from Propositions <a href="#prop:submfld-criterion"
data-reference-type="ref" data-reference="prop:submfld-criterion">27</a>
and <a href="#prop:compute-tangent-space-submfld"
data-reference-type="ref"
data-reference="prop:compute-tangent-space-submfld">29</a> that <span
class="math inline">\(\dim \ker(T_p f) = d\)</span>, hence that <span
class="math inline">\(T_p f\)</span> is surjective, i.e., that <span
class="math inline">\(f\)</span> is submersive at <span
class="math inline">\(p\)</span>, hence that <span
class="math inline">\(S\)</span> is a <span
class="math inline">\(d\)</span>-dimensional submanifold and that <span
class="math inline">\(T_p S = V\)</span> as subspaces of <span
class="math inline">\(T_p M \cong \mathbf{k}^n\)</span>.</p>
<div class="example">
<p><strong>Example 30</strong>. Let <span class="math inline">\(M =
\mathbb{R}^3\)</span> and <span class="math display">\[S :=
\{(x,y,z)  \in M : x^2 + y^2 + z^2 = 1\}.\]</span> Thus <span
class="math inline">\(S\)</span> is defined by <span
class="math inline">\(f = 0\)</span>, where <span
class="math inline">\(f(x,y,z) := x^2 + y^2 + z^2 - 1\)</span>. The
derivative of <span class="math inline">\(f\)</span> at a point <span
class="math inline">\((x,y,z) \in S\)</span> is the linear map <span
class="math inline">\(T_{(x,y,z)}f : \mathbb{R}^3 \rightarrow
  \mathbb{R}\)</span> given by <span class="math display">\[T_{(x,y,z)}
f(d x, d y, d z)
    =
    2 x \, d x + 2 y \, d y + 2 z \, d z.\]</span> Since at least one of
<span class="math inline">\(x,y,z\)</span> is nonzero, we see that <span
class="math inline">\(T_{(x,y,z)} f\)</span> is surjective, hence that
<span class="math inline">\(f\)</span> is submersive at all points of
<span class="math inline">\(S\)</span>. Therefore <span
class="math inline">\(S\)</span> is a submanifold. Its tangent space is
given at a point <span class="math inline">\((x,y,z) \in S\)</span> by
<span class="math display">\[T_{(x,y,z)} S
    = \{(d x , d y , d z) \in \mathbb{R}^3 :
    2 x \, d x + 2 y \, d y + 2 z \, d z = 0
    \},\]</span> which is a translate of (as expected) the plane tangent
to <span class="math inline">\(S\)</span> at <span
class="math inline">\((x,y,z)\)</span> in the familiar geometric
sense.</p>
</div>
<h1 id="sec:orgec9f688">§7. Some review of differential equations<span
id="sec:diffeq" label="sec:diffeq"></span></h1>
<p>The following results will be needed only briefly in the course; we
record them here as a reference for completeness.</p>
<p>Suppose given a continuous map <span class="math inline">\(f :
\mathbf{k} \times \mathbf{k}^n %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%

\mathbf{k}^n\)</span>, with the first coordinate regarded as the “time”
variable, the second as the “position” variable, and elements of the
range as “velocities.” We suppose given an initial time <span
class="math inline">\(t_0 \in \mathbf{k}\)</span> and an initial
position <span class="math inline">\(y_0 \in \mathbf{k}^n\)</span> for
which (of course) <span class="math inline">\((t_0,y_0) \in
\mathop{\mathrm{dom}}(f)\)</span>, and consider the existence and
uniqueness problem for the linear ordinary differential equation (ODE)
<span id="eq:linear-ode" class="math display">\[\label{eq:linear-ode}\tag{44}
  y(t_0) = y_0,
  \quad
  y&#39;(t) = f(t,y(t))
  \text{ for all } t \in U.\]</span></p>
<div class="example">
<p><strong>Example 31</strong>. If <span class="math inline">\(n =
1\)</span> and <span class="math inline">\(f(t,y) := y\)</span> and
<span class="math inline">\((t_0,y_0) := (0,1)\)</span>, then we are
considering the problem <span class="math inline">\(y(0) = 1, y&#39;(t)
= y(t)\)</span>, for which it is well-known that the unique solution is
the exponential map <span class="math inline">\(y(t) := \exp(t) =
\sum_{n=0}^{\infty} t^n/n!\)</span>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 32</strong> (Uniqueness). <em>Assume that <span
class="math inline">\(f\)</span> is uniformly Lipschitz in the second
variable: <span class="math display">\[|f(t,y) - f(t,z)| \leq C |y -
z|.\]</span> Then for any convex open set <span
class="math inline">\(T\)</span> containing <span
class="math inline">\(t_0\)</span>, there is at most one continuously
differentiable <span class="math inline">\(y : T \rightarrow
\mathbf{k}^n\)</span> satisfying <a href="#eq:linear-ode"
data-reference-type="eqref"
data-reference="eq:linear-ode">\((44)\)</a>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If <span class="math inline">\(y(t), z(t)\)</span>
are two solutions to <a href="#eq:linear-ode"
data-reference-type="eqref"
data-reference="eq:linear-ode">\((44)\)</a> defined on <span
class="math inline">\(U\)</span>, then their difference <span
class="math inline">\(w(t) := y(t) - z(t)\)</span> satisfies <span
class="math inline">\(w(t_0) = 0\)</span> and <span
class="math display">\[|w&#39;(t)| = |f(t,y(t)) - f(t,z(t))| \leq
  C |y(t) - z(t)| = C |w(t)|.\]</span> Our aim is to show that the
vanishing set <span class="math inline">\(\Omega := \{t \in T : w(t) =
  0\}\)</span> is in fact all of <span class="math inline">\(T\)</span>.
Since <span class="math inline">\(\Omega\)</span> is nonempty (it
contains <span class="math inline">\(t_0\)</span>) and closed (<span
class="math inline">\(w\)</span> is continuous) and since <span
class="math inline">\(T\)</span> is connected, it will suffice to verify
<span class="math inline">\(\Omega\)</span> is open. The mean value
theorem implies that for each each <span class="math inline">\(t_1,t_2
\in T\)</span> there is some <span class="math inline">\(t\)</span> on
the line segment connecting <span class="math inline">\(t_1\)</span> and
<span class="math inline">\(t_2\)</span> so that <span id="eq:strong-condition-that-implies-vanishing" class="math display">\[\label{eq:strong-condition-that-implies-vanishing}\tag{45}
    |w(t_1) - w(t_2)| \leq |w&#39;(t)| \cdot |t_1
    - t_2| \leq C |w(t)| \cdot |t_1 - t_2|.\]</span> We apply <a
href="#eq:strong-condition-that-implies-vanishing"
data-reference-type="eqref"
data-reference="eq:strong-condition-that-implies-vanishing">\((45)\)</a>
with <span class="math inline">\(t_1 \in \Omega\)</span> (so that <span
class="math inline">\(w(t_1) = 0\)</span>) and with <span
class="math inline">\(t_2\)</span> in a closed ball <span
class="math inline">\(B \subseteq T\)</span> with origin <span
class="math inline">\(t_1\)</span> and radius at most <span
class="math inline">\(1/(2 C)\)</span> to obtain <span
class="math inline">\(|w(t_2)| \leq (1/2) M\)</span> with <span
class="math inline">\(M := \max_{t \in B} |w(t)|\)</span>. Since <span
class="math inline">\(t_2 \in B\)</span> was arbitrary, it follows that
<span class="math inline">\(M \leq (1/2) M\)</span>, hence that <span
class="math inline">\(M = 0\)</span>, hence that <span
class="math inline">\(B \subseteq \Omega\)</span>, hence that <span
class="math inline">\(\Omega\)</span> is open at <span
class="math inline">\(t_1\)</span>, as required. ◻</p>
</span></div>
<div id="thm:existence" class="theorem">
<p><strong>Theorem 33</strong> (Existence). <em>There exists an open
ball <span class="math inline">\(T\)</span> with origin <span
class="math inline">\(t_0\)</span> and a continuously differentiable
solution <span class="math inline">\(y : T \rightarrow
\mathbf{k}^n\)</span> to <a href="#eq:linear-ode"
data-reference-type="eqref"
data-reference="eq:linear-ode">\((44)\)</a>. If <span
class="math inline">\(f\)</span> is smooth, then so is <span
class="math inline">\(y\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(T_1\)</span> be a
ball with origin <span class="math inline">\(t_0\)</span> and let <span
class="math inline">\(Y\)</span> be a ball with origin <span
class="math inline">\(y_0\)</span> so that <span
class="math inline">\(f\)</span> is defined on <span
class="math inline">\(T_1 \times Y\)</span>. Let <span
class="math inline">\(T\)</span> be a ball with origin <span
class="math inline">\(t_0\)</span> so that <span
class="math display">\[\mathop{\mathrm{radius}}(T) \cdot \max_{T_1
\times Y} |f| &lt; \mathop{\mathrm{radius}}(Y).\]</span> We will show
that a solution <span class="math inline">\(y\)</span> exists with
domain <span class="math inline">\(T\)</span>. To that end, let <span
class="math inline">\(\varepsilon&gt; 0\)</span> be small. Define as
follows a function <span class="math inline">\(y_\varepsilon: T
\rightarrow Y \subseteq \mathbf{k}^n\)</span>:</p>
<ol>
<li><p>Set <span id="eq:diff-eqn-euler-initial-cond" class="math display">\[\label{eq:diff-eqn-euler-initial-cond}\tag{46}
      y_\varepsilon(0) := y_0.\]</span></p></li>
<li><p>Define <span class="math inline">\(y_\varepsilon\)</span> on
integral multiples <span class="math inline">\(n \varepsilon\in
T\)</span> of <span class="math inline">\(\varepsilon\)</span>
inductively by requiring that <span id="eq:diff-eqn-euler-initial-step" class="math display">\[\label{eq:diff-eqn-euler-initial-step}\tag{47}
    y_\varepsilon((n+1) \varepsilon)
    = y_\varepsilon(n \varepsilon) + \varepsilon f(n \varepsilon, y(n
\varepsilon)).\]</span> This makes sense: our construction of <span
class="math inline">\(T\)</span> implies that <span
class="math inline">\(y(n \varepsilon) \in Y\)</span> for all <span
class="math inline">\(n \varepsilon\in T\)</span>. (This is the “Euler
method” for solving ODEs.)</p></li>
<li><p>Define <span class="math inline">\(y_\varepsilon(t)\)</span> for
general <span class="math inline">\(t \in T\)</span> by rounding <span
class="math inline">\(t\)</span> to the nearest integral multiple <span
class="math inline">\(n \varepsilon\in T\)</span> of <span
class="math inline">\(\varepsilon\)</span> and setting <span
class="math inline">\(y_\varepsilon(t) := y_\varepsilon(n
\varepsilon)\)</span>.</p></li>
</ol>
<p>Using the elementary consequences <span
class="math display">\[y_\varepsilon(t) \ll 1\]</span> and <span
class="math display">\[|y_\varepsilon(t) - y_\varepsilon(s)| \ll |t - s|
+ o_{\varepsilon\rightarrow 0}(1)\]</span> of the construction of <span
class="math inline">\(y_\varepsilon\)</span> and arguing as in the proof
of Arzeli–Ascoli, we obtain a sequence <span
class="math inline">\(\varepsilon_j \rightarrow 0\)</span> and a bounded
Lipschitz function <span class="math inline">\(y : T \rightarrow
Y\)</span> (given by the uniform limit <span class="math inline">\(y(t)
= \lim_{j \rightarrow \infty} y_{\varepsilon_j}(t)\)</span>) satisfying
<span class="math inline">\(y(0) = y_0\)</span> and, for all <span
class="math inline">\(t_1,t_2 \in T\)</span> with <span
class="math inline">\(t_1 \leq t_2\)</span>, <span
class="math display">\[\begin{align}
    y(t_2) - y(t_1)
    &amp;=
  \lim_{j \rightarrow \infty}
      y_{\varepsilon_j}(t_2) - y_{\varepsilon_j}(t_1)
      \\
    &amp;=
  \lim_{j \rightarrow \infty}
  \sum _{
    \substack{
      n \in \mathbb{Z} : \\
      n \varepsilon_j \in [t_1,t_2]
    }
  }
    \varepsilon_j f(n \varepsilon_j, y_{\varepsilon_j}(n \varepsilon_j))
    \\
    &amp;=
  \lim_{\varepsilon\rightarrow 0}
  \sum _{
    \substack{
      n \in \mathbb{Z} : \\
      n \varepsilon\in [t_1,t_2]
    }
  }
    \varepsilon f(n \varepsilon, y(n \varepsilon))
    \\
    &amp;=
  \int_{t_1}^{t_2} f(t,y(t)) \, d t.
  
\end{align}\]</span> By the fundamental theorem of calculus, we
conclude that <span class="math inline">\(y\)</span> is differentiable
and satisfies <a href="#eq:linear-ode" data-reference-type="eqref"
data-reference="eq:linear-ode">\((44)\)</a>. Note finally that if
<span class="math inline">\(f\)</span> is smooth, then iterated
application of the differential equation implies that <span
class="math inline">\(y\)</span> is also smooth. ◻</p>
</span></div>
<div class="example">
<p><strong>Example 34</strong>. A simple (and well-known) example
illustrating the necessity of taking <span
class="math inline">\(T\)</span> sufficiently small is when <span
class="math inline">\(f : \mathbf{k} \times \mathbf{k}^2 \rightarrow
\mathbf{k}^2\)</span> is given by <span class="math inline">\(f(t,x) :=
(x_1^2,x_1 x_2)\)</span>; for <span class="math inline">\(y_0 = (u,v)
\in \mathbf{k}^2\)</span> with <span class="math inline">\(u \neq
0\)</span> and <span class="math inline">\(t_0 := 0\)</span>, the unique
solution <span class="math inline">\(y\)</span> to <a
href="#eq:linear-ode" data-reference-type="eqref"
data-reference="eq:linear-ode">\((44)\)</a> is given for <span
class="math inline">\(t\)</span> in a neighborhood of <span
class="math inline">\(t_0\)</span> by <span class="math display">\[y(t)
    = (\frac{u}{1 - t u}, \frac{v}{1 - t u}),\]</span> which blows up as
<span class="math inline">\(t \rightarrow 1/u\)</span>.</p>
</div>
<p>We finally discuss the dependence of the solution <span
class="math inline">\(y\)</span> under “smooth deformation of
parameters” in the initial condition or the differential equation.</p>
<div class="theorem">
<p><strong>Theorem 35</strong> (Smooth dependence of solutions). <em>Let
<span class="math inline">\(\Pi\)</span> be an open subset of some
Euclidean space. Let <span class="math display">\[f : \mathbf{k} \times
\mathbf{k}^n \times \Pi %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\]</span> <span class="math display">\[y_0 : \Pi %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^n\]</span> be smooth. Suppose given an initial time <span
class="math inline">\(t_0 \in \mathbf{k}\)</span> and initial parameter
<span class="math inline">\(\pi_0 \in \Pi\)</span> so that <span
class="math inline">\(y_0\)</span> is defined at <span
class="math inline">\(\pi_0\)</span> and <span
class="math inline">\(f\)</span> is defined at <span
class="math inline">\((t_0,y_0(\pi_0),\pi_0)\)</span>. Then there exist
open balls <span class="math inline">\(T \subset \mathbf{k}\)</span>
with origin <span class="math inline">\(t_0\)</span> and <span
class="math inline">\(\Pi_0 \subseteq \Pi\)</span> with origin <span
class="math inline">\(\pi_0\)</span> and a smooth solution <span
class="math inline">\(y : T \times \Pi_0 \rightarrow
\mathbf{k}^n\)</span> to the differential equation <span id="eq:diffeq-with-params" class="math display">\[\label{eq:diffeq-with-params}\tag{48}
    \frac{\partial}{\partial t} y(t,\pi)
  = f(t,y(t,\pi),\pi).\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Arguing as in the proof of Theorem <a
href="#thm:existence" data-reference-type="ref"
data-reference="thm:existence">33</a> and using only the continuity of
<span class="math inline">\(f\)</span>, we may choose <span
class="math inline">\(T,\Pi_0\)</span> as above and a ball <span
class="math inline">\(Y \subseteq \mathbf{k}^n\)</span> so that</p>
<ol>
<li><p><span class="math inline">\(f\)</span> is defined on a
neighborhood of some compact set containing <span
class="math inline">\(T \times Y \times \Pi_0\)</span>,</p></li>
<li><p><span class="math inline">\(y_0\)</span> is defined on <span
class="math inline">\(\Pi_0\)</span>, and</p></li>
<li><p>for each <span class="math inline">\(\pi \in \Pi_0\)</span>, the
ball in <span class="math inline">\(\mathbf{k}^n\)</span> with origin
<span class="math inline">\(y_0(\pi)\)</span> and radius <span
class="math inline">\(R\)</span>, where <span class="math inline">\(R :=
\mathop{\mathrm{radius}}(T) \cdot \max_{T_1 \times Y \times
\Pi_0}|f|\)</span>, is contained in a compact subset of the interior of
<span class="math inline">\(Y\)</span>.</p></li>
</ol>
<p>Running through the proof of Theorem <a href="#thm:existence"
data-reference-type="ref" data-reference="thm:existence">33</a>, we
obtain a function <span class="math inline">\(y : Y \times \Pi
\rightarrow Y\)</span> that is smooth in the first variable and
satisfies <a href="#eq:diffeq-with-params" data-reference-type="eqref"
data-reference="eq:diffeq-with-params">\((48)\)</a>. We
now verify that <span class="math inline">\(y\)</span> is smooth in the
second variable. By a compactness argument, it will suffice (after
possibly shrinking <span class="math inline">\(\Pi_0\)</span> a bit) to
verify that each <span class="math inline">\(\pi_1 \in \Pi_0\)</span> is
contained in a small ball <span class="math inline">\(\Pi_1 \subseteq
\Pi_0\)</span> on which <span class="math inline">\(y\)</span> is
smooth. To that end, fix <span class="math inline">\(d \geq 1\)</span>
and consider for <span class="math inline">\(\pi \in \Pi_1\)</span> the
Taylor series <span class="math display">\[y_0(\pi)
    =
    \sum_{\alpha \leq |d|}
    (\pi - \pi_1)^\alpha y_0^{(\alpha)}(\pi_1)
    + O(|\pi - \pi_1|)^{d + 1},\]</span> <span
class="math display">\[f(t,y,\pi)
    =
    \sum_{\alpha \leq |d|}
    (\pi - \pi_1)^\alpha
    f^{(\alpha)}(t,y,\pi_1)
    + O(|\pi - \pi_1|)^{d + 1}.\]</span> The errors are uniform thanks
to the property (1) of <span class="math inline">\(f\)</span>. Running
through the proof of Theorem <a href="#thm:existence"
data-reference-type="ref" data-reference="thm:existence">33</a> and
staring at <a href="#eq:diff-eqn-euler-initial-cond"
data-reference-type="eqref"
data-reference="eq:diff-eqn-euler-initial-cond">\((46)\)</a>
and <a href="#eq:diff-eqn-euler-initial-step"
data-reference-type="eqref"
data-reference="eq:diff-eqn-euler-initial-step">\((47)\)</a>
for a bit, we obtain an expansion <span class="math display">\[y(t,\pi)
    = \sum_{\alpha \leq |d|}
    (\pi - \pi_1)^\alpha
    y^{(\alpha)}(t,\pi_1)
    + O(|\pi - \pi_1|)^{d + 1}.\]</span> Thus <span
class="math inline">\(y\)</span> is smooth in the second variable. By
iterating the differential equation we conclude that <span
class="math inline">\(y\)</span> is jointly smooth in both
variables. ◻</p>
</span></div>
<h1 id="sec:orgaef96e9">§8. Some review of group theory</h1>
<h2 id="sec:orgd7903af">§8.1. Basic definition</h2>
<p>Recall that a <em>group</em> is a tuple <span
class="math inline">\((G,m,i,e)\)</span>, often abbreviated simply by
<span class="math inline">\(G\)</span>, where</p>
<ol>
<li><p><span class="math inline">\(G\)</span> is a set,</p></li>
<li><p><span class="math inline">\(m : G \times G \rightarrow G\)</span>
is a map called <em>multiplication</em> and abbreviated <span
class="math inline">\(x y := m(x,y)\)</span>,</p></li>
<li><p><span class="math inline">\(i : G \rightarrow G\)</span> is a map
called <em>inversion</em> and abbreviated <span
class="math inline">\(x^{-1} := i(x)\)</span>, and</p></li>
<li><p><span class="math inline">\(e \in G\)</span> is an element called
the <em>identity</em> element</p></li>
</ol>
<p>and so that the usual axioms of group theory are satisfied; we do not
recall them here. For example, the associativity axiom reads <span
class="math inline">\(m(x,m(y,z)) = m(m(x,y),z)\)</span>.</p>
<h2 id="sec:orgcf966cd">§8.2. Permutation groups</h2>
<p>One of the first examples of groups encountered in a basic course is
the symmetric group <span class="math inline">\(S(n)\)</span>. More
generally, one considers for any set <span
class="math inline">\(X\)</span> the permutation group <span
class="math inline">\(\operatorname{Perm}(X)\)</span>, defined to
consist of bijections <span class="math inline">\(\sigma : X \rightarrow
X\)</span> and with the group law given by composition: <span
class="math inline">\(\sigma_1 \sigma_2 := \sigma_1 \circ
\sigma_2\)</span>. For example, <span class="math inline">\(S(n) =
\operatorname{Perm}(\{1,\dotsc,n\})\)</span>.</p>
<p>A particularly concrete class of groups are the subgroups of the form
<span class="math inline">\(G \leq \operatorname{Perm}(X)\)</span> for
some set <span class="math inline">\(X\)</span>. Cayley’s theorem
asserts that <em>every</em> group is isomorphic to one of this form:
indeed, one can take <span class="math inline">\(X = G\)</span> and
define <span class="math inline">\(G \hookrightarrow
\operatorname{Perm}(G)\)</span> via <span class="math inline">\(g
\mapsto [x \mapsto g x]\)</span>. Moreover, if <span
class="math inline">\(G\)</span> is finite, then one can take <span
class="math inline">\(X\)</span> to be finite.</p>
<h2 id="sec:orgaff9727">§8.3. Topological groups</h2>
<p>One reason to phrase the definition in the above way is that it
places the emphasis on the maps <span
class="math inline">\(m,i\)</span>. By equipping <span
class="math inline">\(G\)</span> with some additional structure and then
requiring that those maps respect such structure, one obtains
interesting classes of groups. For example:</p>
<div id="defn:top-gp" class="definition">
<p><strong>Definition 36</strong>. A <em>topological group</em> is
defined to be a group <span class="math inline">\(G = (G,m,i,e)\)</span>
equipped with the structure of a topological space and for which the
maps <span class="math inline">\(m, i\)</span> are continuous. A
<em>morphism of topological groups</em> <span class="math inline">\(f :
G \rightarrow H\)</span> is a continuous group homomorphism. An
<em>action</em> of a topological group <span
class="math inline">\(G\)</span> on a Hausdorff topological space <span
class="math inline">\(X\)</span> is a continuous map <span
class="math inline">\(\alpha : G \times X \rightarrow X\)</span> with
the property that <span class="math inline">\(\alpha(e,x) = x\)</span>
and <span class="math inline">\(\alpha(g_1 g_2,x) =
\alpha(g_1,\alpha(g_2,x))\)</span>; one typically abbreviates <span
class="math inline">\(g x := \alpha(g,x)\)</span>.</p>
</div>
<p>This definition is simple, but already fairly rich:</p>
<div id="exercise:openness-top-groups-ambient-spaces" class="exercise">
<p><strong>Exercise 2</strong>. Let <span
class="math inline">\(X\)</span> be a topological space. Let <span
class="math inline">\(G \subseteq X\)</span> be a topological group that
is also a subspace of <span class="math inline">\(X\)</span>, equipped
with the induced topology. Suppose there is an open <span
class="math inline">\(U
  \subseteq X\)</span> for which <span class="math inline">\(e \in U
\subseteq G\)</span>, where <span class="math inline">\(e\)</span>
denotes the identity element of <span class="math inline">\(G\)</span>.
Show that <span class="math inline">\(G\)</span> is open in <span
class="math inline">\(X\)</span>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 3</strong>. Let <span
class="math inline">\(G\)</span> be a topological group. Let <span
class="math inline">\(H \leq G\)</span> be a subgroup. Suppose that
<span class="math inline">\(H\)</span> is <em>locally closed</em> in
<span class="math inline">\(G\)</span> in the sense that there is a
neighborhood <span class="math inline">\(U \subseteq G\)</span> of the
identity with the property that <span class="math inline">\(H \cap
U\)</span> is closed in <span class="math inline">\(U\)</span>. Show
that <span class="math inline">\(H\)</span> is closed in <span
class="math inline">\(G\)</span>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 4</strong>. Let <span
class="math inline">\(G\)</span> be a topological group, and <span
class="math inline">\(H \leq G\)</span> an open subgroup. Show that
<span class="math inline">\(H\)</span> is closed.</p>
</div>
<div
id="exercise:connected-topological-group-generated-by-any-neighborhood"
class="exercise">
<p><strong>Exercise 5</strong>. Let <span
class="math inline">\(G\)</span> be a connected topological group, and
let <span class="math inline">\(U\)</span> be a neighborhood of the
identity. Show that <span class="math inline">\(U\)</span> generates
<span class="math inline">\(G\)</span>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 6</strong>. Let <span
class="math inline">\(G\)</span> be a topological group, and let <span
class="math inline">\(H \leq G\)</span> be a subgroup. Equip the set
<span class="math inline">\(G/H\)</span> with the quotient topology.
Show that the following are equivalent:</p>
<ol>
<li><p><span class="math inline">\(H\)</span> is closed.</p></li>
<li><p><span class="math inline">\(G/H\)</span> is Hausdorff.</p></li>
</ol>
<p>[Hint: If <span class="math inline">\(H\)</span> is closed, show
first that for each <span class="math inline">\(g \in G - H\)</span>
there is a neighborhood <span class="math inline">\(U\)</span> of the
identity in <span class="math inline">\(G\)</span> so that <span
class="math inline">\(U^{-1} g U \cap H = \emptyset\)</span>.]</p>
</div>
<div class="exercise">
<p><strong>Exercise 7</strong>. Let <span
class="math inline">\(G\)</span> be locally compact topological group,
let <span class="math inline">\(g \in G\)</span>, and let <span
class="math inline">\(V \subseteq G\)</span> be a neighborhood of <span
class="math inline">\(g\)</span>. Show that there is an open
neighborhood <span class="math inline">\(U \subseteq G\)</span> of <span
class="math inline">\(e\)</span> so that</p>
<ol>
<li><p><span class="math inline">\(\overline{U}\)</span> is
compact,</p></li>
<li><p><span class="math inline">\(U = U^{-1}\)</span>,</p></li>
<li><p><span class="math inline">\(U^{n} g \subseteq V\)</span> for all
<span class="math inline">\(n \leq 100\)</span>, and</p></li>
<li><p><span class="math inline">\(g U^{n} \subseteq V\)</span> for all
<span class="math inline">\(n \leq 100\)</span>.</p></li>
</ol>
<p>Here <span class="math inline">\(U^{n} := \{u_1 \dotsb u_{n} :
u_1,\dotsc,u_{n} \in U\}\)</span>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 8</strong>. Let <span
class="math inline">\(G\)</span> be a second countable topological
group. Let <span class="math inline">\(U \subseteq G\)</span> be a
subset with nonempty interior. Show that there is a sequence <span
class="math inline">\(g_n \in G\)</span> so that <span
class="math inline">\(G = \cup U g_n = \cup g_n U\)</span>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 9</strong>. Let <span
class="math inline">\(G\)</span> be a topological group, let <span
class="math inline">\(X\)</span> be a Hausdorff topological space, and
suppose given a transitive action of <span
class="math inline">\(G\)</span> on <span
class="math inline">\(X\)</span>. Let <span
class="math inline">\(U\)</span> be a compact subset of <span
class="math inline">\(G\)</span>, and let <span class="math inline">\(x
\in X\)</span>. Show that <span class="math inline">\(U x\)</span> is
closed.</p>
</div>
<div class="exercise">
<p><strong>Exercise 10</strong>. Say that a topological space <span
class="math inline">\(X\)</span> is <em>countable at infinity</em> if
<span class="math inline">\(X\)</span> can be written as a countalbe
union of compact subsets.</p>
<p>Show that if <span class="math inline">\(X\)</span> is locally
compact and second-countable, then <span
class="math inline">\(X\)</span> is countable at infinity.</p>
</div>
<div id="exercise-topological-groups-quotient-map-homeomorphism"
class="exercise">
<p><strong>Exercise 11</strong>. Let <span
class="math inline">\(G\)</span> be a topological group, let <span
class="math inline">\(X\)</span> be a Hausdorff topological space, and
suppose given a transitive action of <span
class="math inline">\(G\)</span> on <span
class="math inline">\(X\)</span>. Let <span class="math inline">\(x \in
X\)</span>. Show that the stabilizer <span class="math inline">\(H :=
\{g \in G : g x = x\}\)</span> is a closed subgroup of <span
class="math inline">\(G\)</span>. Suppose that</p>
<ol>
<li><p><span class="math inline">\(G\)</span> is locally compact and is
countable at infinity, and</p></li>
<li><p><span class="math inline">\(X\)</span> is locally
compact.</p></li>
</ol>
<p>Show that the map <span class="math inline">\(\pi : G/H \rightarrow
X\)</span> given by <span class="math inline">\(\pi(g) := g x\)</span>
is a homeomorphism. [It suffices to show that <span
class="math inline">\(\pi\)</span> is open. Use some of the previous
exercises together with the following variant of the Baire category
theorem: if a locally compact topological space <span
class="math inline">\(E\)</span> is a countable union of closed subsets
<span class="math inline">\(E_n\)</span>, then some <span
class="math inline">\(E_n\)</span> has nonempty interior.]</p>
</div>
<h1 id="sec:org66cd91a">§9. Some review of functional analysis</h1>
<h2 id="sec:org3082d00">§9.1. Definitions and elementary properties of
operators on Hilbert spaces</h2>
<div class="definition">
<p><strong>Definition 37</strong>. Recall that an <em>operator</em> on a
Hilbert space (real or complex) <span class="math inline">\(V\)</span>
is a linear map <span class="math inline">\(T : V \rightarrow
V\)</span>. It is <em>bounded</em> if <span
class="math inline">\(\sup_{x \in V : |x| = 1} \|T x\| &lt;
  \infty\)</span>, <em>self-adjoint</em> if <span
class="math inline">\(\langle T x, y \rangle = \langle x, T y
\rangle\)</span> for all <span class="math inline">\(x,y \in V\)</span>,
and <em>compact</em> if <span class="math inline">\(T x_n\)</span> has a
convergent subsequence whenever <span class="math inline">\(x_n\)</span>
is a bounded sequence in <span class="math inline">\(V\)</span>. An
<em>eigenvector</em> of <span class="math inline">\(T\)</span> is a
nonzero element <span class="math inline">\(v \in V\)</span> for which
<span class="math inline">\(T v = \lambda v\)</span> for some scalar
<span class="math inline">\(\lambda\)</span>, called the
<em>eigenvalue</em>.</p>
</div>
<div class="lemma">
<p><strong>Lemma 38</strong>. Let <span class="math inline">\(T\)</span>
be a self-adjoint operator on a Hilbert space <span
class="math inline">\(V\)</span>.</p>
<ol>
<li><p>The eigenvalues of <span class="math inline">\(T\)</span> are
real.</p></li>
<li><p>The eigenspaces of <span class="math inline">\(T\)</span> are
orthogonal to one another.</p></li>
<li><p>If <span class="math inline">\(T\)</span> acts on a subspace
<span class="math inline">\(U\)</span> of <span
class="math inline">\(V\)</span>, then it acts also on the orthogonal
complement <span class="math inline">\(U^\perp\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content">  </p>
<ol>
<li><p>If <span class="math inline">\(T u = \lambda u\)</span>, then
<span class="math inline">\(\lambda \langle u, u \rangle = \langle T u,
u \rangle
    = \langle u, T u \rangle = \overline{\langle T u, u \rangle}
    = \overline{\lambda } \langle u, u \rangle\)</span>.</p></li>
<li><p>If moreover <span class="math inline">\(T v = \lambda &#39;
v\)</span>, then <span class="math inline">\(\lambda \langle u,v \rangle
= \langle  T u, v \rangle
    = \langle u, T v \rangle = \lambda &#39; \langle u,v
\rangle\)</span>, and so either <span class="math inline">\(\lambda
&#39; = \lambda\)</span> or <span class="math inline">\(\langle u,v
\rangle = 0\)</span>.</p></li>
<li><p>Suppose <span class="math inline">\(T u \in U\)</span> for all
<span class="math inline">\(u \in U\)</span>. Let <span
class="math inline">\(v \in U^\perp\)</span>. For <span
class="math inline">\(u \in U\)</span>, we have <span
class="math inline">\(T u \in U\)</span>, and so <span
class="math inline">\(\langle T v, u \rangle = \langle v, T u \rangle =
0\)</span>. Thus <span class="math inline">\(T v \in
U^\perp\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="sec:org816b98f">§9.2. Compact self-adjoint operators on nonzero
Hilbert spaces have eigenvectors</h2>
<div id="thm:compact-self-adj-has-eigencetor" class="theorem">
<p><strong>Theorem 39</strong>. <em>Let <span
class="math inline">\(V\)</span> be a nonzero Hilbert space. Let <span
class="math inline">\(T\)</span> be a compact self-adjoint operator on
<span class="math inline">\(V\)</span>. Then <span
class="math inline">\(T\)</span> has an eigenvector.</em></p>
</div>
<p>The basic idea of the proof can seen most transparently when <span
class="math inline">\(V\)</span> is a finite-dimensional real Hilbert
space: if <span class="math inline">\(x\)</span> is an element of the
unit sphere in <span class="math inline">\(V\)</span> at which <span
class="math inline">\(\langle T x, x \rangle\)</span> assumes a local
maximum, then the first derivative test implies that for any <span
class="math inline">\(v\)</span> orthogonal to <span
class="math inline">\(x\)</span>, <span class="math display">\[0 =
\frac{d}{d \varepsilon} \langle T (x + v), x + v)
\rangle|_{\varepsilon=0} = \langle T v, x \rangle + \langle T x, v
\rangle = 2 \langle T x, v \rangle.\]</span> It follows that <span
class="math inline">\(T x \in (x^\perp)^\perp = \mathbb{R} x\)</span>,
and so <span class="math inline">\(x\)</span> is the required
eigenvector.</p>
<p>To adapt the argument to the infinite-dimensional case, we replace
the role of differential calculus with some artful application of the
parallelogram law <span class="math display">\[4 \Re  \langle T x, y
\rangle
= \langle T(x+ y), x + y  \rangle
- \langle T(x- y), x- y \rangle.\]</span> One of the steps en route to
the solution is of independent interest:</p>
<div class="lemma">
<p><strong>Lemma 40</strong>. Let <span class="math inline">\(T\)</span>
be a self-adjoint operator on a Hilbert space <span
class="math inline">\(V\)</span>. Then <span
class="math display">\[\sup_{x \in V : |x| = 1} |\langle T x, x \rangle|
  =
  \sup_{x,y: |x|=|y| = 1} |\langle T x, y \rangle|.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Denote by <span class="math inline">\(M\)</span> the
LHS and by <span class="math inline">\(M&#39;\)</span> the RHS. Clearly
<span class="math inline">\(M \leq M&#39;\)</span>. Conversely, for
<span class="math inline">\(x,y \in V\)</span> with <span
class="math inline">\(|x| = |y| = 1\)</span> and <span
class="math inline">\(\theta \in \mathbb{C}^{(1)}\)</span> chosen so
that <span class="math inline">\(\langle T x, \theta y \rangle\)</span>
is real, the parallelogram law applied to <span
class="math inline">\(x\)</span> and <span class="math inline">\(\theta
y\)</span> gives <span class="math display">\[4 \theta  \langle T x, y
\rangle
  = \langle T(x+ \theta  y), x + \theta y  \rangle
  - \langle T(x-\theta y), x-\theta y \rangle.\]</span> From this it
follows that <span class="math inline">\(M&#39; \leq M\)</span>. ◻</p>
</span></div>
<div class="proof">
<p><em>Proof of Theorem <a href="#thm:compact-self-adj-has-eigencetor"
data-reference-type="ref"
data-reference="thm:compact-self-adj-has-eigencetor">39</a>.</em> Since
<span class="math inline">\(T\)</span> is compact, it is bounded, and so
the quantity <span class="math display">\[M := \sup_{x \in V : |x| = 1}
|\langle T x, x \rangle|\]</span> is finite. If <span
class="math inline">\(M = 0\)</span>, then the self-adjointness of <span
class="math inline">\(T\)</span> and the parallelogram law applied to
<span class="math inline">\(x \in V\)</span> and <span
class="math inline">\(y := T x\)</span> implies that <span
class="math display">\[4 \|T x\|^2
  =
  \langle T (x+y), x+y \rangle -
  \langle T (x-y), x-y \rangle
  = 0,\]</span> so <span class="math inline">\(T\)</span> is the zero
operator and any nonzero element of <span
class="math inline">\(V\)</span> is an eigenvector. We turn to the
remaining case <span class="math inline">\(M \neq 0\)</span>. Recall
from the lemma that <span class="math inline">\(M\)</span> coincides
with the operator norm <span class="math inline">\(\sup_{x,y: |x|=|y| =
1} |\langle T x, y \rangle|\)</span>. There is thus a nonzero real
number <span class="math inline">\(\lambda = \pm M\)</span> and a
sequence of unit vectors <span class="math inline">\(x_n\)</span> so
that <span class="math display">\[\langle T x_n, x_n  \rangle
\rightarrow \lambda,\]</span> <span class="math display">\[\langle T
x_n, T x_n \rangle \leq \lambda^2.\]</span> It follows then from the
identity <span class="math display">\[\|T x_n - \lambda x_n\|^2
  = \langle T x_n, T x_n \rangle
  - 2 \lambda  \langle T x_n, x_n \rangle
  + \lambda^2\]</span> that <span id="eq:some-convergence-of-T-x-n" class="math display">\[\label{eq:some-convergence-of-T-x-n}\tag{49}
    T x_n - \lambda x_n \rightarrow 0.\]</span> Since <span
class="math inline">\(T\)</span> is compact, the sequence <span
class="math inline">\(T x_n\)</span> has a subsequential limit <span
class="math inline">\(y\)</span>. By <a
href="#eq:some-convergence-of-T-x-n" data-reference-type="eqref"
data-reference="eq:some-convergence-of-T-x-n">\((49)\)</a>,
one has <span class="math inline">\(|y| = |\lambda|\)</span>, hence
<span class="math inline">\(y \notin 0\)</span>. By applying <span
class="math inline">\(T\)</span> to <a
href="#eq:some-convergence-of-T-x-n" data-reference-type="eqref"
data-reference="eq:some-convergence-of-T-x-n">\((49)\)</a>,
one obtains <span class="math inline">\(T y = \lambda y\)</span>. Thus
<span class="math inline">\(y\)</span> is the required eigenvector of
<span class="math inline">\(T\)</span>. ◻</p>
</div>
<div class="remark">
<p><strong>Remark 41</strong>. A self-adjoint operator on a Hilbert
space need not have any eigenvectors; consider <span
class="math inline">\(f(x) \mapsto x f(x)\)</span> on <span
class="math inline">\(L^2([0,1])\)</span>. In this sense, the
compactness assumption is necessary.</p>
</div>
<h2 id="sec:orgaec3806">§9.3. Spectral theorem for compact self-adjoint
operators on a Hilbert space</h2>
<div id="thm:spectral-thm-self-adj" class="theorem">
<p><strong>Theorem 42</strong>. <em>Let <span
class="math inline">\(T\)</span> be a compact self-adjoint operator on a
Hilbert space <span class="math inline">\(V\)</span>. For <span
class="math inline">\(\lambda \in \mathbb{R}\)</span>, denote by <span
class="math inline">\(V_\lambda \leq V\)</span> the <span
class="math inline">\(\lambda\)</span>-eigenspace of <span
class="math inline">\(T\)</span>. Then <span
class="math inline">\(V\)</span> is the Hilbert space orthogonal direct
sum <span id="eq:spectral-theorem-compact-self-adjoint-1" class="math display">\[\label{eq:spectral-theorem-compact-self-adjoint-1}\tag{50}
    V = \oplus_\lambda V_\lambda\]</span> of its kernel <span
class="math inline">\(V_0 = \ker(T)\)</span> and its eigenspaces <span
class="math inline">\(V_\lambda\)</span> with nonzero eigenvalue <span
class="math inline">\(\lambda\)</span>. Moreover, for any <span
class="math inline">\(\varepsilon&gt; 0\)</span>, <span id="eq:spectral-theorem-compact-self-adjoint-2" class="math display">\[\label{eq:spectral-theorem-compact-self-adjoint-2}\tag{51}
    \dim(\oplus_{\lambda : |\lambda| &gt; \varepsilon} V_\lambda ) &lt;
\infty.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The orthogonal complement of <span
class="math inline">\(\oplus_\lambda V_\lambda\)</span> is <span
class="math inline">\(T\)</span>-stable and contains no eigenvectors for
<span class="math inline">\(T\)</span>; by Lemma <a
href="#eq:spectral-theorem-compact-self-adjoint-1"
data-reference-type="ref"
data-reference="eq:spectral-theorem-compact-self-adjoint-1">50</a>,
it is the zero space, giving <a
href="#eq:spectral-theorem-compact-self-adjoint-1"
data-reference-type="eqref"
data-reference="eq:spectral-theorem-compact-self-adjoint-1">\((50)\)</a>.</p>
<p>For each <span class="math inline">\(\varepsilon&gt; 0\)</span>, the
space <span class="math inline">\(\oplus_{\lambda : |\lambda| &gt;
\varepsilon} V_\lambda\)</span> admits an orthonormal basis of
eigenvectors for <span class="math inline">\(T\)</span> with eigenvalues
of magnitude at least <span class="math inline">\(\varepsilon\)</span>;
if that basis were to contain an infinite sequence, then the image of
that sequence under <span class="math inline">\(T\)</span> would have no
convergent subsequence, contradicting the compactness of <span
class="math inline">\(T\)</span>. This establishes <a
href="#eq:spectral-theorem-compact-self-adjoint-2"
data-reference-type="eqref"
data-reference="eq:spectral-theorem-compact-self-adjoint-2">\((51)\)</a>. ◻</p>
</span></div>
<h2 id="sec:org14df4a0">§9.4. Basics on matrix coefficients</h2>
<h2 id="sec:org39a802e">§9.5. Finite functions on a compact group are
dense<span id="sec:finite-functions-dense"
label="sec:finite-functions-dense"></span></h2>
<p>Let <span class="math inline">\(G\)</span> be a compact topological
group. Let <span class="math inline">\(\mu\)</span> denote the
probability Haar measure on <span class="math inline">\(G\)</span>. We
may define <span class="math inline">\(L^2(G)\)</span> with respect to
<span class="math inline">\(\mu\)</span>. Denote by <span
class="math inline">\(\mathop{\mathrm{U}}(L^2(G))\)</span> the group of
unitary operators on <span class="math inline">\(L^2(G)\)</span>. We
then have the right regular representation <span class="math inline">\(R
: G \rightarrow \mathop{\mathrm{U}}(L^2(G))\)</span> given by <span
class="math display">\[R(g) f(x) := f(x g)\]</span> as well as the left
regular representation <span class="math inline">\(L : G \rightarrow
\mathop{\mathrm{U}}(L^2(G))\)</span> given by <span
class="math display">\[L(g) f(x) := f(g^{-1} x).\]</span> We may extend
the latter map linearly to <span class="math inline">\(L : L^1(G)
\rightarrow \mathop{\mathrm{End}}(L^2(G))\)</span> given for <span
class="math inline">\(\phi \in L^2(G)\)</span> by <span
class="math display">\[L(\phi) f(x) := \int_{g \in G} \phi(g) f(g^{-1}
x).\]</span></p>
<div id="lem:right-finite-implies-left-finite" class="lemma">
<p><strong>Lemma 43</strong>. Let <span class="math inline">\(f \in
L^2(G)\)</span>. If the span of the right translates of <span
class="math inline">\(f\)</span> is finite-dimensional, then so is the
span of its left translates, and vice-versa.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span
class="math inline">\(f_1,\dotsc,f_n\)</span> be an orthonormal basis
for the span of the right translates of <span
class="math inline">\(f\)</span>. Then for each <span
class="math inline">\(g \in G\)</span> there are complex coefficients
<span class="math inline">\(a_1(g),\dotsc,a_n(g)\)</span> so that for
all <span class="math inline">\(x \in G\)</span>, <span
class="math display">\[R(g) f(x) = f(x g) = \sum_i a_i(g)
f_i(x).\]</span> Explicitly, we may take <span class="math inline">\(a_i
:= \langle R(g) f, f_i \rangle\)</span>, which defines a bounded
function and thus an element <span class="math inline">\(a_i  \in
L^2(G)\)</span>. It follows that <span class="math display">\[L(g) f(x)
= f(g^{-1} x)
  = \sum_i f_i(g^{-1}) a_i(x),\]</span> thus the <span
class="math inline">\(a_i\)</span> span the space of left translates of
<span class="math inline">\(f\)</span>. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 44</strong>. We say that an element <span
class="math inline">\(f \in L^2(G)\)</span> is <em>finite</em> if the
span of its left and right translates under <span
class="math inline">\(G\)</span> is finite-dimensional. Denote by <span
class="math inline">\(L^2(G)_{\mathop{\mathrm{fin}}}\)</span> the space
of finite functions. (Lemma <a
href="#lem:right-finite-implies-left-finite" data-reference-type="ref"
data-reference="lem:right-finite-implies-left-finite">43</a> says that
to check that a given function is finite, it suffices to show either
that its left translates or its right translates have finite span.)</p>
</div>
<p>The main result of this subsection is as follows.</p>
<div id="thm:finite-elements-dense" class="theorem">
<p><strong>Theorem 45</strong>. <em>Let <span
class="math inline">\(G\)</span> be a compact group. Then the finite
elements of <span class="math inline">\(L^2(G)\)</span> are
dense.</em></p>
</div>
<p>The proof requires a couple lemmas.</p>
<div id="lem:approximate-vectors-by-convolutions" class="lemma">
<p><strong>Lemma 46</strong>. Set <span class="math inline">\(V :=
L^2(G)\)</span>. For each <span class="math inline">\(v \in V\)</span>
and <span class="math inline">\(\varepsilon&gt; 0\)</span> there exists
a real-valued symmetric <span class="math inline">\(\phi \in
C_c(G)\)</span> so that <span class="math inline">\(\|L(\phi) v - v \|
&lt; \varepsilon\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By the continuity of the representation <span
class="math inline">\(L\)</span>, one has for all <span
class="math inline">\(g\)</span> in some small neighborhood <span
class="math inline">\(U\)</span> of the identity in <span
class="math inline">\(G\)</span> that <span class="math inline">\(\|L(g)
v - v \| &lt; \varepsilon\)</span>. We may assume after shrinking <span
class="math inline">\(U\)</span> as necessary that <span
class="math inline">\(U = U^{-1}\)</span>. By Urysohn’s lemma, there
exists a real-valued <span class="math inline">\(\phi \in C_c(U)
\subseteq C_c(G)\)</span> with <span class="math inline">\(\mu(\phi) =
1\)</span>. For such a <span class="math inline">\(\phi\)</span>, the
required estimate follows from the triangle inequality. We can easily
arrange that <span class="math inline">\(\phi\)</span> be symmetric by
averaging it with the function <span class="math inline">\(x \mapsto
\phi(x^{-1})\)</span>. ◻</p>
</span></div>
<div class="lemma">
<p><strong>Lemma 47</strong>. Let <span class="math inline">\(\phi \in
L^1(G) \cap L^2(G)\)</span>. Then the operator <span
class="math inline">\(L(\phi)\)</span> is compact.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We will use that <span id="eq:kernel-is-integrable" class="math display">\[\label{eq:kernel-is-integrable}\tag{52}
    \int_{g_1,g_2 \in G}
    |\phi(g_1^{-1} g_2)|^2 &lt; \infty\]</span> as follows from the
compactness of <span class="math inline">\(G\)</span>. (The natural
context for this result is thus in the setting of operators defined by
kernels in <span class="math inline">\(L^2(G \times G)\)</span>; see any
book on functional analysis.) For concreteness, I’ll give the proof of
the compactness of <span class="math inline">\(T := L(\phi)\)</span> in
the special case that <span class="math inline">\(V := L^2(G)\)</span>
is a separable Hilbert space; this case certainly suffices when <span
class="math inline">\(G\)</span> is a compact Lie group (and perhaps
somewhat more generally). We will show that the image under <span
class="math inline">\(T\)</span> of the unit ball is precompact. Let
<span class="math inline">\(e_1,e_2,\dotsc\)</span> be a Hilbert space
basis of <span class="math inline">\(V\)</span>. Write <span
class="math inline">\(A_{i j} := \langle e_i, T e_j \rangle\)</span>, so
that for <span class="math inline">\(v = \sum a_i e_i \in V\)</span>,
one has <span class="math inline">\(T v =
  \sum_{i} b_i e_i\)</span> where <span class="math inline">\(b_i :=
\sum_j A_{i j} a_j\)</span>. If <span class="math inline">\(\|v\| \leq
1\)</span>, then Cauchy–Schwartz implies that <span
class="math inline">\(|b_i|^2 \leq B_i\)</span> where <span
class="math inline">\(B_i := \sum_{j} |A_{i
    j}|^2\)</span>, so the image under <span
class="math inline">\(T\)</span> of the unit ball is contained in <span
class="math inline">\(S := \{\sum b_i e_i : |b_i|^2 \leq B_i\}\)</span>.
Since <span class="math display">\[\sum B_i =  \sum_{i,j} |A_{i j}|^2
&lt; \infty,\]</span> the set <span class="math inline">\(S\)</span> is
precompact, as required. (If <span class="math inline">\(v^{(n)} = \sum
b_i^{(n)} e_i\)</span> is a sequence in <span
class="math inline">\(S\)</span>, then we may assume by a diagonlization
argument that after passing to a subsequence, one has <span
class="math inline">\(b_i^{(n)} \rightarrow b_i\)</span> for some scalar
<span class="math inline">\(b_i\)</span>, which obviously satisfies
<span class="math inline">\(|b_i|^2 \leq B_i\)</span>; it then follows
easily that <span class="math inline">\(v := \sum b_i e_i\)</span>
belongs to <span class="math inline">\(V\)</span> and that <span
class="math inline">\(v^{(n)} \rightarrow v\)</span>.) ◻</p>
</span></div>
<div class="proof">
<p><em>Proof of Theorem <a href="#thm:finite-elements-dense"
data-reference-type="ref"
data-reference="thm:finite-elements-dense">45</a>.</em> By Lemma <a
href="#lem:approximate-vectors-by-convolutions"
data-reference-type="ref"
data-reference="lem:approximate-vectors-by-convolutions">46</a>,
elements of the form <span class="math inline">\(L(\phi) v\)</span> with
<span class="math inline">\(\phi \in L^1(G), v \in L^2(G)\)</span>, and
with <span class="math inline">\(\phi\)</span> real-valued and
symmetric, are dense in <span class="math inline">\(L^2(G)\)</span>, so
it suffices to approximate such elements by finite functions. Thus
consider some such elements <span class="math inline">\(\phi,v\)</span>.
The operator <span class="math inline">\(T := L(\phi)\)</span> is
compact and self-adjoint. Denote by <span
class="math inline">\(V_\lambda\)</span> its eigenspaces. Decompose
<span class="math inline">\(v = \sum v_\lambda\)</span> with <span
class="math inline">\(v_\lambda \in V_\lambda\)</span>. For each <span
class="math inline">\(\varepsilon&gt; 0\)</span>, we then have <span
class="math inline">\(L(\phi) v = u_\varepsilon+ O(\varepsilon)\)</span>
where <span class="math inline">\(u_\varepsilon:= \sum_{\lambda :
|\lambda| &gt; \varepsilon} \lambda v_\lambda\)</span>. Since <span
class="math inline">\(T\)</span> commutes with <span
class="math inline">\(R(G)\)</span>, the eigenspaces <span
class="math inline">\(V_\lambda\)</span> of <span
class="math inline">\(T\)</span> are <span
class="math inline">\(R(G)\)</span>-invariant; Theorem <a
href="#thm:spectral-thm-self-adj" data-reference-type="ref"
data-reference="thm:spectral-thm-self-adj">42</a> implies that <span
class="math inline">\(\dim( \oplus_{\lambda : |\lambda| &gt;
\varepsilon}
  V_\lambda) &lt; \infty\)</span>, so the right translates of <span
class="math inline">\(u_\varepsilon\)</span> have finite span, and so
<span class="math inline">\(u_\varepsilon\)</span> is a finite element
of <span class="math inline">\(L^2(G)\)</span>. Since it converges to
<span class="math inline">\(T v\)</span> as <span
class="math inline">\(\varepsilon\rightarrow 0\)</span>, we are
done. ◻</p>
</div>
<h2 id="sec:orga60f514">§9.6. Schur orthogonality relations</h2>
<p>We continue to assume here that <span
class="math inline">\(G\)</span> is a compact group.</p>
<div id="lem:schur-lemma-for-morphisms" class="lemma">
<p><strong>Lemma 48</strong>. Let <span class="math inline">\((\pi,V),
(\rho,W)\)</span> be finite-dimensional irreducible representations of
<span class="math inline">\(G\)</span>. Then the space <span
class="math display">\[{\mathop{\mathrm{Hom}}}_G(V,W)
  :=
  \{\phi : V \rightarrow W \lvert \phi(\pi(g) v) = \rho(g) \phi(v)
\text{ for all } v \in V, g \in G \}\]</span> of <span
class="math inline">\(G\)</span>-equivariant linear maps from <span
class="math inline">\(V\)</span> to <span
class="math inline">\(W\)</span> satisfies <span
class="math display">\[\dim {\mathop{\mathrm{Hom}}}_G(V,W)
  =
\begin{cases}
    1 &amp; V \cong W \\
    0 &amp; \text{otherwise.}
  \end{cases}\]</span> If <span class="math inline">\(V \cong
W\)</span>, then every nonzero element of <span
class="math inline">\({\mathop{\mathrm{Hom}}}_G(V,W)\)</span> is an
isomorphism <span class="math inline">\(V \rightarrow W\)</span>. In
particular, <span
class="math inline">\({\mathop{\mathrm{Hom}}}_G(V,V)\)</span> is the
one-dimensional space consisting of scalar operators of the form <span
class="math inline">\(v \mapsto c v\)</span>, <span
class="math inline">\(c \in \mathbb{C}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> For <span class="math inline">\(\phi \in
{\mathop{\mathrm{Hom}}}_G(V,W)\)</span>, we check that the kernel of <span
class="math inline">\(\phi\)</span> is an invariant subspace of <span
class="math inline">\(V\)</span> and the image of <span
class="math inline">\(\phi\)</span> is an invariant subspace of <span
class="math inline">\(W\)</span>. So if <span
class="math inline">\(V\)</span> is not the zero map, then its kernel is
the zero space (since <span class="math inline">\(V\)</span> is
irreducible) and its image is all of <span
class="math inline">\(W\)</span> (since <span
class="math inline">\(W\)</span> is irreducible). The conclusion
follows. ◻</p>
</span></div>
<div id="lem:schur-ortho-in-useful-form" class="lemma">
<p><strong>Lemma 49</strong>. Let <span
class="math inline">\(V,W\)</span> be finite-dimensional irreducible
representations of <span class="math inline">\(G\)</span>. Let <span
class="math inline">\(\ell \otimes v \in V^* \otimes V\)</span> and
<span class="math inline">\(w \in W\)</span>. If <span
class="math inline">\(V\)</span> is not isomorphic to <span
class="math inline">\(W\)</span>, then <span id="eq:schur-orth-1-0" class="math display">\[\label{eq:schur-orth-1-0}\tag{53}
    \frac{1}{\dim W}
    \int_{g \in G} \ell(g v) g^{-1} w
    = 0.\]</span> Otherwise, let us fix an equivariant identification
<span class="math inline">\(W = V\)</span>. Then <span id="eq:schur-orth-1-1" class="math display">\[\label{eq:schur-orth-1-1}\tag{54}
    \frac{1}{\dim W}
    \int_{g \in G} \ell(g v) g^{-1} w
    = \ell(w) v.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Fix <span class="math inline">\(\ell,w\)</span>, and
denote by <span class="math inline">\(S : V \rightarrow W\)</span> the
the linear function of <span class="math inline">\(v\)</span> defined by
the LHS of <a href="#eq:schur-orth-1-0" data-reference-type="eqref"
data-reference="eq:schur-orth-1-0">\((53)\)</a>. Then a quick
change of variables shows that <span class="math inline">\(S\)</span> is
equivariant, so by Lemma <a href="#lem:schur-lemma-for-morphisms"
data-reference-type="ref"
data-reference="lem:schur-lemma-for-morphisms">48</a>, it is the zero
map unless <span class="math inline">\(V \cong W\)</span>; this
establishes <a href="#eq:schur-orth-1-0" data-reference-type="eqref"
data-reference="eq:schur-orth-1-0">\((53)\)</a>. We turn to
<a href="#eq:schur-orth-1-1" data-reference-type="eqref"
data-reference="eq:schur-orth-1-1">\((54)\)</a>. By Lemma <a
href="#lem:schur-lemma-for-morphisms" data-reference-type="ref"
data-reference="lem:schur-lemma-for-morphisms">48</a>, we know that
<span class="math inline">\(S : V \rightarrow V\)</span> is a scalar
operator; we wish to verify that the scalar is <span
class="math inline">\(\ell(w)\)</span>. To that end, it will suffice to
verify that <span class="math inline">\(\mathop{\mathrm{trace}}(S) =
(\dim V) \ell(w)\)</span>, or equivalently, that <span
class="math display">\[\sum_{i}
  \int_{g \in G} \ell(g e_i) e_i^*(g^{-1} w)
  = \ell(w)\]</span> where <span class="math inline">\((e_i)\)</span> is
a basis of <span class="math inline">\(V\)</span> with dual basis <span
class="math inline">\((e_i^*)\)</span> of <span
class="math inline">\(V^*\)</span>. The integrand is independent of
<span class="math inline">\(g\)</span> (since it is independent of the
choice of basis, and the basis dual to <span class="math inline">\(g
e_1,\dotsc,g e_n\)</span> is <span class="math inline">\(e_1^* \circ
g^{-1}, \dotsc, e_n^* \circ g^{-1}\)</span>) so we reduce to showing
that <span class="math display">\[\sum_i \ell(e_i) e_i^*(w) =
\ell(w),\]</span> which is immediate. ◻</p>
</span></div>
<div class="corollary">
<p><strong>Corollary 50</strong>. <em>Let <span
class="math inline">\(V_1, V_2\)</span> be finite-dimensional
irreducible representations of <span class="math inline">\(G\)</span>.
Let <span class="math inline">\(\ell_1 \otimes v_1 \in V_1^* \otimes
V_1\)</span> and <span class="math inline">\(\ell_2 \otimes v_2 \in
V_2^* \otimes V_2\)</span> Then <span id="eq:schur-orth-1-0b" class="math display">\[\label{eq:schur-orth-1-0b}\tag{55}
    \int_{g \in G} \ell_1(g v_1) \ell_2(g^{-1} v_2)
    =
    \begin{cases}
      \dim(V_1) \ell_1(v_2) \ell_2(v_1) &amp; V_1 \cong V_2 \\
      0 &amp; \text{otherwise.}
    \end{cases}\]</span> where <span
class="math inline">\(\ell_1(v_2)\)</span> and <span
class="math inline">\(\ell_2(v_1)\)</span> are defined in the first case
by fixing an equivariant identification between <span
class="math inline">\(V_1\)</span> and <span
class="math inline">\(V_2\)</span>.</em></p>
</div>
<h2 id="sec:org9fd6b0d">§9.7. Peter–Weyl theorem</h2>
<p>Let <span class="math inline">\(G\)</span> be a compact group. Let
<span class="math inline">\(L^2(G)_{\mathop{\mathrm{fin}}}\)</span>
denote the subspace of finite elements; we saw in §<a
href="#sec:finite-functions-dense" data-reference-type="ref"
data-reference="sec:finite-functions-dense">9.5</a>
that it is dense in <span class="math inline">\(L^2(G)\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 51</strong>. <em>Let <span
class="math inline">\(V\)</span> traverse the set of isomorphism classes
of finite-dimensional irreducible representation of <span
class="math inline">\(G\)</span>. Then the canonical morphism of <span
class="math inline">\(G \times G\)</span>-modules <span
class="math display">\[\mathfrak{m} : \oplus V^* \otimes V \rightarrow
L^2(G)_{\mathop{\mathrm{fin}}}\]</span> given in terms of matrix
coefficients by setting, for <span class="math inline">\(\ell \otimes v
\in V^* \otimes V\)</span>, <span
class="math display">\[\mathfrak{m}(\ell \otimes v)(g) := \ell(g
v),\]</span> is an isomorphism with inverse <span
class="math display">\[\mathcal{F} : L^2(G) \rightarrow \oplus
\mathop{\mathrm{End}}(V)\]</span> where <span
class="math inline">\(\mathcal{F} = \oplus \mathcal{F}_V\)</span> where
for <span class="math inline">\(u \in V\)</span>, <span
class="math display">\[\mathcal{F}_V(f) u := \frac{1}{\dim (V)} \int_{g
\in G}
  f(g) g^{-1} u.\]</span> (The action is as in the proof of Lemma <a
href="#lem:right-finite-implies-left-finite" data-reference-type="ref"
data-reference="lem:right-finite-implies-left-finite">43</a>.)</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We first check surjectivity. Let <span
class="math inline">\(v \in L^2(G)_{\mathop{\mathrm{fin}}}\)</span>. Its
span under the right regular representation of <span
class="math inline">\(G\)</span> is then a finite-dimensional
representation <span class="math inline">\(W\)</span> of <span
class="math inline">\(G\)</span>. We “have seen” (the chronology of the
lectures differs from that of the notes) in §<a href="#sec:compl-red"
data-reference-type="ref"
data-reference="sec:compl-red">16.7</a> that any
finite-dimensional representation of a compact group is completely
reducible. In particular, <span class="math inline">\(W\)</span> is
completely reducible. By decomposing <span
class="math inline">\(W\)</span> into irreducibles and <span
class="math inline">\(v\)</span> into its irreducilbe components, we
reduce to verifying in the special case in which <span
class="math inline">\(W\)</span> is irreducible that <span
class="math inline">\(v\)</span> belongs to the image of <span
class="math inline">\(W^* \otimes W\)</span> in <span
class="math inline">\(L^2(G)_{\mathop{\mathrm{fin}}}\)</span>. But this
follows immediately from the proof of Lemma <a
href="#lem:right-finite-implies-left-finite" data-reference-type="ref"
data-reference="lem:right-finite-implies-left-finite">43</a>.</p>
<p>We now check that <span class="math inline">\(\mathcal{F} \circ
\mathfrak{m}  = 1\)</span>. It suffices to show for each <span
class="math inline">\(V,W \in \mathop{\mathrm{Irr}}(G)\)</span> and
<span class="math inline">\(\ell \otimes v \in V^* \otimes V\)</span>
that <span class="math display">\[\mathcal{F}_W(\mathfrak{m}(\ell
\otimes v))
  =
  \begin{cases}
    \ell \otimes v &amp; W = V \\
    0 &amp; W \neq V.
  \end{cases}\]</span> Thus, let <span class="math inline">\(w \in
W\)</span> be given. Then <span
class="math display">\[\mathcal{F}_W(\mathfrak{m}(\ell \otimes v))
  w
  =
  \frac{1}{\dim W}
  \int_{g \in G} \ell(g v) g^{-1} w,\]</span> while <span
class="math inline">\((\ell \otimes v)(w) = \ell(w) v\)</span>, so the
required conclusion follows from Lemma <a
href="#lem:schur-ortho-in-useful-form" data-reference-type="ref"
data-reference="lem:schur-ortho-in-useful-form">49</a>. ◻</p>
</span></div>
<div class="corollary">
<p><strong>Corollary 52</strong>. <em>Let <span
class="math inline">\(G\)</span> act on <span
class="math inline">\(L^2(G)_{\mathop{\mathrm{fin}}}\)</span> by the
right regular representation. Then as <span
class="math inline">\(G\)</span>-representations, <span
class="math display">\[L^2(G)_{\mathop{\mathrm{fin}}}
  = \oplus V^{\oplus \dim(V)}.\]</span> where <span
class="math inline">\(V^{\oplus \dim(V)}\)</span> is the image of <span
class="math inline">\(V^* \otimes V\)</span>, regarded now only as a
<span class="math inline">\(G\)</span>-module rather than as a <span
class="math inline">\(G \times G\)</span>-module.</em></p>
</div>
<h1 id="sec:org22598a8">§10. Some facts concerning invariant measures<span
id="sec:inv-measures" label="sec:inv-measures"></span></h1>
<h2 id="sec:org171fce1">§10.1. Definition of Haar measures</h2>
<p>Let <span class="math inline">\(G\)</span> be a locally compact
topological group.</p>
<div class="definition">
<p><strong>Definition 53</strong>. By a <em>Radon measure</em> on <span
class="math inline">\(G\)</span> we shall mean a linear functional <span
class="math inline">\(\mu : C_c(G) \rightarrow \mathbb{C}\)</span> for
which <span class="math inline">\(f \geq 0 \implies \mu(f) \geq
0\)</span>; thanks to the Riesz representation theorem, this definition
may also be formulated in terms of countably additive functions on the
Borel <span class="math inline">\(\sigma\)</span>-algebra satisfying
certain properties.</p>
</div>
<p>For <span class="math inline">\(y \in G\)</span> and <span
class="math inline">\(f \in C_c(G)\)</span>, define the left and right
translates <span class="math inline">\(L_y f, R_y f \in C_c(G)\)</span>
by setting <span class="math inline">\(L[y] f(x) := f(y x), R[y] f(x) :=
f(x y)\)</span>.</p>
<p>To interpret some of the statements to follow, we “recall” that it
makes sense to integrate functions taking values in a Banach space. The
only spaces we’ll really need in the end are finite-dimensional vector
spaces (where everything should be familiar) and the Hilbert space <span
class="math inline">\(L^2(G)\)</span>, where one doesn’t lose much by
interpreting everything in a pointwise fashion. (TODO: dfdfd)</p>
<div id="defn:" class="definition">
<p><strong>Definition 54</strong>. A <em>left (resp. right) Haar
measure</em> on <span class="math inline">\(G\)</span> is a nonzero
Radon measure <span class="math inline">\(\mu\)</span> with the property
<span class="math inline">\(\mu(L[y] f) = \mu(f)\)</span> (resp. <span
class="math inline">\(\mu(R[y] f) = \mu(f)\)</span>).</p>
</div>
<p>We may reformulate this definition in various ways. For example,
<span class="math inline">\(\mu\)</span> is a left Haar measure if <span
class="math inline">\(\mu(g E) = \mu(E)\)</span> for all <span
class="math inline">\(g \in G\)</span> and all Borel subsets <span
class="math inline">\(E\)</span> of <span
class="math inline">\(G\)</span>, or in integral form, if <span
class="math display">\[\int_{g \in G} f(h g) \, d \mu(g) = \int_{g \in
G} f(g) \, d \mu(g)\]</span> for all <span class="math inline">\(h \in
G\)</span> and all <span class="math inline">\(f \in
C_c(G)\)</span>.</p>
<h2 id="sec:orga3b0a45">§10.2. Existence theorem</h2>
<div id="thm:basics-on-haar-measure" class="theorem">
<p><strong>Theorem 55</strong>. <em> </em></p>
<ol>
<li><p><em>There exist left Haar measures and there exist right Haar
measures on any locally compact group <span
class="math inline">\(G\)</span>. They need neither coincide nor be
scalar multiples of one another.</em></p></li>
<li><p><em>Any two left (resp. right) Haar measures are positive
multiples of one another.</em></p></li>
<li><p><em>Any left or right Haar measure <span
class="math inline">\(\mu\)</span> satisfies <span
class="math inline">\(\mu(f) &gt; 0\)</span> for any nonzero nonnegative
<span class="math inline">\(f \in C_c(G)\)</span>.</em></p></li>
<li><p><em>There is a continuous homomorphism <span
class="math inline">\(\Delta : G \rightarrow
  \mathbb{R}_+^\times\)</span> so that for any left (resp. right) Haar
measure <span class="math inline">\(\mu\)</span> and <span
class="math inline">\(f \in C_c(G)\)</span>, one has <span
class="math inline">\(\mu(R[g] f) = \Delta(g)\)</span> (resp. <span
class="math inline">\(\mu(L[g] f) = \Delta(g^{-1})\)</span>). (TODO:
check inverse here.)</em></p></li>
<li><p><em>If <span class="math inline">\(G\)</span> is compact, then
<span class="math inline">\(\{\text{left Haar measures}\}
  = \{\text{right Haar measures}\}\)</span>.</em></p></li>
</ol>
</div>
<p>We sketch the idea of one proof; filling in the details may be
regarded as an exercise, or alternatively, looked up somewhere. For each
nonnegative nonzero <span class="math inline">\(\phi \in C_c(G)\)</span>
and each nonnegative <span class="math inline">\(f \in C_c(G)\)</span>,
denote by <span class="math inline">\([f:\phi]\)</span> the infinum of
<span class="math inline">\(\sum c_i\)</span> taken over all finite
tuples of positive coefficients <span
class="math inline">\(c_1,\dotsc,c_n\)</span> and group elements <span
class="math inline">\(g_1,\dotsc,g_n\)</span> with the property that
<span class="math inline">\(f \leq \sum c_i L[g_i] \phi\)</span>. Fix
also some nonzero nonnegative <span class="math inline">\(f_0 \in
C_c(G)\)</span>. We may then attempt to define a left Haar measure <span
class="math inline">\(\mu\)</span> on <span
class="math inline">\(G\)</span> by requiring that <span
class="math inline">\(\mu(f_0) = 1\)</span> and that <span id="eq:haar-formula" class="math display">\[\label{eq:haar-formula}\tag{56}
  \frac{\mu(f)}{\mu(f_0)}
  =
  \lim_{\phi}
  \frac{[f:\phi]}{[f_0:\phi]}\]</span> where <span
class="math inline">\(\phi\)</span> traverses a net consisting of
nonzero nonnegative elements of <span
class="math inline">\(C_c(G)\)</span> with support shrinking to the
identity. This turns out to work. Conversely, to establish uniqueness,
it suffices to show that <a href="#eq:haar-formula"
data-reference-type="eqref"
data-reference="eq:haar-formula">\((56)\)</a> holds for any
left Haar measure <span class="math inline">\(\mu\)</span>. The key
lemma is that each nonnegative <span class="math inline">\(f \in
C_c(G)\)</span> may uniformly approximated by some finite sum <span
class="math inline">\(c_i L[g_i] \phi_\alpha\)</span> as above with
support in a fixed compact; it follows then that <span
class="math inline">\(\mu(f)\)</span> is approximated by <span
class="math inline">\(\mu(\sum c_i L[g_i] \phi_\alpha) =
\mu(\phi_\alpha) \sum c_i \approx \mu(\phi_\alpha) [f:\phi]\)</span>,
giving <a href="#eq:haar-formula" data-reference-type="eqref"
data-reference="eq:haar-formula">\((56)\)</a>.</p>
<div class="definition">
<p><strong>Definition 56</strong>. A locally compact group is
<em>unimodular</em> if <span class="math inline">\(\{\text{left Haar
measures}\}
  = \{\text{right Haar measures}\}\)</span>, or equivalently, if <span
class="math inline">\(\Delta(g) = 1\)</span> for all <span
class="math inline">\(g \in G\)</span>. On a unimodular group, we may
speak unambiguously simply about a <em>Haar measure</em> (without
specifying “left” or “right”). For example, Theorem <a
href="#thm:basics-on-haar-measure" data-reference-type="ref"
data-reference="thm:basics-on-haar-measure">55</a> says that compact
groups are unimodular.</p>
</div>
<h2 id="sec:org720d559">§10.3. Unimodularity of compact groups</h2>
<p>Note that if <span class="math inline">\(G\)</span> is a compact
group, then the image of the continuous homomorphism <span
class="math inline">\(\Delta : G
\rightarrow \mathbb{R}_+^\times\)</span> is a compact subgroup of <span
class="math inline">\(\mathbb{R}_+^\times\)</span>; the only such
subgroup is <span class="math inline">\(\{1\}\)</span>, so <span
class="math inline">\(\Delta\)</span> is trivial, which explains why
left and right Haar measures coincide on such a group. It follows that
on each compact group, there is a unique (left and right) invariant
probability measure.</p>
<h2 id="sec:orgb26c793">§10.4. Direct construction for Lie groups<span
id="sec:inv-measure-lie" label="sec:inv-measure-lie"></span></h2>
<p>When <span class="math inline">\(G\)</span> is a Lie group, a simpler
proof may be given using differential forms. Let <span
class="math inline">\(\omega_e\)</span> be a nonzero element of <span
class="math inline">\(\det(T_e^* G)\)</span>. Denote by <span
class="math inline">\(\omega\)</span> the volume form on <span
class="math inline">\(G\)</span> whose components <span
class="math inline">\(\omega_g \in \det(T_g^* G)\)</span> for <span
class="math inline">\(g \in G\)</span> are given by the pullback <span
class="math display">\[\omega_g := R[g^{-1}]^*_g \omega_e\]</span> under
the differential <span class="math inline">\(R[g^{-1}]_g : T_g G
\rightarrow T_e G\)</span>. Then <span class="math inline">\(L[g]^*
\omega = \omega\)</span> for all <span class="math inline">\(g \in
G\)</span>, so <span class="math inline">\(\omega\)</span> is
left-invariant. The map <span class="math inline">\(C_c(G) \ni f \mapsto
\int_G f \, \omega\)</span> then defines a left Haar measure.</p>
<h2 id="sec:org02a337d">§10.5. Some exercises</h2>
<div class="exercise">
<p><strong>Exercise 12</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group with left Haar measure
<span class="math inline">\(d g\)</span>. Let <span
class="math inline">\(\Delta : G \rightarrow
\mathbb{R}^\times_+\)</span> be the function <span
class="math display">\[\Delta(g) := \det(\mathop{\mathrm{Ad}}(g) |
\mathfrak{g}).\]</span> Show that <span class="math inline">\(\Delta(g)
\, d g\)</span> is a right Haar measure.</p>
</div>
<div class="exercise">
<p><strong>Exercise 13</strong>. Determine a left and right Haar measure
on the Lie group <span
class="math display">\[\operatorname{Aff}(\mathbb{R})
    :=
    \left\{
\begin{pmatrix}
      \ast &amp; \ast \\
       &amp; 1
     \end{pmatrix}
\right\}
   \leq {\mathop{\mathrm{GL}}}_2(\mathbb{R}).\]</span></p>
</div>
<div class="exercise">
<p><strong>Exercise 14</strong>. </p>
<ol>
<li><p>Let <span class="math inline">\(G\)</span> be a locally compact
group for which <span class="math inline">\([G,G]\)</span> is dense in
<span class="math inline">\(G\)</span>. Show that <span
class="math inline">\(G\)</span> is unimodular.</p></li>
<li><p>Let <span class="math inline">\(G,B,K\)</span> be locally compact
groups and let <span class="math inline">\(\phi : B \times K \rightarrow
G\)</span> be a morphism. Suppose that <span
class="math inline">\(G\)</span> is unimodular, <span
class="math inline">\(K\)</span> is compact, and <span
class="math inline">\(\phi\)</span> has dense image. Let <span
class="math inline">\(d_l b\)</span> be a left Haar measure on <span
class="math inline">\(G\)</span> and let <span class="math inline">\(d
k\)</span> be a Haar measure on <span class="math inline">\(K\)</span>.
Show that <span class="math display">\[\mu(f) := \int_{b \in B} \int_{k
\in K} f(b k) \, d_l b \, d k\]</span> defines a Haar measure on <span
class="math inline">\(G\)</span>.</p></li>
</ol>
</div>
<h2 id="sec:org0bc8f8b">§10.6. Construction of a Haar measure on a compact
group via averaging<span id="sec:haar-compact-gp-via-avg"
label="sec:haar-compact-gp-via-avg"></span></h2>
<p>Let <span class="math inline">\(G\)</span> be a compact topological
group (not necessarily a Lie group). There is a nice way to construct
the unique Haar probability measure <span
class="math inline">\(\mu\)</span> on <span
class="math inline">\(G\)</span> via averaging.</p>
<div class="definition">
<p><strong>Definition 57</strong>. Let <span class="math inline">\(f : G
\rightarrow \mathbb{C}\)</span> be a continuous function on a compact
group <span class="math inline">\(G\)</span>. Let <span
class="math inline">\(\operatorname{Averages}(f)\)</span> denote the
space of functions <span class="math inline">\(G \rightarrow
\mathbb{C}\)</span> of the form <span class="math display">\[G \ni x
\mapsto
    \sum_{i=1}^n
    c_i
    f(\lambda_i x) \in \mathbb{C}\]</span> for some <span
class="math inline">\(n \in \mathbb{Z}_{\geq 1}\)</span> and <span
class="math inline">\(\lambda_1,\dotsc,\lambda_n \in G\)</span> and some
<span class="math inline">\(c_1,\dotsc,c_n \in [0,1]\)</span> with <span
class="math inline">\(c_1 + \dotsb + c_n = 1\)</span>.</p>
</div>
<div id="lem:averages-give-unique-constant" class="lemma">
<p><strong>Lemma 58</strong>. There exists a unique constant function in
the closure (with respect to the uniform topology) of <span
class="math inline">\(\operatorname{Averages}(f)\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> One should be able to prove this as follows:</p>
<ol>
<li><p>It suffices to consider the case that <span
class="math inline">\(f\)</span> is real-valued.</p></li>
<li><p>The space of continuous functions on <span
class="math inline">\(G\)</span> is closed with respect to the uniform
topology.</p></li>
<li><p>For a continuous real-valued function <span
class="math inline">\(f\)</span> on <span
class="math inline">\(G\)</span>, set <span
class="math display">\[\mathop{\mathrm{osc}}(f) := \max_{g \in G} f(g) -
\min_{g \in G} f(g).\]</span> Note that <span
class="math inline">\(f\)</span> is constant if and only if <span
class="math inline">\(\mathop{\mathrm{osc}}(f) = 0\)</span>. Note also
that <span class="math inline">\(\mathop{\mathrm{osc}}(f&#39;) \leq
\mathop{\mathrm{osc}}(f)\)</span> for all <span
class="math inline">\(f&#39; \in
\operatorname{Averages}(f)\)</span>.</p></li>
<li><p>Given a continuous real-valued function <span
class="math inline">\(f\)</span> on <span
class="math inline">\(G\)</span> that is non-constant, show that there
exists <span class="math inline">\(f&#39; \in
\operatorname{Averages}(f)\)</span> so that <span
class="math inline">\(\mathop{\mathrm{osc}}(f&#39;) &lt;
\mathop{\mathrm{osc}}(f)\)</span>. (Use the compactness of <span
class="math inline">\(G\)</span> and hence the uniform continuity of
<span class="math inline">\(f\)</span>. If <span
class="math inline">\(f\)</span> is smaller than typical in some part of
<span class="math inline">\(G\)</span>, translate <span
class="math inline">\(f\)</span> around a bit to dampen the contribution
from parts of <span class="math inline">\(G\)</span> where <span
class="math inline">\(f\)</span> is large.)</p></li>
<li><p>The family of functions <span
class="math inline">\(\operatorname{Averages}(f)\)</span> is
equicontinuous.</p></li>
<li><p>The function <span class="math inline">\(\mathop{\mathrm{osc}}:
C(G) \rightarrow \mathbb{R}_{\geq 0}\)</span> is continuous with respect
to the uniform topology on the domain.</p></li>
<li><p>To prove the existence part of the theorem, we can take a
sequence <span class="math inline">\(f_i \in
\operatorname{Averages}(f)\)</span> so that <span
class="math inline">\(\mathop{\mathrm{osc}}(f_i)\)</span> tends to the
infinum of <span class="math inline">\(\mathop{\mathrm{osc}}(h)\)</span>
over all <span class="math inline">\(h \in
\operatorname{Averages}(f)\)</span>. After passing to a subsequence and
appealing to Arzela–Ascoli, we get a limit <span
class="math inline">\(h\)</span> of the sequence <span
class="math inline">\(f_i\)</span>. If <span
class="math inline">\(h\)</span> is non-constant, then we can find <span
class="math inline">\(h&#39; \in \operatorname{Averages}(h)\)</span> for
which <span class="math inline">\(\mathop{\mathrm{osc}}(h&#39;) &lt;
\mathop{\mathrm{osc}}(h)\)</span>. But one should then be able to check
that <span class="math inline">\(h&#39;\)</span> lies in the closure of
<span class="math inline">\(\operatorname{Averages}(f)\)</span>, giving
the required contradiction.</p></li>
<li><p>To get uniqueness, let <span
class="math inline">\(c_1,c_2\)</span> be values taken by constant
functions in the closure of <span
class="math inline">\(\operatorname{Averages}(f)\)</span>. Let <span
class="math inline">\(c&#39;\)</span> be a value taken by some constant
function in the closure of the set defined analogously to <span
class="math inline">\(\operatorname{Averages}(f)\)</span>, but using
right translations in place of left translations. Since left and right
translations commute, it’s not so hard to check that <span
class="math inline">\(c_i = c&#39;\)</span> for <span
class="math inline">\(i=1,2\)</span>, hence that <span
class="math inline">\(c_1 =c_2\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<p>We may then define <span class="math inline">\(\mu(f) = \int_G f \, d
\mu\)</span> to be the value taken by the constant function arising in
Lemma <a href="#lem:averages-give-unique-constant"
data-reference-type="ref"
data-reference="lem:averages-give-unique-constant">58</a>. It’s not hard
to check that this defines a positive linear functional on the space of
continuous functions on <span class="math inline">\(G\)</span>, hence
defines a measure; the key point is to verify additivity, which follows
from some of the assertions made above.</p>
<h1 id="sec:orgfa95dc3">§11. Definition and basic properties of Lie
groups</h1>
<h2 id="sec:org11b4fd5">§11.1. Lie groups: definition</h2>
<div id="defn:lie-group" class="definition">
<p><strong>Definition 59</strong>. By a <em>Lie group</em> we shall mean
a group <span class="math inline">\(G\)</span> equipped with the
structure of a manifold for which the maps <span class="math inline">\(m
: G \times G \rightarrow G\)</span> and <span class="math inline">\(i :
G \rightarrow G\)</span> are smooth. The <em>Lie algebra</em> of <span
class="math inline">\(G\)</span> is the vector space <span
class="math inline">\(\mathop{\mathrm{Lie}}(G) := T_e(G)\)</span>, often
denoted <span class="math inline">\(\mathfrak{g}\)</span>, given by the
tangent space at the identity; it is a vector space of dimension equal
to the dimension of <span class="math inline">\(G\)</span>. (The word
“algebra” appearing in the term “Lie algebra” will be justified
later.)</p>
<p>For Lie groups <span class="math inline">\(G, H\)</span>, a
<em>morphism of Lie groups</em> or simply a <em>morphism</em> <span
class="math inline">\(f : G \rightarrow H\)</span> is a smooth group
homomorphism.</p>
<p>For a Lie group <span class="math inline">\(G\)</span> and a manifold
<span class="math inline">\(X\)</span>, an <em>action of <span
class="math inline">\(G\)</span> on <span
class="math inline">\(X\)</span></em> is a smooth map <span
class="math inline">\(\alpha : G \times X \rightarrow X\)</span>,
abbreviated <span class="math inline">\(g x := \alpha(g,x)\)</span>,
that satisfies the same assumptions as in Definition <a
href="#defn:top-gp" data-reference-type="ref"
data-reference="defn:top-gp">36</a>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 15</strong>. It suffices to check that <span
class="math inline">\(m\)</span> is smooth; the smoothness of <span
class="math inline">\(i\)</span> is automatic. [Hint: apply the inverse
function theorem to the map <span class="math inline">\((x,y) \mapsto
(x,x y)\)</span>.]</p>
</div>
<h2 id="sec:org7a9cd32">§11.2. Basic examples</h2>
<p>The <em>additive group</em> <span
class="math inline">\((\mathbf{k},+)\)</span> of the field <span
class="math inline">\(\mathbf{k}\)</span> is a Lie group, since the
addition map <span class="math inline">\(\mathbf{k} \times \mathbf{k}
\ni (x,y) \mapsto x + y \in \mathbf{k}\)</span> has the property that
all of its partial derivatives exist. Similarly, the <em>multiplicative
group</em> <span
class="math inline">\((\mathbf{k}^\times,\times)\)</span> is a Lie
group. A slightly more interesting example can be obtained by
considering any finite-dimensional unital associative algebra <span
class="math inline">\(A\)</span> over <span
class="math inline">\(\mathbf{k}\)</span>. A good example to keep in
mind is when <span class="math inline">\(A\)</span> is the algebra <span
class="math display">\[A := M_n(\mathbf{k})
:=
{\mathop{\mathrm{Mat}}}_{n \times n}(\mathbf{k})\]</span> of <span
class="math inline">\(n \times n\)</span> matrices, in which case <span
class="math display">\[A^\times =
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\]</span> is the general linear group.
The algebra <span class="math inline">\(A\)</span> is a vector space,
hence a manifold. Moreover, the unit group <span
class="math inline">\(A^\times\)</span> is open in <span
class="math inline">\(A\)</span>: by Exercise <a
href="#exercise:openness-top-groups-ambient-spaces"
data-reference-type="ref"
data-reference="exercise:openness-top-groups-ambient-spaces">2</a>, it
suffices to verify that <span class="math inline">\(A^\times\)</span>
contains a neighborhood of the identity element <span
class="math inline">\(1\)</span>, and this follows from the observation
that for <span class="math inline">\(x \in A\)</span> small enough, the
element <span class="math inline">\(1 + x\)</span> has inverse given by
the convergent series <span class="math inline">\(\sum_{n \geq 0}
(-x)^n\)</span>. Since the multiplication on <span
class="math inline">\(A^\times\)</span> is bilinear, it is smooth, and
so <span class="math inline">\(A^\times\)</span> is a Lie group of
dimension <span class="math inline">\(\dim(A)\)</span>. Moreover, one
can naturally identify <span class="math inline">\(T_0(A) = A\)</span>
and <span class="math inline">\(T_1(A^\times) = A\)</span>, where <span
class="math inline">\(1 \in A^\times\)</span> denotes the identity
element, as in Example <a
href="#example:tangent-space-open-subset-euclidean-space"
data-reference-type="ref"
data-reference="example:tangent-space-open-subset-euclidean-space">10</a>.</p>
<p>By what was shown above, <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> is an
<span class="math inline">\(n^2\)</span>-dimensional Lie group with
<span id="eq:lie-algebra-general-linear-group" class="math display">\[\label{eq:lie-algebra-general-linear-group}\tag{57}
  T_1({\mathop{\mathrm{GL}}}_n(\mathbf{k})) =
M_n(\mathbf{k}).\]</span></p>
<h2 id="sec:orgc7b7f1f">§11.3. Lie subgroups: definition</h2>
<p>There are at least a couple different conventions concerning what a
“Lie subgroup” is.</p>
<div class="definition">
<p><strong>Definition 60</strong>. Given a Lie group <span
class="math inline">\(G\)</span>, we say that a subset <span
class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span> is a <em>Lie subgroup</em> if it is a
subgroup and a submanifold.</p>
</div>
<div class="lemma">
<p><strong>Lemma 61</strong>. Let <span class="math inline">\(G\)</span>
be a Lie group. Let <span class="math inline">\(H\)</span> be a Lie
subgroup of <span class="math inline">\(G\)</span>. Then <span
class="math inline">\(H\)</span> is a Lie group.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We must show that the multiplication map <span
class="math inline">\(\mu_H : H \times H \rightarrow H\)</span> is
smooth, and that it coincides with the restriction <span
class="math inline">\(\mu_G|_{H \times H} : H \times H \rightarrow
G\)</span> of the smooth multiplication map <span
class="math inline">\(\mu_G : G \times G \rightarrow
  G\)</span>. So we reduce to the following: if <span
class="math inline">\(f : M \rightarrow N\)</span> is a smooth map
between manifolds whose image lands in some submanifold <span
class="math inline">\(S \subseteq N\)</span>, then the induced map <span
class="math inline">\(f : M \rightarrow S\)</span> is also smooth. This
is given by Proposition <a
href="#prop:smoothness-preserved-codomain-pass-to-submfld"
data-reference-type="ref"
data-reference="prop:smoothness-preserved-codomain-pass-to-submfld">25</a>. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 62</strong>. A <em>linear Lie group</em> is a Lie
subgroup <span class="math inline">\(G\)</span> of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> for
some <span class="math inline">\(n\)</span>. (Essentially all of our
examples will be of this form.)</p>
</div>
<div id="defn:immersed-lie-subgroup" class="definition">
<p><strong>Definition 63</strong>. Given a Lie group <span
class="math inline">\(G\)</span>, by an <em>immersed Lie subgroup</em>
we will mean a subset <span class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span> so that there exists a pair <span
class="math inline">\((\hat{H},\iota)\)</span>, where <span
class="math inline">\(\hat{H}\)</span> is a Lie group and <span
class="math inline">\(\iota : \hat{H} \rightarrow G\)</span> is an
injective immersion with image <span class="math inline">\(H\)</span>.
(We will see much later in the course that such a pair is essentially
uniquely determined by <span class="math inline">\(H\)</span>, at least
if <span class="math inline">\(H\)</span> is connected.)</p>
</div>
<div id="example:immersed-subgroup" class="example">
<p><strong>Example 64</strong>. Let <span class="math inline">\(G  :=
(\mathbb{R}/\mathbb{Z})^2\)</span> be the two-dimensional torus, let
<span class="math inline">\(H := \mathbb{R}\)</span> be the real line,
let <span class="math inline">\(\alpha \in \mathbb{R} -
\mathbb{Q}\)</span> be an irrational real number, and define <span
class="math inline">\(\iota : H \rightarrow G\)</span> by the formula
<span class="math display">\[\iota(x) := (x,\alpha x).\]</span> Since
<span class="math inline">\(\alpha\)</span> is irrational, the map <span
class="math inline">\(\iota\)</span> is injective. It is also an
immersion, since its differential is given everywhere by the column
matrix <span class="math display">\[T_x \iota
  =
\begin{pmatrix}
    1  \\
    \alpha
  \end{pmatrix}\]</span> which defines an injective linear map <span
class="math inline">\(\mathbf{k}
  \rightarrow \mathbf{k}^2\)</span>. Thus <span
class="math inline">\((H,\iota)\)</span> is an immersed Lie subgroup of
<span class="math inline">\(G\)</span>. On the other hand, <span
class="math inline">\(\iota(H)\)</span> is not a Lie subgroup because it
is not a submanifold: submanifolds are open in their closure (Remark <a
href="#rmk:submfld-locally-closed" data-reference-type="ref"
data-reference="rmk:submfld-locally-closed">26</a>), and <span
class="math inline">\(\overline{\iota(H)} = G\)</span>, but <span
class="math inline">\(\iota(H)\)</span> is not open in <span
class="math inline">\(G\)</span>. On a related note, <span
class="math inline">\(\iota\)</span> does not define a homeomorphism
onto its image: for instance, there exist sequences <span
class="math inline">\(x_n \in \mathbb{R}\)</span> with <span
class="math inline">\(x_n \rightarrow \infty\)</span> for which <span
class="math inline">\(\iota(x_n) \rightarrow \iota(0)\)</span>.</p>
</div>
<div class="remark">
<p><strong>Remark 65</strong>. An injective immersion is called an
<em>embedding</em> if it defines a homeomorphism onto its image. (This
is not the case in Example <a href="#example:immersed-subgroup"
data-reference-type="ref"
data-reference="example:immersed-subgroup">64</a>.) With this
terminology, we could alternatively define a Lie subgroup to be a pair
<span class="math inline">\((H,\iota)\)</span>, where <span
class="math inline">\(H\)</span> is a Lie group and <span
class="math inline">\(\iota\)</span> is an embedding.</p>
</div>
<h2 id="sec:orgd63ace1">§11.4. A handy criterion for being a Lie subgroup</h2>
<p>Here is a very handy criterion for checking that a subgroup of a Lie
group is a Lie subgroup; we shall use it in several examples.</p>
<div id="lem:lie-subgroups-criterion" class="lemma">
<p><strong>Lemma 66</strong>. Let <span class="math inline">\(G\)</span>
be a Lie group. Let <span class="math inline">\(H \leq G\)</span> be a
subgroup that is given near the identity <span class="math inline">\(e
\in G\)</span> element by a system of equations <span id="eq:define-lie-group-near-identity-by-equations" class="math display">\[\label{eq:define-lie-group-near-identity-by-equations}\tag{58}
      f_1 = \dotsb = f_m = 0,\]</span> where the <span
class="math inline">\(f_i : G %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}\)</span> are smooth maps defined near <span
class="math inline">\(e\)</span> for which <span class="math inline">\(f
:= (f_1,\dotsc,f_m) : G %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathbf{k}^m\)</span> is submersive, i.e., satisfies either of the
equivalent conditions <span
class="math inline">\(\mathop{\mathrm{rank}}(T_e f) = m\)</span> or
<span class="math inline">\(\dim (V) = d\)</span>, where <span
class="math inline">\(d := \dim(G) - m\)</span> and <span
class="math inline">\(V := \ker(T_e f)\)</span> is the vector space
given in local coordinates <span
class="math inline">\(x_1,\dotsc,x_n\)</span> at <span
class="math inline">\(e \in G\)</span> (<span class="math inline">\(n =
  \dim(G)\)</span>) by the space of solutions <span
class="math inline">\((d x_1,\dotsc, d x _n) \in \mathbf{k}^n\)</span>
to the system of homogeneous linear equations <span
class="math display">\[\sum_{j=1}^n \frac{\partial f_i}{\partial x_j}(e)
d x _j = 0
    \quad (i=1..m)\]</span> obtained by differentiating <a
href="#eq:define-lie-group-near-identity-by-equations"
data-reference-type="eqref"
data-reference="eq:define-lie-group-near-identity-by-equations">\((58)\)</a>.
Then <span class="math inline">\(H\)</span> is a <span
class="math inline">\(d\)</span>-dimensional Lie subgroup of <span
class="math inline">\(G\)</span>. Moreover, <span
class="math inline">\(\mathop{\mathrm{Lie}}(H) = T_e H\)</span> is equal
to <span class="math inline">\(V\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Thanks to Propositions <a
href="#prop:submfld-criterion" data-reference-type="ref"
data-reference="prop:submfld-criterion">27</a>, <a
href="#prop:compute-tangent-space-submfld" data-reference-type="ref"
data-reference="prop:compute-tangent-space-submfld">29</a>, we need only
verify that <span class="math inline">\(H\)</span> is a <span
class="math inline">\(d\)</span>-dimensional submanifold of <span
class="math inline">\(G\)</span>. Set <span class="math inline">\(n :=
\dim(G)\)</span>. As in the proof of Proposition <a
href="#prop:submfld-criterion" data-reference-type="ref"
data-reference="prop:submfld-criterion">27</a>, there is a coordinate
system <span class="math inline">\(x_1,\dotsc,x_n\)</span> on <span
class="math inline">\(G\)</span> at <span
class="math inline">\(e\)</span> so that <span
class="math inline">\(H\)</span> is given near <span
class="math inline">\(e\)</span> by <span class="math inline">\(x_{1}=
\dotsb = x_m = 0\)</span>. Let <span class="math inline">\(p \in
H\)</span>, and let <span class="math inline">\(\psi : G \rightarrow
G\)</span> be the map <span class="math inline">\(\psi(x) := p^{-1}
x\)</span>. Since <span class="math inline">\(G\)</span> is a Lie group,
the map <span class="math inline">\(\psi\)</span> is a diffeomorphism
with <span class="math inline">\(\psi(p) = e\)</span>, and so <span
class="math inline">\(y_1 := x_1 \circ \psi, \dotsc, y_n := x_n \circ
\psi\)</span> defines a coordinate system on <span
class="math inline">\(G\)</span> at <span
class="math inline">\(p\)</span>. For <span class="math inline">\(g \in
G\)</span> near <span class="math inline">\(p\)</span>, the following
are then visibly equivalent:</p>
<ol>
<li><p><span class="math inline">\(y_1(g) = \dotsb = y_m(g) =
0\)</span></p></li>
<li><p><span class="math inline">\(x_1(p^{-1} g) = \dotsb = x_m(p^{-1}
g) = 0\)</span></p></li>
<li><p><span class="math inline">\(p^{-1} g \in H\)</span></p></li>
<li><p><span class="math inline">\(g \in H\)</span>.</p></li>
</ol>
<p>In relating the final two steps, we used that <span
class="math inline">\(H\)</span> is a subgroup and that <span
class="math inline">\(p \in H\)</span>. ◻</p>
</span></div>
<div class="example">
<p><strong>Example 67</strong>. The subgroup <span
class="math inline">\(H := {\mathop{\mathrm{SL}}}_n(\mathbf{k})\)</span>
of <span class="math inline">\(G :=
  {\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> is defined by the single
equation <span class="math inline">\(\det(g) = 1\)</span>.
Differentiating this equation and evaluating at the identity element
gives the linear equation <span
class="math display">\[\mathop{\mathrm{trace}}(d g) = 0\]</span> in the
matrix variable <span class="math inline">\(d g \in M_n(\mathbf{k}) =
T_e(G)\)</span> (see <a href="#eq:lie-algebra-general-linear-group"
data-reference-type="eqref"
data-reference="eq:lie-algebra-general-linear-group">\((57)\)</a>).
Since this equation has an <span
class="math inline">\(n^2-1\)</span>-dimensional solution space, we
deduce from Lemma <a href="#lem:lie-subgroups-criterion"
data-reference-type="ref"
data-reference="lem:lie-subgroups-criterion">66</a> that <span
class="math inline">\(H\)</span> is a Lie subgroup of <span
class="math inline">\(G\)</span>, called the <em>special linear
group</em>. Moreover, <span
class="math display">\[T_e({\mathop{\mathrm{SL}}}_n(\mathbf{k}))
  = \{d g \in M_n(\mathbf{k}) : \mathop{\mathrm{trace}}(d g) =
0\}\]</span> is the space of traceless <span class="math inline">\(n
\times n\)</span> matrices.</p>
</div>
<div class="exercise">
<p><strong>Exercise 16</strong>. Show that the <em>orthogonal group</em>
<span class="math display">\[O_n(\mathbf{k}) := \{g \in
{\mathop{\mathrm{GL}}}_n(\mathbf{k}) : g g^t =
  1\},\]</span> where <span class="math inline">\(g \mapsto g^t\)</span>
denotes the transpose map, is defined by a system of <span
class="math inline">\(n(n+1)/2\)</span> equations having full rank at
the identity (i.e., satisfying the submersiveness condition). Deduce
that <span class="math inline">\(O_n(\mathbf{k})\)</span> is a Lie group
of dimension <span class="math inline">\(n^2 - n(n+1)/2 =
n(n-1)/2\)</span>.</p>
</div>
<h2 id="sec:orgc0ef6df">§11.5. Lie subgroups are closed<span
id="sec:lie-subgroups-are-closed"
label="sec:lie-subgroups-are-closed"></span></h2>
<div id="thm:lie-subgroups-are-closed" class="theorem">
<p><strong>Theorem 68</strong>. <em>Let <span
class="math inline">\(G\)</span> be a Lie group and <span
class="math inline">\(H \leq G\)</span> a Lie subgroup. Then <span
class="math inline">\(H\)</span> is closed in <span
class="math inline">\(G\)</span>.</em></p>
</div>
<p>Recalling from Remark <a href="#rmk:submfld-locally-closed"
data-reference-type="ref"
data-reference="rmk:submfld-locally-closed">26</a> that <span
class="math inline">\(H\)</span> is locally closed in <span
class="math inline">\(G\)</span>, the proof of Theorem <a
href="#thm:lie-subgroups-are-closed" data-reference-type="ref"
data-reference="thm:lie-subgroups-are-closed">68</a> reduces to that of
the following:</p>
<div class="lemma">
<p><strong>Lemma 69</strong>. A locally closed subgroup <span
class="math inline">\(H\)</span> of a topological group <span
class="math inline">\(G\)</span> is closed.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By the continuity of the group operations in <span
class="math inline">\(G\)</span>, the closure <span
class="math inline">\(\overline{H}\)</span> is itself a group. For <span
class="math inline">\(g \in \overline{H}\)</span>, the coset <span
class="math inline">\(g H\)</span> is then an open subset of <span
class="math inline">\(\overline{H}\)</span> (using here that <span
class="math inline">\(H\)</span> is locally closed). Since <span
class="math inline">\(H\)</span> is dense in <span
class="math inline">\(\overline{H}\)</span>, the subsets <span
class="math inline">\(g H\)</span> and <span
class="math inline">\(H\)</span> intersect. This means that we can write
<span class="math inline">\(g x = y\)</span> for some <span
class="math inline">\(x,y \in H\)</span>, whence <span
class="math inline">\(g = x^{-1} y\)</span> belongs to <span
class="math inline">\(H\)</span>. Since <span
class="math inline">\(g\)</span> was arbitrary, we conclude as required
that <span class="math inline">\(\overline{H} = H\)</span>. ◻</p>
</span></div>
<h2 id="sec:org89c17c6">§11.6. Translation of tangent spaces by group
elements<span id="sec:translate-tangent-spaces-gp-elts"
label="sec:translate-tangent-spaces-gp-elts"></span></h2>
<p>Let <span class="math inline">\(G\)</span> be a Lie group. An element
<span class="math inline">\(g \in G\)</span> acts on <span
class="math inline">\(G\)</span> by the left and right multiplication
maps <span class="math display">\[L[g] : G \rightarrow G\]</span> <span
class="math display">\[h \mapsto g h,\]</span> <span
class="math display">\[R[g] : G \rightarrow G\]</span> <span
class="math display">\[h \mapsto h g.\]</span> One has <span id="eq:hom-property-left-right-translation" class="math display">\[\label{eq:hom-property-left-right-translation}\tag{59}
  L[g_1] \circ L[g_2] = L[g_1 g_2],
  \quad R[g_1] \circ R[g_2] = R[g_2 g_1].\]</span> These maps are
smooth, so it makes sense to differentiate them at an element <span
class="math inline">\(h \in G\)</span> to obtain linear maps of tangent
spaces <span class="math display">\[T_h L[g] : T_{h} G \rightarrow T_{g
h}(G)\]</span> <span class="math display">\[T_h R[g] : T_{h} G
\rightarrow T_{h g}(G).\]</span> By the chain rule and the identities <a
href="#eq:hom-property-left-right-translation"
data-reference-type="eqref"
data-reference="eq:hom-property-left-right-translation">\((59)\)</a>,
these maps are in fact linear isomorphisms of the tangent spaces. It
will be convenient to introduce for <span class="math inline">\(X \in
T_h G\)</span> and <span class="math inline">\(g \in G\)</span> the
abbreviations <span id="eq:abbrev-gX-Xg" class="math display">\[\label{eq:abbrev-gX-Xg}\tag{60}
    g X := (T_h L[g])(X) \in T_{g h}(G),
  \quad
  X g := (T_h R[g])(X) \in T_{h g}(G).\]</span> These will be used most
often when <span class="math inline">\(h = 1\)</span>, so that <span
class="math inline">\(X \in T_e G = \mathfrak{g}\)</span>. The special
case worth focusing on is when <span class="math inline">\(G\)</span> is
a linear Lie group <span class="math inline">\(G \leq
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>. In that case, we can
identify the various tangent spaces <span
class="math inline">\(T_h(G)\)</span> with subspaces of <span
class="math inline">\(M_n(\mathbf{k})\)</span>; under this
identification, the quantities <span class="math inline">\(g X, X
g\)</span> defined in <a href="#eq:abbrev-gX-Xg"
data-reference-type="eqref"
data-reference="eq:abbrev-gX-Xg">\((60)\)</a> are given by the
matrix products of <span class="math inline">\(g \in
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> and <span
class="math inline">\(X \in M_n(\mathbf{k})\)</span>.</p>
<h1 id="sec:orgf603676">§12. The connected component</h1>
<h2 id="sec:org948d2a7">§12.1. Generalities</h2>
<p>Any group may be regarded as a discrete topological group, or even a
discrete <span class="math inline">\(0\)</span>-dimensional Lie group
(provided the group is countable, so as to satisfy the hypothesis of
second-countability), but Lie theory has nothing interesting to say
about such Lie groups; its techniques show their true strength only when
the group is connected. Recall, then, that a topological space <span
class="math inline">\(X\)</span> is <em>connected</em> if it cannot be
written as a disjoint union of two nonempty closed subsets, or
equivalently, if every continuous map from <span
class="math inline">\(X\)</span> to a discrete topological space is
constant. Any topological space <span class="math inline">\(X\)</span>
admits a unique decomposition <span class="math inline">\(X = \sqcup_{i}
X_i\)</span> into maximal connected subsets <span
class="math inline">\(X_i\)</span>, called the <em>connected
components</em> of <span class="math inline">\(X\)</span>; since the
closure of any connected set is connected, the connected components are
always closed, but need not be open in general. However, if <span
class="math inline">\(X\)</span> is <em>locally connected</em>, that is
to say, if each point has a connected neighborhood, then the connected
components are open. In particular, any manifold is locally Euclidean,
hence locally connected, and so is the disjoint union of its connected
components which are in turn open submanifolds. Moreover, since
manifolds are locally path-connected, we know that any connected
manifold is necessarily path-connected, even by smooth paths.</p>
<p>In particular, the connected components of a Lie group <span
class="math inline">\(G\)</span> are submanifolds. It is customary to
denote by <span class="math inline">\(G^0\)</span> the connected
component of the identity element of <span
class="math inline">\(G\)</span>. Then <span
class="math inline">\(G^0\)</span> has the defining property that</p>
<ul>
<li><p>if <span class="math inline">\(C\)</span> is any connected subset
of <span class="math inline">\(G\)</span> that contains the identity
element, then <span class="math inline">\(C \subseteq
G^0\)</span>.</p></li>
</ul>
<p>We have the following:</p>
<div class="theorem">
<p><strong>Theorem 70</strong>. <em><span
class="math inline">\(G^0\)</span> is a normal Lie subgroup of <span
class="math inline">\(G\)</span>, and the connected components of <span
class="math inline">\(G\)</span> are precisely the cosets of <span
class="math inline">\(G^0\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We have already observed that <span
class="math inline">\(G^0\)</span> is a submanifold. Let <span
class="math inline">\(g \in G\)</span>. Since left and right
multiplication maps <span class="math inline">\(x \mapsto g x, x \mapsto
x g\)</span> define homeomorphisms from <span
class="math inline">\(G\)</span> to itself, they permute the connected
components. The various assertions follow easily from this:</p>
<ol>
<li><p>If <span class="math inline">\(g \in G^0\)</span>, then <span
class="math inline">\(g G^0\)</span> is a connected component of <span
class="math inline">\(G\)</span> containing <span
class="math inline">\(g\)</span>. Since <span
class="math inline">\(G^0\)</span> is also a connected component of
<span class="math inline">\(G\)</span> containing <span
class="math inline">\(g\)</span>, it follows that <span
class="math inline">\(g G^0 = G^0\)</span>. This implies that <span
class="math inline">\(G^0\)</span> is a subgroup.</p></li>
<li><p>For any <span class="math inline">\(g \in G\)</span>, the
conjugate <span class="math inline">\(g G^0 g^{-1}\)</span> is a
connected component of <span class="math inline">\(G\)</span> that
contains <span class="math inline">\(g g^{-1} = 1\)</span>, hence <span
class="math inline">\(g G^0 g^{-1} = G^0\)</span>. Thus <span
class="math inline">\(G^0\)</span> is normal.</p></li>
<li><p>If <span class="math inline">\(C\)</span> is any connected
component of <span class="math inline">\(G^0\)</span>, then it is
nonempty; if <span class="math inline">\(g \in C\)</span> is any
element, then <span class="math inline">\(g^{-1} C\)</span> is a
connected component of <span class="math inline">\(G^0\)</span> that
contains <span class="math inline">\(g^{-1} g = 1\)</span>, hence <span
class="math inline">\(g^{-1} C = G^0\)</span> and so <span
class="math inline">\(C = g G^0\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="sec:orgdc3e70e">§12.2. Some examples<span
id="sec:connectedness-examples"
label="sec:connectedness-examples"></span></h2>
<p>In the following table, we list the number of connected components of
some Lie groups. Here <span class="math inline">\(\mathbf{k}\)</span> is
one of the fields <span class="math inline">\(\mathbb{R}\)</span> or
<span class="math inline">\(\mathbb{C}\)</span>, <span
class="math inline">\(n \geq 1\)</span> and <span
class="math inline">\(p \geq q \geq 1\)</span>.</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(1\)</span>
component</th>
<th style="text-align: center;"><span class="math inline">\(2\)</span>
components</th>
<th style="text-align: center;"><span class="math inline">\(4\)</span>
components</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span></td>
<td style="text-align: center;"><span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(O(p,q)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbf{k})\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(O(n)\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\mathop{\mathrm{SO}}(p,q)\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(U(n),
\mathop{\mathrm{SU}}(n)\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(U(p,q),
\mathop{\mathrm{SU}}(p,q)\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</div>
<p>These Lie groups were defined in lecture. It was proved that <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbf{k})\)</span>, <span
class="math inline">\(\operatorname{O}(n)\)</span>, <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span>, <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> have the indicated
number of connected components; the remaining cases were left as
exercises.</p>
<ul>
<li><p>For the case of <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbf{k})\)</span>, we
argued using elementary matrices.</p></li>
<li><p>The group <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> is the
image of the connected domain <span
class="math inline">\(\mathbb{C}^\times \times
{\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> under the continuous
homomorphism <span class="math inline">\((\zeta,g) \mapsto \zeta
g\)</span>, which is surjective because <span
class="math inline">\(\det(\zeta g) = \zeta^n\)</span> and the <span
class="math inline">\(n\)</span>th power map on <span
class="math inline">\(\mathbb{C}^\times\)</span> is surjective.</p></li>
<li><p>The proof in the case of <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> was by induction
on <span class="math inline">\(n\)</span>, using that the trivial group
<span class="math inline">\(\mathop{\mathrm{SO}}(1) = \{1\}\)</span> is
connected and that <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> acts transitively
on the (connected) sphere <span class="math inline">\(S^{n-1}\)</span>
with <span class="math inline">\(\mathop{\mathrm{SO}}(n-1)
\hookrightarrow \mathop{\mathrm{SO}}(n)\)</span> as the stabilizer group
of the point <span class="math inline">\(e_n := (0,\dotsc,0,1)\)</span>.
Since several people asked for clarifications regarding this proof, I
have written it down in the following subsection.</p></li>
<li><p>The proof in the case of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> was to recall that
every conjugacy class in <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> contains a
diagonal element, and that the diagonal elements <span
class="math display">\[\begin{pmatrix}
    e^{i \theta_1} &amp;  &amp;  \\
     &amp; \dotsb  &amp;  \\
     &amp;  &amp; e^{i \theta_n}
  \end{pmatrix}\]</span> are obviously in the connected component of the
identity, because (for instance) they are the values <span
class="math inline">\(\gamma(1)\)</span> of the continuous maps <span
class="math display">\[\gamma(t) =
  \begin{pmatrix}
    e^{i \theta_1 t} &amp;  &amp;  \\
     &amp; \dotsb  &amp;  \\
     &amp;  &amp; e^{i \theta_n t}
  \end{pmatrix}\]</span> for which <span class="math inline">\(\gamma(0)
= 1\)</span> is the identity.</p></li>
</ul>
<h2 id="sec:orga8ac11a">§12.3. Connectedness of <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span></h2>
<p>We verify by induction on <span class="math inline">\(n\)</span> that
<span class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> is
connected. The group <span class="math inline">\(\mathop{\mathrm{SO}}(1)
= \{1\}\)</span> is trivial, hence connected. Let <span
class="math inline">\(n \geq 2\)</span>. The group <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> acts smoothly on
the unit sphere <span class="math inline">\(S^{n-1} := \{x
\in \mathbb{R}^n : |x| = 1\}\)</span>. The action is transitive. In
fact, the connected component already acts transitively:</p>
<div id="lem:so-n-connected-component-acts-transitively-on-sphere"
class="lemma">
<p><strong>Lemma 71</strong>. Let <span class="math inline">\(n \geq
2\)</span>. Then <span
class="math inline">\(\mathop{\mathrm{SO}}(n)^0\)</span> acts
transitively on <span class="math inline">\(S^{n-1}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Denote by <span
class="math inline">\(e_1,\dotsc,e_n\)</span> the standard basis
elements; they all belong to <span
class="math inline">\(S^{n-1}\)</span>. Let <span
class="math inline">\(v \in S^{n-1}\)</span>. We will show that there
exists <span class="math inline">\(g \in
\mathop{\mathrm{SO}}(n)^0\)</span> with <span class="math inline">\(g
e_n = v\)</span>.</p>
<ol>
<li><p>Consider first the case <span class="math inline">\(n =
2\)</span>. Define <span class="math inline">\(\gamma : \mathbb{R}
\rightarrow \mathop{\mathrm{SO}}(2)\)</span> by the formula <span
class="math display">\[\gamma(\theta) :=
\begin{pmatrix}
      \cos \theta  &amp; \sin \theta  \\
      -\sin \theta  &amp; \cos \theta
    \end{pmatrix}
\in \mathop{\mathrm{SO}}(2).\]</span> Since <span
class="math inline">\(\gamma\)</span> is continuous and <span
class="math inline">\(\gamma(0) = 1\)</span>, we see that <span
class="math inline">\(\gamma(\theta) \in
\mathop{\mathrm{SO}}(2)^0\)</span> for all <span
class="math inline">\(\theta\)</span>. Now let <span
class="math inline">\(v \in S^{1}\)</span>. We may then write <span
class="math inline">\(v = (x,y)\)</span> where <span
class="math inline">\(x^2 + y^2 = 1\)</span> and solve <span
class="math inline">\(x = \sin(\theta), y = \cos(\theta)\)</span> for
some <span class="math inline">\(\theta\)</span>. Then <span
class="math inline">\(\gamma(\theta) e_2 = (x,y)\)</span>, as
required.</p></li>
<li><p>Suppose now that <span class="math inline">\(n \geq 3\)</span>.
Define <span class="math inline">\(\gamma : \mathbb{R} \rightarrow
\mathop{\mathrm{SO}}(n)\)</span> by <span
class="math display">\[\gamma(\theta)
    :=
    \begin{pmatrix}
      1 &amp;  &amp; &amp; &amp; \\
      &amp; \dotsb &amp; &amp; &amp; \\
      &amp;  &amp; 1 &amp; &amp; \\
      &amp; &amp; &amp; \cos(\theta) &amp; \sin(\theta) \\
      &amp; &amp; &amp; -\sin(\theta) &amp; \cos(\theta)
    \end{pmatrix}
.\]</span> As above, <span class="math inline">\(\gamma(\theta) \in
\mathop{\mathrm{SO}}(n)^0\)</span> for all <span
class="math inline">\(\theta\)</span>. Let <span class="math inline">\(v
\in S^{n-1}\)</span>. If <span class="math inline">\(v\)</span> belongs
to the line spanned by <span class="math inline">\(e_n\)</span>, then
either <span class="math inline">\(v = e_n\)</span> (in which case <span
class="math inline">\(v = g e_n\)</span> with <span
class="math inline">\(g = 1 \in \mathop{\mathrm{SO}}(n)^0\)</span>) or
<span class="math inline">\(v = - e_n\)</span> (in which case <span
class="math inline">\(v = \gamma(\pi) e_n\)</span>); in either case,
<span class="math inline">\(v\)</span> is of the form <span
class="math inline">\(v = g e_n\)</span> for some <span
class="math inline">\(g \in \mathop{\mathrm{SO}}(n)^0\)</span>. If <span
class="math inline">\(v\)</span> and <span
class="math inline">\(e_n\)</span> are linearly independent, we may use
Gram–Schmidt to find an orthonormal basis <span
class="math inline">\(e_{n-1}&#39;, e_n\)</span> for their span. We may
then extend this to an orthonormal basis <span
class="math inline">\(e_1&#39;, e_2&#39;, \dotsc, e_{n-1}&#39;,
e_n\)</span> for <span class="math inline">\(\mathbb{R}^n\)</span>. We
can find <span class="math inline">\(g\)</span> in <span
class="math inline">\(\operatorname{O}(n)\)</span> taking one
orthonormal basis to the other, so that <span class="math inline">\(g
v\)</span> belongs to the span of <span class="math inline">\(e_{n-1},
e_n\)</span> and <span class="math inline">\(g e_n = e_n\)</span> Then
<span class="math inline">\(g v\)</span> is of the form <span
class="math inline">\((0,\dotsc,0,x,y)\)</span> with <span
class="math inline">\(x^2 + y^2 = 1\)</span>; we can then solve <span
class="math inline">\(x = \sin(\theta), y = \cos(\theta)\)</span> as
before to obtain <span class="math inline">\(\gamma(\theta) e_n = g
v\)</span> and thus <span class="math inline">\(g^{-1} \gamma(\theta) g
e_n = v\)</span>. Since <span
class="math inline">\(\mathop{\mathrm{SO}}(n)^0 =
\operatorname{O}(n)^0\)</span> is normal in <span
class="math inline">\(\operatorname{O}(n)\)</span>, we have <span
class="math inline">\(g^{-1} \gamma(\theta) g \in
\mathop{\mathrm{SO}}(n)^0\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<div id="lem:compute-stabilizer-north-pole-so-n" class="lemma">
<p><strong>Lemma 72</strong>. The stabilizer group <span
class="math inline">\({\mathop{\mathrm{Stab}}}_{\mathop{\mathrm{SO}}(n)}(e_n)\)</span>
is isomorphic to <span
class="math inline">\(\mathop{\mathrm{SO}}(n-1)\)</span>, with an
isomorphism in the opposite direction given by <span
class="math display">\[\mathop{\mathrm{SO}}(n-1) \xrightarrow{\cong}
{\mathop{\mathrm{Stab}}}_{\mathop{\mathrm{SO}}(n)}(e_n)\]</span> <span
class="math display">\[h \mapsto
\begin{pmatrix}
    h &amp;  \\
    &amp; 1
  \end{pmatrix}
.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If <span class="math inline">\(g \in
\mathop{\mathrm{SO}}(n)\)</span> fixes <span
class="math inline">\(e_n\)</span>, then the identity <span
class="math display">\[\langle g v, e_n \rangle = \langle v, g^t e_n
\rangle
  =
  \langle v, g^{-1} e_n \rangle\]</span> implies that <span
class="math inline">\(g^{-1}\)</span> and hence <span
class="math inline">\(g\)</span> also stabilizes the orthogonal
complement <span class="math inline">\(\langle e_n \rangle^\perp =
\langle
  e_1,\dotsc,e_{n-1} \rangle\)</span>. We may thus put it in in the
block-upper triangular form <span class="math inline">\(g =
\begin{pmatrix}
    h &amp;  \\
    &amp; 1
  \end{pmatrix}\)</span> for some <span class="math inline">\(h \in
{\mathop{\mathrm{GL}}}_{n-1}(\mathbb{R})\)</span>. The condition <span
class="math inline">\(g g^t = 1\)</span> implies <span
class="math inline">\(h h^t = 1\)</span>, hence that <span
class="math inline">\(h \in \mathop{\mathrm{SO}}(n-1)\)</span>. ◻</p>
</span></div>
<p>Using the above lemmas, we now complete the inductive step in the
proof that <span class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span>
is connected, i.e., that <span
class="math inline">\(\mathop{\mathrm{SO}}(n) =
\mathop{\mathrm{SO}}(n)^0\)</span>. Let <span class="math inline">\(g
\in \mathop{\mathrm{SO}}(n)\)</span>; we wish to show that in fact <span
class="math inline">\(g \in \mathop{\mathrm{SO}}(n)^0\)</span>. Consider
the element <span class="math inline">\(g e_n \in S^{n-1}\)</span>. By
Lemma <a
href="#lem:so-n-connected-component-acts-transitively-on-sphere"
data-reference-type="ref"
data-reference="lem:so-n-connected-component-acts-transitively-on-sphere">71</a>,
we may write <span class="math inline">\(g e_n = \gamma e_n\)</span> for
some <span class="math inline">\(\gamma \in
\mathop{\mathrm{SO}}(n)^0\)</span>. We then have <span
class="math inline">\(\gamma^{-1} g e_n = e_n\)</span>, i.e., <span
class="math inline">\(\gamma^{-1} g \in
{\mathop{\mathrm{Stab}}}_{\mathop{\mathrm{SO}}(n)}(e_n)\)</span>. By Lemma
<a href="#lem:compute-stabilizer-north-pole-so-n"
data-reference-type="ref"
data-reference="lem:compute-stabilizer-north-pole-so-n">72</a>, we have
<span class="math inline">\(\gamma^{-1} g = h\)</span> for some <span
class="math inline">\(h \in \mathop{\mathrm{SO}}(n-1) \hookrightarrow
\mathop{\mathrm{SO}}(n)\)</span>. By the inductive hypothesis, <span
class="math inline">\(\mathop{\mathrm{SO}}(n-1)\)</span> is connected,
hence <span class="math inline">\(\mathop{\mathrm{SO}}(n-1) \subseteq
\mathop{\mathrm{SO}}(n)^0\)</span>. Thus <span class="math inline">\(g =
\gamma h\)</span> is the product of two elements of <span
class="math inline">\(\mathop{\mathrm{SO}}(n)^0\)</span>; since the
latter is known to be a group, we conclude that <span
class="math inline">\(g \in \mathop{\mathrm{SO}}(n)^0\)</span>.</p>
<div class="remark">
<p><strong>Remark 74</strong>. One doesn’t actually need to prove Lemma
<a href="#lem:so-n-connected-component-acts-transitively-on-sphere"
data-reference-type="ref"
data-reference="lem:so-n-connected-component-acts-transitively-on-sphere">71</a>
to complete the inductive argument; a slightly softer way to proceed is
to make use of the following general lemma:</p>
<div class="lemma">
<p><strong>Lemma 73</strong>. Let <span class="math inline">\(G\)</span>
be a topological group that acts on a topological space <span
class="math inline">\(X\)</span> (i.e., we assume given an action <span
class="math inline">\(\alpha : G \times X
    \rightarrow X\)</span> as in Definition <a href="#defn:top-gp"
data-reference-type="ref" data-reference="defn:top-gp">36</a>). Assume
that:</p>
<ol>
<li><p>For <span class="math inline">\(x_0 \in X\)</span>, the orbit map
<span class="math inline">\(G \rightarrow X\)</span> given by <span
class="math inline">\(g \mapsto g x_0\)</span> is a quotient
map.</p></li>
<li><p>The action is transitive.</p></li>
<li><p><span class="math inline">\(X\)</span> is connected.</p></li>
<li><p>The stabilizer <span class="math inline">\(H\)</span> in <span
class="math inline">\(G\)</span> of some (equivalently, any) point <span
class="math inline">\(x_0 \in X\)</span> is connected.</p></li>
</ol>
<p>Then <span class="math inline">\(G\)</span> is connected.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If not, we may find a non-constant continuous map
<span class="math inline">\(f : G \rightarrow D\)</span> for some
discrete topological space <span class="math inline">\(D\)</span> (e.g.,
<span class="math inline">\(D = \{0,1\}\)</span>). Since <span
class="math inline">\(H\)</span> and hence any coset of <span
class="math inline">\(H\)</span> is connected, the restriction of <span
class="math inline">\(f\)</span> to any coset of <span
class="math inline">\(H\)</span> is constant, hence <span
class="math inline">\(f\)</span> induces a continuous map <span
class="math inline">\(G/H \rightarrow D\)</span>, where <span
class="math inline">\(G/H\)</span> is equipped with the quotient
topology. Since the orbit map assumed to be a quotient map, we obtain a
continuous map <span class="math inline">\(X \rightarrow D\)</span>
sending <span class="math inline">\(g x_0\)</span> to <span
class="math inline">\(f(g)\)</span>. Since <span
class="math inline">\(X\)</span> is connected, this last map must be
constant, hence so must the original map <span
class="math inline">\(f\)</span>. Therefore <span
class="math inline">\(G\)</span> is connected. ◻</p>
</span></div>
<p>The orbit maps for the action <span
class="math inline">\(\mathop{\mathrm{SO}}(n) \circlearrowright
S^{n-1}\)</span> are quotient maps because (for instance) <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> is Hausdorff and
<span class="math inline">\(S^{n-1}\)</span> is compact. Alternatively,
one can appeal here to Exercise <a
href="#exercise-topological-groups-quotient-map-homeomorphism"
data-reference-type="ref"
data-reference="exercise-topological-groups-quotient-map-homeomorphism">11</a>,
which tells us that the orbits map are open maps, hence are quotient
maps.</p>
</div>
<h1 id="sec:org77618cc">§13. Basics on the exponential map<span
id="sec:exp-map" label="sec:exp-map"></span></h1>
<h2 id="sec:orgd602cac">§13.1. Review of the matrix exponential<span
id="sec:matrix-exp" label="sec:matrix-exp"></span></h2>
<p>Let <span class="math inline">\(\mathbf{k}\)</span> be either <span
class="math inline">\(\mathbb{R}\)</span> of <span
class="math inline">\(\mathbb{C}\)</span>. Let <span
class="math inline">\(n \geq 1\)</span> and <span
class="math display">\[A := M_n(\mathbf{k}) := {\mathop{\mathrm{Mat}}}_{n
\times n}(\mathbf{k}).\]</span> It is a finite-dimensional unital
associative algebra over <span class="math inline">\(\mathbf{k}\)</span>
(and the discussion to follow applies more generally to any such
algebra). The operator norm <span class="math inline">\(\|.\|\)</span>
on <span class="math inline">\(A\)</span> is given by <span
class="math inline">\(\|x\| := \sup_{v \in \mathbf{k}^n : |v| = 1} |x
v|\)</span>; it satisfies the submultiplicativity property <span
class="math inline">\(\|x y\| \leq \|x\| \|y\|\)</span>. The unit group
of <span class="math inline">\(A\)</span> is <span
class="math display">\[A^\times =
{\mathop{\mathrm{GL}}}_n(\mathbf{k}).\]</span> For <span
class="math inline">\(x \in A\)</span> with <span
class="math inline">\(\|x\| &lt; 1\)</span>, the series <span
class="math inline">\(\sum_{n \geq 0} x^n\)</span> converges (by the
same proof as in the one-variable case, using the submultiplicativity).
Therefore <span class="math inline">\(1 - x\)</span> has the inverse
<span class="math inline">\(\sum_{n \geq 0} x^n\)</span> and hence
belongs to <span class="math inline">\(A^\times\)</span> whenever <span
class="math inline">\(\|x\| &lt; 1\)</span>. Therefore <span
class="math inline">\(A^\times\)</span> is open in <span
class="math inline">\(A\)</span>. (One can also see this more directly.)
Since <span class="math inline">\(A\)</span> is a Euclidean space, it
follows that we have natural identifications of tangent spaces <span
class="math display">\[T_0(A) = A,
  \quad
  T_1(A^\times) = A.\]</span> For any <span class="math inline">\(x \in
A\)</span>, the series <span class="math display">\[\exp(x) := \sum_{n
\geq 0} \frac{x^n}{n!}\]</span> converges. It satisfies the following
properties:</p>
<ol>
<li><p><span class="math inline">\(\exp\)</span> is smooth</p></li>
<li><p><span class="math inline">\(\exp(0) = 1\)</span></p></li>
<li><p>One has <span class="math inline">\(\exp(x+y) = \exp(x)
\exp(y)\)</span> whenever <span class="math inline">\(x,y\)</span>
commute (but not in general otherwise). In particular:</p>
<ol>
<li><p><span class="math inline">\(\exp(x) \exp(-x) = \exp(0) =
1\)</span>, hence <span class="math inline">\(\exp(A) \subseteq
A^\times\)</span>.</p></li>
<li><p><span class="math inline">\(\exp((s+t) x) = \exp(s x) \exp(t
x)\)</span> for all <span class="math inline">\(s,t \in
    \mathbf{k}\)</span>, hence the map <span
class="math inline">\(\mathbf{k} \ni t \mapsto \exp(t x) \in
    A^\times\)</span> is morphism of Lie groups for each <span
class="math inline">\(x \in A\)</span>.</p></li>
</ol></li>
<li><p><span class="math inline">\(\frac{d}{d t} \exp(t x) = x\)</span>,
hence <span class="math inline">\(T_0 \exp : A \rightarrow A\)</span> is
the identity transformation. Consequently <span
class="math inline">\(\exp\)</span> defines a local diffeomorphism at
<span class="math inline">\(0\)</span>, i.e., induces a diffeomorphism
<span class="math inline">\(\exp : U \rightarrow V\)</span> for some
open <span class="math inline">\(0 \in U \subseteq A\)</span> and <span
class="math inline">\(1 \in V \subseteq A^\times\)</span>.</p></li>
<li><p>An inverse to <span class="math inline">\(\exp\)</span> on the
subset <span class="math inline">\(\{1 - x : \|x\| &lt; 1\}\)</span> of
<span class="math inline">\(A^\times\)</span> is given by the logarithm
<span class="math display">\[\log(1-x) := - \sum_{n \geq 1}
\frac{x^n}{n}.\]</span></p></li>
<li><p>For <span class="math inline">\(g \in A^\times\)</span> and <span
class="math inline">\(x \in A\)</span> one has <span
class="math inline">\(\exp(g x g^{-1}) = g \exp(x)
g^{-1}\)</span>.</p></li>
</ol>
<p>For a diagonal matrix, one has <span class="math display">\[\exp (
\begin{pmatrix}
    t_1 &amp;  &amp;  \\
    &amp; \dotsb  &amp;  \\
    &amp;  &amp; t_n
  \end{pmatrix}
)
  =
\begin{pmatrix}
    \exp(t_1) &amp;  &amp;  \\
    &amp; \dotsb  &amp;  \\
    &amp;  &amp; \exp(t_n)
  \end{pmatrix}
.\]</span> For a basic nilpotent Jordan block <span
class="math inline">\(N\)</span>, given in the case (say) <span
class="math inline">\(n = 4\)</span> by <span class="math display">\[N =
\begin{pmatrix}
    &amp; 1 &amp;  &amp; \\
    &amp;  &amp; 1 &amp; \\
    &amp;  &amp; &amp; 1 \\
    &amp; &amp; &amp;
  \end{pmatrix}
,\]</span> one has <span class="math inline">\(N^k = 0\)</span> for all
<span class="math inline">\(k \geq n\)</span>, hence the series defining
<span class="math inline">\(\exp(N)\)</span> is finite. The series
defining <span class="math inline">\(\log(1 + t N)\)</span> is also
finite for any <span class="math inline">\(t
\in \mathbf{k}\)</span>.</p>
<div class="exercise">
<p><strong>Exercise 17</strong>. Using the above facts and Jordan
decomposition, show that <span class="math inline">\(\exp :
M_n(\mathbb{C}) \rightarrow {\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>
is surjective. (The corresponding assertion over the reals is false for
several reasons to be discussed in due course.)</p>
</div>
<p>The exponential map is very rarely injective (away from the origin);
for example, <span class="math inline">\(\exp(2 \pi i) = 1\)</span>, and
<span class="math display">\[\exp (\theta
\begin{pmatrix}
     &amp; 1 \\
    -1 &amp;
  \end{pmatrix}
)
  =
\begin{pmatrix}
    \cos \theta  &amp;  \sin \theta  \\
    - \sin \theta  &amp; \cos \theta
  \end{pmatrix}
.\]</span> Some other good examples to keep in mind are <span
class="math display">\[\exp (t
\begin{pmatrix}
     &amp; 1 \\
    1 &amp;
  \end{pmatrix}
)
  =
\begin{pmatrix}
    \cosh t  &amp;  \sinh t  \\
    \sinh t  &amp; \cosh t
  \end{pmatrix}\]</span> and <span class="math display">\[\exp
\begin{pmatrix}
    0 &amp; x &amp; z \\
     &amp; 0 &amp; y \\
     &amp;  &amp; 0
   \end{pmatrix}
   =
   \begin{pmatrix}
     1 &amp; x &amp; z + x y/2 \\
      &amp; 1 &amp; y \\
      &amp;  &amp; 1
   \end{pmatrix}
.\]</span></p>
<h2 id="sec:org964bb98">§13.2. One-parameter subgroups<span
id="sec:one-param-subgps" label="sec:one-param-subgps"></span></h2>
<p>Let <span class="math inline">\(G\)</span> be a Lie group. Let <span
class="math inline">\(\mathfrak{g} := \mathop{\mathrm{Lie}}(G)\)</span>
denote its Lie algebra.</p>
<div class="definition">
<p><strong>Definition 75</strong>. By a <em>one-parameter subgroup</em>
of <span class="math inline">\(G\)</span>, we shall mean a morphism of
Lie groups <span class="math inline">\(\Phi : \mathbf{k} \rightarrow
G\)</span>.</p>
</div>
<div class="remark">
<p><strong>Remark 76</strong>.  </p>
<ol>
<li><p>Note the standard but slightly misleading terminology: a
“one-parameter subgroup” <span class="math inline">\(\Phi\)</span> is
not a subgroup; its image <span
class="math inline">\(\mathop{\mathrm{image}}(\Phi) \leq G\)</span> a
subgroup, but even if <span class="math inline">\(\Phi\)</span> is
injective, the datum of <span class="math inline">\(\Phi\)</span>
contains strictly more information than that of its image. For example,
the one-parameter subgroups <span class="math inline">\(\Phi(t) :=
t\)</span> and <span class="math inline">\(\Phi(t) := 2 t\)</span> in
the additive group <span class="math inline">\(G =
(\mathbf{k},+)\)</span> have the same image.</p></li>
<li><p>Note also that a one-parameter subgroup <span
class="math inline">\(\Phi\)</span> of <span
class="math inline">\(G\)</span> is, in particular, a curve (in the
sense of §<a href="#sec:diff-geom-tangent-spaces"
data-reference-type="ref"
data-reference="sec:diff-geom-tangent-spaces">6.5</a>)
with basepoint the identity element <span class="math inline">\(e \in
G\)</span>. Its initial velocity <span class="math inline">\(\Phi
&#39;(0)\)</span> is an element of <span
class="math inline">\(\mathfrak{g}\)</span>.</p></li>
</ol>
</div>
<div id="example:one-param-subgroups-gln" class="example">
<p><strong>Example 77</strong>. For <span class="math inline">\(v \in
M_n(\mathbf{k})\)</span>, the discussion of §<a href="#sec:matrix-exp"
data-reference-type="ref"
data-reference="sec:matrix-exp">13.1</a> shows that the map
<span class="math inline">\(\Phi_v : \mathbf{k} \rightarrow
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> given by <span
class="math inline">\(\Phi_v(t) := \exp(t v)\)</span> is a one-parameter
subgroup of the Lie group <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> with
initial velocity <span class="math inline">\(\Phi_v&#39;(0) =
v\)</span>. Moreover, the map <span
class="math inline">\(M_n(\mathbf{k}) \ni v \mapsto \Phi_v(1) = \exp(v)
\in {\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> is smooth.</p>
</div>
<p>For general <span class="math inline">\(G\)</span>, a one-parameter
subgroup <span class="math inline">\(\Phi\)</span> satisfies the
identity <span class="math inline">\(\Phi(s+t) = \Phi(s) \Phi(t) =
\Phi(t) \Phi(s)\)</span>. Applying <span class="math inline">\(\frac{d}{
d s}|_{s=0}\)</span> to this identity gives the differential equation<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a> <span id="eq:one-param-subgp-diffeq" class="math display">\[\label{eq:one-param-subgp-diffeq}\tag{61}
  \Phi &#39;(t)= \Phi &#39;(0) \Phi(t) = \Phi(t) \Phi&#39;(0).\]</span>
By the initial condition <span class="math inline">\(\Phi(0) =
1\)</span> and general uniqueness theorem for ODE’s (§<a
href="#sec:diffeq" data-reference-type="ref"
data-reference="sec:diffeq">7</a>), it follows that <span
class="math inline">\(\Phi\)</span> is determined uniquely by its
initial velocity <span class="math inline">\(\Phi&#39;(0) \in
\mathfrak{g}\)</span>. To put it another way, for each element <span
class="math inline">\(v \in \mathfrak{g}\)</span>, there is <em>at most
one</em> one-parameter subgroup <span
class="math inline">\(\Phi_v\)</span> of <span
class="math inline">\(G\)</span> with initial velocity <span
class="math inline">\(v\)</span>. Conversely, we will now show that such
a one-parameter subgroup actually exists, and moreover, that its values
<span class="math inline">\(\Phi_v(t)\)</span> vary smoothly with <span
class="math inline">\(v\)</span>. For illustration, we explain a few
different ways to establish existence:</p>
<ol>
<li><p>In the special case <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>, one can just take <span
class="math inline">\(\Phi_v(t) := \exp(t v)\)</span>.</p></li>
<li><p>If <span class="math inline">\(G\)</span> is a <em>linear</em>
Lie group, that is to say, if it is a Lie subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> for
some <span class="math inline">\(n\)</span>, so that <span
class="math inline">\(\mathfrak{g} \leq M_n(\mathbf{k})\)</span>, then
it turns out that one can again take <span
class="math inline">\(\Phi_v(t) := \exp(t v)\)</span> where <span
class="math inline">\(\exp : M_n(\mathbf{k}) \rightarrow
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> is as defined above. What
requires proof here is the following:</p>
<div class="lemma">
<p><strong>Lemma 78</strong>. Let <span class="math inline">\(G\)</span>
be a Lie subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>. Then
<span class="math inline">\(\exp(\mathfrak{g}) \subseteq G\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(x \in
\mathfrak{g}\)</span>, and let <span class="math inline">\(\gamma :
\mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
G\)</span> be any curve with <span class="math inline">\(\gamma &#39;(0)
= x\)</span>. (Such a curve exists, more-or-less by definition of the
tangent space; see §<a href="#sec:diff-geom-tangent-spaces"
data-reference-type="ref"
data-reference="sec:diff-geom-tangent-spaces">6.5</a>
and especially Remark <a href="#rmk:tangent-vectors-via-curves"
data-reference-type="ref"
data-reference="rmk:tangent-vectors-via-curves">11</a>.) Since <span
class="math inline">\(G \leq {\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>
and <span class="math inline">\(\gamma(t) = 1 + t v + o(t)\)</span> as
<span class="math inline">\(t \rightarrow 0\)</span>, we may take for
<span class="math inline">\(t\)</span> small enough the logarithm of
<span class="math inline">\(\gamma(t)\)</span>, which then satisfies
<span class="math inline">\(\log \gamma (t) = t v + o(t)\)</span>.
Taking <span class="math inline">\(t := 1/n\)</span> with <span
class="math inline">\(n \in \mathbb{Z}\)</span> tending off to <span
class="math inline">\(\infty\)</span> gives <span
class="math inline">\(n \log \gamma(1/n) = n ( v/n + o(1/n)) = v +
o(1)\)</span>. Exponentiating, one obtains <span
class="math inline">\(\gamma(1/n)^n = \exp(v + o(1))\)</span>. Hence
<span class="math inline">\(\exp(v) = \lim_{n \rightarrow \infty}
\gamma(1/n)^n\)</span>. Since <span
class="math inline">\(\gamma\)</span> is a curve in <span
class="math inline">\(G\)</span> and <span
class="math inline">\(G\)</span> is a group, we have <span
class="math inline">\(\gamma(1/n)^n \in G\)</span> for all <span
class="math inline">\(n\)</span>. Since <span
class="math inline">\(G\)</span> is closed (see §<a
href="#sec:lie-subgroups-are-closed" data-reference-type="ref"
data-reference="sec:lie-subgroups-are-closed">11.5</a>),
it follows that <span class="math inline">\(\exp(v) \in G\)</span>, as
required. ◻</p>
</span></div></li>
<li><p>For general <span class="math inline">\(G\)</span>, we can appeal
to existence theorems for ODE’s (see §<a href="#sec:diffeq"
data-reference-type="ref" data-reference="sec:diffeq">7</a>)
to produce a curve <span class="math inline">\(\gamma : \mathbf{k} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
G\)</span> satisfying <span id="eq:curve-in-G-used-to-produce-exp" class="math display">\[\label{eq:curve-in-G-used-to-produce-exp}\tag{62}
    \gamma(0) = 1 \in G,
    \quad \gamma&#39;(t) = \gamma(t) v\]</span> for all <span
class="math inline">\(t\)</span> in the domain of <span
class="math inline">\(\gamma\)</span>. Moreover, the values of <span
class="math inline">\(\gamma\)</span> vary smoothly with the initial
data <span class="math inline">\(v\)</span>. A priori, the domain of
<span class="math inline">\(\gamma\)</span> might be quite small, but we
can now use the group structure on <span
class="math inline">\(G\)</span>, as follows, to enlarge it to all of
<span class="math inline">\(\mathbf{k}\)</span>. To that end, it
suffices to show that each solution <span
class="math inline">\(\gamma\)</span> to <a
href="#eq:curve-in-G-used-to-produce-exp" data-reference-type="eqref"
data-reference="eq:curve-in-G-used-to-produce-exp">\((62)\)</a>
on some ball<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> <span
class="math inline">\(B\)</span> with the center the origin can be
extended to a solution domain the enlarged ball <span
class="math inline">\(2 B\)</span> of twice the radius of <span
class="math inline">\(B\)</span>; iterating this, one eventually obtains
a solution on all of <span class="math inline">\(\mathbf{k}\)</span>.
(Many variations on this argument are also possible.)</p>
<ol>
<li><p>For <span class="math inline">\(s \in B\)</span>, the curve <span
class="math inline">\(\gamma_s(t) := \gamma(s)^{-1} \gamma(s +
t)\)</span> is defined whenever <span class="math inline">\(s+t \in
B\)</span> and satisfies the same initial condition <span
class="math inline">\(\gamma_s(0) = 1\)</span> and differential equation
<span class="math inline">\(\gamma_s&#39;(t) = \gamma(s)^{-1}
\gamma&#39;(s + t) = \gamma(s)^{-1}
    \gamma(s+t) v = \gamma_s(t) v\)</span> as <span
class="math inline">\(\gamma(t)\)</span> does. By the uniqueness theorem
cited above, we deduce that <span class="math inline">\(\gamma_s(t) =
\gamma(t)\)</span> and hence that <span id="eq:curve-is-local-hom-on-B" class="math display">\[\label{eq:curve-is-local-hom-on-B}\tag{63}
      \gamma(s+t) = \gamma(s) \gamma(t) \text{ provided that }s,t, s+t
      \in B.\]</span></p></li>
<li><p>For any <span class="math inline">\(s \in B\)</span>, denote by
<span class="math inline">\(\delta_s\)</span> the curve in <span
class="math inline">\(G\)</span> with domain <span
class="math inline">\(B + s := \{t : t - s \in B\}\)</span> given by
<span class="math inline">\(\delta_s(t) := \gamma(t-s)
\gamma(s)\)</span>. By differentiating the condition <a
href="#eq:curve-is-local-hom-on-B" data-reference-type="eqref"
data-reference="eq:curve-is-local-hom-on-B">\((63)\)</a>
, one sees that <span class="math inline">\(\delta_s\)</span> defines a
solution to <a href="#eq:curve-in-G-used-to-produce-exp"
data-reference-type="eqref"
data-reference="eq:curve-in-G-used-to-produce-exp">\((62)\)</a>
on its domain. For any two <span class="math inline">\(s_1,s_2 \in
B\)</span>, the identity <a href="#eq:curve-is-local-hom-on-B"
data-reference-type="eqref"
data-reference="eq:curve-is-local-hom-on-B">\((63)\)</a>
implies that <span class="math inline">\(\delta_{s_1} = \gamma =
\delta_{s_2}\)</span> on the neighborhood <span class="math inline">\(B
+ s_1 \cap B \cap B + s_2\)</span> of the origin, hence by the
uniqueness theorem cited above also that <span
class="math inline">\(\delta_{s_1} = \delta_{s_2}\)</span> on <span
class="math inline">\(B+ s_1 \cap B + s_2\)</span>. By the smoothness of
the group operation in <a href="#eq:curve-is-local-hom-on-B"
data-reference-type="eqref"
data-reference="eq:curve-is-local-hom-on-B">\((63)\)</a>,
we see that the values of <span class="math inline">\(\delta_s\)</span>
still vary smoothly with <span
class="math inline">\(v\)</span>.</p></li>
<li><p>Since <span class="math inline">\(\cup \{B + s : s \in B\} = 2
B\)</span>, we can patch together the solutions given in the previous
step to obtain a well-defined curve <span
class="math inline">\(\tilde{\gamma} : 2 B \rightarrow G\)</span> given
for <span class="math inline">\(t \in B+s\)</span> by <span
class="math inline">\(\tilde{\gamma}(t) := \delta_s(t - s)\)</span>.
This curve solves <a href="#eq:curve-in-G-used-to-produce-exp"
data-reference-type="eqref"
data-reference="eq:curve-in-G-used-to-produce-exp">\((62)\)</a>,
and extends <span class="math inline">\(\gamma\)</span>, as
required.</p></li>
</ol></li>
</ol>
<p>To summarize the above discussion, we have the following:</p>
<div id="thm:classification-smooth-1-param-subgroups" class="theorem">
<p><strong>Theorem 79</strong>. <em>Let <span
class="math inline">\(G\)</span> be a Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g} := \mathop{\mathrm{Lie}}(G)\)</span>.
For each <span class="math inline">\(x \in \mathfrak{g}\)</span> there
exists a unique one-parameter subgroup <span
class="math inline">\(\Phi_x\)</span> of <span
class="math inline">\(G\)</span> for which <span
class="math inline">\(\Phi_x&#39;(0) = x\)</span>. Moreover, the map
<span class="math inline">\(x \mapsto \Phi_x(1)\)</span> is
smooth.</em></p>
</div>
<h2 id="sec:org1d85865">§13.3. Definition and basic properties of exponential
map</h2>
<div class="definition">
<p><strong>Definition 80</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. The <em>exponential
map</em> <span class="math inline">\(\exp : \mathfrak{g} \rightarrow
G\)</span> is defined by <span class="math inline">\(\exp(x) :=
\Phi_x(1)\)</span>, where <span class="math inline">\(\Phi_x\)</span>
denotes the unique one-parameter subgroup of <span
class="math inline">\(G\)</span> having initial velocity <span
class="math inline">\(\Phi_x&#39;(0) = x\)</span>.</p>
</div>
<p>The notation is consistent with that discussed in §<a
href="#sec:matrix-exp" data-reference-type="ref"
data-reference="sec:matrix-exp">13.1</a>. We also have the
following immediate consequences of §<a href="#sec:one-param-subgps"
data-reference-type="ref"
data-reference="sec:one-param-subgps">13.2</a>:</p>
<div id="thm:exp-local-diffeo" class="theorem">
<p><strong>Theorem 81</strong> (Lie’s first theorem). <em>For a Lie
group <span class="math inline">\(G\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>, the exponential map <span
class="math inline">\(\exp : \mathfrak{g} \rightarrow G\)</span> has the
following properties:</em></p>
<ol>
<li><p><em><span class="math inline">\(\exp : \mathfrak{g} \rightarrow
G\)</span> is smooth</em></p></li>
<li><p><em>The derivative <span class="math inline">\(T_0 \exp :
\mathfrak{g} \rightarrow \mathfrak{g}\)</span> is the identity
transformation, or equivalently, <span class="math inline">\(\frac{d}{d
t} \exp(t x) = x\)</span> for all <span class="math inline">\(x \in
\mathfrak{g}\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(\exp : \mathfrak{g} \rightarrow
G\)</span> is a local diffeomorphism at <span
class="math inline">\(0\)</span>, i.e., there are open <span
class="math inline">\(0 \in U \subseteq \mathfrak{g}\)</span> and <span
class="math inline">\(1 \in V \subseteq G\)</span> so that <span
class="math inline">\(\exp : U \rightarrow V\)</span> is a
diffeomorphism.</em></p></li>
<li><p><em>For any <span class="math inline">\(X \in
\mathfrak{g}\)</span>, the map <span class="math inline">\(\mathbf{k}
\ni t \mapsto \exp(t x)\)</span> is the unique one-parameter subgroup of
<span class="math inline">\(G\)</span> with initial velocity <span
class="math inline">\(x\)</span>.</em></p></li>
<li><p><em>Let <span class="math inline">\(\gamma\)</span> be any curve
in <span class="math inline">\(G\)</span> with basepoint given by the
identity. Set <span class="math inline">\(X := \gamma &#39;(0) \in
\mathfrak{g}\)</span>. Then <span class="math inline">\(\exp(X) =
\lim_{n \rightarrow \infty} \gamma(1/n)^n\)</span>.</em></p></li>
</ol>
</div>
<p>(The proof of the final assertion proceeds exactly as in the case of
linear Lie groups now that we have the logarithm map on general Lie
groups at our disposal.)</p>
<p>Here is another key consequence:</p>
<div id="cor:connected-component-generated-by-exp" class="corollary">
<p><strong>Corollary 82</strong>. <em><span
class="math inline">\(\exp(\mathfrak{g})\)</span> generates the
connected component <span class="math inline">\(G^0\)</span> of <span
class="math inline">\(G\)</span>. In particular, if <span
class="math inline">\(G\)</span> is connected, then <span
class="math inline">\(G\)</span> is generated by <span
class="math inline">\(\exp(\mathfrak{g})\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We saw earlier that <span
class="math inline">\(G^0\)</span> is generated by any neighborhood of
the identity, and saw just now that <span
class="math inline">\(\exp\)</span> is a local diffeomorphism at <span
class="math inline">\(0\)</span>; in particular, <span
class="math inline">\(\exp(\mathfrak{g})\)</span> contains a
neighborhood of the identity in <span
class="math inline">\(G\)</span>. ◻</p>
</span></div>
<div id="rmk:exp-need-not-surject" class="remark">
<p><strong>Remark 83</strong>. Even if <span
class="math inline">\(G\)</span> is connected, it need not be the case
that <span class="math inline">\(\exp(\mathfrak{g}) = G\)</span>. For
example, one can show that <span class="math display">\[\begin{pmatrix}
      -1/2 &amp;  \\
       &amp; -2
    \end{pmatrix}
\notin \exp(\mathfrak{s} \mathfrak{l} _2(\mathbb{R})).\]</span> It is a
non-obvious fact (which we might conceivably see later in the course)
that if <span class="math inline">\(G\)</span> is a compact connected
Lie group, then <span class="math inline">\(\exp(\mathfrak{g}) =
G\)</span>.</p>
</div>
<h2 id="sec:org4b91333">§13.4. Application to detecting invariance by a
connected Lie group<span id="sec:appl-inv-by-connected"
label="sec:appl-inv-by-connected"></span></h2>
<p>In lecture, we explained how the connectedness of <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> and Lie’s first
theorem imply that a smooth function <span class="math inline">\(f :
\mathbb{R}^n \rightarrow \mathbb{R}\)</span> is rotation-invariant
(i.e., <span class="math inline">\(f(x)\)</span> depends only upon <span
class="math inline">\(|x|\)</span>) if and only if it satisfies the
finite system of homogeneous linear differential equations <span id="eqn:pdes-characterizing-rotation-invariance" class="math display">\[\label{eqn:pdes-characterizing-rotation-invariance}\tag{64}
  x_j \frac{\partial }{\partial x_i} f(x)
  =
  x_i \frac{\partial }{\partial x_j} f(x)
  \quad \text{ for all }
  1 \leq i &lt; j \leq n.\]</span> This is computationally useful; for
instance, it applies when <span class="math inline">\(f\)</span> is a
polynomial of large degree in many variables. This is not an
earth-shaking fact, and it can probably be proved directly in various
ways, but the proof we will give here illustrates in a simple way a
rather fundamental technique of Lie theory.</p>
<p>To summarize the proof, we noted that the first condition is visibly
equivalent to <span id="eq:group-invariance-son" class="math display">\[\label{eq:group-invariance-son}\tag{65}
    f(g x) = f(x) \text{ for all } g \in \mathop{\mathrm{SO}}(n), x \in
\mathbb{R}^n\]</span> while the second is visibly equivalent to <span id="eq:lie-invariance-basis-son" class="math display">\[\label{eq:lie-invariance-basis-son}\tag{66}
    X f = 0 \text{ for all } X \in \mathcal{B}\]</span> where for <span
class="math inline">\(X \in \mathfrak{g}\)</span> we set <span
class="math display">\[X f(x) := \frac{d}{d \varepsilon}
f(\exp(-\varepsilon X) x) |_{\varepsilon=0}\]</span> and where <span
class="math inline">\(\mathcal{B}\)</span> is the basis of <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(n)\)</span>
given by <span class="math display">\[\mathcal{B} := \{X_{i j} : 1 \leq
i &lt; j \leq n\}\]</span> where <span class="math display">\[X_{i j} :=
E_{i j} - E_{j i}\]</span> where <span class="math inline">\(E_{i
j}\)</span> has a <span class="math inline">\(1\)</span> in the <span
class="math inline">\((i,j)\)</span> entry and <span
class="math inline">\(0\)</span>’s elsewhere; for instance, when <span
class="math inline">\(n = 3\)</span>, a basis for <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(3)\)</span>
is given by <span class="math display">\[X_{12}
  \begin{pmatrix}
    &amp; 1 &amp;  \\
    -1 &amp;  &amp;  \\
    &amp;  &amp;
  \end{pmatrix}
,
  \quad
  X_{13}
  \begin{pmatrix}
    &amp;  &amp; 1\\
    &amp;  &amp;  \\
    -1 &amp;  &amp;
  \end{pmatrix}
,
  \quad
  X_{23}
  \begin{pmatrix}
    &amp;  &amp; \\
    &amp;  &amp; 1 \\
    &amp; -1  &amp;
  \end{pmatrix}
.\]</span> To relate <a
href="#eqn:pdes-characterizing-rotation-invariance"
data-reference-type="eqref"
data-reference="eqn:pdes-characterizing-rotation-invariance">\((64)\)</a>
to <a href="#eq:lie-invariance-basis-son" data-reference-type="eqref"
data-reference="eq:lie-invariance-basis-son">\((66)\)</a>
we used that <span class="math display">\[X_{i j} x =
  x_j e_i - x_i e_j\]</span> and hence that <span
class="math display">\[f(x \exp(-\varepsilon X_{i j}) x)
  = f(x  -  \varepsilon(x_j e_i - x_i e_j) + O(\varepsilon^2))\]</span>
to compute that <span class="math display">\[X_{i j} f(x) = -
  (x_j \frac{\partial }{\partial x_i}
  - x_i \frac{\partial }{\partial x_j}
  ) f(x).\]</span> Each of the following conditions is visible
equivalent to the next:</p>
<ol>
<li><p>The condition <a href="#eq:group-invariance-son"
data-reference-type="eqref"
data-reference="eq:group-invariance-son">\((65)\)</a>.</p></li>
<li><p>The condition <a href="#eq:group-invariance-son"
data-reference-type="eqref"
data-reference="eq:group-invariance-son">\((65)\)</a>
but restricted to <span class="math inline">\(g\)</span> in a generating
set for <span class="math inline">\(G\)</span>.</p></li>
<li><p>The condition <a href="#eq:group-invariance-son"
data-reference-type="eqref"
data-reference="eq:group-invariance-son">\((65)\)</a>
for <span class="math inline">\(g \in \exp(\mathfrak{g})\)</span>. (Here
we use Lie’s theorem and the connectedness of <span
class="math inline">\(G\)</span>.)</p></li>
<li><p>The condition that <span class="math display">\[f(\exp(-t X)
x)\]</span> be independent of <span class="math inline">\(t\)</span> for
all <span class="math inline">\(x \in \mathbb{R}^n\)</span> and all
<span class="math inline">\(X
   \in \mathfrak{g}\)</span>.</p></li>
<li><p>The condition that <span id="eqn:some-derivative-bla-blab-alsdfsd-" class="math display">\[\label{eqn:some-derivative-bla-blab-alsdfsd-}\tag{67}
     \frac{d}{d t} f(\exp(-t X) x) = 0\]</span> for all <span
class="math inline">\(x \in \mathbb{R}^n\)</span> and all <span
class="math inline">\(X
   \in \mathfrak{g}\)</span>.</p></li>
<li><p>The condition that <span class="math inline">\(X f = 0\)</span>
for all <span class="math inline">\(X \in \mathfrak{g}\)</span>. To
relate this to the previous condition, we used the following key
calculation: <span class="math display">\[\begin{align}
     \frac{d}{d t} f(\exp(-t X) x)
     &amp;=
       \frac{d}{d \varepsilon} f(\exp(-(t+\varepsilon) X)
x)|_{\varepsilon=0}
       \\
     &amp;=
       \frac{d}{d \varepsilon} f(\exp(- \varepsilon X) \exp(-t X)
x)|_{\varepsilon=0}
       \\
     &amp;=
     X f(\exp(-t X) x).
   
\end{align}\]</span> Thus if <a
href="#eqn:some-derivative-bla-blab-alsdfsd-"
data-reference-type="eqref"
data-reference="eqn:some-derivative-bla-blab-alsdfsd-">\((67)\)</a>
holds, then <span class="math inline">\(X f (\exp(-t X) x) = 0\)</span>
for all <span class="math inline">\(t,X,x\)</span>, and in particular
for <span class="math inline">\(t = 0\)</span>, giving <span
class="math inline">\(X f(x) = 0\)</span> and thus <span
class="math inline">\(X f = 0\)</span>. Conversely, if <span
class="math inline">\(X f = 0\)</span>, then in particular <span
class="math inline">\(X f(\exp(-t X) x) = 0\)</span> for all <span
class="math inline">\(t,X,x\)</span>; the above calculation then implies
that <a href="#eqn:some-derivative-bla-blab-alsdfsd-"
data-reference-type="eqref"
data-reference="eqn:some-derivative-bla-blab-alsdfsd-">\((67)\)</a>
holds.</p></li>
<li><p>The condition <a href="#eq:lie-invariance-basis-son"
data-reference-type="eqref"
data-reference="eq:lie-invariance-basis-son">\((66)\)</a>.
(Here we used that <span class="math inline">\(X \mapsto X f\)</span> is
linear to reduce from testing all <span class="math inline">\(X \in
\mathfrak{g}\)</span> to testing those in the basis <span
class="math inline">\(\mathcal{B}\)</span>.)</p></li>
</ol>
<div class="remark">
<p><strong>Remark 84</strong>. It’s not too hard to show that <span
class="math inline">\(\exp :
\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(n) \rightarrow
\mathop{\mathrm{SO}}(n)\)</span> is actually surjective (in contrast to
the general case mentioned in Remark <a href="#rmk:exp-need-not-surject"
data-reference-type="ref"
data-reference="rmk:exp-need-not-surject">83</a>), so we didn’t
<em>really</em> need Lie’s theorem in the above argument, the point of
which was to illustrate a technique in a simple case.</p>
</div>
<h2 id="sec:org51d5203">§13.5. Connected Lie subgroups are determined by their
Lie algebras</h2>
<div class="theorem">
<p><strong>Theorem 85</strong>. <em>Let <span
class="math inline">\(G\)</span> be a Lie group. Then connected Lie
subgroups of <span class="math inline">\(G\)</span> are classified by
their Lie algebra: if <span class="math inline">\(H_1, H_2\)</span> are
two connected Lie subgroups of <span class="math inline">\(G\)</span>
for which <span class="math inline">\(\mathop{\mathrm{Lie}}(H_1) =
\mathop{\mathrm{Lie}}(H_2)\)</span>, then <span
class="math inline">\(H_1 = H_2\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We know by Exercise <a
href="#exercise:connected-topological-group-generated-by-any-neighborhood"
data-reference-type="ref"
data-reference="exercise:connected-topological-group-generated-by-any-neighborhood">5</a>
that <span class="math inline">\(H_i\)</span> is generated by any
neighborhood of the identity; by Theorem <a href="#thm:exp-local-diffeo"
data-reference-type="ref" data-reference="thm:exp-local-diffeo">81</a>,
it follows that <span class="math inline">\(H_i\)</span> is generated by
<span class="math inline">\(\exp(\mathop{\mathrm{Lie}}(H_i))\)</span>.
Since <span class="math inline">\(H_1,H_2\)</span> are generated by the
same set, they are equal. ◻</p>
</span></div>
<h2 id="sec:org45e312b">§13.6. The exponential map commutes with morphisms<span
id="sec:exp-commutes-with-morphisms"
label="sec:exp-commutes-with-morphisms"></span></h2>
<div class="theorem">
<p><strong>Theorem 86</strong>. <em>The exponential map commutes with
Lie group morphisms: If <span class="math inline">\(f : G \rightarrow
H\)</span> is a morphism of Lie groups and <span class="math inline">\(x
\in \mathop{\mathrm{Lie}}(G)\)</span> is given, then <span
class="math inline">\(f(\exp (x)) = \exp(d f(x))\)</span>, where <span
class="math inline">\(d f := T_e f : \mathfrak{g} \rightarrow
\mathfrak{h}\)</span>.</em></p>
</div>
<p>For the sake of illustration, we record a few proofs.</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof #1." data-folded-text="Proof #1. (...)">Proof #1.</em></a>
<span class="proof-content"> It suffices to show that <span
class="math inline">\(f(\exp(t x)) = \exp(d f(t x))\)</span> for all
<span class="math inline">\(t\)</span>. But now both sides, viewed as
functions of <span class="math inline">\(t\)</span>, are one-parameter
subgroups of <span class="math inline">\(H\)</span> with inital velocity
<span class="math inline">\(d f(x) = T_e f(x)\)</span>: indeed, we have
<span class="math display">\[f(\exp(t x))
  = f(1 + t x + o(t))
  = 1 + t \,d f(x)  + o(t)\]</span> and similarly <span
class="math display">\[\exp(d f(t x)) = 1 + t \, d f(x) + o(t).\]</span>
By the uniqueness given in Theorem <a
href="#thm:classification-smooth-1-param-subgroups"
data-reference-type="ref"
data-reference="thm:classification-smooth-1-param-subgroups">79</a>, we
conclude. ◻</p>
</span></div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof #2." data-folded-text="Proof #2. (...)">Proof #2.</em></a>
<span class="proof-content"> Let <span class="math inline">\(\gamma\)</span> be
any curve on <span class="math inline">\(G\)</span> with basepoint <span
class="math inline">\(\gamma(0) = e\)</span> and initial velocity <span
class="math inline">\(\gamma &#39;(0) =
  x\)</span>. The curve <span class="math inline">\(f \circ
\gamma\)</span> on <span class="math inline">\(H\)</span> then has
basepoint <span class="math inline">\(e\)</span> and initial velocity
<span class="math inline">\((f \circ \gamma )&#39;(0) = d f(x)\)</span>.
By the final assertion of Theorem <a href="#thm:exp-local-diffeo"
data-reference-type="ref" data-reference="thm:exp-local-diffeo">81</a>,
we have <span class="math display">\[\exp (x) = \lim_{n \rightarrow
\infty} \gamma(1/n)^n\]</span> and similarly <span
class="math inline">\(\exp(d f(x)) = \lim_{n \rightarrow \infty}
  f(\gamma(1/n))^n\)</span>. Since <span
class="math inline">\(f\)</span> is a continuous group homomorphism, it
follows that <span class="math display">\[f(\exp(x))
  = f( \lim_{n \rightarrow \infty} \gamma(1/n)^n)
  = \lim_{n \rightarrow \infty} f(\gamma(1/n))^n
  = \exp(d f(x)),\]</span> as required. ◻</p>
</span></div>
<div class="example">
<p><strong>Example 87</strong>. Set <span class="math inline">\(f :=
\det : {\mathop{\mathrm{GL}}}_n(\mathbf{k}) \rightarrow
  \mathbf{k}^\times\)</span>. Since <span class="math inline">\(\det(1 +
\varepsilon X) = 1 + \varepsilon\mathop{\mathrm{trace}}(X) +
O(\varepsilon^2)\)</span>, we have <span class="math inline">\(d f =
\mathop{\mathrm{trace}}: M_n(\mathbf{k}) \rightarrow
  \mathbf{k}\)</span>. The theorem then implies for <span
class="math inline">\(X \in M_n(\mathbf{k})\)</span> that <span
class="math display">\[\det(\exp(X)) = f(\exp(X))
    = \exp(d f(X)) = \exp(\mathop{\mathrm{trace}}(X)),\]</span> which
can also be seen directly via Jordan decomposition.</p>
</div>
<h2 id="sec:org84c10f5">§13.7. Morphisms out of a connected Lie group are
determined by their differentials</h2>
<div class="theorem">
<p><strong>Theorem 88</strong>. <em>Let <span
class="math inline">\(G\)</span> be a connected Lie group and <span
class="math inline">\(H\)</span> any Lie group. Then morphisms <span
class="math inline">\(f : G \rightarrow H\)</span> are determined by
their differentials <span class="math inline">\(d f : \mathfrak{g}
\rightarrow \mathfrak{h}\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since <span class="math inline">\(G\)</span> is
connected, it is generated by a neighborhood of the identity, hence in
particular by <span class="math inline">\(\exp(\mathfrak{g})\)</span>.
Since <span class="math inline">\(f\)</span> is a homomorphism, it is
thus determined by the quantities <span
class="math inline">\(\exp(X)\)</span> for all <span
class="math inline">\(X \in \mathfrak{g}\)</span>. But by the result of
§<a href="#sec:exp-commutes-with-morphisms" data-reference-type="ref"
data-reference="sec:exp-commutes-with-morphisms">13.6</a>,
we have <span class="math inline">\(f(\exp(X)) = \exp(d f(X))\)</span>.
Hence <span class="math inline">\(f\)</span> is determined by <span
class="math inline">\(f\)</span>. ◻</p>
</span></div>
<h1 id="sec:org03a946d">§14. Putting the “algebra” in “Lie algebra”</h1>
<h2 id="sec:org3a6e4da">§14.1. The commutator of small group elements</h2>
<p>Let <span class="math inline">\(G\)</span> be a Lie subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>.
Consider a pair of elements <span class="math inline">\(X,Y \in
\mathfrak{g} := \mathop{\mathrm{Lie}}(G)\)</span> and a corresponding
pair of curves <span class="math inline">\(\xi, \eta : \mathbf{k}
%
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
G\)</span> with basepoints <span class="math inline">\(\xi(0) = \eta(0)
= 1\)</span> and initial velocities <span class="math inline">\(\xi
&#39; (0) = X,
\eta &#39;(0) = Y\)</span>. For example:</p>
<ol>
<li><p>One can always take <span class="math inline">\(\xi(s) := \exp(s
X),
\eta(t) := \exp(t Y)\)</span>.</p></li>
<li><p>If <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>, one could also take <span
class="math inline">\(\xi(s) := 1 + s X, \eta(t) := 1 + t
Y\)</span>.</p></li>
</ol>
<p>We can then consider, for small enough <span
class="math inline">\(s,t \in \mathbf{k}\)</span>, the commutator <span
class="math display">\[\Gamma(s,t) :=
  (\xi(s),\eta(t))
  :=
  \xi(s) \eta(t) \xi(s)^{-1} \eta(t)^{-1}.\]</span> From the basepoint
condition we have <span class="math display">\[\Gamma(0,0) = \Gamma(s,0)
= \Gamma(0,t) = 1,\]</span> so every term in the Taylor expansion of
<span class="math inline">\(\Gamma(s,t) - 1\)</span> is divisible by
<span class="math inline">\(s t\)</span>. We now determine the
coefficient of <span class="math inline">\(s t\)</span>, or
equivalently, the derivative <span class="math inline">\(\partial_{s=0}
\partial_{t=0} \Gamma(s,t)\)</span>. To compute this, we write <span
class="math display">\[\xi(s) \eta(t) = \Gamma(s,t) \eta(t)
\xi(s)\]</span> and differentiate both sides, first with respect to
<span class="math inline">\(s\)</span> at <span
class="math inline">\(s=0\)</span>, giving <span
class="math display">\[X \eta(t) = \partial_{s=0} \Gamma(s,t) \eta(t)
\xi(0)
  + \Gamma(0,t) \eta(t) X
  =
  \partial_{s=0} \Gamma(s,t) \eta(t)
  + \eta(t) X\]</span> and then with respect to <span
class="math inline">\(t\)</span> at <span
class="math inline">\(t=0\)</span>, giving after analogous
simplifications that <span class="math display">\[X Y = \partial_{s=0}
\partial_{t=0} \Gamma(s,t)
  + Y X,\]</span> whence <span class="math display">\[\Gamma(s,t) = X Y
- Y X.\]</span></p>
<h2 id="sec:org166886b">§14.2. The Lie bracket as an infinitesimal
commutator</h2>
<p>For a general Lie group <span class="math inline">\(G\)</span>, we
define the commutator bracket <span class="math inline">\([,] :
\mathfrak{g}  \otimes
\mathfrak{g} \rightarrow \mathfrak{g}\)</span> by setting <span
class="math display">\[:= \partial_{s=0}
  \partial_{t=0} \Gamma(s,t),\]</span> with notation as in the previous
section. To interpret this properly, we have <span
class="math display">\[\partial_{t=0}
  \Gamma(s,t)
  =
  \partial_{t=0}
  \xi(s)
  \eta(t)
  \xi(s)^{-1}
  \eta(t)^{-1}\]</span> This is the initial velocity of a curve passing
through the identity element of <span class="math inline">\(G\)</span>
at time <span class="math inline">\(t=0\)</span>, hence it makes sense
to regard it as an element of <span
class="math inline">\(\mathfrak{g}\)</span>. Thus <span
class="math display">\[s \mapsto \partial_{t=0} \Gamma(s,t)\]</span>
defines a curve in <span class="math inline">\(\mathfrak{g}\)</span>.
Hence its <span class="math inline">\(s\)</span>-derivative at <span
class="math inline">\(s=0\)</span> defines an element of <span
class="math inline">\(\mathfrak{g}\)</span>. Similar arguments show that
<span class="math inline">\([X,Y]\)</span> is independent of the choice
of <span class="math inline">\(\xi\)</span>, <span
class="math inline">\(\eta\)</span>; alternatively, one could always
take <span class="math inline">\(\xi(s) := \exp(s X), \eta(t) := \exp(t
Y)\)</span> in the definition, but it’s occasionally convenient to make
other choices.</p>
<p>The bracket <span class="math inline">\([,]\)</span> on the Lie
algebra <span class="math inline">\(\mathfrak{g}\)</span> of a Lie group
<span class="math inline">\(G\)</span> has the following properties:</p>
<ol>
<li><p><span class="math inline">\([,]\)</span> is bilinear. This is
immediate from the definition</p></li>
<li><p><span class="math inline">\([X,X] = 0\)</span>. This is again
immediate from the definition. It follows that <span
class="math inline">\([X+Y,X+Y] = [X,X]  + [X,Y] + [Y,X] + [Y,Y]
  = [X,Y] + [Y,X]\)</span>, hence that <span id="eq:lie-bracket-alternating" class="math display">\[\label{eq:lie-bracket-alternating}\tag{68}
    [X,Y] = - [Y,X].\]</span></p></li>
<li><p>It satisfies the Jacobi identity <span id="eq:jacobi-identity" class="math display">\[\label{eq:jacobi-identity}\tag{69}
    [X,[Y,Z]]
    +
    [Y,[Z,X]]
    +
    [Z,[X,Y]]
    = 0\]</span> which, thanks to <a href="#eq:lie-bracket-alternating"
data-reference-type="eqref"
data-reference="eq:lie-bracket-alternating">\((68)\)</a>,
can be put in the equivalent forms <span class="math display">\[]
    =[[X,Y],Z]
    + [Y,[X,Z]]\]</span> or <span class="math display">\[,Z]=
    [[X,Z],Y]
    + [X,[Y,Z]].\]</span> In the linear case <span
class="math inline">\(G \leq
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>, one can prove the Jacobi
identity by expanding everything out using the identity <span
class="math inline">\([X,Y] = X Y -
  Y X\)</span>. In general, they follow from the associativity of the
group law in <span class="math inline">\(G\)</span> in the form <span
class="math display">\[g h = (g h g^{-1}) g\]</span> together with some
artful use of the chain rule. We do not give the details here; we
promise instead that a couple more “conceptual” derivations of the
Jacobi identity will be given later.</p></li>
</ol>
<h2 id="sec:org0f4ac0a">§14.3. Lie algebras</h2>
<div class="definition">
<p><strong>Definition 89</strong>. A <em>Lie algebra</em> <span
class="math inline">\(L\)</span> over <span
class="math inline">\(\mathbf{k}\)</span> is a vector space equipped
with a bilinear form <span class="math inline">\([,] : L \otimes L
\rightarrow
  L\)</span> satisfying the properties mentioned in the previous
section.</p>
</div>
<p>Here are the basic examples:</p>
<ol>
<li><p>We’ve seen (modulo verification of the Jacobi identity in
general) that for any Lie group <span class="math inline">\(G\)</span>,
what we’ve already called the “Lie algebra” <span
class="math inline">\(\mathfrak{g} := \mathop{\mathrm{Lie}}(G)\)</span>
of <span class="math inline">\(G\)</span> is in fact a Lie algebra in
the above sense when equipped with the commutator bracket as we’ve
defined it.</p></li>
<li><p>Any associative algebra <span class="math inline">\(A\)</span>
over <span class="math inline">\(\mathbf{k}\)</span> becomes a Lie
algebra when equipped with the bracket <span class="math inline">\([x,y]
:= x y - y x\)</span>. A notable example is when <span
class="math inline">\(A = \mathop{\mathrm{End}}(V)\)</span> for a vector
space <span class="math inline">\(V\)</span>. If <span
class="math inline">\(V = \mathbf{k}^n\)</span>, then of course <span
class="math inline">\(A = \mathop{\mathrm{End}}(V) =
  M_n(\mathbf{k})\)</span>.</p></li>
<li><p>If <span class="math inline">\(L_1\)</span> is a Lie algebra and
<span class="math inline">\(L_2 \leq L_1\)</span> is a vector subspace
with the property that <span class="math inline">\([x,y] \in
L_2\)</span> whenever <span class="math inline">\(x,y \in L_2\)</span>,
then <span class="math inline">\(L_2\)</span> is a Lie algebra when
equipped with the commutator bracket induced from that on <span
class="math inline">\(L_1\)</span>; it is then (fittingly) called a
<em>Lie subalgebra</em> of <span
class="math inline">\(L_1\)</span>.</p></li>
<li><p>Given an algebra <span class="math inline">\(A\)</span>, the
space <span class="math inline">\(\mathop{\mathrm{Der}}(A)\)</span> of
<em>derivation</em> of <span class="math inline">\(A\)</span> (i.e.,
<span class="math inline">\(\mathbf{k}\)</span> -linear maps <span
class="math inline">\(D  : A \rightarrow A\)</span> satisfying <span
class="math inline">\(D(x \cdot y) = D x \cdot y + x \cdot D y\)</span>)
is a Lie algebra. (Exercise: check this.) It is a Lie subalgebra of
<span class="math inline">\(\mathop{\mathrm{End}}(A)\)</span>.</p>
<p>When <span class="math inline">\(A\)</span> is finite-dimensional,
one can show that <span
class="math inline">\(\mathop{\mathrm{Aut}}(A)\)</span> is a Lie group
with Lie algebra <span
class="math inline">\(\mathop{\mathrm{Der}}(A)\)</span>, hence that this
example is a special case of the first one. But what we’ve said here
applies (usefully) also when <span class="math inline">\(A\)</span> is
infinite-dimensional; see below.</p></li>
</ol>
<p>Every finite-dimensional example is already of the above form:</p>
<div class="theorem">
<p><strong>Theorem 90</strong> (Ado). <em>Let <span
class="math inline">\(L\)</span> be a finite-dimensional Lie algebra.
Then <span class="math inline">\(L\)</span> is isomorphic to a Lie
subalgebra of <span
class="math inline">\(\mathop{\mathrm{End}}(V)\)</span> for some
finite-dimensional vector space <span
class="math inline">\(V\)</span>.</em></p>
</div>
<p>The proof of this innocent-sounding theorem is not egregiously
difficult, but does seem to require most of the basic structure theory
of Lie algebras, and so will not be proved now. However, it may aid
intuition to know up front that one can always think of any
finite-dimensional Lie algebra as a Lie subalgebra of some matrix
algebra.</p>
<p>A special case of the final example mentioned above is when <span
class="math inline">\(A = C^\infty(M)\)</span> for a manifold <span
class="math inline">\(M\)</span>. In that case, it is known that <span
class="math display">\[\mathop{\mathrm{Der}}(C^\infty(M))
  \cong \operatorname{Vect}(M)\]</span> where <span
class="math inline">\(\operatorname{Vect}(M)\)</span> denotes the space
of vector fields on <span class="math inline">\(M\)</span>, i.e., smooth
assignments <span class="math display">\[X : M \rightarrow T M :=
\sqcup_{p \in M} T_p M\]</span> satisfying <span
class="math inline">\(X_p := X(p) \in T_p M\)</span> for all <span
class="math inline">\(p \in M\)</span>. Such a vector field induces a
derivation by the rule: for <span class="math inline">\(f \in
C^\infty(M)\)</span>, the image <span class="math inline">\(X f \in
C^\infty(M)\)</span> under <span class="math inline">\(X \in
\operatorname{Vect}(X)\)</span> is defined to be <span
class="math display">\[(X f)(p) := (T_p f)(X_p),\]</span> i.e., “the
directional derivative of <span class="math inline">\(f\)</span> at
<span class="math inline">\(p\)</span> in the direction of the tangent
vector <span class="math inline">\(X_p\)</span>.”</p>
<div class="remark">
<p><strong>Remark 91</strong>. It can be instructive to check for some
simple examples of linear Lie groups <span class="math inline">\(G \leq
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{g} \leq M_n(\mathbf{k})\)</span> that
the bracket <span class="math inline">\([,]\)</span> does in fact
preserve <span class="math inline">\(\mathfrak{g}\)</span> (as it must).
For <span class="math inline">\(X,Y \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbf{k})\)</span> we
have <span class="math inline">\(\mathop{\mathrm{trace}}([X,Y]) =
0\)</span>; indeed, the trace of any commutator is zero. For <span
class="math inline">\(X,Y \in \mathfrak{o}_n(\mathbf{k})\)</span>, so
that <span class="math inline">\(X + X^t = 0, Y + Y^t = 0\)</span>, we
have <span class="math inline">\([X,Y]^t = (X Y)^t - (Y X)^t
  = Y^t X^t - X^t Y^t
  = (-Y)(-X) - (-X)(-Y)
  = -[X,Y]\)</span>, hence <span class="math inline">\([X,Y] \in
\mathfrak{o}_n(\mathbf{k})\)</span>.</p>
</div>
<h2 id="sec:org96fd5c4">§14.4. The Lie bracket commutes with differentials of
morphisms<span id="sec:diff-morphism-is-morphism"
label="sec:diff-morphism-is-morphism"></span></h2>
<p>Let <span class="math inline">\(f : G \rightarrow H\)</span> be a
morphism of Lie groups. Then for <span class="math inline">\(X, Y \in
\mathfrak{g}\)</span>, one has <span
class="math display">\[\begin{align}
  d f ([X,Y])
  &amp;=
    d f( \partial_{s=0} \partial_{t=0} (e^{s X}, e^{t Y}))
  &amp;&amp;
  \text{ (definition of $[,]$) }
  \\
  &amp;=
    \partial_{s=0}  d f( \partial_{t=0} (e^{s X}, e^{t Y}))
    &amp;&amp; \text{ ($d f$ is linear) }
    \\
  &amp;=
    \partial_{s=0}  \partial_{t=0}
    f(  (e^{s X}, e^{t Y}))
    &amp;&amp; \text{ (definition of $d f$) }
    \\
  &amp;=
    \partial_{s=0}  \partial_{t=0}
    (f(e^{s X}), f(e^{t Y}))
    &amp;&amp; \text{ ($f$ is a homomorphism) }
    \\
  &amp;=
    \partial_{s=0}  \partial_{t=0}
    (e^{d f(s X)}, e^{t \, d f(s Y)})
  &amp;&amp; \text{ ($f \circ \exp = \exp \circ d f$)}
     \\
  &amp;=
    \partial_{s=0}  \partial_{t=0}
    (e^{s \, d f(X)}, e^{t \, d f(Y)})
  &amp;&amp; \text{ ($d f$ is linear)}
     \\
  &amp;=
    [d f(X), d f(Y)]
  &amp;&amp; \text{ (definition of $[,]$)}.
\end{align}\]</span> Thus <span class="math inline">\(d f :
\mathfrak{g} \rightarrow \mathfrak{h}\)</span> is a morphismo f Lie
algebras.</p>
<h1 id="sec:org7275cd0">§15. How pretend that every Lie group is a matrix
group and survive<span id="sec:pretend-lie-groups-are-matrix-groups"
label="sec:pretend-lie-groups-are-matrix-groups"></span></h1>
<p>(TODO: rewrite this section.) For many arguments it is convenient to
assume that a Lie group <span class="math inline">\(G\)</span> is a
matrix group, i.e., embeds in <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span>, so
that its Lie algebra embeds in <span
class="math inline">\(M_n(\mathbb{R})\)</span>. Then lots of stuff
simplifies (in a non-serious way) because we can just regard everything
as a matrix and not worry about which tangent space stuff belongs to,
etc. Not every Lie group is a matrix group, but they are all close
enough to being matrix groups (e.g., up to covering homomorphisms to be
discussed later) that nothing really bad goes wrong if one pretends that
they are. For example, it was convenient in class today to pretend that
<span class="math inline">\(G\)</span> was a matrix Lie group when
discussing the proof of Maurer–Cartan equations.</p>
<p>However, there is a rigorous trick by which one can always treat a
Lie group <span class="math inline">\(G\)</span> as if it were a matrix
group by embedding it in the space <span
class="math inline">\(\mathop{\mathrm{GL}}(C^\infty(G))\)</span> of
linear automorphisms of the (typically infinite-dimensional) vector
space <span class="math inline">\(C^\infty(G)\)</span>. The fact that
<span class="math inline">\(\mathop{\mathrm{GL}}(C^\infty(G))\)</span>
is not itself a Lie group doesn’t matter much in practice. More
precisely, one defines an injective homomorphism <span
class="math display">\[G \hookrightarrow
\mathop{\mathrm{GL}}(C^\infty(G))\]</span> as follows: we identify each
<span class="math inline">\(g \in G\)</span> with the element of <span
class="math inline">\(\mathop{\mathrm{Aut}}(C^\infty(G))\)</span> that
sends a smooth function <span class="math inline">\(\varphi \in
C^\infty(G)\)</span> to the new function <span class="math inline">\(g
\varphi \in C^\infty(G)\)</span> given by right translation: for <span
class="math inline">\(x \in G\)</span>, <span class="math display">\[g
\varphi(x) := \varphi(x g).\]</span> (This is an action: <span
class="math inline">\((g_1 g_2) \varphi = g_1 (g_2 \varphi)\)</span>.)
It makes sense to differentiate this action of <span
class="math inline">\(G\)</span> element-wise. We obtain in this way
induces a morphism <span class="math inline">\(X \hookrightarrow
\mathop{\mathrm{End}}(C^\infty(G))\)</span>, whose image actually lies
in an easily characterized subspace of <span
class="math inline">\(\mathop{\mathrm{Der}}(C^\infty(G))\)</span>; more
on that later. The action of <span class="math inline">\(X \in
\mathfrak{g}\)</span> on <span class="math inline">\(\varphi \in
C^\infty(G)\)</span> is given by <span class="math display">\[X
\varphi(x) := \partial_{t=0}
  \varphi(x \exp(t X)).\]</span> (This is a Lie algebra representation:
<span class="math inline">\([X,Y] \varphi = X Y \varphi - Y X
\varphi\)</span>.) In this way, one can make perfectly rigorous sense of
identities such as <span class="math display">\[= X Y - Y X\]</span> or
<span class="math display">\[\mathop{\mathrm{Ad}}(g) X = g X
g^{-1}\]</span> even when <span class="math inline">\(G\)</span> is not
a matrix Lie group: for instance, the products <span
class="math inline">\(X Y\)</span> in the above expression are just the
compositions taking place inside <span
class="math inline">\(\mathop{\mathrm{End}}(C^\infty(G))\)</span>.</p>
<h1 id="sec:orgf4f0402">§16. Something about representations, mostly <span
class="math inline">\({\mathop{\mathrm{SL}}}_2\)</span></h1>
<p><span id="sec:reps-sl2" label="sec:reps-sl2"></span></p>
<h2 id="sec:org2880980">§16.1. Some preliminaries</h2>
<p>We have spoken so far in the course quite a bit about <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> and
its Lie algebra <span class="math inline">\(M_n(\mathbf{k})\)</span>.
More abstractly, one can work with any finite-dimensional vector space
<span class="math inline">\(V\)</span> over <span
class="math inline">\(\mathbf{k}\)</span>. Then <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> is a Lie group
over <span class="math inline">\(\mathbf{k}\)</span> with Lie algebra
<span class="math inline">\(\mathop{\mathrm{End}}(V)\)</span>. If <span
class="math inline">\(V = \mathbf{k}^n\)</span>, then <span
class="math inline">\(\mathop{\mathrm{GL}}(V) =
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span> and <span
class="math inline">\(\mathop{\mathrm{End}}(V) =
M_n(\mathbf{k})\)</span>.</p>
<p>When <span class="math inline">\(\mathbf{k} = \mathbb{C}\)</span>, we
can regard <span class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span>
either as a complex Lie group or as a real Lie group.</p>
<h2 id="sec:org959bbb9">§16.2. Definition</h2>
<div class="definition">
<p><strong>Definition 92</strong>. Let <span
class="math inline">\(\mathbf{k} = \mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span>. For us, a
<em>representation</em> of a Lie group <span
class="math inline">\(G\)</span> is a pair <span
class="math inline">\((V,R)\)</span>, where</p>
<ul>
<li><p><span class="math inline">\(V\)</span> is a finite-dimensional
vector space and</p></li>
<li><p><span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> is a morphism of Lie groups over <span
class="math inline">\(\mathbf{k}\)</span>.</p></li>
</ul>
<p>We allow the possibility that <span class="math inline">\(\mathbf{k}
= \mathbb{R}\)</span> and <span class="math inline">\(V\)</span> is a
complex vector space but regarded as a real vector space (<span
class="math inline">\(\mathbb{C}^n \cong \mathbb{R}^{
    2n}\)</span>). When we wish to be more specific, we might introduce
the following terminology:</p>
<ol>
<li><p>Let <span class="math inline">\(G\)</span> be a real Lie group. A
<em>real representation</em> of <span class="math inline">\(G\)</span>
is a morphism of real Lie groups <span class="math inline">\(R : G
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> (i.e., an
infinitely-real-differentiable group homomorphism).</p></li>
<li><p>Let <span class="math inline">\(G\)</span> be a real Lie group. A
<em>complex representation</em> of <span
class="math inline">\(G\)</span> is a morphism of real Lie groups <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
(i.e., an infinitely-real-differentiable group homomorphism).</p></li>
<li><p>Let <span class="math inline">\(G\)</span> be a complex Lie
group. A <em>holomorphic representation</em> of <span
class="math inline">\(G\)</span> is a morphism of complex Lie groups
<span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> (i.e., a complex-differentiable group
homomorphism).</p></li>
</ol>
<p>One can also regard a complex Lie group as a real Lie group and
consider its representations in that sense.</p>
<p>A <em>representation</em> of a Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> is likewise a pair <span
class="math inline">\((V,\rho)\)</span>, where <span
class="math inline">\(V\)</span> is as above and <span
class="math inline">\(\rho : \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> is a morphism of Lie algebras over
<span class="math inline">\(\mathbf{k}\)</span>. We can also speak of
real or complex representations of Lie algebras, or of holomorphic
representations of complex Lie algebras.</p>
<p>The action of a representation <span class="math inline">\(R : G
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> is often abbreviated <span
class="math inline">\(g v := R(g) v\)</span> and likewise that of <span
class="math inline">\(\rho  : \mathfrak{g}  \rightarrow
\mathop{\mathrm{End}}(V)\)</span> by <span class="math inline">\(X v :=
\rho(X) v\)</span>.</p>
<p>Given two representations <span class="math inline">\(R_1 : G
\rightarrow \mathop{\mathrm{GL}}(V_1)\)</span> and <span
class="math inline">\(R_2 : G \rightarrow
\mathop{\mathrm{GL}}(V_2)\)</span>, a <em>morphism of
representations</em> or <em>equivariant map</em> <span
class="math inline">\(\Phi : V_1 \rightarrow V_2\)</span> is a linear
map that commutes with the action, i.e., so that <span
class="math inline">\(\Phi(R_1(g) v) = R_2(g) \Phi(v)\)</span> for all
<span class="math inline">\(g \in G\)</span>, <span
class="math inline">\(v \in V\)</span>; one defines similarly the
analogous notion for <span
class="math inline">\(\mathfrak{g}\)</span>-representations. An
<em>isomorphism of representations</em> or <em>equivariant
isomorphism</em> is a morphism with a two-sided inverse (equivalently, a
bijective morphism), and two representations are said to be
<em>isomorphic</em> if there is an isomorphism between them.</p>
</div>
<p>By what we’ve seen above, a representation <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
of a Lie group <span class="math inline">\(G\)</span> induces a
representation <span class="math display">\[d R : \mathfrak{g}
\rightarrow \mathop{\mathrm{End}}(V)\]</span> of its Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>, given explicitly by for
<span class="math inline">\(X \in \mathfrak{g}\)</span> by <span
class="math display">\[X v := d R(X) v :=\frac{d}{ d t} R(\exp(t X)) v
|_{t=0}.\]</span></p>
<div id="ex:polynomial-reps-linear-groups" class="example">
<p><strong>Example 93</strong>. Let <span class="math inline">\(G :=
{\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>. Let <span
class="math inline">\(V := \mathbb{C}[x_1,\dotsc,x_n]_{(d)}\)</span> be
the space of homogeneous polynomials of degree <span
class="math inline">\(d\)</span> in the variables <span
class="math inline">\(x_1,\dotsc,x_n\)</span>. One then has a
representation <span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> sending <span class="math inline">\(g
\in G\)</span> to the element <span class="math inline">\(R(g) \in
\mathop{\mathrm{GL}}(V)\)</span> that acts on a polynomial <span
class="math inline">\(\phi \in V\)</span> by the formula <span
class="math display">\[g \phi(x) :=
    (R(g) \phi)(x) :=
    \phi(x g),\]</span> where <span class="math inline">\(x =
(x_1,\dotsc,x_n)\)</span> is regarded as an <span
class="math inline">\(n\)</span>-tuple of variables and <span
class="math inline">\(x g\)</span> denotes the right multiplication of
the matrix <span class="math inline">\(g\)</span> against the row vector
<span class="math inline">\(x\)</span>. This is already an interesting
representation. The differential <span class="math inline">\(d R :
\mathfrak{g} \rightarrow \mathop{\mathrm{End}}(V)\)</span> is given on
the standard basis elements <span class="math inline">\(E_{i j}\)</span>
of <span class="math inline">\(\mathfrak{g} =
\mathfrak{g}\mathfrak{l}_n(\mathbf{k})\)</span> <span
class="math display">\[E_{i j} \phi(x) := (d R(E_{i j}) \phi )(x)
  = x_i \frac{\partial }{\partial_{x_j}} \phi(x).\]</span> (To see this,
note that <span class="math inline">\(x E_{i j} = x_i e_j\)</span> and
thus <span class="math inline">\(\phi(x(1 + \varepsilon E_{i j}))
  = \phi(x) + x_i \frac{\partial \phi}{\partial x_j}(x) \varepsilon+
O(\varepsilon^2)\)</span>.) The same definition makes sense and similar
considerations apply more generally when <span
class="math inline">\(G\)</span> is any subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>.</p>
</div>
<h2 id="sec:org601ff7d">§16.3. Matrix multiplication</h2>
<p>Let <span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> be a representation of a Lie group
<span class="math inline">\(G\)</span>. Fixing a basis <span
class="math inline">\((v_i)\)</span> for <span
class="math inline">\(V\)</span>, one can express a representation of
<span class="math inline">\(G\)</span> in matrix form <span
class="math display">\[R(g) = (R_{i j}(g))_{i,j},\]</span> where <span
class="math inline">\(R_{i j}(g)\)</span> denotes the coefficient of the
basis element <span class="math inline">\(v_i\)</span> in <span
class="math inline">\(R(g) v_j\)</span>. It’s a fact of life that pretty
much every special function of mathematics or physics is of the form
<span class="math inline">\(R_{i j}(g)\)</span>. Identities such as the
consequence <span class="math display">\[\sum_j R_{i j}(g) R_{j k}(h)
  = R_{i k}(g h)\]</span> of the homomorphism property <span
class="math inline">\(R(g) R(h) = R(g h)\)</span> can be of use. For
example, let <span class="math inline">\(G := \mathbb{R}, V :=
\mathbb{R}^2\)</span>, <span class="math display">\[R : G \rightarrow
{\mathop{\mathrm{GL}}}_2(\mathbb{R})\]</span> <span
class="math display">\[R(\theta) :=
\begin{pmatrix}
    \cos \theta  &amp; \sin \theta  \\
    - \sin \theta  &amp; \cos \theta
  \end{pmatrix}
.\]</span> Then <span class="math display">\[\cos(\theta + \phi)
  = R_{1 1}(\theta + \phi)
  = R_{1 1}(\theta) R_{1 1}(\phi)
  + R_{1 2}(\theta) R_{2 1}(\phi)
  = \cos(\theta) \cos(\phi)
  - \sin(\theta) \sin(\phi),\]</span> which makes for a nice way to
remember addition laws for trigonometric functions.</p>
<h2 id="sec:orgfac8ca7">§16.4. Invariant subspaces and irreducibility<span
id="sec:stability-subspaces"
label="sec:stability-subspaces"></span></h2>
<div class="definition">
<p><strong>Definition 94</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group, and let <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
be a finite-dimensional representation of <span
class="math inline">\(G\)</span>. A subspace <span
class="math inline">\(W\)</span> of <span
class="math inline">\(V\)</span> is said to be <em>invariant</em> (or
<em>stable</em> or <em><span
class="math inline">\(G\)</span>-invariant</em> or <em><span
class="math inline">\(G\)</span>-stable</em>) if <span
class="math inline">\(R(g) W \subseteq  W\)</span> for all <span
class="math inline">\(g \in G\)</span>.</p>
<p>Similarly, given a representation <span class="math inline">\(\rho :
\mathfrak{g} \rightarrow \mathop{\mathrm{End}}(V)\)</span> of a Lie
algebra <span class="math inline">\(\mathfrak{g}\)</span>, we say that a
subspace <span class="math inline">\(W\)</span> of <span
class="math inline">\(V\)</span> is <em>invariant</em> (or
<em>stable</em> or <em><span
class="math inline">\(\mathfrak{g}\)</span>-invariant</em> or <em><span
class="math inline">\(\mathfrak{g}\)</span>-stable</em>) if <span
class="math inline">\(\rho(X) W \subseteq W\)</span> for all <span
class="math inline">\(X \in \mathfrak{g}\)</span>.</p>
<p>We say that a representation <span
class="math inline">\((R,V)\)</span> of a Lie group or a representation
<span class="math inline">\((\rho,V)\)</span> of a Lie algebra is
<em>irreducible</em> if <span class="math inline">\(V \neq
\{0\}\)</span> and if <span class="math inline">\(V\)</span> has no
nonzero proper invariant subspaces (i.e., none other than <span
class="math inline">\(\{0\}\)</span> and <span
class="math inline">\(V\)</span>). Otherwise, it is said to be
<em>reducible</em>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 18</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group and <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
an <span class="math inline">\(n\)</span>-dimensional representation.
Fix a basis of <span class="math inline">\(V\)</span> and hence an
identification <span class="math inline">\(V := \mathbb{C}^n\)</span>.
Let <span class="math inline">\(m\)</span> be an integer satisfying
<span class="math inline">\(0 &lt; m &lt; n\)</span>, and let <span
class="math inline">\(W := \mathbb{C}^m\)</span> regarded as a subspace
of <span class="math inline">\(V\)</span> via the standard inclusion
<span class="math inline">\((x_1,\dotsc,x_m) \mapsto
(x_1,\dotsc,x_m,0,\dotsc,0)\)</span>. Denote by <span
class="math inline">\(P_m(V)\)</span> the subgroup of <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> given by matrices
of the form <span class="math inline">\(\begin{pmatrix}
    a &amp; b \\
    0 &amp; d
  \end{pmatrix}\)</span>, where <span class="math inline">\(a\)</span>
is an <span class="math inline">\(m \times m\)</span> matrix, <span
class="math inline">\(b\)</span> is an <span class="math inline">\(m
\times (n-m)\)</span> matrix, and <span class="math inline">\(d\)</span>
is an <span class="math inline">\((n-m) \times (n-m)\)</span> matrix.
Show that the following are equivalent:</p>
<ol>
<li><p><span class="math inline">\(R\)</span> is reducible.</p></li>
<li><p>There exist <span class="math inline">\(0 &lt; m &lt; n\)</span>
and <span class="math inline">\(\gamma \in
\mathop{\mathrm{GL}}(V)\)</span> so that <span
class="math inline">\(R(G) \subseteq \gamma P_m(V)
\gamma^{-1}\)</span>.</p></li>
</ol>
</div>
<div id="thm:equivalences-irreducibility" class="theorem">
<p><strong>Theorem 95</strong>. <em>Let <span
class="math inline">\(G\)</span> be a Lie group, and let <span
class="math inline">\(R: G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
be a finite-dimensional representation of <span
class="math inline">\(G\)</span>.</em></p>
<ol>
<li><p><em>Any <span class="math inline">\(G\)</span>-invariant subspace
of <span class="math inline">\(V\)</span> is also <span
class="math inline">\(\mathfrak{g}\)</span>-invariant.</em></p></li>
<li><p><em>If <span class="math inline">\(G\)</span> is connected, then
any <span class="math inline">\(\mathfrak{g}\)</span>-invariant subspace
of <span class="math inline">\(V\)</span> is also <span
class="math inline">\(G\)</span>-stable.</em></p></li>
<li><p><em>If <span class="math inline">\(G\)</span> is connected, then
<span class="math inline">\(V\)</span> is irreducible if and only if it
is nonzero and contains no proper <span
class="math inline">\(\mathfrak{g}\)</span>-stable
subspaces.</em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If <span class="math inline">\(W \leq V\)</span> is
<span class="math inline">\(G\)</span>-invariant, then for each <span
class="math inline">\(X \in \mathfrak{g}\)</span> and <span
class="math inline">\(v \in W\)</span> and <span class="math inline">\(t
\in \mathbb{R}\)</span>, we have <span
class="math display">\[\frac{R(\exp(t X)) v - v}{t} \in W\]</span>
(because <span class="math inline">\(W\)</span> is a vector space),
hence upon differentiating that <span class="math display">\[d R(X) v
\in V\]</span> (because <span class="math inline">\(W\)</span> is
closed). This shows that <span class="math inline">\(W\)</span> is <span
class="math inline">\(\mathfrak{g}\)</span>-invariant. Conversely, if
<span class="math inline">\(W \leq V\)</span> is <span
class="math inline">\(\mathfrak{g}\)</span>-invariant and <span
class="math inline">\(G\)</span> is connected, then <span
class="math display">\[R(\exp(t X)) v
    = \exp(t \, d R(X)) v
    = \sum_{n \geq 0}
    \frac{t^n}{n!}
    d R(X)^n v
    \in W,\]</span> hence <span class="math inline">\(W\)</span> is
<span class="math inline">\(\exp(\mathfrak{g})\)</span>-invariant, hence
(because <span class="math inline">\(G\)</span> is connected and thus
generated by <span class="math inline">\(\exp(\mathfrak{g})\)</span>)
<span class="math inline">\(W\)</span> is <span
class="math inline">\(G\)</span>-invariant. Etc. ◻</p>
</span></div>
<h2 id="sec:orgb2dd983">§16.5. Polynomial representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span></h2>
<p><span id="sec:reps-sl2-C" label="sec:reps-sl2-C"></span> Here we
specialize Example <a href="#ex:polynomial-reps-linear-groups"
data-reference-type="ref"
data-reference="ex:polynomial-reps-linear-groups">93</a> to <span
class="math inline">\(G = {\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>.
Let <span class="math inline">\(W_n\)</span> denote the space of
homogeneous polynomials <span class="math inline">\(\phi \in
\mathbb{C}[x,y]\)</span> of degree <span
class="math inline">\(n\)</span>. Then <span
class="math inline">\(W_n\)</span> is an <span
class="math inline">\((n+1)\)</span>-dimensional vector space with basis
given by the monomials <span class="math inline">\(x^n, x^{n-1} y,
\dotsc, x y^{n-1}, y^n\)</span>. As motivation, one can check that for
<span class="math inline">\(g =
\begin{pmatrix}
  \cos \theta  &amp;  \sin \theta  \\
  - \sin \theta  &amp;  \cos \theta
\end{pmatrix}\)</span>, the matrix coefficients <span
class="math inline">\(R_{ij}(g)\)</span> of this representation with
respect to the above basis give the classical spherical polynomials
(e.g., when <span class="math inline">\(n\)</span> is even, the
coefficient of <span class="math inline">\(x^n y^n\)</span> in <span
class="math inline">\(R(g) x^n y^n\)</span> is essentially the Legendre
polynomial <span class="math inline">\(P_{n/2}(\cos
\theta)\)</span>).</p>
<p>By specializing the calculation of Example <a
href="#ex:polynomial-reps-linear-groups" data-reference-type="ref"
data-reference="ex:polynomial-reps-linear-groups">93</a>, we see that
the basis elements <span class="math display">\[X :=
\begin{pmatrix}
    &amp; 1 \\
    &amp;
  \end{pmatrix}
,
  \quad
  Y :=
\begin{pmatrix}
    &amp;  \\
    1 &amp;
  \end{pmatrix}
,
  \quad
  H :=
\begin{pmatrix}
    1 &amp;  \\
    &amp; -1
  \end{pmatrix}\]</span> of <span
class="math inline">\(\mathfrak{g}\)</span> act by <span
class="math display">\[d R(X) =
  x \partial_y,
  \quad
  d R(Y)
  = y \partial_x,
  \quad
  d R(H)
  = x \partial_x - y \partial_y.\]</span> Their effects on the basis
elements is thus given by <span class="math inline">\(X x^n = 0,
Y y^n = 0\)</span> and in all other cases by <span
class="math display">\[X x^{n-k} y^k
  = k x^{n-k+1} y^{k-1},
  \quad
  Y x^{n-k} y^k
  = (n-k) x^{n-k-1} y^{k+1},
  \quad
  H x^{n-k} y^k
  = (n- 2 k) x^{n-k} y^{k}.\]</span> In lecture, we drew a picture in
which the basis elements <span class="math inline">\(y^n, x y^{n-1}
\dotsc, x^n y, x^n\)</span> were lined up from left to right and
indicated by circles in which we indicated their <span
class="math inline">\(H\)</span>-eigenvalues <span
class="math inline">\(-n, -n+2, \dotsc, n-2, n\)</span>. The action of
<span class="math inline">\(X\)</span> may be depicted <span
class="math display">\[y^n \xrightarrow{n}
  x y^{n-1} \xrightarrow{n-1}
  x^2 y^{n-2} \xrightarrow{n-2}
  \dotsb \xrightarrow{2}
  x^{n-1} y
  \xrightarrow{1}
  x^n
  \rightarrow 0.\]</span> The action of <span
class="math inline">\(Y\)</span> may be depicted <span
class="math display">\[0
  \leftarrow
  y^n \xleftarrow{1}
  x y^{n-1} \xleftarrow{2}
  x^2 y^{n-2} \xleftarrow{3}
  \dotsb \xleftarrow{n-1}
  x^{n-1} y
  \xleftarrow{n}
  x^n.\]</span> Explicitly, when <span class="math inline">\(n =
3\)</span>, we may represent the various actions with respect to the
basis <span class="math inline">\(x^3, x^2 y, x y^2, y^3\)</span> by
<span class="math display">\[d R(X)
  =
\begin{pmatrix}
    &amp; 1 &amp; &amp; \\
    &amp;  &amp; 2 &amp; \\
    &amp;  &amp; &amp; 3 \\
    &amp; &amp; &amp;
  \end{pmatrix}
,\]</span> <span class="math display">\[d R(Y)
  =
\begin{pmatrix}
    &amp;  &amp; &amp; \\
    3 &amp;  &amp;  &amp; \\
    &amp; 2 &amp;  &amp; \\
    &amp; &amp; 1 &amp;
  \end{pmatrix}
,\]</span> <span class="math display">\[d R(H)
  =
\begin{pmatrix}
    3 &amp;  &amp; &amp; \\
    &amp;  1 &amp;  &amp; \\
    &amp;  &amp; -1  &amp; \\
    &amp; &amp;  &amp; -3
  \end{pmatrix}
.\]</span> As we saw in Homework <a href="#hw:sl2-rep-verify-commutator"
data-reference-type="ref"
data-reference="hw:sl2-rep-verify-commutator">4</a>, the relation <span
class="math display">\[= H\]</span> implies that <span
class="math display">\[= d R(H).\]</span> It is an instructive exercise
to verify this directly from as many perspective as possible (e.g., by
direct inspection of the action, by staring at the action on basis
vectors using the graph-theoretic depiction described above, by
explicitly computing the commutators of the above <span
class="math inline">\(4 \times
4\)</span> matrices, etc.).</p>
<div class="theorem">
<p><strong>Theorem 96</strong>. <em><span
class="math inline">\(W_n\)</span> is an irreducible representation of
<span class="math inline">\(G =
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>.</em></p>
</div>
<p>By Theorem <a href="#thm:equivalences-irreducibility"
data-reference-type="ref"
data-reference="thm:equivalences-irreducibility">95</a>, it is
equivalent to show that <span class="math inline">\(W_n\)</span> is
irreducible as a representation of <span
class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>. There
are a couple ways to show this. Firstly, given any nonzero invariant
subspace <span class="math inline">\(W\)</span> of <span
class="math inline">\(W_n\)</span> and take a nonzero element <span
class="math inline">\(v \in W\)</span>, then it follows from the above
description of the action that there is a <span class="math inline">\(k
\geq 0\)</span> for which <span class="math inline">\(X^{k+1} v =
0\)</span>, and moreover, that if <span class="math inline">\(k\)</span>
is the smallest integer with this property, then <span
class="math inline">\(X^k v\)</span> is a nonzero multiple of <span
class="math inline">\(x^n\)</span>; then <span class="math inline">\(Y^m
X^k v\)</span> is a nonzero multiple of <span
class="math inline">\(x^{n-k} y^k\)</span>. Since <span
class="math inline">\(W\)</span> is invariant, it contains <span
class="math inline">\(Y^m X^k v\)</span>, hence contains all the basis
elements for <span class="math inline">\(W_n\)</span>, and so <span
class="math inline">\(W = W_n\)</span>, i.e., <span
class="math inline">\(W_n\)</span> is irreducible.</p>
<p>Another way to structure part of the argument is to use the following
elementary consequence of the invertibility of the Vandermonde
determinant:</p>
<div class="lemma">
<p><strong>Lemma 97</strong>. If <span class="math inline">\(V\)</span>
is a representation of <span class="math inline">\(\mathfrak{g}\)</span>
and <span class="math inline">\(W\)</span> is an invariant subspaces and
<span class="math inline">\(v \in W\)</span> is a vector that may be
expressed as a sum <span class="math inline">\(v = v_1 + \dotsb +
v_n\)</span> where <span class="math inline">\(H v_i = \lambda_i
v_i\)</span> for some <span class="math inline">\(\lambda_i \in
\mathbb{C}\)</span> with <span class="math inline">\(\lambda_i \neq
\lambda_j\)</span> whenever <span class="math inline">\(i \neq
j\)</span>, then each <span class="math inline">\(v_i\)</span> also
belongs to <span class="math inline">\(W\)</span>.</p>
</div>
<p>This shows that any invariant subspace <span
class="math inline">\(W\)</span> of <span
class="math inline">\(W_n\)</span> contains the components of each of
its vectors wrt the standard basis, and one can then argue as above to
get all the basis elements.</p>
<h2 id="sec:orgbd19a70">§16.6. Classifying finite-dimensional irreducible
representations of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span></h2>
<p>One cares to do this because it shows up all over the place (in
studying special functions, in classifying Lie groups and Lie algebras,
in studying representations of other Lie groups thanks to the various
ways that <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> may be
embedded in them, in quantum mechanics, Hodge theory, etc.)</p>
<div id="thm:classify-irreps-sl2" class="theorem">
<p><strong>Theorem 98</strong>. <em>Let <span
class="math inline">\(V\)</span> be any finite-dimensional irreducible
representation of <span class="math inline">\(G =
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>. Then <span
class="math inline">\(V\)</span> is isomorphic to one of the
representations <span class="math inline">\(W_n\)</span> considered in
the previous section for some <span class="math inline">\(n \geq
0\)</span>.</em></p>
</div>
<p>By arguing as in the proof of Lemma <a
href="#thm:equivalences-irreducibility" data-reference-type="ref"
data-reference="thm:equivalences-irreducibility">95</a>, it suffices to
show this for <span
class="math inline">\(\mathfrak{g}\)</span>-representations instead of
<span class="math inline">\(G\)</span>-representations, which makes the
problem a bit easier.</p>
<div id="lem:linear-transformations-have-eigenvectors" class="lemma">
<p><strong>Lemma 99</strong>. Let <span class="math inline">\(T\)</span>
be a linear transformation on a nonzero finite-dimensional complex
vector space <span class="math inline">\(V\)</span>. Then <span
class="math inline">\(T\)</span> has an eigenvector, i.e., a nonzero
vector <span class="math inline">\(v \in V\)</span> so that <span
class="math inline">\(T v = \lambda v\)</span> for some <span
class="math inline">\(\lambda \in \mathbb{C}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The characteristic polynomial <span
class="math inline">\(\det(x - T)\)</span> is monic of degree <span
class="math inline">\(\dim(V) \geq 1\)</span>, hence has a root <span
class="math inline">\(\lambda\)</span>; then <span
class="math inline">\(\det(\lambda - T) = 0\)</span>, so <span
class="math inline">\(T - \lambda\)</span> is non-invertible, so <span
class="math inline">\(\ker(T - \lambda) \neq 0\)</span>, i.e., <span
class="math inline">\(T\)</span> has an eigenvector. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 100</strong>. Let <span
class="math inline">\(V\)</span> be a representation of <span
class="math inline">\(\mathfrak{g} =
  {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>, and
let <span class="math inline">\(\lambda \in \mathbb{C}\)</span>. We say
that a nonzero vector <span class="math inline">\(v \in V\)</span> has
<em>weight <span class="math inline">\(\lambda\)</span></em> if <span
class="math inline">\(v\)</span> is an eigenvector for <span
class="math inline">\(H\)</span> with eigenvalue <span
class="math inline">\(\lambda\)</span>, i.e., <span
class="math inline">\(H v = \lambda v\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 101</strong>. The vector <span
class="math inline">\(x^{n-k} y^k \in W_n\)</span> has weight <span
class="math inline">\(n-2k\)</span>.</p>
</div>
<div class="remark">
<p><strong>Remark 102</strong>. In what follows, we write (for instance)
<span class="math inline">\(H X\)</span> as an abbreviation for <span
class="math inline">\(d R(H) d R(X)\)</span>; this differs from the
matrix product of <span class="math inline">\(H\)</span> and <span
class="math inline">\(X\)</span>, which we shall have no occasion to
refer to.</p>
</div>
<div id="lem:raising-ops-etc" class="lemma">
<p><strong>Lemma 103</strong>. Suppose <span class="math inline">\(v \in
V\)</span> as above has weight <span
class="math inline">\(\lambda\)</span>. Then <span
class="math inline">\(X v\)</span> has weight <span
class="math inline">\(\lambda + 2\)</span> and <span
class="math inline">\(Y v\)</span> has weight <span
class="math inline">\(\lambda - 2\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We will use that <span class="math display">\[= 2 X,
    \quad [H,Y] = - 2 Y.\]</span> We have <span
class="math display">\[\begin{align}
    H X v &amp;= (H X - X H) v + X H v \\
          &amp;= [H,X] v + X H v
            \\
          &amp;= 2 X v + X (\lambda  v)
            \\
          &amp;= (\lambda + 2)X v,
  
\end{align}\]</span> and similarly <span class="math inline">\(H Y v =
(\lambda - 2) Y v\)</span>. ◻</p>
</span></div>
<div class="lemma">
<p><strong>Lemma 104</strong>. Let <span
class="math inline">\(V\)</span> be a finite-dimensional representation
of <span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>. Then
there is a nonzero <span class="math inline">\(v \in V\)</span> and
<span class="math inline">\(\lambda \in \mathbb{C}\)</span> so that
<span class="math display">\[H v = \lambda v,\]</span> <span
class="math display">\[X v = 0.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By Lemma <a
href="#lem:linear-transformations-have-eigenvectors"
data-reference-type="ref"
data-reference="lem:linear-transformations-have-eigenvectors">99</a>,
there exists some nonzero <span class="math inline">\(u \in V\)</span>
with some weight <span class="math inline">\(\mu \in
\mathbb{C}\)</span>. The vectors <span class="math inline">\(X^k
u\)</span> have weight <span class="math inline">\(\mu + 2k\)</span>.
Since <span class="math inline">\(V\)</span> is finite-dimensional,
<span class="math inline">\(H\)</span> has only finitely many
eigenvalues, so we have <span class="math inline">\(X^{k+1} u =
0\)</span> for large enough <span class="math inline">\(k\)</span>.
Choosing <span class="math inline">\(k\)</span> minimal with this
property and taking <span class="math inline">\(v := X^k u\)</span>
gives <span class="math inline">\(H v = (\mu + 2 k) v\)</span> and <span
class="math inline">\(X v = 0\)</span>, as required. ◻</p>
</span></div>
<div class="remark">
<p><strong>Remark 105</strong>. Although Lemma <a
href="#lem:raising-ops-etc" data-reference-type="ref"
data-reference="lem:raising-ops-etc">103</a> is basically trivial, it is
one of the most frequently applied calculations in Lie theory, and
deserves careful study.</p>
</div>
<p>To prove Theorem <a href="#thm:classify-irreps-sl2"
data-reference-type="ref"
data-reference="thm:classify-irreps-sl2">98</a>, we now take for <span
class="math inline">\(V\)</span> any irreducible finite-dimensional
representation of <span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> and
let <span class="math inline">\(v_0 \in V\)</span> be a nonzero element
satisfying <span class="math display">\[H v = \lambda_0 v,
  \quad X v = 0.\]</span> Such a vector exists by the previous lemma.
For <span class="math inline">\(k \geq 0\)</span>, set <span
class="math display">\[v_k := Y^k v_0.\]</span> Then <span
class="math inline">\(v_k\)</span> has weight <span
class="math inline">\(\lambda_0 - 2k\)</span>, so the various <span
class="math inline">\(v_k\)</span> are all linearly independent. Let
<span class="math inline">\(W := \oplus \mathbb{C} v_k\)</span> be the
span of the <span class="math inline">\(v_k\)</span>. We claim that
<span class="math inline">\(W\)</span> is <span
class="math inline">\(\mathfrak{g}\)</span>-invariant. To that end, it
suffices by the linearity of the action to show for each basis element
<span class="math inline">\(Z \in \{H,X,Y\}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> and basis element <span
class="math inline">\(v_k\)</span> of <span
class="math inline">\(W\)</span> that <span class="math inline">\(Z v_k
\in W\)</span>. Clearly <span class="math display">\[H v_k = (\lambda_0
- 2 k) v_k \in W\]</span> and <span class="math display">\[Y v_k =
v_{k+1} \in W.\]</span> We now verify by induction on <span
class="math inline">\(k\)</span> that <span class="math display">\[X v_k
= c_k v_{k-1} \in W\]</span> with <span class="math inline">\(c_k :=
k(\lambda_0 - k + 1)\)</span> and (by convention) <span
class="math inline">\(v_{-1} := 0\)</span>. When <span
class="math inline">\(k = 0\)</span>, this is clear. For <span
class="math inline">\(k \geq 0\)</span>, it follows by our inductive
hypothesis and using the trick <span class="math inline">\(X Y = (X Y -
Y X) + Y X\)</span> as in the proof of Lemma <a
href="#lem:raising-ops-etc" data-reference-type="ref"
data-reference="lem:raising-ops-etc">103</a> that <span
class="math display">\[\begin{align}
  X v_{k+1}
  &amp;=
    X Y v_k
  \\
  &amp;=
    [X,Y] v_k + Y X v_k
  \\
  &amp;=
    H v_k + Y c_k v_{k-1}
  \\
  &amp;= (\lambda - 2k + c_k) v_k.
\end{align}\]</span> We conclude by checking that <span
class="math inline">\(c_{k+1} =\lambda - 2k + c_k\)</span>.</p>
<p>Since <span class="math inline">\(W\)</span> is nonzero and <span
class="math inline">\(\mathfrak{g}\)</span>-invariant and since <span
class="math inline">\(V\)</span> is assumed irreducible, we must have
<span class="math inline">\(W = V\)</span>. Since <span
class="math inline">\(V\)</span> is finite-dimensional, we have <span
class="math inline">\(v_{n+1} = 0\)</span> for some <span
class="math inline">\(n\)</span>. Choosing <span
class="math inline">\(n\)</span> minimal with this property implies that
<span class="math display">\[v_n \neq 0\]</span> and <span
class="math display">\[v_{n+1} = 0\]</span> whence <span
class="math display">\[0 = X v_{n+1}
  = c_{n+1} v_n
  = (n+1)(\lambda_0 - n) v_n.\]</span> Since <span
class="math inline">\(n+1 \neq 0\)</span> and <span
class="math inline">\(v_n \neq 0\)</span>, it follows that <span
class="math inline">\(\lambda_0 = n\)</span>.</p>
<p>In summary, we have shown that <span class="math inline">\(V\)</span>
has the basis <span class="math inline">\(v_0,\dotsc,v_n\)</span> on
which the action is given by <span
class="math display">\[\begin{align}
  H v_k &amp;= (n - 2k ) v_k,
          \\
  Y v_k &amp;= v_{k+1},
          \\
  X v_k &amp;= k(n-k+1) v_{k-1}.
\end{align}\]</span> But it is easy to check that <span
class="math inline">\(W_n\)</span> has the basis <span
class="math inline">\(w_0,\dotsc,w_n\)</span> with <span
class="math inline">\(w_k := Y^k x^n\)</span> on which the action is
described in the same way. Thus the linear map <span
class="math inline">\(V \rightarrow W_n\)</span> extending <span
class="math inline">\(v_k \mapsto w_k\)</span> is an isomorphism of
<span class="math inline">\(\mathfrak{g}\)</span>-representations, as
required.</p>
<h2 id="sec:orgf4dbdd0">§16.7. Complete reducibility<span id="sec:compl-red"
label="sec:compl-red"></span></h2>
<p>It is interesting to ask whether one can classify <em>all</em>
finite-dimensional representations of a group such as <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> rather
than just the irreducible ones as done in §<a href="#sec:reps-sl2-C"
data-reference-type="ref"
data-reference="sec:reps-sl2-C">16.5</a>. For example, can
we break arbitrary representations up into sums of irreducible ones? We
can also ask the same question for more general Lie groups <span
class="math inline">\(G\)</span>: how can we understand general
representations <span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> in terms of the irreducible ones? This
was a basic question of late 19th century mathematics known nowadays as
classical invariant theory; the representations of interest were as in
Example <a href="#ex:polynomial-reps-linear-groups"
data-reference-type="ref"
data-reference="ex:polynomial-reps-linear-groups">93</a>.</p>
<div class="definition">
<p><strong>Definition 106</strong>. Let <span
class="math inline">\(G\)</span> be any Lie group and <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
a finite-dimensional representation. We say that <span
class="math inline">\(V\)</span> is <em>completely reducible</em> if
there are irreducible invariant subspaces <span
class="math inline">\(V_1, \dotsc, V_n\)</span> of <span
class="math inline">\(V\)</span> so that <span class="math inline">\(V =
V_1 \oplus \dotsb \oplus V_n\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 107</strong>. Similarly, let <span
class="math inline">\(\mathfrak{g}\)</span> be a Lie algebra and <span
class="math inline">\(\rho : \mathfrak{g}  \rightarrow
\mathop{\mathrm{End}}(V)\)</span> a finite-dimensional representation.
We say that <span class="math inline">\(V\)</span> is <em>completely
reducible</em> if there are irreducible invariant subspaces <span
class="math inline">\(V_1, \dotsc, V_n\)</span> of <span
class="math inline">\(V\)</span> so that <span class="math inline">\(V =
V_1 \oplus \dotsb \oplus V_n\)</span>.</p>
</div>
<div id="lem:complete-irreducible-gp-vs-alg" class="lemma">
<p><strong>Lemma 108</strong>. Let <span
class="math inline">\(G\)</span> be a connected Lie group, let <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
a finite-dimensional representation, and let <span
class="math inline">\(d R : \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> be the induced representation of the
Lie algebra <span class="math inline">\(\mathfrak{g}\)</span> of <span
class="math inline">\(G\)</span>. Then <span
class="math inline">\(V\)</span> is completely reducible as a
representation of <span class="math inline">\(G\)</span> if and only if
<span class="math inline">\(V\)</span> is completely reducible as a
representation of <span class="math inline">\(\mathfrak{g}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Indeed, the invariant subspaces of <span
class="math inline">\(G\)</span> and <span
class="math inline">\(\mathfrak{g}\)</span> are the same, thanks to
Lemma <a href="#thm:equivalences-irreducibility"
data-reference-type="ref"
data-reference="thm:equivalences-irreducibility">95</a>. ◻</p>
</span></div>
<div class="example">
<p><strong>Example 109</strong>. The zero representation <span
class="math inline">\(V := \{0\}\)</span> is completely reducible (take
<span class="math inline">\(n := 0\)</span>). Any irreducible
representation is completely reducible (take <span
class="math inline">\(n := 1, V_1 := V\)</span>).</p>
</div>
<div id="lem:compl-red-vs-complements" class="lemma">
<p><strong>Lemma 110</strong>. Let <span class="math inline">\(R : G
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> be a finite-dimensional
representation. The following are equivalent:</p>
<ol>
<li><p><span class="math inline">\(V\)</span> is completely
reducible.</p></li>
<li><p>Every invariant subspace <span class="math inline">\(W\)</span>
of <span class="math inline">\(V\)</span> has an invariant complement
<span class="math inline">\(W&#39;\)</span>.</p></li>
</ol>
</div>
<p>Recall here that a subspace <span class="math inline">\(W&#39; \leq
V\)</span> is said to be a <em>complement</em> of a subspace <span
class="math inline">\(W \leq V\)</span> if <span class="math inline">\(V
= W \oplus W&#39;\)</span>, that is to say, if every <span
class="math inline">\(v \in V\)</span> may be expressed as <span
class="math inline">\(v = w + w&#39;\)</span> for some unique <span
class="math inline">\(w \in W, w&#39; \in W&#39;\)</span>.</p>
<div
id="example:invariant-inner-product-implies-complete-irreducibility"
class="example">
<p><strong>Example 111</strong>. Suppose that <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
has the property that there is an inner product <span
class="math inline">\(\langle , \rangle\)</span> on <span
class="math inline">\(V\)</span> that is invariant by <span
class="math inline">\(G\)</span> in the sense that <span id="eq:invariant-inner-product" class="math display">\[\label{eq:invariant-inner-product}\tag{70}
    \langle R(g) u, R(g) v  \rangle = \langle u,v \rangle\]</span> for
all <span class="math inline">\(g \in G\)</span> and all <span
class="math inline">\(u, v \in V\)</span>. (In other words, after
choosing an orthonormal basis of <span class="math inline">\(V\)</span>
and using that basis to identify <span class="math inline">\(V \cong
  \mathbb{C}^n\)</span>, we are assuming that <span
class="math inline">\(R(G)\)</span> is contained in the unitary group
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>.) Then every
invariant subspace <span class="math inline">\(W\)</span> has an
invariant complement <span class="math inline">\(W&#39;\)</span>: one
can just take for <span class="math inline">\(W&#39;\)</span> the
<em>orthogonal complement</em> <span class="math display">\[W^\perp :=
\{v \in V : \langle v,w \rangle = 0 \text{ for
all }
w \in W\}\]</span> of <span class="math inline">\(W\)</span>. It follows
from the definition of an inner product that the orthogonal complement
is in fact a complement; what needs to be checked is that it is
invariant. Thus, let <span class="math inline">\(v \in W^\perp\)</span>
and <span class="math inline">\(g \in G\)</span>; we want to check that
<span class="math inline">\(R(g) v \in W^\perp\)</span>, i.e., that
<span class="math inline">\(\langle R(g) v, w \rangle = 0\)</span> for
all <span class="math inline">\(w \in W\)</span>. But <a
href="#eq:invariant-inner-product" data-reference-type="eqref"
data-reference="eq:invariant-inner-product">\((70)\)</a>
implise that <span class="math display">\[\langle R(g) v, w \rangle =
\langle R(g^{-1}) R(g) v,
    R(g^{-1}) w \rangle
    = \langle v, R(g^{-1}) w \rangle,\]</span> and the invariance of
<span class="math inline">\(W\)</span> implies that <span
class="math inline">\(R(g^{-1}) \in w\)</span>, hence that <span
class="math inline">\(\langle v, R(g^{-1}) w \rangle= 0\)</span>, as
required.</p>
</div>
<p>We turn to the proof of Lemma <a href="#lem:compl-red-vs-complements"
data-reference-type="ref"
data-reference="lem:compl-red-vs-complements">110</a>, which we split
into two parts.</p>
<div class="proof">
<p><em>Existence of invariant complements implies complete
reducibility.</em> Assume first that every invariant subspace of <span
class="math inline">\(V\)</span> has an invariant complement; we aim
then to show that <span class="math inline">\(V\)</span> is completely
reducible. (In following this argument, it may be helpful to pretend
that we are in the setting of Example <a
href="#example:invariant-inner-product-implies-complete-irreducibility"
data-reference-type="ref"
data-reference="example:invariant-inner-product-implies-complete-irreducibility">111</a>.)
If <span class="math inline">\(V = \{0\}\)</span>, then we are done.
Since <span class="math inline">\(\dim(V) &lt; \infty\)</span>, there
exists a minimal nonzero invariant subspace <span
class="math inline">\(V_1\)</span> of <span
class="math inline">\(V\)</span>. If <span class="math inline">\(V_1 =
V\)</span>, then we are done. Otherwise, let <span
class="math inline">\(V_1&#39;\)</span> be an invariant complement of
<span class="math inline">\(V_1\)</span>; by assumption, <span
class="math inline">\(V_1&#39; \neq 0\)</span> and <span
class="math display">\[V = V_1 \oplus V_1&#39;.\]</span> Let <span
class="math inline">\(V_2\)</span> be a minimal nonzero invariant
subspace of <span class="math inline">\(V_1&#39;\)</span>. If <span
class="math inline">\(V_2 = V_1&#39;\)</span>, then <span
class="math inline">\(V = V_1 \oplus V_2\)</span> is a sum of invariant
irreducible subspaces, so we are done. If not, let <span
class="math inline">\(W_2 \leq V\)</span> be an invariant complement to
<span class="math inline">\(V_2\)</span>, and let <span
class="math inline">\(V_2&#39; := W_2 \cap V_1 \leq V_1&#39;\)</span> be
its intersection with <span class="math inline">\(V_1&#39;\)</span>,
which is then invariant and satisfies <span
class="math inline">\(V_1&#39; = V_2 \oplus V_2&#39;\)</span> (check
this; it’s easy), hence <span class="math display">\[V = V_1 \oplus V_2
\oplus V_2&#39;.\]</span> By assumption, <span
class="math inline">\(W_2\)</span> is nonzero, hence <span
class="math inline">\(V_2&#39;\)</span> is nonzero. Let <span
class="math inline">\(V_3\)</span> be a minimal nonzero invariant
subspace of <span class="math inline">\(V_2&#39;\)</span>. If <span
class="math inline">\(V_3 = V_2&#39;\)</span>, then we are done as
before. If not, let <span class="math inline">\(V_3&#39; := V_2&#39;
\cap W_3 \leq V_2&#39;\)</span> be the intersection with <span
class="math inline">\(V_2&#39;\)</span> of some invariant complement
<span class="math inline">\(W_3&#39; \leq V\)</span> of <span
class="math inline">\(V_2&#39;\)</span>; then, as before, <span
class="math display">\[V = V_1 \oplus V_2 \oplus V_3 \oplus
V_3&#39;.\]</span> Proceed as above, and invoke that <span
class="math inline">\(\dim(V) &lt; \infty\)</span> to know that the
process must eventually terminate.</p>
<p>(The argument just presented is “obvious” and fairly natural, but
somewhat suboptimal. I’ll leave it as an exercise for the interested
reader to make it “slicker” by considering in the first step an
invariant subspace <span class="math inline">\(W\)</span> of <span
class="math inline">\(V\)</span> that is maximal with respect to the
property of being a direct sum of irreducible invariant subspaces, and
deriving a contradiction if <span class="math inline">\(W \neq
V\)</span>. This “slicker” formulation of the argument has certain
advantages; for instance, it works without any fuss in the
infinite-dimensional setting.) ◻</p>
</div>
<div class="proof">
<p><em>Complete reducibility implies existence of invariant
complements.</em> Okay, now let’s show that if <span
class="math inline">\(V\)</span> is completely reducible, then every
invariant subspace <span class="math inline">\(W\)</span> of <span
class="math inline">\(V\)</span> has an invariant complement <span
class="math inline">\(W&#39;\)</span>. Thus, suppose we can write <span
class="math inline">\(V = V_1 \oplus \dotsb \oplus V_n\)</span> as a sum
of irreducible invariant subspaces. Let <span
class="math inline">\(I\)</span> be a subset of <span
class="math inline">\(\{1,\dotsc,n\}\)</span> that is maximal with
respect to the property that <span class="math display">\[W
    \cap (\oplus_{i \in I} V_i) = \{0\}.\]</span> (Note that the empty
set satisfies this property, and there are only finitely many subsets,
so such an <span class="math inline">\(I\)</span> exists.) Set <span
class="math inline">\(W&#39; := \oplus_{i \in I} V_i\)</span>. We claim
that <span class="math inline">\(V = W \oplus W&#39;\)</span>. By
construction, we have <span class="math inline">\(W \cap W&#39; =
\{0\}\)</span>, so it suffices to show that <span
class="math inline">\(V = W + W&#39;\)</span>. To that end, it suffices
to show for each <span class="math inline">\(j \in
\{1,\dotsc,n\}\)</span> that <span id="eq:each-simple-compoennt-is-in-sum" class="math display">\[\label{eq:each-simple-compoennt-is-in-sum}\tag{71}
    V_j \subseteq W + W&#39;.\]</span> If <span class="math inline">\(j
\in I\)</span>, then <span class="math inline">\(V_j \subseteq
W&#39;\)</span>, so <a href="#eq:each-simple-compoennt-is-in-sum"
data-reference-type="ref"
data-reference="eq:each-simple-compoennt-is-in-sum">71</a>
holds, so suppose <span class="math inline">\(j \notin I\)</span>. If <a
href="#eq:each-simple-compoennt-is-in-sum" data-reference-type="eqref"
data-reference="eq:each-simple-compoennt-is-in-sum">\((71)\)</a>
fails, then <span class="math inline">\(V_j \cap (W + W&#39;)\)</span>
is a proper invariant subspace of <span
class="math inline">\(V_j\)</span>, hence <span
class="math display">\[V_j \cap (W + W&#39;) = 0,\]</span> or in other
words, there is no nontrivial solution to the equation <span
class="math inline">\(v = w + w&#39;\)</span> with <span
class="math inline">\(v \in V_j\)</span>, <span class="math inline">\(w
\in W, w&#39; \in W&#39;\)</span>, or equivalently (upon replacing <span
class="math inline">\(w,v\)</span> by their negatives), there is no
nontrivial solution to the equation <span class="math inline">\(w =
w&#39; + v\)</span> with <span class="math inline">\(v \in V_j\)</span>,
<span class="math inline">\(w \in W, w&#39; \in W&#39;\)</span>, i.e.,
<span class="math display">\[W \cap (W&#39; \oplus V_j) = 0,\]</span>
which says that <span class="math inline">\(W \cap (\oplus_{i \in I \cup
\{j\}} V_i) = 0\)</span>, contradicting the assumed maximality of <span
class="math inline">\(I\)</span>. ◻</p>
</div>
<div class="remark">
<p><strong>Remark 112</strong>. The natural setting for Lemma <a
href="#lem:compl-red-vs-complements" data-reference-type="ref"
data-reference="lem:compl-red-vs-complements">110</a> is the theory of
semisimple modules over a ring.</p>
</div>
<div
id="example:defining-representation-of-borel-is-not-completely-reducible"
class="example">
<p><strong>Example 113</strong> (A representation that is not completely
reducible). Consider the Lie subgroup <span
class="math inline">\(P\)</span> of <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>
consisting of matricse of the form <span
class="math inline">\(\begin{pmatrix}
    a &amp; b \\
    0 &amp; d
  \end{pmatrix}\)</span>. Let <span class="math inline">\(R : P
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> be the standard
representation of <span class="math inline">\(P\)</span> on <span
class="math inline">\(V := \mathbb{C}^2\)</span>, thus <span
class="math display">\[R(
\begin{pmatrix}
      a &amp; b \\
      &amp; d
    \end{pmatrix}
)
    \begin{pmatrix}
      x  \\
      y        
    \end{pmatrix}
    :=
    \begin{pmatrix}
      a x + b  \\
      d y        
    \end{pmatrix}
.\]</span> Then <span class="math inline">\(V\)</span> is not completely
reducible. Indeed, consider the subspace <span class="math inline">\(W
:= \mathbb{C} e_1 \leq V\)</span> consisting of column vectors of the
form <span class="math display">\[\begin{pmatrix}
      x  \\
      0
    \end{pmatrix}
.\]</span> It is easy to check that <span
class="math inline">\(W\)</span> is invariant, and that every complement
<span class="math inline">\(W&#39;\)</span> of <span
class="math inline">\(W\)</span> has the form <span
class="math display">\[W&#39; = \left\{
\begin{pmatrix}
        c y  \\
        y
      \end{pmatrix}
: y \in \mathbb{C}  \right\}\]</span> for some <span
class="math inline">\(c \in \mathbb{C}\)</span>. But it is equally clear
that <span class="math inline">\(W&#39;\)</span> is not invariant; for
instance, one has <span class="math display">\[\begin{pmatrix}
      1 &amp; 1 \\
       &amp; 1
     \end{pmatrix}
\in P,
     \quad
    \begin{pmatrix}
      c  \\
      1
    \end{pmatrix}
\in W,
    \quad
    \begin{pmatrix}
      1 &amp; 1 \\
       &amp; 1
     \end{pmatrix}
    \begin{pmatrix}
      c  \\
      1
    \end{pmatrix}
    =
\begin{pmatrix}
      c+1  \\
      1      
    \end{pmatrix}
\notin  W.\]</span> Thus not all representations are completely
reducible.</p>
<p>One gets more general examples of this sort by replacing <span
class="math inline">\(P\)</span> by the stabilizer <span
class="math inline">\(P\)</span> of any nontrivial flag of vector spaces
<span class="math inline">\(0 = V_0 \subset V_1 \subset \dotsb \subset
V_r =
  \mathbb{C}^n\)</span>.</p>
</div>
<div id="boring-examples-of-non-reductivity" class="example">
<p><strong>Example 114</strong>. The representation <span
class="math display">\[\mathbb{R} \rightarrow
{\mathop{\mathrm{GL}}}_2(\mathbb{R})\]</span> <span
class="math display">\[x \mapsto
\begin{pmatrix}
      1 &amp; x \\
       &amp; 1
    \end{pmatrix}\]</span> is not completely reducible, for the same
reason as in the previous example. Similarly for the representation
<span class="math inline">\(\mathbb{C}  \rightarrow
  {\mathop{\mathrm{GL}}}_2(\mathbb{C})\)</span> defined by the same
formula. Likewise for the representation <span
class="math display">\[\mathbb{R}^\times \rightarrow
{\mathop{\mathrm{GL}}}_2(\mathbb{R})\]</span> <span
class="math display">\[x \mapsto
\begin{pmatrix}
      1 &amp; \log|x| \\
       &amp; 1
    \end{pmatrix}
.\]</span> Likewise for the representation <span
class="math display">\[{\mathop{\mathrm{GL}}}_n(\mathbb{R}) \rightarrow
{\mathop{\mathrm{GL}}}_2(\mathbb{R})\]</span> <span
class="math display">\[g \mapsto
\begin{pmatrix}
      1 &amp; \log|\det(g)| \\
       &amp; 1
    \end{pmatrix}
.\]</span></p>
</div>
<div class="definition">
<p><strong>Definition 115</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group. We say that <span
class="math inline">\(G\)</span> is <em>linearly reductive</em> if every
finite-dimensional representation of <span
class="math inline">\(G\)</span> is completely reducible.</p>
</div>
<div id="rmk:lie-vs-alg" class="example">
<p><strong>Example 116</strong>. We have seen that the groups <span
class="math inline">\(P\)</span> from Example <a
href="#example:defining-representation-of-borel-is-not-completely-reducible"
data-reference-type="ref"
data-reference="example:defining-representation-of-borel-is-not-completely-reducible">113</a>
are <em>not</em> linearly reductive. Similarly, we see from Example <a
href="#boring-examples-of-non-reductivity" data-reference-type="ref"
data-reference="boring-examples-of-non-reductivity">114</a> that the
real Lie groups <span class="math inline">\(\mathbb{R}\)</span> and
<span class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span>
and the complex Lie group <span
class="math inline">\(\mathbb{C}\)</span> are not linearly
reductive.</p>
<p>A minor caution regarding terminology: We are working here in the
category of Lie groups over the field <span
class="math inline">\(\mathbf{k} =
  \mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span>. When we speak of any property
of a Lie group, it matters which we field we regard it as being defined
over. For example, we will show eventually that <span
class="math inline">\(\mathbb{C}^\times\)</span>, regarded as a complex
Lie group is linearly reductive. However, if we instead regard <span
class="math inline">\(\mathbb{C}^\times\)</span> as a real Lie group,
then it is not linearly reductive: the representation <span
class="math display">\[\mathbb{C}^\times \ni z
    \mapsto
\begin{pmatrix}
      1 &amp; \log |z| \\
       &amp; 1
    \end{pmatrix}\]</span> is not completely reducible. That
representation is not smooth in the complex sense (i.e., is not
holomorphic), and so does not define a representation of <span
class="math inline">\(\mathbb{C}^\times\)</span> when we regard it as a
complex Lie group.</p>
<p>Similarly, although we are working in this course in the category of
Lie groups, we could instead work in the category of <em>algebraic
groups</em>, which are obtained by replacing manifolds with solution
spaces to polynomial equations (called <em>varieties</em>) and replacing
smooth maps between manifolds with maps described by polynomials (called
<em>morphisms of varieties</em>). The group <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span> can be
regarded either as a Lie group or as an algebraic group. In the category
of Lie groups, it is not linearly reductive. But the counter-example we
gave involved the logarithm function, which is not algebraic. It turns
out that when <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span> is
regarded as an algebraic group, it is linearly reductive. This means
that one can’t construct non-completely-reducible representations of
<span class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span>
using only polynomials; to put it another way, it turns out that any
representation <span class="math inline">\(R :
{\mathop{\mathrm{GL}}}_n(\mathbb{R}) \rightarrow
{\mathop{\mathrm{GL}}}_N(\mathbb{R})\)</span> whose matrix coefficients
<span class="math inline">\(R_{i j}(g)\)</span> are polynomial functions
of the coordinates <span class="math inline">\(g_{k l}\)</span> is
completely reducible.</p>
</div>
<h2 id="sec:org7d9bd5a">§16.8. Linear reductivity of compact groups<span
id="sec:linear-reductivity-compact-groups"
label="sec:linear-reductivity-compact-groups"></span></h2>
<div id="thm:maschke-finite-groups" class="theorem">
<p><strong>Theorem 117</strong> (Maschke). <em>Any finite group <span
class="math inline">\(G\)</span> is linearly reductive.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(V\)</span> be a
complex vector space, and let <span class="math inline">\(R : G
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> be a representation. We
wish to show that <span class="math inline">\(V\)</span> is completely
reducible. There are a couple ways to phrase the argument; I’ll record
both for the sake of variety.</p>
<p>First, by Lemma <a href="#lem:compl-red-vs-complements"
data-reference-type="ref"
data-reference="lem:compl-red-vs-complements">110</a> and Example <a
href="#example:invariant-inner-product-implies-complete-irreducibility"
data-reference-type="ref"
data-reference="example:invariant-inner-product-implies-complete-irreducibility">111</a>,
it will suffice to show that there exists a invariant inner product on
<span class="math inline">\(V\)</span>. To show this, let <span
class="math inline">\(\langle , \rangle_0\)</span> be any inner product
on <span class="math inline">\(V\)</span> (just fix a linear isomorphism
<span class="math inline">\(V \cong \mathbb{C}^n\)</span> and take the
standard one), and then define the averaged inner product <span
class="math inline">\(\langle ,
  \rangle\)</span> by the formula <span class="math display">\[\langle
u, v \rangle := \frac{1}{|G|}
    \sum_{g \in G}
    \langle R(g) u, R(g) v \rangle_0.\]</span> It is then easy to check
that <span class="math inline">\(\langle , \rangle\)</span> is the
required an invariant inner product.</p>
<p>We now phrase the argument another way by making more direct use of
the criterion of Lemma <a href="#lem:compl-red-vs-complements"
data-reference-type="ref"
data-reference="lem:compl-red-vs-complements">110</a>. It will suffice
to show that each invariant subspace <span
class="math inline">\(W\)</span> of <span
class="math inline">\(V\)</span> has an invariant complement. To that
end, it will suffice to construct an <em>equivariant projection</em>
<span class="math inline">\(p : V \rightarrow W\)</span>. (A
<em>projection</em> from a vector space <span
class="math inline">\(V\)</span> to a subspace <span
class="math inline">\(W\)</span> is a linear map <span
class="math inline">\(p : V \rightarrow W\)</span> whose restriction to
<span class="math inline">\(W\)</span> is the identity map. A linear map
<span class="math inline">\(p\)</span> between representations is said
to be <em>equivariant</em> if it is a morphism of representations, i.e.,
if <span class="math inline">\(p(g v) = g p(v)\)</span> for all <span
class="math inline">\(v \in V, g \in G\)</span>.) Assuming we have
constructed such a projection, we may take <span
class="math inline">\(W&#39; := \ker(p)\)</span>. Since <span
class="math inline">\(p\)</span> is a projection, we then have <span
class="math display">\[V = W \oplus W&#39;.\]</span> On the other hand,
since <span class="math inline">\(p\)</span> is equivariant, its kernel
<span class="math inline">\(W&#39;\)</span> is invariant. We thereby
obtain the required invariant complement of <span
class="math inline">\(W\)</span>, assuming the existence of an
equivariant projection.</p>
<p>To produce an equivariant projection, start with any projection <span
class="math inline">\(\phi_0 : V \rightarrow W\)</span> (e.g., by taking
a basis <span class="math inline">\(e_1,\dotsc,e_d\)</span> for <span
class="math inline">\(W\)</span>, extending it to a basis <span
class="math inline">\(e_1,\dotsc,e_n\)</span> for <span
class="math inline">\(V\)</span>, and defining <span
class="math inline">\(\phi_0(e_j)\)</span> to be <span
class="math inline">\(e_j\)</span> if <span class="math inline">\(j \leq
d\)</span> and <span class="math inline">\(0\)</span> otherwise) and
define the average <span class="math inline">\(\phi : V \rightarrow
W\)</span> by <span class="math display">\[\phi(v) := \frac{1}{|G|}
\sum_{g \in G}
    R(g) \phi_0(R(g)^{-1} v).\]</span> Then it is easy to check that
<span class="math inline">\(\phi\)</span> is still a projection, and
also that <span class="math inline">\(\phi\)</span> is equivariant: for
<span class="math inline">\(h \in G\)</span>, one obtains using the
change of variables <span class="math inline">\(g \mapsto h g\)</span>
on <span class="math inline">\(G\)</span> and the homomorphism property
of representations that <span class="math display">\[\begin{align}
    \phi(R(h) v)
    &amp;=
     \frac{1}{|G|} \sum_{g \in G}
      R(g) \phi_0(R(g)^{-1} R(h) v)
      \\
    &amp;=
     \frac{1}{|G|} \sum_{g \in G}
      R(g) \phi_0(R(h^{-1} g)^{-1} v)
      \\
    &amp;=
     \frac{1}{|G|} \sum_{g \in G}
      R(h g) \phi_0(R(g)^{-1} v)
      \\
    &amp;=
      R(h) \phi(v),
  
\end{align}\]</span> so <span class="math inline">\(\phi\)</span> is
equivariant, as required. ◻</p>
</span></div>
<div id="thm:compact-implies-lin-red" class="theorem">
<p><strong>Theorem 118</strong>. <em>Any compact Lie group <span
class="math inline">\(G\)</span> is linearly reductive. More generally,
if <span class="math inline">\(G\)</span> is a compact topological group
and <span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> is any continuous finite-dimensional
representation, then <span class="math inline">\(R\)</span> is
completely reducible.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We will use the following fact, whose proof is
sketched in §<a href="#sec:inv-measures" data-reference-type="ref"
data-reference="sec:inv-measures">10</a>, §<a
href="#sec:inv-measure-lie" data-reference-type="ref"
data-reference="sec:inv-measure-lie">10.4</a>, §<a
href="#sec:haar-compact-gp-via-avg" data-reference-type="ref"
data-reference="sec:haar-compact-gp-via-avg">10.6</a>:
there is a unique Radon probability measure <span
class="math inline">\(\mu\)</span> which is left and right invariant
under <span class="math inline">\(G\)</span> in the sense that <span
class="math inline">\(\mu(E g) = \mu(g E) = \mu(E)\)</span> for all
Borel subsets <span class="math inline">\(E
  \subseteq G\)</span> and <span class="math inline">\(g \in G\)</span>,
or equivalently, <span class="math display">\[\int_{g \in G} f(g) \, d
\mu(g)
    =
    \int_{g \in G} f(h g) \, d \mu(g)
    =
    \int_{g \in G} f(g h) \, d \mu(g)\]</span> for all <span
class="math inline">\(h \in G\)</span> and all continuous functions
<span class="math inline">\(f : G
  \rightarrow \mathbb{C}\)</span>. For example, if <span
class="math inline">\(G\)</span> is a finite group, one can take for
<span class="math inline">\(\mu\)</span> the normalized counting
measure. We may then argue exactly as in either of the proofs of Theorem
<a href="#thm:maschke-finite-groups" data-reference-type="eqref"
data-reference="thm:maschke-finite-groups">\((117)\)</a>
by replacing averaging over the group with averaging with respect to
<span class="math inline">\(\mu\)</span>, i.e., taking <span
class="math display">\[\langle u, v \rangle :=
    \int_{g \in G}
    \langle R(g) u, R(g) v \rangle_0
    \, d \mu(g)\]</span> or <span class="math display">\[\phi(v)
:=  \int_{g \in G}
    R(g) \phi_0(R(g)^{-1} v) \, d \mu(g)\]</span> instead of what we did
above. ◻</p>
</span></div>
<p>The tools of §<a href="#sec:unitary-trick" data-reference-type="ref"
data-reference="sec:unitary-trick">17</a> will give us
a number of examples of linearly reductive complex Lie groups (<span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span>, <span
class="math inline">\({\mathop{\mathrm{SO}}}_n(\mathbb{C})\)</span>, etc.)
and also linearly reductive real Lie groups (<span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{R})\)</span>, <span
class="math inline">\(\mathop{\mathrm{SO}}(p,q)^0\)</span> for <span
class="math inline">\((p,q) \neq (1,1)\)</span>) in addition to the
compact groups (<span class="math inline">\(\mathop{\mathrm{U}}(n),
\mathop{\mathrm{SO}}(n)\)</span>, etc.) already covered above. The
following result was established in the above, and is of independent
interest:</p>
<div class="theorem">
<p><strong>Theorem 119</strong>. <em>Let <span class="math inline">\(R :
G \rightarrow \mathop{\mathrm{GL}}(V)\)</span> be a finite-dimensional
representation of a compact group <span
class="math inline">\(G\)</span>. Then there exists an invariant inner
product on <span class="math inline">\(V\)</span>.</em></p>
</div>
<p>The proofs given above were self-contained except that we punted the
existence of the Haar measure <span class="math inline">\(\mu\)</span>
to §<a href="#sec:inv-measures" data-reference-type="ref"
data-reference="sec:inv-measures">10</a>. Here we record
a self-contained way (learned from Onishchik–Vinberg) to “get around”
constructing such a <span class="math inline">\(\mu\)</span>. (I put
“get around” in quotes because the ideas here are similar to those used
in §<a href="#sec:haar-compact-gp-via-avg" data-reference-type="ref"
data-reference="sec:haar-compact-gp-via-avg">10.6</a>
to construct such a <span class="math inline">\(\mu\)</span>; however,
they are somewhat simpler in the present context.)</p>
<div id="thm:fixed-point-theorem-for-affine-actions-of-compact-groups"
class="theorem">
<p><strong>Theorem 120</strong>. <em>Let <span
class="math inline">\(S\)</span> be a finite-dimensional vector space,
let <span class="math inline">\(G\)</span> be a compact group, and let
<span class="math inline">\(\alpha : G \rightarrow
\mathop{\mathrm{GL}}(S)\)</span> be a representation. Let <span
class="math inline">\(M \subseteq S\)</span> be a nonempty convex <span
class="math inline">\(G\)</span>-invariant subset. Then <span
class="math inline">\(M\)</span> contains a fixed point of <span
class="math inline">\(G\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We reduce first to the case that <span
class="math inline">\(M\)</span> is bounded by replacing <span
class="math inline">\(M\)</span> as necessary by the convex hull of some
orbit of <span class="math inline">\(G\)</span> on <span
class="math inline">\(M\)</span>; such an orbit is compact because of
the compactness of <span class="math inline">\(G\)</span>. The idea is
then that <span class="math inline">\(M\)</span> has a well-defined
“center of mass” which, being canonically defined, will turn out to be
<span class="math inline">\(G\)</span>-invariant.</p>
<p>Turning to details, let <span class="math inline">\(W \leq S\)</span>
denote the span of all differences of pairs of elements of <span
class="math inline">\(M\)</span>. Let <span
class="math inline">\(P\)</span> denote the smallest plane containing
<span class="math inline">\(M\)</span>, or equivalently, the union of
all lines in <span class="math inline">\(S\)</span> containing at least
two elements of <span class="math inline">\(M\)</span>. Then <span
class="math inline">\(P\)</span> is a coset of <span
class="math inline">\(W\)</span>. Since <span
class="math inline">\(M\)</span> is <span
class="math inline">\(G\)</span>-invariant and the associations <span
class="math inline">\(M \mapsto W,P\)</span> are canonical, we know that
<span class="math inline">\(W\)</span> and <span
class="math inline">\(P\)</span> are <span
class="math inline">\(G\)</span>-invariant, too. The vector space <span
class="math inline">\(W\)</span> has a Lebesgue measure <span
class="math inline">\(\mu\)</span>. For <span class="math inline">\(g
\in G\)</span>, let <span class="math inline">\(J(g)\)</span> denote the
Jacobian of the linear transformation of <span
class="math inline">\(W\)</span> induced by <span
class="math inline">\(R(g)\)</span>. Then <span class="math inline">\(J
: G \rightarrow \mathbb{R}_+^\times\)</span> is a homomorphism. Since
<span class="math inline">\(G\)</span> is compact, <span
class="math inline">\(J\)</span> is trivial. Thus the Lebesgue measure
<span class="math inline">\(\mu\)</span> is <span
class="math inline">\(G\)</span>-invariant. By fixing a basepoint on
<span class="math inline">\(P\)</span>, we can transfer <span
class="math inline">\(\mu\)</span> to a measure <span
class="math inline">\(\nu\)</span> on <span
class="math inline">\(P\)</span>, which is again <span
class="math inline">\(G\)</span>-invariant. The <em>center of mass</em>
<span class="math display">\[c(M)
  :=
  \frac{\int_{x \in M} x \, d \nu(x)}{\nu(M)}\]</span> of <span
class="math inline">\(M\)</span> then makes sense (because <span
class="math inline">\(M\)</span> is bounded) and is <span
class="math inline">\(G\)</span>-invariant (because <span
class="math inline">\(\nu\)</span> is <span
class="math inline">\(G\)</span>-invariant). Since <span
class="math inline">\(M\)</span> is convex, we have moreover that <span
class="math inline">\(c(M)\)</span> belongs to <span
class="math inline">\(M\)</span>: this is clear if <span
class="math inline">\(M\)</span> is a point, while otherwise the
interior <span class="math inline">\(M^0\)</span> of <span
class="math inline">\(M\)</span> (as defined using the topology on <span
class="math inline">\(P\)</span>) is nonempty, so if <span
class="math inline">\(c(M) \notin M\)</span>, then (by the separating
hyperplane theorem, i.e., Hahn–Banach in finite dimensions) there is an
affine-linear function <span class="math inline">\(\ell : S \rightarrow
\mathbb{R}\)</span> satisfying <span class="math inline">\(\ell(M^0)
  \subseteq \mathbb{R}_{&gt;0}\)</span> but <span
class="math inline">\(\ell(c(M)) = 0\)</span>, which leads to a
contradiction upon applying <span class="math inline">\(\ell\)</span> to
the definition of <span class="math inline">\(c(M)\)</span>. Thus <span
class="math inline">\(c(M) \in M\)</span> gives the required <span
class="math inline">\(G\)</span>-fixed point. ◻</p>
</span></div>
<div id="example:fixed-point-thm-gives-equivariant-projections"
class="example">
<p><strong>Example 121</strong>. Let <span
class="math inline">\(G\)</span> be a compact group, let <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
be a finite-dimensional representation, let <span
class="math inline">\(W \leq V\)</span> be an invariant subspace, and
let <span class="math inline">\(S\)</span> denote the set of all linear
maps <span class="math inline">\(V \rightarrow W\)</span> and <span
class="math inline">\(M \subseteq S\)</span> the subset consisting of
projections <span class="math inline">\(\phi
  : V  \rightarrow W\)</span>. Then <span
class="math inline">\(G\)</span> acts on <span
class="math inline">\(S\)</span> by the rule <span
class="math inline">\(g \cdot \phi :=  R(g) \circ \phi \circ
R(g)^{-1}\)</span>, and <span class="math inline">\(M\)</span> is a
nonempty convex <span class="math inline">\(G\)</span>-invariant subset.
A projection <span class="math inline">\(\phi \in M\)</span> is
equivariant if and only if it is a fixed point for this action, so
Theorem <a
href="#thm:fixed-point-theorem-for-affine-actions-of-compact-groups"
data-reference-type="ref"
data-reference="thm:fixed-point-theorem-for-affine-actions-of-compact-groups">120</a>
tells us that an equivariant projection exists. Using this, we can
complete the proof of Theorem <a href="#thm:compact-implies-lin-red"
data-reference-type="ref"
data-reference="thm:compact-implies-lin-red">118</a> without directly
establishing the existence of <span
class="math inline">\(\mu\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 122</strong>. Let <span
class="math inline">\(G\)</span> be a compact group, let <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
be a finite-dimensional representation, let <span
class="math inline">\(S\)</span> be the space of hermitian forms on
<span class="math inline">\(V\)</span>, and let <span
class="math inline">\(M \subseteq S\)</span> be the subset of positive
definite hermitian forms (i.e., inner products). Then <span
class="math inline">\(G\)</span> acts on <span
class="math inline">\(S\)</span> by <span class="math inline">\((g \cdot
B)(v_1,v_2) := B(R(g)^{-1} v_1, R(g)^{-1} v_2)\)</span>, and the
subspace <span class="math inline">\(M\)</span> is convex, nonempty and
<span class="math inline">\(G\)</span>-invariant. An inner product <span
class="math inline">\(B \in M\)</span> is <span
class="math inline">\(G\)</span>-invariant in the present sense if and
only if it is invariant in the sense defined above, so Theorem <a
href="#thm:fixed-point-theorem-for-affine-actions-of-compact-groups"
data-reference-type="ref"
data-reference="thm:fixed-point-theorem-for-affine-actions-of-compact-groups">120</a>
tells us that an invariant inner product exists.</p>
</div>
<h2 id="sec:orgfb8c0e1">§16.9. Constructing new representations from old
ones</h2>
<h3 id="sec:org3c4515a">§16.9.1. Direct sum</h3>
<p>Given a pair of representations <span class="math inline">\(V_1,
V_2\)</span> of a Lie group <span class="math inline">\(G\)</span>, we
get a representation on their direct sum <span class="math inline">\(V_1
\oplus V_2\)</span> by <span class="math display">\[g (v_1 \oplus v_2)
:= g v_1 \oplus g v_2.\]</span> Similarly for representations of a Lie
algebra. The two constructions are compatible under differentiation.</p>
<h3 id="sec:orgb0fcad8">§16.9.2. Tensor product</h3>
<p>Given a pair of representations <span class="math inline">\(V_1,
V_2\)</span> of a Lie group <span class="math inline">\(G\)</span>, we
get a representation on their tensor product <span
class="math inline">\(V_1 \otimes V_2\)</span> by <span
class="math display">\[g (v_1 \otimes v_2) := g v_1 \otimes g
v_2.\]</span> If <span class="math inline">\(V_1, V_2\)</span> are
instead representations of a Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>, then the natural action to
take on their tensor product is <span class="math display">\[X (v_1
\otimes v_2) := X v_1 \otimes v_2 + v_1 \otimes X v_2.\]</span> One of
the homework problems for this week is to check that this in fact
defines a Lie algebra representation. We checked in class that if we
differentiate the first action, we get the second: <span
class="math display">\[\frac{d}{d t} (\exp(t X) v_1 \otimes \exp(t X)
v_2)|_{t=0}
  = X v_1 \otimes v_2 + v_1 \otimes X v_2.\]</span></p>
<h3 id="sec:org4d627e9">§16.9.3. Symmetric power representations<span
id="sec:constructing-sym-power"
label="sec:constructing-sym-power"></span></h3>
<p>Given a complex vector space <span class="math inline">\(V\)</span>
and <span class="math inline">\(t \in \mathbb{Z}_{\geq 0}\)</span>, the
<em>symmetric power</em> <span
class="math inline">\({\mathop{\mathrm{Sym}}}^t(V)\)</span> is the space
of homogeneous polynomials of degree <span
class="math inline">\(t\)</span> on the dual space <span
class="math inline">\(V^*\)</span>. Each element of <span
class="math inline">\(V\)</span> may be identified with a linear
polynomial on <span class="math inline">\(V^*\)</span>. Any element of
<span class="math inline">\({\mathop{\mathrm{Sym}}}^t(V)\)</span> may be
written as a finite linear combination of monomials <span
class="math inline">\(v_1 \dotsb v_t\)</span> with each <span
class="math inline">\(v_j \in V\)</span>. If <span
class="math inline">\(e_1,\dotsc,e_n\)</span> is a basis for <span
class="math inline">\(V\)</span>, then the polynomials <span
class="math inline">\(e_{i_1} \dotsb e_{i_t}\)</span> taken over all
indices satisfying <span class="math inline">\(1 \leq i_1 \leq \dotsb
\leq i_t \leq n\)</span> form a basis for <span
class="math inline">\({\mathop{\mathrm{Sym}}}^t(V)\)</span>.</p>
<p>Given a representation <span class="math inline">\(R : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> of a Lie group <span
class="math inline">\(G\)</span>, one obtains a symmetric power
representation <span class="math inline">\({\mathop{\mathrm{Sym}}}^n(R) :
G \rightarrow \mathop{\mathrm{GL}}({\mathop{\mathrm{Sym}}}^n(V))\)</span>
by setting: for <span class="math inline">\(v_1,\dotsc,v_t \in
V\)</span>, <span class="math display">\[({\mathop{\mathrm{Sym}}}^n(R)(g))
v_1 \dotsb v_t
  := (R(g) v_1) \dotsb (R(g) v_t).\]</span> (See Wikipedia or Google for
more details on this construction.)</p>
<h2 id="sec:orgc5f3d81">§16.10. Characters</h2>
<p>For each representation <span class="math inline">\(V\)</span> of
<span class="math inline">\(\mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>,
define the <em>character</em> of <span class="math inline">\(V\)</span>
to be the Laurent polynomial <span
class="math display">\[\operatorname{ch}(V) \in  A :=
\mathbb{Z}[z,z^{-1}]\]</span> given by <span
class="math display">\[\operatorname{ch}(V) :=
  \sum_{m \in \mathbb{Z}}
  (\dim V[m]) z^m,\]</span> where <span class="math inline">\(V[m] :=
\{v \in V : H v = m v\}\)</span> with <span class="math inline">\(H =
\left(
  \begin{smallmatrix}
    1&amp;\\
    &amp;-1
  \end{smallmatrix}
\right) \in \mathfrak{g}\)</span> as before. (By this point in lecture,
we saw that the action of <span class="math inline">\(H\)</span> on any
finite-dimensional representation is diagonalizable, so <span
class="math inline">\(V = \oplus V[m]\)</span>.) For example, for the
irreducible representations <span class="math inline">\(W_m\)</span>
(<span class="math inline">\(m \in \mathbb{Z}_{\geq 0}\)</span>)
considered in lecture, we have <span
class="math inline">\(\operatorname{ch}(W_m) = \sum_{-m \leq j \leq m :
j \equiv m(2)} z^m
= z^m + z^{m-2} + \dotsb + z^{-m}\)</span>. Such functions are
<em>symmetric</em> (i.e., invariant under <span class="math inline">\(z
\mapsto z^{-1}\)</span>.) The <em>Weyl denominator</em> is the element
<span class="math display">\[D := z - z^{-1} \in A.\]</span> It is the
simplest example of an <em>anti-symmetric</em> element of <span
class="math inline">\(A\)</span>. One has <span class="math display">\[D
\cdot \operatorname{ch}(W_m)
  = z^{m+1} - z^{-(m+1)}.\]</span> In other words, <em>as <span
class="math inline">\(V\)</span> traverses the set of isomorphism
classes of irreducible representations, <span class="math inline">\(D
\cdot \operatorname{ch}(V)\)</span> traverses the “obvious” basis for
the space of anti-symmetric elements of <span
class="math inline">\(A\)</span></em>.</p>
<p>For a finite-dimensional representation <span class="math inline">\(R
: G \rightarrow \mathop{\mathrm{GL}}(V)\)</span> of <span
class="math inline">\(G :=
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>, one has <span
class="math display">\[\operatorname{ch}(V)|_{z=e^{i \theta}}
  =
  \mathop{\mathrm{trace}}(R(
\begin{pmatrix}
    e^{i \theta} &amp;  \\
     &amp; e^{-i \theta}
  \end{pmatrix}
)).\]</span></p>
<p>The character satisfies <span
class="math display">\[\operatorname{ch}(V_1 \oplus V_2) =
\operatorname{ch}(V_1) + \operatorname{ch}(V_2),\]</span> <span
class="math display">\[\operatorname{ch}(V_1 \otimes V_2) =
\operatorname{ch}(V_1) \operatorname{ch}(V_2).\]</span> This is easily
seen by taking a basis <span
class="math inline">\(e_1,\dotsc,e_m\)</span> of <span
class="math inline">\(H\)</span>-eigenvectors for <span
class="math inline">\(V_1\)</span> and a basis <span
class="math inline">\(f_1,\dotsc,f_m\)</span> of <span
class="math inline">\(H\)</span>-eigenvectors for <span
class="math inline">\(V_2\)</span> and using that <span
class="math inline">\(e_1,\dotsc,e_m,f_1,\dotsc,f_m\)</span> is then a
basis of <span class="math inline">\(H\)</span>-eigenvectors for <span
class="math inline">\(V_1 \oplus V_2\)</span> while <span
class="math inline">\(e_i \otimes f_j\)</span> give a basis of <span
class="math inline">\(H\)</span>-eigenvectors for <span
class="math inline">\(V_1 \otimes V_2\)</span>.</p>
<p>If we’re given a representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span>, we know that we can
decompose <span class="math display">\[V \cong  \oplus_{m \geq 0}
W_m^{\mu(m)}\]</span> for some multiplicities <span
class="math inline">\(\mu(m) \geq 0\)</span>. We can determine the
multiplicities easily if we know the character of <span
class="math inline">\(V\)</span>, and particularly easily if we multiply
first by the Weyl denominator: we have <span class="math display">\[D
\cdot \operatorname{ch}(V)
  = \sum_{m \geq 0} \mu(m) D \cdot \operatorname{ch}(W_m)
  = \sum_{m \geq 0}
  \mu(m)
  (z^{m+1} - z^{-m-1}),\]</span> so we can read off the multiplicity
<span class="math inline">\(\mu(m)\)</span> of <span
class="math inline">\(W_m\)</span> inside <span
class="math inline">\(V\)</span> as the coefficient of <span
class="math inline">\(z^{m+1}\)</span> in the anti-symmetric Laurent
polynomial <span class="math inline">\(D \cdot
\operatorname{ch}(V)\)</span>. For example, in this way (or in others)
we can easily derive the <em>Clebsh–Gordon decomposition</em> <span
class="math display">\[W_m \otimes W_n \cong
  W_{m+n} \oplus W_{m+n-2} \oplus \dotsb \oplus W_{|m-n|}
  = \oplus_{
    \substack{
      |m-n| \leq j \leq m+n :  \\
      j \equiv m+n (2)
    }
  } W_j\]</span> from the polynomial identity: for <span
class="math inline">\(m \geq n\)</span> (say), <span
class="math display">\[(z^{m+1} - z^{-m-1}) (z^n + z^{n-2} + \dotsb +
z^{-n})
  =
  \sum _{\substack{
      m-n \leq j \leq m + n : \\
      j \equiv m+n(2)
    }
  }
  (z^{j + 1} - z^{-j-1}).\]</span> We can make this more explicit, e.g.,
the isomorphism <span class="math display">\[W_2 \oplus W_0 \cong W_1
\otimes W_1\]</span> can be given by identifying <span
class="math inline">\(W_2 = \mathbb{C}[z,w]_{(2)}\)</span> and <span
class="math inline">\(W_0 = \mathbb{C}\)</span> and <span
class="math inline">\(W_1 = \mathbb{C}[x,y]_{(1)}\)</span> (where a
subscripted <span class="math inline">\((n)\)</span> denotes homogeneous
elements of order <span class="math inline">\(n\)</span>) and the map
<span class="math display">\[W_0 \rightarrow W_1 \otimes W_1\]</span> is
given by <span class="math display">\[1 \mapsto (x \otimes y - y \otimes
x)/2\]</span> and the map <span class="math display">\[W_2 \rightarrow
W_1 \otimes W_1\]</span> by <span class="math display">\[z^2 \mapsto x
\otimes x,\]</span> <span class="math display">\[w^2 \mapsto y \otimes
y,\]</span> <span class="math display">\[z w \mapsto (x \otimes y + y
\otimes x)/2.\]</span> See any introductory textbook on quantum
mechanics for more on the importance of these sorts of decompositions in
physics.</p>
<h1 id="sec:orgb4bc044">§17. The unitary trick<span id="sec:unitary-trick"
label="sec:unitary-trick"></span></h1>
<div class="definition">
<p><strong>Definition 123</strong>. Let <span
class="math inline">\(\mathfrak{g}\)</span> be a complex Lie algebra.
Let <span class="math inline">\(\mathfrak{h}\)</span> be a real Lie
algebra. We say that</p>
<ul>
<li><p><span class="math inline">\(\mathfrak{h}\)</span> is a <em>real
form</em> of <span class="math inline">\(\mathfrak{g}\)</span>, or
equivalently, that</p></li>
<li><p><span class="math inline">\(\mathfrak{g}\)</span> is the
<em>complexification</em> of <span
class="math inline">\(\mathfrak{h}\)</span>,</p></li>
</ul>
<p>if <span class="math inline">\(\mathfrak{h}\)</span> is (isomorphic
to) a real Lie subalgebra of <span
class="math inline">\(\mathfrak{g}\)</span> for which <span
class="math display">\[\mathfrak{g} = \mathfrak{h} \oplus i
\mathfrak{h},\]</span> or equivalently, for which the natural map <span
class="math inline">\(\mathfrak{h} \otimes_\mathbb{R} \mathbb{C}
\rightarrow
  \mathfrak{g}\)</span> is an isomorphism. In other words, every <span
class="math inline">\(z \in \mathfrak{g}\)</span> may be expressed
uniquely as <span class="math inline">\(x + i y\)</span> with <span
class="math inline">\(x,y \in \mathfrak{h}\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 124</strong>. <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{R})\)</span>
and <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(n)\)</span>
are real forms of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>;
<span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(n)\)</span>
is a real form of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_n(\mathbb{C})\)</span>.
<span
class="math inline">\(\mathfrak{g}\mathfrak{l}_n(\mathbb{R})\)</span>
and <span class="math inline">\(\mathfrak{u}(n)\)</span> are real forms
of <span
class="math inline">\(\mathfrak{g}\mathfrak{l}_n(\mathbb{C})\)</span>. A
bit less obviously, <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(p,q)\)</span>
is (isomorphic to) a real form of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_n(\mathbb{C})\)</span>
(try to check this!).</p>
</div>
<div id="lem:real-froms-same-reps-1" class="lemma">
<p><strong>Lemma 125</strong>. Let <span
class="math inline">\(L\)</span> be any complex Lie algebra. Let <span
class="math inline">\(\mathfrak{g}\)</span> be a complex Lie algebra and
<span class="math inline">\(\mathfrak{h}\)</span> a real form of <span
class="math inline">\(\mathfrak{g}\)</span>. Then the natural
restriction map <span class="math display">\[\left\{
      \begin{gathered}
        \text{morphisms of complex Lie algebras} \\
        \Phi : \mathfrak{g} \rightarrow L
      \end{gathered}
    \right\}
    \rightarrow
    \left\{
      \begin{gathered}
        \text{morphisms of real Lie algebras} \\
        \phi : \mathfrak{h} \rightarrow L
      \end{gathered}
    \right\}\]</span> is a bijective.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Given <span class="math inline">\(\Phi\)</span>, one
defines <span class="math inline">\(\phi\)</span> by restriction. Given
<span class="math inline">\(\phi\)</span>, one defines <span
class="math inline">\(\Phi(x + i y) := \phi(x) + i
  \phi(y)\)</span>. One checks that the associations <span
class="math inline">\(\phi \mapsto \Phi\)</span> and <span
class="math inline">\(\Phi \mapsto \phi\)</span> are mutually inverse,
and that one defines a Lie algebra morphism (over the relevant field) if
and only if the other does. (One could alternatively take the conclusion
of this lemma as the <em>definition</em> of real form/complexification,
as in the functorial characterization of tensor product.) ◻</p>
</span></div>
<div id="ex:complex-vs-real-reps" class="example">
<p><strong>Example 126</strong>. Suppose <span class="math inline">\(L =
\mathop{\mathrm{End}}(V)\)</span> for a complex vector space <span
class="math inline">\(V\)</span>. Then Lemma <a
href="#lem:real-froms-same-reps-1" data-reference-type="ref"
data-reference="lem:real-froms-same-reps-1">125</a> says that for a
complex Lie algebra <span class="math inline">\(\mathfrak{g}\)</span>
with real form <span class="math inline">\(\mathfrak{h}\)</span>, the
following sets are in natural bijection:</p>
<ol>
<li><p>holomorphic representations <span class="math inline">\(\rho :
\mathfrak{g} \rightarrow \mathop{\mathrm{End}}(V)\)</span>.</p></li>
<li><p>representations <span class="math inline">\(\rho_0 : \mathfrak{h}
\rightarrow \mathop{\mathrm{End}}(V)\)</span>.</p></li>
</ol>
<p>Moreover, the invariant subspaces <span
class="math inline">\(W\)</span> for <span
class="math inline">\(\rho\)</span> and <span
class="math inline">\(\rho_0\)</span> are the same. In particular, <span
class="math inline">\(\rho\)</span> is irreducible if and only if <span
class="math inline">\(\rho_0\)</span> is irreducible, and also <span
class="math inline">\(\rho\)</span> is completely reducible if and only
if <span class="math inline">\(\rho_0\)</span> is completely
reducible.</p>
</div>
<div class="definition">
<p><strong>Definition 127</strong>. Let <span
class="math inline">\(G\)</span> be a connected complex Lie group. A
<em>real form</em> of <span class="math inline">\(G\)</span> is a
connected real Lie subgroup <span class="math inline">\(H \leq
G\)</span> with the property that the Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span> of <span
class="math inline">\(H\)</span> is a real form of the Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> of <span
class="math inline">\(G\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 128</strong>. <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span> and
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> are real
forms of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>. <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{R})\)</span> and
<span class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span> are real
forms of <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span>. <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span> and <span
class="math inline">\(\mathop{\mathrm{SO}}(p,q)^0\)</span> (<span
class="math inline">\(p + q = n\)</span>) are real forms of <span
class="math inline">\({\mathop{\mathrm{SO}}}_n(\mathbb{C})\)</span>.</p>
</div>
<div id="thm:real-form-implies-linearly-reductive" class="theorem">
<p><strong>Theorem 129</strong>. <em>Let <span
class="math inline">\(G\)</span> be a connected complex Lie group.
Suppose that <span class="math inline">\(G\)</span> has a compact
(connected) real form. Then <span class="math inline">\(G\)</span> is
linearly reductive.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(H\)</span> be a
compact (connected) real form of <span class="math inline">\(G\)</span>,
and denote Lie algebras in the usual way. Let <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
be a finite-dimensional representation of <span
class="math inline">\(G\)</span>. We wish to show that <span
class="math inline">\(V\)</span> is completely reducible under <span
class="math inline">\(G\)</span>. We have seen in Lemma <a
href="#lem:complete-irreducible-gp-vs-alg" data-reference-type="ref"
data-reference="lem:complete-irreducible-gp-vs-alg">108</a> that <span
class="math inline">\(V\)</span> is completely reducible under <span
class="math inline">\(G\)</span> if and only if it is under <span
class="math inline">\(\mathfrak{g}\)</span>, and likewise that <span
class="math inline">\(V\)</span> is completely reducible under <span
class="math inline">\(H\)</span> if and only if it is under <span
class="math inline">\(\mathfrak{h}\)</span>. By Lemma <a
href="#lem:real-froms-same-reps-1" data-reference-type="ref"
data-reference="lem:real-froms-same-reps-1">125</a>, we know that <span
class="math inline">\(V\)</span> is completely reducible under <span
class="math inline">\(\mathfrak{g}\)</span> if and only if it is under
<span class="math inline">\(\mathfrak{h}\)</span>. In summary, <span
class="math inline">\(V\)</span> is completely reducible under any one
of <span class="math inline">\(G,\mathfrak{g},\mathfrak{h},H\)</span> if
and only if it is under all of them. Since compact Lie groups as
linearly reductive (Theorem <a href="#thm:compact-implies-lin-red"
data-reference-type="ref"
data-reference="thm:compact-implies-lin-red">118</a>), we know that
<span class="math inline">\(V\)</span> is completely reducible under
<span class="math inline">\(H\)</span>, so we are done. ◻</p>
</span></div>
<div class="example">
<p><strong>Example 130</strong>. It follows that the groups <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> (e.g.,
<span class="math inline">\(\mathbb{C}^\times\)</span>) <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span>, <span
class="math inline">\({\mathop{\mathrm{SO}}}_n(\mathbb{C})\)</span> are
linearly reductive.</p>
</div>
<div class="remark">
<p><strong>Remark 131</strong>. Let <span
class="math inline">\(G\)</span> be a connected complex Lie group which
has a compact (connected) real form, then we have seen that <span
class="math inline">\(G\)</span>, as well as its compact (connected)
real form, is linearly reductive. However, it need not be the case that
every real form <span class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span> is linearly reductive; consider for
instance the case <span class="math inline">\(G = \mathbb{C}^\times,
  H = \mathbb{R}^\times\)</span>. (This is another example where things
become nicer by working in the category of algebraic groups; compare
with Remark <a href="#rmk:lie-vs-alg" data-reference-type="ref"
data-reference="rmk:lie-vs-alg">116</a>.)</p>
</div>
<p>In the proof of Theorem <a
href="#thm:real-form-implies-linearly-reductive"
data-reference-type="ref"
data-reference="thm:real-form-implies-linearly-reductive">129</a>, the
notion of “completely reducible” relevant for the representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\(\mathfrak{h}\)</span> is that there exist no
invariant complex subspaces. One can ask what happens if one works
instead with invariant real subspaces:</p>
<div class="exercise">
<p><strong>Exercise 19</strong>. Let <span
class="math inline">\(V\)</span> be a complex vector space and <span
class="math inline">\(\mathop{\mathrm{End}}(V)\)</span> the Lie algebra
of <span class="math inline">\(\mathbb{C}\)</span>-linear endomorphisms
of <span class="math inline">\(V\)</span>. Let <span
class="math inline">\(\mathfrak{h}\)</span> be a real Lie algebra and
<span class="math inline">\(\rho : \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> a morphism.</p>
<p>Let <span class="math inline">\(W \leq V\)</span> be a real subspace
(i.e., a subspace of the real vector space underlying <span
class="math inline">\(V\)</span>).</p>
<ol>
<li><p>Show that if <span class="math inline">\(W\)</span> is invariant
or irreducible (under the action by <span
class="math inline">\(\mathfrak{h}\)</span>), then so is <span
class="math inline">\(i W\)</span>.</p></li>
<li><p>Suppose that <span class="math inline">\(W\)</span> is invariant
and irreducible. Show that either</p>
<ol>
<li><p><span class="math inline">\(W = i W\)</span>, in which case <span
class="math inline">\(W\)</span> is an invariant irreducible complex
subspace, or</p></li>
<li><p><span class="math inline">\(W \cap i W = \{0\}\)</span>, in which
case <span class="math inline">\(W + i W\)</span> is an invariant
irreducible complex subspace.</p></li>
</ol>
<p>Deduce that if <span class="math inline">\(V\)</span> decomposes as a
direct sum of invariant irreducible real subspaces, then it also
decomposes as a direct sum of invariant irreducible complex
subspaces.</p></li>
</ol>
</div>
<p>Let us work out the complexification of <span class="math inline">\(H
:= \mathop{\mathrm{SO}}(p,q)^0\)</span>. Recall that <span
class="math inline">\(\mathop{\mathrm{SO}}(p,q) = \{g \in
{\mathop{\mathrm{SL}}}_{p+q}(\mathbb{R}) : g I_{p,q} g^t =
I_{p,q}\}\)</span> where <span class="math inline">\(I_{p,q} :=
\mathop{\mathrm{diag}}(1,\dotsc,1,-1,\dotsc,-1)\)</span>, thus <span
class="math display">\[\mathfrak{h} = \{X \in
{\mathop{\mathrm{SL}}}_{p+q}(\mathbb{R}) :
  X I_{p,q} + I_{p,q} X^t = 0 \}
  = \left\{
\begin{pmatrix}
      A &amp; B \\
      C &amp; D
    \end{pmatrix}
\in M_{p+q}(\mathbb{R})
    : A^t = - A, D^t = - D, B^t = C \right\}.\]</span> The
complexification is given by <span class="math display">\[\mathfrak{h}
\otimes_{\mathbb{R}} \mathbb{C}
  \cong
  \mathfrak{h}  \oplus i \mathfrak{h}
  =
   \left\{
\begin{pmatrix}
      A &amp; B \\
      C &amp; D
    \end{pmatrix}
\in M_{p+q}(\mathbb{C}) : A^t = - A, D^t = -
    D, B^t= C
  \right\} \subseteq M_{p+q}(\mathbb{C}).\]</span> If <span
class="math inline">\(\varepsilon:=
\mathop{\mathrm{diag}}(i,\dotsc,i,1,\dotsc,1)\)</span>, then we can
check easily that <span class="math display">\[\varepsilon(\mathfrak{h}
\oplus i \mathfrak{h}) \varepsilon^{-1}
  =
  {\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{p+q}(\mathbb{C}).\]</span>
Thus the complexification of <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(p,q)\)</span>
is isomorphic to <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{p+q}(\mathbb{C})\)</span>.
Similarly, <span
class="math inline">\(\mathop{\mathrm{SO}}(p,q)^0\)</span> is
(isomorphic to) a real form of <span
class="math inline">\({\mathop{\mathrm{SO}}}_{p+q}(\mathbb{C})\)</span>;
just consider <span
class="math display">\[\varepsilon\mathop{\mathrm{SO}}(p,q)^0
\varepsilon^{-1}
  \leq {\mathop{\mathrm{SO}}}_{p+q}(\mathbb{C}) \leq
{\mathop{\mathrm{SL}}}_{p+q}(\mathbb{C}).\]</span></p>
<p>To cook up some more interesting examples, let <span
class="math display">\[\mathbb{H} :=
  \left\{
\begin{pmatrix}
      z &amp; w \\
      -\overline{w} &amp;  \overline{z}
    \end{pmatrix}
: z,w \in \mathbb{C}  \right\}
  \subseteq M_2(\mathbb{C})\]</span> denote Hamilton’s quaternion
algebra over the reals. (It is an associative algebra with center <span
class="math inline">\(\mathbb{R}\)</span> and of dimension <span
class="math inline">\(4\)</span> over its center.) There is a natural
involution <span class="math inline">\(x \mapsto x^*\)</span> on <span
class="math inline">\(\mathbb{H}\)</span>, given by <span
class="math inline">\(x^* := \overline{x}^t\)</span>, or equivalently,
<span class="math display">\[\begin{pmatrix}
    a &amp; b \\
    c &amp; d
  \end{pmatrix}
^*
  =
  \begin{pmatrix}
    d &amp; -b \\
    -c &amp; a
  \end{pmatrix}
.\]</span> Then <span class="math inline">\(\mathbb{H}^\times\)</span>
is a Lie group and <span
class="math display">\[\mathop{\mathrm{Lie}}(\mathbb{H}^\times) =
\mathbb{H}.\]</span> The space <span
class="math inline">\(M_n(\mathbb{H})\)</span> of <span
class="math inline">\(n \times n\)</span> matrices with quaternionic
entries can be regarded as a subspace of <span
class="math inline">\(M_{2 n}(\mathbb{C})\)</span>. Set <span
class="math display">\[{\mathop{\mathrm{SL}}}_n(\mathbb{H}) :=
  M_n(\mathbb{H}) \cap {\mathop{\mathrm{SL}}}_{2n}(\mathbb{C})\]</span>
and <span class="math display">\[{\mathop{\mathrm{U}}}_n(\mathbb{H})
  :=
  \{ g \in M_n(\mathbb{H}) : g \overline{g^*} = 1 \}.\]</span> Recall
that <span class="math inline">\(\mathop{\mathrm{SU}}(p,q) = \{g \in
{\mathop{\mathrm{SL}}}_{p+q}(\mathbb{C}) :
g I_{p,q} \overline{g}^t = I_{p,q}
\}\)</span>.</p>
<div id="exe:complexifications" class="exercise">
<p><strong>Exercise 20</strong>. Determine the complexifications of the
Lie algebras of the following real Lie groups:</p>
<ol>
<li><p><span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{H})\)</span></p></li>
<li><p><span
class="math inline">\(\mathop{\mathrm{SU}}(p,q)\)</span></p></li>
<li><p><span
class="math inline">\({\mathop{\mathrm{U}}}_m(\mathbb{H})\)</span></p></li>
</ol>
<p>(Each is isomorphic to a classical complex Lie group we’re already
familiar with.)</p>
</div>
<p>It turns out that with this exercise and the examples given
previously, we’ve found all of the real forms of the complex Lie
algebras <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C}),
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_n(\mathbb{C})\)</span>.</p>
<div class="exercise">
<p><strong>Exercise 21</strong>. Let <span
class="math inline">\(\mathfrak{h} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>, but
regarded as a real Lie algebra rather than a complex one. (Concretely,
we can think of <span class="math inline">\(\mathfrak{h}\)</span> as a
real Lie subalgebra of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_{2
n}(\mathbb{R})\)</span>.) Show that one has an isomorphism of complex
Lie algebras <span class="math inline">\(\mathfrak{h}
\otimes_{\mathbb{R}} \mathbb{C}
  \cong {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})
\oplus  {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>.</p>
</div>
<div id="rmk:real-forms-vs-involutions" class="remark">
<p><strong>Remark 132</strong>. Let <span
class="math inline">\(\mathfrak{h}\)</span> be a real form of a complex
Lie algebra <span class="math inline">\(\mathfrak{g}\)</span>. Then
<span class="math inline">\(\mathfrak{h}\)</span> is the fixed point set
of the automorphism <span class="math inline">\(\sigma : \mathfrak{g}
\rightarrow \mathfrak{g}\)</span> given by identifying <span
class="math inline">\(\mathfrak{g}\)</span> with <span
class="math inline">\(\mathfrak{h}
  \otimes_{\mathbb{R}} \mathbb{C}\)</span> and requiring that for <span
class="math inline">\(X \in \mathfrak{h}\)</span> and <span
class="math inline">\(z \in \mathbb{C}\)</span>, one has <span
class="math inline">\(\sigma(X \otimes z) := X \otimes
\overline{z}\)</span>; in other words, if we identify <span
class="math inline">\(\mathfrak{g}\)</span> with <span
class="math inline">\(\mathfrak{h} \oplus i \mathfrak{h}\)</span>, then
<span class="math inline">\(\sigma(x + i y) := x - i y\)</span> for
<span class="math inline">\(x,y \in \mathfrak{h}\)</span>. Then <span
class="math inline">\(\sigma\)</span> is an involution on <span
class="math inline">\(\mathfrak{g}\)</span> (i.e., <span
class="math inline">\(\sigma^2\)</span> is the identity transformation);
moreover, <span class="math inline">\(\sigma\)</span> is a Lie algebra
automorphism that is anti-linear with respect to scalar multiplication
by complex numbers, i.e., for all <span class="math inline">\(c \in
\mathbb{C}\)</span>, <span class="math inline">\(Z \in
\mathfrak{g}\)</span>, <span class="math inline">\(\sigma(c Z) =
\overline{c} \sigma(Z)\)</span>, and satisfies <span
class="math inline">\(\sigma^2 = 1\)</span>.</p>
<p>Conversely, given an anti-linear involution <span
class="math inline">\(\sigma : \mathfrak{g} \rightarrow
\mathfrak{g}\)</span>, we claim that its fixed point subspace <span
class="math inline">\(\mathfrak{h} : \{X \in \mathfrak{g} : \sigma(X) =
X\}\)</span> is a real form of <span
class="math inline">\(\mathfrak{g}\)</span>. Well, since <span
class="math inline">\(\sigma\)</span> is a real Lie algebra
automorphism, we know at least that <span
class="math inline">\(\mathfrak{h}\)</span> is a real Lie subalgebra.
Observe that <span class="math inline">\(i \mathfrak{h} = \{X \in
\mathfrak{g} :
  \sigma(X) = - X\}\)</span>. Since <span
class="math inline">\(\mathfrak{g}\)</span> is the sum of the <span
class="math inline">\(+1\)</span> and <span
class="math inline">\(-1\)</span> eigenspaces of <span
class="math inline">\(\sigma\)</span>, we deduce that <span
class="math inline">\(\mathfrak{g} = \mathfrak{h} \oplus i
  \mathfrak{h}\)</span>. Hence <span
class="math inline">\(\mathfrak{h}\)</span> is a real form.</p>
</div>
<h1 id="sec:orga45c298">§18. Ad and ad</h1>
<h2 id="sec:org7eda827">§18.1. Basic definitions</h2>
<p>When one learns basic group theory (say of finite groups), one
studies groups <span class="math inline">\(G\)</span> acting on sets
<span class="math inline">\(X\)</span>. A particularly important action
is the conjugation action of <span class="math inline">\(G\)</span> on
itself, given by <span class="math inline">\((g,x) \mapsto g x
g^{-1}\)</span>. The orbits for this action are the conjugacy classes in
<span class="math inline">\(G\)</span>. Much nontrivial information
about <span class="math inline">\(G\)</span> can be extracted from a
careful study of the conjugation action of <span
class="math inline">\(G\)</span> on itself. For example, the Sylow
theorems are proved in this way.</p>
<p>When <span class="math inline">\(G\)</span> is a Lie group, one can
again consider the conjugation action of <span
class="math inline">\(G\)</span> on itself, but it turns out to be more
useful to differentiate this action a bit, so that tools from linear
algebra become at our disposal.</p>
<div class="definition">
<p><strong>Definition 133</strong>. Given a Lie group <span
class="math inline">\(G\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>, the <em>adjoint
representation</em> of <span class="math inline">\(G\)</span> is the map
<span class="math display">\[\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\]</span> is defined by <span
class="math display">\[\mathop{\mathrm{Ad}}(g) X := g X g^{-1},\]</span>
where the RHS may be interpreted in various ways:</p>
<ol>
<li><p>If <span class="math inline">\(G\)</span> is a subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>, then
<span class="math inline">\(\mathfrak{g}\)</span> is a subalgebra of
<span class="math inline">\(M_n(\mathbf{k})\)</span>, and so we can
interpret <span class="math inline">\(g X g^{-1}\)</span> as a product
of matrices.</p></li>
<li><p>We can use the trick of §<a
href="#sec:pretend-lie-groups-are-matrix-groups"
data-reference-type="ref"
data-reference="sec:pretend-lie-groups-are-matrix-groups">15</a>
(“pretending that every Lie group is a matrix Lie group”) to embed both
<span class="math inline">\(G\)</span> and <span
class="math inline">\(\mathfrak{g}\)</span> inside <span
class="math inline">\(\mathop{\mathrm{End}}(C^\infty(G))\)</span>; in
that optic, the product <span class="math inline">\(g X g^{-1}\)</span>
is given by composition.</p></li>
<li><p>(I don’t recommend spending too much time studying this
interpretation.) In general, for <span class="math inline">\(g \in
G\)</span> and <span class="math inline">\(x_0 \in G\)</span> and <span
class="math inline">\(X \in T_{x_0}(G)\)</span>, we can define <span
class="math inline">\(g X \in T_{g x_0}(G)\)</span> to be the image of
<span class="math inline">\(X\)</span> under the differential of left
translation by <span class="math inline">\(g\)</span>, i.e.,: if <span
class="math inline">\(\psi : G \rightarrow G\)</span> is the map <span
class="math inline">\(\psi(x) := g x\)</span>, then <span
class="math inline">\(g X := (T_{x_0} \psi)(X)\)</span> where <span
class="math inline">\(T_{x_0} \psi : T_{x_0}(G)  \rightarrow T_{g
x_0}(G)\)</span> is the derivative. We can similarly define <span
class="math inline">\(X g \in T_{x_0 g}(G)\)</span> using right
translations. This makes sense in particular when <span
class="math inline">\(x_0 = e\)</span> is the identity element, so that
<span class="math inline">\(T_{e} G = \mathfrak{g}\)</span>; then for
<span class="math inline">\(X \in \mathfrak{g}\)</span> we have <span
class="math inline">\(g X \in T_g G\)</span> and thus <span
class="math inline">\((g X) g^{-1} \in
    \mathfrak{g}\)</span>. Alternatively, we may first form <span
class="math inline">\(X g^{-1} \in T_{g^{-1}} G\)</span> and then <span
class="math inline">\(g (X g^{-1}) \in
    \mathfrak{g}\)</span>. The two answers are the same because left and
right translations commute with one another. (See §<a
href="#sec:translate-tangent-spaces-gp-elts" data-reference-type="ref"
data-reference="sec:translate-tangent-spaces-gp-elts">11.6</a>
for related discussion.)</p></li>
<li><p>For any <span class="math inline">\(g \in G\)</span> and <span
class="math inline">\(X \in \mathfrak{g}\)</span>, the map <span
class="math inline">\(\mathbf{k} \ni t \mapsto g \exp(t X)
g^{-1}\)</span> is a one-parameter subgroup, so its initial velocity is
an element of the Lie algebra: <span class="math display">\[g X g^{-1} =
\partial_{t=0}
      g \exp(t X) g^{-1}.\]</span></p></li>
</ol>
<p>It is clear that <span class="math inline">\(\mathop{\mathrm{Ad}}: G
\rightarrow \mathop{\mathrm{GL}}(\mathfrak{g})\)</span> is a morphism of
Lie groups.</p>
<p>Note that if <span class="math inline">\(G\)</span> is a real Lie
group, then <span class="math inline">\(\mathop{\mathrm{Ad}}\)</span> is
a real representation, not a complex representation of the sort that we
have primarily been considering. If <span
class="math inline">\(G\)</span> is a complex Lie group, then <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span> is a holomorphic
representation.</p>
</div>
<div id="exercise:conjugation-and-Ad-are-intertwined-by-exponential"
class="exercise">
<p><strong>Exercise 22</strong>. Let <span class="math inline">\(g \in
G, X \in \mathfrak{g}\)</span>. Show that <span class="math display">\[g
\exp(X) g^{-1}
    =
    \exp(\mathop{\mathrm{Ad}}(g) X).\]</span> Hint: one can either</p>
<ol>
<li><p>appeal to uniqueness of one-parameter subgroups (§<a
href="#sec:one-param-subgps" data-reference-type="ref"
data-reference="sec:one-param-subgps">13.2</a>),
or</p></li>
<li><p>apply the result of §<a href="#sec:exp-commutes-with-morphisms"
data-reference-type="ref"
data-reference="sec:exp-commutes-with-morphisms">13.6</a>
to <span class="math inline">\(f : G \rightarrow G\)</span> given by
<span class="math inline">\(f(a) := g a g^{-1}\)</span>.</p></li>
</ol>
</div>
<p>Since the Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> of a Lie group is a vector
space, we may form its linear dual <span
class="math inline">\(\mathfrak{g}^* :=
{\mathop{\mathrm{Hom}}}_{\mathbf{k}}(\mathfrak{g},\mathbf{k})\)</span>.
From some perspectives (which we might discuss eventually), the
following action is better behaved than the adjoint action:</p>
<div class="definition">
<p><strong>Definition 134</strong>. The <em>coadjoint
representation</em> of a Lie group <span
class="math inline">\(G\)</span> is the map <span
class="math display">\[{\mathop{\mathrm{Ad}}}^* : G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g}^*)\]</span> given for <span
class="math inline">\(g \in G, \lambda \in \mathfrak{g}^*, X \in
  \mathfrak{g}\)</span> by <span
class="math display">\[({\mathop{\mathrm{Ad}}}^*(g) \lambda)(X) :=
\lambda(\mathop{\mathrm{Ad}}(g)^{-1} X).\]</span></p>
</div>
<div class="exercise">
<p><strong>Exercise 23</strong>. Check that <span
class="math inline">\({\mathop{\mathrm{Ad}}}^*\)</span> is a
representation, but that it wouldn’t be in general had we omitted the
inverse in the definition.</p>
</div>
<div class="definition">
<p><strong>Definition 135</strong>. Given any Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> with Lie bracket <span
class="math inline">\(\mathfrak{g}\)</span>, we can define <span
class="math display">\[\mathop{\mathrm{ad}}: \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\]</span> by the formula <span
class="math display">\[(\mathop{\mathrm{ad}}(X))(Y) := [X,Y].\]</span>
We usually abbreviate the LHS to <span
class="math inline">\(\mathop{\mathrm{ad}}(X) Y\)</span>. We might
sometimes also abbreviate <span
class="math inline">\({\mathop{\mathrm{ad}}}_X :=
\mathop{\mathrm{ad}}(X)\)</span>, so that <span
class="math inline">\({\mathop{\mathrm{ad}}}_X Y = [X,Y]\)</span>. Recall
that the Jacobi identity may be written in the following equivalent
ways: <span id="eq:ad-is-a-morphism" class="math display">\[\label{eq:ad-is-a-morphism}\tag{72}
    [[X,Y],Z] = [[X,Z],Y] + [X,[Y,Z]],\]</span> <span id="eq:ad-X-is-a-derivation" class="math display">\[\label{eq:ad-X-is-a-derivation}\tag{73}
    [X,[Y,Z]] = [[X,Y],Z] + [Y,[X,Z]].\]</span> The first identity <a
href="#eq:ad-is-a-morphism" data-reference-type="eqref"
data-reference="eq:ad-is-a-morphism">\((72)\)</a> may be
interpreted as saying that <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{g}
  \rightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span> is a morphism
of Lie algebras, that is to say, that <span
class="math display">\[\mathop{\mathrm{ad}}([X,Y]) =
[\mathop{\mathrm{ad}}(X),\mathop{\mathrm{ad}}(Y)],\]</span> since indeed
<span class="math inline">\(\mathop{\mathrm{ad}}([X,Y]) Z =
[[X,Y],Z]\)</span> and <span
class="math inline">\([\mathop{\mathrm{ad}}(X),\mathop{\mathrm{ad}}(Y)]
Z
  = \mathop{\mathrm{ad}}(X) \mathop{\mathrm{ad}}(Y) Z -
\mathop{\mathrm{ad}}(Y) \mathop{\mathrm{ad}}(X) Z
  = \mathop{\mathrm{ad}}(X) [Y,Z] - \mathop{\mathrm{ad}}(Y) [X,Z]
  = [X,[Y,Z]] - [Y,[X,Z]]\)</span>. The second identity may be
interpreted as saying that that <span
class="math inline">\({\mathop{\mathrm{ad}}}_X\)</span> is a derivation
for each <span class="math inline">\(X \in \mathfrak{g}\)</span>, i.e.,
that <span class="math display">\[{\mathop{\mathrm{ad}}}_X [Y,Z] =
[{\mathop{\mathrm{ad}}}_X Y, Z] + [Y,{\mathop{\mathrm{ad}}}_X Z],\]</span>
i.e., that <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{g}) \subseteq
\mathop{\mathrm{Der}}(\mathfrak{g})\)</span>. So in summary, <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span> defines a morphism
of Lie algebras <span class="math display">\[\mathop{\mathrm{ad}}:
\mathfrak{g} \rightarrow \mathop{\mathrm{Der}}(\mathfrak{g}).\]</span>
One can already get <em>huge</em> mileage out of this simple statement
(see the tricky problem on this week’s homework). Note in particular
that it contains two different interpretations of the Jacobi
identity.</p>
</div>
<h2 id="sec:orgeaeefa5">§18.2. Relationship between <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span> and <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span></h2>
<p>The above definitions are related as follows:</p>
<div id="lem:dAd-is-ad" class="lemma">
<p><strong>Lemma 136</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Then the differential <span
class="math inline">\(d \mathop{\mathrm{Ad}}: \mathfrak{g}
  \rightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span> of the
morphism of Lie groups <span class="math inline">\(\mathop{\mathrm{Ad}}:
G \rightarrow \mathop{\mathrm{GL}}(\mathfrak{g})\)</span> is the
morphism of Lie algebras <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span>, that is to say, <span
class="math inline">\(d \mathop{\mathrm{Ad}}=
\mathop{\mathrm{ad}}\)</span>, or more verbosely, for any <span
class="math inline">\(X ,Y \in \mathfrak{g}\)</span>, <span
class="math display">\[\partial_{s=0}
    \mathop{\mathrm{Ad}}(\exp(s X)) Y = \mathop{\mathrm{ad}}(X)
Y.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The RHS is <span
class="math inline">\(\mathop{\mathrm{ad}}(X) Y = [X,Y]\)</span>. We
expand out its definition and compute, obtaining <span
class="math display">\[\begin{align}
&amp;:=
      \partial_{s=0} \partial_{t=0} (e^{s X}, e^{t Y})
      \\
    &amp;=
      \partial_{s=0} \partial_{t=0}  e^{s X} e^{t Y} e^{-s X} e^{-t Y}
      \\
    &amp;=
      \partial_{s=0} (e^{s X} Y e^{-s X}  - Y )
      \\
    &amp;=
      \partial_{s=0} \mathop{\mathrm{Ad}}(e^{s X}) Y,
  
\end{align}\]</span> as required. ◻</p>
</span></div>
<h2 id="sec:orgeedd74d">§18.3. Interpretation of the Jacobi identity</h2>
<div class="remark">
<p><strong>Remark 137</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group. When we defined its Lie
algebra <span class="math inline">\(\mathfrak{g}\)</span> and defined
the Lie bracket <span class="math inline">\([,]\)</span>, we
<em>promised</em> that the Jacobi identity followed from the
associativity of the group law on <span
class="math inline">\(G\)</span>, but didn’t prove it. We can now give a
rigorous and fairly conceptual proof: Recall that we proved that any
morphism <span class="math inline">\(f : G \rightarrow H\)</span> of Lie
groups induces a morphism <span class="math inline">\(d f : \mathfrak{g}
\rightarrow
  \mathfrak{h}\)</span> of Lie algebras. Applying this fact with <span
class="math inline">\(H := \mathop{\mathrm{GL}}(\mathfrak{g})\)</span>
to the adjoint representation <span class="math inline">\(f :=
\mathop{\mathrm{Ad}}\)</span> implies that <span
class="math inline">\(\mathop{\mathrm{ad}}= d
\mathop{\mathrm{Ad}}\)</span> is a morphism of Lie algebras. But we saw
above that this last assertion is equivalent to the Jacobi identity.
(Exercise: check carefully that we haven’t used circular reasoning
here.)</p>
</div>
<h2 id="sec:orgcb8cdaf">§18.4. <span
class="math inline">\(\mathop{\mathrm{Ad}},
\mathop{\mathrm{ad}}\)</span> are intertwined by the exponential
map<span id="sec:Ad-ad-intertwined-exp"
label="sec:Ad-ad-intertwined-exp"></span></h2>
<p>Let <span class="math inline">\(G\)</span> be a Lie group with Lie
algebra <span class="math inline">\(\mathfrak{g}\)</span>. One has maps
<span class="math display">\[\exp : \mathfrak{g} \rightarrow G\]</span>
and also a map <span class="math display">\[\exp :
\mathop{\mathrm{End}}(\mathfrak{g}) \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\]</span> (the matrix exponential).
The adjoint maps defined above are intertwined by these exponential
maps, that is to say, <span
class="math inline">\(\mathop{\mathrm{Ad}}\circ \exp = \exp \circ
\mathop{\mathrm{ad}}\)</span>, or more verbosely, for each <span
class="math inline">\(X \in \mathfrak{g}\)</span>, <span
class="math display">\[\mathop{\mathrm{Ad}}(\exp(X)) =
\exp(\mathop{\mathrm{ad}}(X))
  :=
  \sum_{n = 0}^{\infty} \frac{\mathop{\mathrm{ad}}(X)^n}{n!},\]</span>
or even more verbosely, for each <span class="math inline">\(X,Y \in
\mathfrak{g}\)</span>, <span class="math display">\[\exp(X) Y \exp(-X)
  =\mathop{\mathrm{Ad}}(\exp(X)) Y
  =
  \sum_{n=0}^{\infty}
  \frac{\mathop{\mathrm{ad}}(X)^n Y}{n!}
  =
  \sum_{n=0}^{\infty}
  \frac{[X,[X,\dotsc,[X,Y]]]}{n!}\]</span> where there are <span
class="math inline">\(n\)</span> copies of <span
class="math inline">\(X\)</span> in the iterated commutator on the RHS.
One can prove this by writing the LHS and RHS as <span
class="math inline">\(\Phi_1(1)\)</span> and <span
class="math inline">\(\Phi_2(1)\)</span> respectively, where <span
class="math inline">\(\Phi_1(t) := \mathop{\mathrm{Ad}}(\exp(t
X))\)</span> and <span class="math inline">\(\Phi_2(t) :=
\exp(\mathop{\mathrm{ad}}(t
X))
= \exp(t \mathop{\mathrm{ad}}(X))\)</span> are one-parameter subgroups
in <span
class="math inline">\(\mathop{\mathrm{GL}}(\mathfrak{g})\)</span>; by
Lemma <a href="#lem:dAd-is-ad" data-reference-type="ref"
data-reference="lem:dAd-is-ad">136</a>, we have <span
class="math inline">\(\Phi_1&#39;(0) = d \mathop{\mathrm{Ad}}(X) =
\mathop{\mathrm{ad}}(X) = \Phi_2&#39;(0)\)</span>, hence by the
uniqueness of one-parameter subgroups the two sides coincide. This
identity is already not entirely obvious in the matrix case <span
class="math inline">\(G = {\mathop{\mathrm{GL}}}_n(\mathbf{k})\)</span>;
it is instructive to verify it directly in that case.</p>
<h2 id="sec:orgcb7a112">§18.5. Some low-rank exceptional isomorphisms induced
by the adjoint representation<span
id="sec:low-rank-exceptional-isomorphisms"
label="sec:low-rank-exceptional-isomorphisms"></span></h2>
<p>The adjoint representation <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span> of the groups <span
class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C}),
\mathop{\mathrm{SU}}(2), {\mathop{\mathrm{SL}}}_2(\mathbb{R})\)</span>
induce the exceptional isomorphisms <span
class="math display">\[{\mathop{\mathrm{PSL}}}_2(\mathbb{C}) :=
{\mathop{\mathrm{SL}}}_2(\mathbb{C}) / \{\pm 1\}
  \cong {\mathop{\mathrm{SO}}}_3(\mathbb{C}),\]</span> <span
class="math display">\[\mathop{\mathrm{SU}}(2) / \{\pm 1\}
  \cong \mathop{\mathrm{SO}}(3),\]</span> <span
class="math display">\[{\mathop{\mathrm{PSL}}}_2(\mathbb{R}) :=
{\mathop{\mathrm{SL}}}_2(\mathbb{R}) / \{\pm 1\}
  \cong \mathop{\mathrm{SO}}(1,2)^0.\]</span> We explained this in
detail in class for the first two examples and left the third as an
exercise. The adjoint representations <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span> of the corresponding
Lie algebras likewise induce isomorphisms <span
class="math display">\[{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
\cong {\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_3(\mathbb{C}),\]</span>
<span
class="math display">\[\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)
\cong \mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(3),\]</span> <span
class="math display">\[{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{R})
\cong \mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}(1,2).\]</span> (Note
that <span
class="math inline">\(\mathop{\mathrm{Lie}}({\mathop{\mathrm{PSL}}}_2(\mathbb{C}))
= \mathop{\mathrm{Lie}}({\mathop{\mathrm{SL}}}_2(\mathbb{C}))\)</span>,
etc., because <span class="math inline">\(\{\pm 1\}\)</span> is
discrete.)</p>
<p>We spent some time in class introducing some terminology for
interpreting the above isomorphisms in a natural way.</p>
<div class="definition">
<p><strong>Definition 138</strong>. Let <span
class="math inline">\(\mathbf{k}\)</span> be a field, perhaps of
characteristic <span class="math inline">\(\neq
  2\)</span>. A (non-degenerate) <em>quadratic space <span
class="math inline">\(V\)</span> over <span
class="math inline">\(\mathbf{k}\)</span></em> is a pair <span
class="math inline">\(V = (V,Q)\)</span>, where</p>
<ol>
<li><p><span class="math inline">\(V\)</span> is a finite-dimensional
<span class="math inline">\(\mathbf{k}\)</span>-vector space,
and</p></li>
<li><p><span class="math inline">\(Q\)</span> is a map <span
class="math inline">\(Q : V \rightarrow \mathbf{k}\)</span> for which
the map <span class="math inline">\(B := B_Q : V \times V \rightarrow
\mathbf{k}\)</span> defined by <span class="math inline">\(B(x,y) :=
Q(x+y) - Q(x) - Q(y)\)</span> has the properties:</p>
<ol>
<li><p><span class="math inline">\(B\)</span> is <em>bilinear</em>,
i.e., <span class="math inline">\(B(a_1 x_1 + a_2 x_2, b_1 y_1 + b_2
y_2)
      = \sum_{i=1,2} \sum_{j=1,2} a_i b_j B_Q(x_i,y_j)\)</span> for all
<span class="math inline">\(a_i,b_j \in \mathbf{k}\)</span> and <span
class="math inline">\(x_i,y_j \in V\)</span>;</p></li>
<li><p><span class="math inline">\(B\)</span> is <em>non-degenerate</em>
in the sense that for each nonzero <span class="math inline">\(x \in
V\)</span> there exists a nonzero <span class="math inline">\(y \in
      V\)</span> so that <span class="math inline">\(B(x,y) \neq
0\)</span>; equivalently, the map <span class="math inline">\(x \mapsto
B(x,\cdot)\)</span> defines a linear isomorphism from <span
class="math inline">\(V\)</span> to its linear dual <span
class="math inline">\(V^*\)</span>.</p></li>
</ol></li>
</ol>
<p>A <em>morphism</em> of quadratic spaces <span class="math inline">\(f
: (V_1,Q_1) \rightarrow (V_2,Q_2)\)</span> is a linear map <span
class="math inline">\(f : V_1 \rightarrow V_2\)</span> so that <span
class="math inline">\(Q_2 \circ f = Q_1\)</span>. Two such quadratic
spaces are thus <em>isomorphic</em> if there exists a linear isomorphism
<span class="math inline">\(f : V_1 \rightarrow V_2\)</span> satisfying
<span class="math inline">\(Q_2 \circ f = Q_1\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 139</strong>. If <span
class="math inline">\(\mathbf{k} = \mathbb{C}\)</span> and <span
class="math inline">\(n \in \mathbb{Z}_{\geq 0}\)</span>, then <span
class="math inline">\(V := \mathbb{C}^n\)</span> with <span
class="math inline">\(Q_{n}(x) := \sum_{i=1}^n x_i^2\)</span> is a
quadratic space, called the <em>standard <span
class="math inline">\(n\)</span>-dimensional quadratic space over <span
class="math inline">\(\mathbb{C}\)</span></em>.</p>
</div>
<div class="example">
<p><strong>Example 140</strong>. If <span
class="math inline">\(\mathbf{k} = \mathbb{R}\)</span> and <span
class="math inline">\(p,q \in \mathbb{Z}_{\geq 0}\)</span>, then <span
class="math inline">\(V := \mathbb{R}^{p+q}\)</span> with <span
class="math inline">\(Q_{p,q}(x) := \sum_{i=1}^p x_i^2 - \sum_{j=1}^q
x_{p+j}^2\)</span> is a quadratic space, called the <em>standard
quadratic space over <span class="math inline">\(\mathbb{R}\)</span> of
signature <span class="math inline">\((p,q)\)</span></em>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 141</strong>. <em>Over <span
class="math inline">\(\mathbf{k} = \mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span>, every quadratic space is
isomorphic to one of the above examples.</em></p>
</div>
<div class="definition">
<p><strong>Definition 142</strong>. Given a quadratic space <span
class="math inline">\(V = (V,Q)\)</span> over <span
class="math inline">\(\mathbf{k}\)</span> (take <span
class="math inline">\(\mathbf{k} = \mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span> for the purposes of this
course, although the construction applies more generally) we may define
its <em>orthogonal group</em> <span
class="math inline">\(\operatorname{O}(V) = \{g \in
\mathop{\mathrm{GL}}(V) : Q(g v) = Q(v) \text{ for all } v \in
  V\}\)</span> and <em>special orthogonal group</em> <span
class="math inline">\(\mathop{\mathrm{SO}}(V) = \operatorname{O}(V) \cap
\mathop{\mathrm{SL}}(V)\)</span>.</p>
</div>
<p>If two quadratic spaces are isomorphism, it is clear that their
(special) orthogonal groups are likewise isomorphic. The above
definition thus introduces no new groups beyond the examples <span
class="math inline">\(\operatorname{O}_n(\mathbb{C})\)</span>, <span
class="math inline">\(\operatorname{O}(n)\)</span>, <span
class="math inline">\(\operatorname{O}(p,q)\)</span>, <span
class="math inline">\({\mathop{\mathrm{SO}}}_n(\mathbb{C})\)</span>, <span
class="math inline">\(\mathop{\mathrm{SO}}(n)\)</span>, <span
class="math inline">\(\mathop{\mathrm{SO}}(p,q)\)</span> that we have
already seen, but it is sometimes convenient to be able to refer to them
in a coordinate-free manner.</p>
<div class="example">
<p><strong>Example 143</strong>. Over <span
class="math inline">\(\mathbf{k} = \mathbb{C}\)</span>, the space <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
with the quadratic form <span class="math inline">\(\det\)</span> is a
quadratic space. In fact, the linear map <span class="math inline">\(j :
\mathbb{C}^3 \rightarrow
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> given
by <span id="eq:coordinates-for-exceptional-isomorphism-sl2" class="math display">\[\label{eq:coordinates-for-exceptional-isomorphism-sl2}\tag{74}
        (x,y,z)
    \mapsto
\begin{pmatrix}
      i x &amp; y + i z \\
      -y + i z &amp; -i x
    \end{pmatrix}
    \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\]</span>
satisfies <span class="math inline">\(\det(j(x,y,z)) = x^2 + y^2 +
z^2\)</span>, and hence induces an explicit isomorphism of quadratic
spaces <span class="math display">\[(\mathbb{C}^3, Q_3)
    \cong
({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}),\det).\]</span>
Thus, in particular, <span
class="math display">\[\mathop{\mathrm{SO}}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}),\det)
\cong {\mathop{\mathrm{SO}}}_3(\mathbb{C}).\]</span></p>
</div>
<div class="example">
<p><strong>Example 144</strong>. Over <span
class="math inline">\(\mathbf{k} = \mathbb{R}\)</span>, the space <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span>
with the quadratic form <span class="math inline">\(\det\)</span> is a
quadratic space. In fact, the linear map <span class="math inline">\(j :
\mathbb{R}^3 \rightarrow
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span> given by <a
href="#eq:coordinates-for-exceptional-isomorphism-sl2"
data-reference-type="eqref"
data-reference="eq:coordinates-for-exceptional-isomorphism-sl2">\((74)\)</a>
satisfies <span class="math inline">\(\det(j(x,y,z)) = x^2 + y^2 +
z^2\)</span>, and hence induces an explicit isomorphism of quadratic
spaces <span
class="math display">\[\mathop{\mathrm{SO}}(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2),\det)
\cong \mathop{\mathrm{SO}}(3).\]</span></p>
</div>
<p>One of the homework problems for this week is to work out something
similar for <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{R})\)</span>.</p>
<p>Consider now the adjoint map <span
class="math display">\[\mathop{\mathrm{Ad}}:
{\mathop{\mathrm{SL}}}_2(\mathbb{C}) \rightarrow
\mathop{\mathrm{GL}}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})).\]</span>
Since <span class="math inline">\(\det(\mathop{\mathrm{Ad}}(g) X) =
\det(X)\)</span> for all <span class="math inline">\(g \in
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> and <span
class="math inline">\(X \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>, we
have in fact <span
class="math display">\[\mathop{\mathrm{Ad}}({\mathop{\mathrm{SL}}}_2(\mathbb{C}))
\subseteq
  \operatorname{O}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}),\det)
\cong \operatorname{O}_3(\mathbb{C}).\]</span> Since (as we have shown)
<span class="math inline">\({\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>
is connected, so is its image under <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span>, thus in fact <span
class="math display">\[\mathop{\mathrm{Ad}}({\mathop{\mathrm{SL}}}_2(\mathbb{C}))
\subseteq {\mathop{\mathrm{SO}}}_3(\mathbb{C}).\]</span> Similarly <span
class="math display">\[\mathop{\mathrm{ad}}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}))
  \subseteq
\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}),\det)
\cong {\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_3(\mathbb{C}).\]</span>
We may check easily that <span
class="math inline">\(\ker(\mathop{\mathrm{Ad}}) = \{\pm 1\}\)</span>
and <span class="math inline">\(\ker(\mathop{\mathrm{ad}}) =
\{0\}\)</span>; from this and a dimensionality check it follows that
<span class="math inline">\(\mathop{\mathrm{ad}}\)</span> is a linear
isomorphism and hence (using that <span
class="math inline">\({\mathop{\mathrm{SO}}}_3(\mathbb{C})\)</span> is
connected and that the exponential map has the properties that it has)
that <span class="math inline">\(\mathop{\mathrm{Ad}}:
{\mathop{\mathrm{SL}}}_2(\mathbb{C}) \rightarrow
{\mathop{\mathrm{SO}}}_3(\mathbb{C})\)</span> is surjective. We thereby
obtain an isomorphism <span
class="math display">\[{\mathop{\mathrm{SL}}}_2(\mathbb{C}) / \{\pm 1\}
\cong {\mathop{\mathrm{SO}}}_3(\mathbb{C}).\]</span> Similar arguments
give the other isomorphisms claimed above. The homework problems for
this week give some other interpretations.</p>
<div class="remark">
<p><strong>Remark 145</strong>. One can check that the inverse
isomorphism <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_3(\mathbb{C})
\xrightarrow{\cong }
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> is not
of the form <span class="math inline">\(d f\)</span> for some morphism
<span class="math inline">\(f\)</span> of Lie groups <span
class="math inline">\({\mathop{\mathrm{SO}}}_3(\mathbb{C}) \rightarrow
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>; we
shall return to this point later.</p>
</div>
<p>Using the above exceptional isomorphisms, together with the fact that
<span class="math inline">\(-1 \in
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span> acts on the irreducible
representation <span class="math inline">\(W_n\)</span> by the sign
<span class="math inline">\((-1)^n\)</span>, we deduce that the
irreducible representations of <span
class="math inline">\({\mathop{\mathrm{SO}}}_3(\mathbb{C})\)</span> are
given by the <span class="math inline">\(W_{2 n}\)</span> for all <span
class="math inline">\(n \geq 0\)</span>; the action of <span
class="math inline">\(g \in {\mathop{\mathrm{SO}}}_3(\mathbb{C})\)</span>
on <span class="math inline">\(W_{2 n}\)</span> is defined to be <span
class="math inline">\(R(\tilde{g})\)</span> for some preimage <span
class="math inline">\(\tilde{g} \in
{\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>. We should see next time a
bit more explicitly how this goes.</p>
<h1 id="sec:org6e14ee2">§19. Maurer–Cartan equations and applications</h1>
<h2 id="sec:org61f279c">§19.1. The equations<span id="sec:cartan-maurer-eqn"
label="sec:cartan-maurer-eqn"></span></h2>
<p>Let <span class="math inline">\(G\)</span> be a Lie group and a
smooth map <span class="math display">\[g : \mathbf{k}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
G.\]</span> We can think of <span class="math inline">\(g\)</span> as a
smooth parametrized surface, or as a family of (possibly disconnected)
curves <span class="math inline">\(t \mapsto g(t,s)\)</span> indexed by
a deformation parameter <span class="math inline">\(s\)</span>. The
velocity of the curve with parameter <span
class="math inline">\(s\)</span> may be described by the smooth map
<span class="math display">\[\xi : \mathbf{k}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\]</span> characterized by the equation <span
class="math display">\[\frac{\partial g}{\partial t} = g \xi.\]</span>
Similarly, for a fixed time <span class="math inline">\(t\)</span>, the
velocity of the deformation is quantified by the map <span
class="math display">\[\eta : \mathbf{k}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\]</span> characterized by <span
class="math display">\[\frac{\partial g}{\partial s} = g \eta.\]</span>
Since <span class="math inline">\(g\)</span> is smooth, we have <span
class="math display">\[\frac{\partial ^2 g }{\partial s \partial t} =
\frac{\partial ^2 g }{\partial t \partial s}.\]</span> Equating the two
expressions obtained by expanding out the LHS and RHS and making use of
the definition of the Lie bracket give what is known as the
Maurer–Cartan equation.</p>
<p>For the remaining discussion, we either assume that <span
class="math inline">\(G\)</span> is a matrix Lie group (so that
everything is a matrix for us to multiply willy-nilly) or use the trick
of §<a href="#sec:pretend-lie-groups-are-matrix-groups"
data-reference-type="ref"
data-reference="sec:pretend-lie-groups-are-matrix-groups">15</a>.
Then <span class="math display">\[\frac{\partial ^2 g }{\partial s
\partial t} = \frac{\partial (g \xi) }{\partial s} = g \eta \xi + g
\frac{\partial \xi }{ \partial s},\]</span> while <span
class="math display">\[\frac{\partial ^2 g }{\partial t \partial s} =
\frac{\partial (g \eta) }{\partial t} = g \xi \eta + g \frac{\partial
\eta }{ \partial t}.\]</span> Equating the two and using the key
relation <span class="math display">\[g \eta \xi - g \xi \eta = g
[\eta,\xi]\]</span> now gives <span id="eq:cartan-maurer" class="math display">\[\label{eq:cartan-maurer}\tag{75}
  \frac{\partial \eta }{\partial t} - \frac{\partial \xi }{\partial s}
  = [\eta,\xi],\]</span> which we may expand a bit more verbosely as
<span id="eq:cartan-maurer-expanded" class="math display">\[\label{eq:cartan-maurer-expanded}\tag{76}
  \frac{\partial}{\partial t}
  (g^{-1} \frac{\partial g}{\partial s})
  - \frac{\partial}{\partial s}
  (g^{-1} \frac{\partial g}{\partial t})
  =
  [g^{-1} \frac{\partial g}{\partial s},
  g^{-1} \frac{\partial g}{\partial t}].\]</span></p>
<p>One can rewrite everything we’ve said here in the language of
differential geometry in terms of derivatives of a certain natural <span
class="math inline">\(\mathfrak{g}\)</span>-valued <span
class="math inline">\(1\)</span>-form on <span
class="math inline">\(G\)</span>; see Google for details.</p>
<h2 id="sec:org6f964c7">§19.2. Lifting morphisms of Lie algebras</h2>
<div class="theorem">
<p><strong>Theorem 146</strong>. <em>Let <span
class="math inline">\(G,H\)</span> be Lie groups. Consider the natural
map <span class="math inline">\(j : \mathop{\mathrm{Hom}}(G,H)
\rightarrow \mathop{\mathrm{Hom}}(\mathfrak{g},\mathfrak{h})\)</span>
given by <span class="math inline">\(f \mapsto d f\)</span>.</em></p>
<ol>
<li><p><em>If <span class="math inline">\(G\)</span> is connected, then
<span class="math inline">\(j\)</span> is injective.</em></p></li>
<li><p><em>If <span class="math inline">\(G\)</span> is
simply-connected, then <span class="math inline">\(j\)</span> is
surjective.</em></p></li>
</ol>
</div>
<p>We have already shown the first part. It remains to show when <span
class="math inline">\(G\)</span> is simply-connected that for each
morphism <span class="math inline">\(\phi : \mathfrak{g} \rightarrow
\mathfrak{h}\)</span> of Lie algebras that there is a morphism <span
class="math inline">\(f : G \rightarrow H\)</span> of Lie groups so that
<span class="math inline">\(d f = \phi\)</span>.</p>
<p>To construct <span class="math inline">\(f\)</span>, start with an
element <span class="math inline">\(x \in G\)</span>. Since <span
class="math inline">\(G\)</span> is connected, we can find a smooth
curve <span class="math inline">\(\gamma\)</span> in <span
class="math inline">\(G\)</span> with <span
class="math inline">\(\gamma(0) = e, \gamma(1) = x\)</span>. This curve
will satisfy a differential equation <span
class="math display">\[\frac{\partial \gamma }{\partial t} = \gamma
\xi\]</span> for some <span class="math inline">\(\xi : \mathbb{R} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\)</span>. We take <span class="math inline">\(\phi(\xi) :=
\phi \circ \xi : \mathbb{R} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{h}\)</span> and consider the curve <span
class="math inline">\(\delta : \mathbb{R} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
H\)</span> satisfying the initial condition <span
class="math inline">\(\delta(0) = e\)</span> and the differential
equation <span class="math display">\[\frac{\partial \delta }{\partial
t} = \delta \phi(\xi);\]</span> this can always be solved, by an
argument similar to that used to construct the exponential map. We now
attempt to define <span class="math display">\[f(x) :=
\delta(1).\]</span> The issue is that this definition is not obviously
independent of the choice of path <span
class="math inline">\(\gamma\)</span>.</p>
<p>However, since <span class="math inline">\(G\)</span> is
<em>simply-connected</em>, we can join any two such paths <span
class="math inline">\(\gamma_0, \gamma_1\)</span> by a smooth homotopy
<span class="math inline">\(g : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
G\)</span> satisfying <span class="math display">\[g(t,0) = \gamma_0(t),
\quad g(t,1) = \gamma_1(t), \quad g(0,s) = e, \quad g(1,s) = x.\]</span>
It will again satisfy a differential equation <span
class="math display">\[\frac{\partial g}{\partial t} = g \xi\]</span>
now for some <span class="math inline">\(\xi : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\)</span>. We can take the composition <span
class="math inline">\(\phi(\xi) : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{h}\)</span> and solve for a function <span
class="math inline">\(h : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
H\)</span> satisfying the initial condition <span
class="math inline">\(h(0,s) = e\)</span> and the differential equation
<span id="eq:velocity-h-path" class="math display">\[\label{eq:velocity-h-path}\tag{77}
  \frac{\partial h}{\partial t}
  = h \phi(\xi).\]</span> Then <span class="math inline">\(h(t,0) =
\delta_0(t)\)</span> and <span class="math inline">\(h(t,1) =
\delta_1(t)\)</span> where <span
class="math inline">\(\delta_0,\delta_1\)</span> are attached to <span
class="math inline">\(\gamma_0,\gamma_1\)</span> as above. Our aim is to
show that <span class="math inline">\(\delta_0(1) =
\delta_1(1)\)</span>. To that end, it will suffice to show that <span id="eq:initial-cond-h-at-1" class="math display">\[\label{eq:initial-cond-h-at-1}\tag{78}
  \text{$h(1,s)$ is independent of $s$.}\]</span> We can express what we
are given and what we want to show more succinctly in terms of the
deformation velocities <span class="math inline">\(\eta : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{g}\)</span> of <span class="math inline">\(g\)</span> and
<span class="math inline">\(\zeta : \mathbb{R}^2 %
  \mathrel{%
    \mathpalette{\da@xarrow{}{}{}\mathchar&quot;0\hexnumber@\symAMSa 4B
{\,}{}}{}%
  }%
\mathfrak{h}\)</span> characterized by <span id="eq:velocity-g-deformation" class="math display">\[\label{eq:velocity-g-deformation}\tag{79}
  \frac{\partial g}{\partial s}
  = g \eta\]</span> and <span id="eq:velocity-h-deformation" class="math display">\[\label{eq:velocity-h-deformation}\tag{80}
  \frac{\partial h}{\partial s}
  = g \zeta.\]</span> With this notation, what we are given is that
<span id="eq:given-eta-at-s-equals-1" class="math display">\[\label{eq:given-eta-at-s-equals-1}\tag{81}
  \eta(1,s) = 0\]</span> and what we want to show is that <span id="eq:given-zeta-at-s-equals-1" class="math display">\[\label{eq:given-zeta-at-s-equals-1}\tag{82}
  \zeta(1,s) = 0.\]</span> The required implication will follow in a
slightly stronger form if we can show that <span id="eq:deformation-velocity-preserved" class="math display">\[\label{eq:deformation-velocity-preserved}\tag{83}
  \zeta = \phi(\eta).\]</span> We are given the compatible inital
conditions <span id="eq:deformation-velocity-preserved-initial-conditions" class="math display">\[\label{eq:deformation-velocity-preserved-initial-conditions}\tag{84}
  \zeta(0,s) = 0 = \phi(\eta)(0,s).\]</span> The Maurer–Cartan equation
now gives <span id="eq:claimed-double-partial-identity" class="math display">\[\label{eq:claimed-double-partial-identity}\tag{85}
  \frac{\partial \eta }{ \partial t } - \frac{\partial \xi
  }{ \partial s}
  = [\eta,\xi].\]</span> and <span class="math display">\[\frac{\partial
\zeta }{ \partial t } - \frac{\partial \phi(\xi) }{ \partial s} =
[\zeta,\phi(\xi)].\]</span> By applying <span
class="math inline">\(\phi\)</span> to <a
href="#eq:claimed-double-partial-identity" data-reference-type="eqref"
data-reference="eq:claimed-double-partial-identity">\((85)\)</a>
and using that <span class="math inline">\(\phi\)</span> preserves
brackets, we obtain <span class="math display">\[\frac{\partial
\phi(\eta) }{ \partial t } - \frac{\partial \phi(\xi) }{ \partial s} =
[\phi(\eta),\phi(\xi)].\]</span> Thus for each <span
class="math inline">\(s\)</span>, the functions <span
class="math inline">\(t \mapsto \zeta(t,s)\)</span> and <span
class="math inline">\(t \mapsto \phi(\eta)(t,s)\)</span> satisfy the
same initial conditions at <span class="math inline">\(t = 0\)</span>
and the same differential equation. The required identity <a
href="#eq:deformation-velocity-preserved" data-reference-type="eqref"
data-reference="eq:deformation-velocity-preserved">\((83)\)</a>
follows finally from the basic uniqueness theorem for ODEs.</p>
<p>We’ve shown that the map <span class="math inline">\(f : G
\rightarrow H\)</span> is well-defined, i.e., independent of the choice
of path.</p>
<div class="exercise">
<p><strong>Exercise 24</strong>. Show that <span
class="math inline">\(f\)</span> is a group homomorphism, i.e., <span
class="math inline">\(f(g_1 g_2) = f(g_1) f(g_2)\)</span>. [Hint: use
the uniqueness of paths involved in the definition of <span
class="math inline">\(f\)</span>.]</p>
</div>
<p>It’s also not hard to verify that <span
class="math inline">\(f\)</span> is smooth.</p>
<h1 id="sec:org1f9aec4">§20. The universal covering group</h1>
<p>We record the basic definitions and results from class (in the order
essentially opposite to that in which they were presented)</p>
<div class="definition">
<p><strong>Definition 147</strong>. Let <span class="math inline">\(p_1
: X_1 \rightarrow Y\)</span> and <span class="math inline">\(p_2 : X_2
\rightarrow Y\)</span> be a pair of maps. A map <span
class="math inline">\(f : X_1 \rightarrow X_2\)</span> will be said to
<em>commute with <span class="math inline">\(p_1\)</span> and <span
class="math inline">\(p_2\)</span></em> if the only conceivable
condition relating the three maps is satisfied: <span
class="math inline">\(p_1 = p_2 \circ f\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 148</strong>. Let <span
class="math inline">\(Z\)</span> be a manifold and let <span
class="math inline">\(Y\)</span> be a connected manifold. The
<em>trivial fiber bundle over <span class="math inline">\(Y\)</span>
with fiber <span class="math inline">\(Z\)</span></em> is the map <span
class="math inline">\({\mathop{\mathrm{pr}}}_1 : Y \times Z \rightarrow
Y\)</span> given by taking the first coordinate. More generally, a
<em>trivial fiber bundle over <span class="math inline">\(Y\)</span>
with fiber <span class="math inline">\(Z\)</span></em> is a smooth map
of manifolds <span class="math inline">\(p : X \rightarrow Y\)</span>
such that there exists a diffeomorphism <span
class="math inline">\(\iota : X \rightarrow Y \times Z\)</span>
commuting with <span class="math inline">\(p\)</span> and <span
class="math inline">\({\mathop{\mathrm{pr}}}_1\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 149</strong>. Let <span
class="math inline">\(Z\)</span> be a manifold and let <span
class="math inline">\(Y\)</span> be a connected manifold. A <em>locally
trivial fiber bundle over <span class="math inline">\(Y\)</span> with
fiber <span class="math inline">\(Z\)</span></em> is a map <span
class="math inline">\(p : X \rightarrow Y\)</span>, where <span
class="math inline">\(X\)</span> is a manifold and <span
class="math inline">\(p\)</span> is a smooth map with the property that
each element of <span class="math inline">\(Y\)</span> is contained in
an open neighborhood <span class="math inline">\(U\)</span> for which
the induced map <span class="math inline">\(p : p^{-1}(U) \rightarrow
U\)</span> is a trivial fiber bundle over <span
class="math inline">\(U\)</span> with fiber <span
class="math inline">\(Z\)</span>.</p>
</div>
<div id="defn:cover" class="definition">
<p><strong>Definition 150</strong>. Let <span
class="math inline">\(X,Y\)</span> be connected manifolds. A
<em>cover</em> <span class="math inline">\(p : X \rightarrow Y\)</span>
is a locally trivial fiber bundle with discrete fiber. This means more
concretely that every element of <span class="math inline">\(Y\)</span>
has an open neighborhood <span class="math inline">\(U\)</span> so that
<span class="math inline">\(p^{-1}(U)\)</span> is a disjoint union of
open subsets <span class="math inline">\(V_\alpha\)</span> with the
property that <span class="math inline">\(p : V_\alpha \rightarrow
U\)</span> is a diffeomorphism. (A picture involving a “stack of
pancakes” is appropriate here.)</p>
</div>
<div class="remark">
<p><strong>Remark 151</strong>. One can speak about covers of much more
general topological spaces; we won’t ened such notions here.</p>
</div>
<div class="example">
<p><strong>Example 152</strong>. The natural map <span
class="math inline">\(p : \mathbb{R} \rightarrow \mathbb{R}/\mathbb{Z}
\cong U(1) \cong S^1\)</span> is a non-trivial locally trivial fiber
bundle over the circle <span class="math inline">\(S^1\)</span> with
fiber <span class="math inline">\(\mathbb{Z}\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 153</strong>. A morphism <span
class="math inline">\(f : G \rightarrow H\)</span> between connected Lie
groups is a <em>covering morphism</em> if it is a morphism of Lie groups
that is also a cover in the above sense.</p>
</div>
<div id="exercise:covering-morphisms" class="exercise">
<p><strong>Exercise 25</strong>. The following are equivalent for a
morphism <span class="math inline">\(f : G \rightarrow H\)</span>
between connected Lie groups:</p>
<ol>
<li><p><span class="math inline">\(f\)</span> is a cover in the sense of
Definition <a href="#defn:cover" data-reference-type="ref"
data-reference="defn:cover">150</a>, i.e., a locally trivial fiber
bundle.</p></li>
<li><p><span class="math inline">\(\ker(f)\)</span> is discrete and
<span class="math inline">\(f\)</span> is onto.</p></li>
<li><p><span class="math inline">\(f\)</span> is a local
homeomorphism.</p></li>
<li><p><span class="math inline">\(d f : \mathfrak{g} \rightarrow
\mathfrak{h}\)</span> is an isomorphism.</p></li>
</ol>
<p>(In all cases, <span class="math inline">\(f\)</span> is
surjective.)</p>
</div>
<div id="lemma:discrete-norma-implies-central" class="lemma">
<p><strong>Lemma 154</strong>. If <span class="math inline">\(N\)</span>
is a discrete normal subgroup of a connected Lie group <span
class="math inline">\(G\)</span>, then <span
class="math inline">\(N\)</span> is contained in the center of <span
class="math inline">\(G\)</span>.</p>
<p>In particular, the kernel of any covering morphism is a discrete
subgroup of the center</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(n \in N\)</span>. To
show that <span class="math inline">\(n\)</span> belongs to the center
of <span class="math inline">\(G\)</span>, we must verify that the set
<span class="math inline">\(S := \{g n g^{-1} : g \in G \} \subseteq
N\)</span> satisfies <span class="math inline">\(S = \{n\}\)</span>.
Indeed, <span class="math inline">\(S\)</span> is a subset of the
<em>discrete</em> topological space <span
class="math inline">\(N\)</span> that contains <span
class="math inline">\(n\)</span>, but <span
class="math inline">\(S\)</span> is the continuous image under the map
<span class="math inline">\(g \mapsto g n g^{-1}\)</span> of the
<em>connected</em> topological space <span
class="math inline">\(G\)</span>, so <span
class="math inline">\(S\)</span> is connected and thus <span
class="math inline">\(S = \{n\}\)</span>. ◻</p>
</span></div>
<p>The following key result classifies connected Lie groups as quotients
of simply-connected Lie groups by discrete central subgroups:</p>
<div class="theorem">
<p><strong>Theorem 155</strong>. <em>Let <span
class="math inline">\(G\)</span> be a connected Lie group. Then there
exists a simply-connected (connected) Lie group <span
class="math inline">\(\tilde{G}\)</span> and a covering morphism <span
class="math inline">\(p : \tilde{G} \rightarrow G\)</span>. The kernel
<span class="math inline">\(N\)</span> of <span
class="math inline">\(p\)</span> is a discrete subgroup of the center of
<span class="math inline">\(G\)</span>. One has <span
class="math inline">\(\pi_1(G) \cong N\)</span>. The pair <span
class="math inline">\((\tilde{G},N)\)</span> is unique up to
isomorphism.</em></p>
</div>
<p>By combining with the result from last lecture, together with the
(not proved yet and not obvious) fact that every finite-dimensional Lie
algebra arises as the Lie algbebra of some Lie group, we obtain:</p>
<div class="corollary">
<p><strong>Corollary 156</strong>. <em>The category of simply-connected
Lie groups is equivalent to the category of finite-dimensional Lie
algebras, that is to say:</em></p>
<ul>
<li><p><em>Every simply-connected Lie group has a finite-dimensional Lie
algebra, and every finite-dimensional Lie algebra arises (up to
isomorphism) in this way.</em></p></li>
<li><p><em>If <span class="math inline">\(G,H\)</span> are
simply-connected Lie groups with Lie algebras <span
class="math inline">\(\mathfrak{g},\mathfrak{h}\)</span>, then the map
<span class="math inline">\(f \mapsto d f\)</span> induces a bijection
<span class="math inline">\(\mathop{\mathrm{Hom}}(G,H) =
\mathop{\mathrm{Hom}}(\mathfrak{g},\mathfrak{h})\)</span>. In
particular, <span class="math inline">\(G \cong H\)</span> if and only
if <span class="math inline">\(\mathfrak{g} \cong
\mathfrak{h}\)</span>.</em></p></li>
</ul>
</div>
<p>In lecture we gave the following examples:</p>
<ol>
<li><p><span class="math inline">\(G = \mathbb{R}/\mathbb{Z} \cong
\mathop{\mathrm{U}}(1) \cong S^1\)</span>, <span
class="math inline">\(\tilde{G} = \mathbb{R}\)</span>, <span
class="math inline">\(N = \mathbb{Z}\)</span></p></li>
<li><p><span class="math inline">\(G = \mathop{\mathrm{SO}}(3),
\tilde{G} = \mathop{\mathrm{SU}}(2), N = \{\pm 1\}\)</span>.</p></li>
<li><p><span class="math inline">\(G = \mathbb{C}^\times, \tilde{G} =
\mathbb{C}, p = \exp : \tilde{G} \rightarrow G\)</span>, <span
class="math inline">\(N = 2 \pi i \mathbb{Z}\)</span></p></li>
</ol>
<p>We gave a few other similar examples. See the homework for further
examples.</p>
<p>The proof of the theorem relies on the construction of the universal
cover <span class="math inline">\(p : \tilde{X} \rightarrow X\)</span>
of a connected manifold <span class="math inline">\(X\)</span>, which is
a cover in the sense of Definition <a href="#defn:cover"
data-reference-type="ref" data-reference="defn:cover">150</a> with the
property: for any cover <span class="math inline">\(q : \tilde{Y}
\rightarrow Y\)</span> and any smooth map <span class="math inline">\(f
: X \rightarrow Y\)</span> and any <span class="math inline">\(x \in X,
y \in Y, \tilde{x} \in \tilde{X}, \tilde{y} \in \tilde{Y}\)</span>
satisfying the compatibility conditions <span class="math inline">\(x =
p(\tilde{x})\)</span> and <span class="math inline">\(y = f(x) =
q(\tilde{y})\)</span> there exists a unique smooth map <span
class="math inline">\(\tilde{f} : \tilde{X} \rightarrow
\tilde{Y}\)</span> such that</p>
<ol>
<li><p><span class="math inline">\(\tilde{f}\)</span> lifts <span
class="math inline">\(f\)</span> in the sense that <span
class="math inline">\(q \circ \tilde{f} = p \circ f\)</span>,
and</p></li>
<li><p><span class="math inline">\(\tilde{f}(\tilde{x}) =
\tilde{y}\)</span>.</p></li>
</ol>
<p>The construction of <span class="math inline">\(p : \tilde{X}
\rightarrow X\)</span> (which is not terribly important for our
purposes) is as follows: One fixes a basepoint <span
class="math inline">\(x_0 \in X\)</span> and defines <span
class="math inline">\(\tilde{X}\)</span> as a set to be the set of all
pairs <span class="math inline">\((x,[\gamma])\)</span>, where <span
class="math inline">\(x \in X\)</span> and <span
class="math inline">\([\gamma]\)</span> is a homotopy class of smooth
paths <span class="math inline">\(\gamma : [0,1] \rightarrow X\)</span>
with <span class="math inline">\(\gamma(0) = x_0\)</span> and <span
class="math inline">\(\gamma(1) = x\)</span>. The map <span
class="math inline">\(p : \tilde{X} \rightarrow X\)</span> is given by
<span class="math inline">\(p((x,[\gamma])) := x\)</span>. We must now
define a smooth structure on <span
class="math inline">\(\tilde{X}\)</span> and verify that it is indeed a
locally trivial fiber with discrete fiber and that the universal
property is satisfied. We will content ourselves here to define the
smooth structure; the verifications are then routine. Given a point
<span class="math inline">\(x_1 \in X\)</span>, there is a small open
neighborhood <span class="math inline">\(U\)</span> of <span
class="math inline">\(x_1\)</span> that is diffeomorphic to an open
Euclidean ball <span class="math inline">\(B\)</span>. For each <span
class="math inline">\(x \in U\)</span>, each homotopy class <span
class="math inline">\([\gamma]\)</span> of paths <span
class="math inline">\(\gamma\)</span> from <span
class="math inline">\(x_0\)</span> to <span
class="math inline">\(x\)</span> may be factored uniquely as <span
class="math inline">\([\delta_x \circ \gamma_1]\)</span>, where <span
class="math inline">\(\delta_x\)</span> is given by the straight line
from <span class="math inline">\(x\)</span> to <span
class="math inline">\(x_1\)</span> (under the identification <span
class="math inline">\(U \cong B\)</span>) and <span
class="math inline">\([\gamma_1]\)</span> traverses the set <span
class="math inline">\(A\)</span> of homotopy classes of paths <span
class="math inline">\(\gamma_1\)</span> from <span
class="math inline">\(x_0\)</span> to <span
class="math inline">\(x_1\)</span>. We obtain in this way an
identification of sets <span class="math inline">\(p^{-1}(U) =
\bigsqcup_{\alpha \in A} V_\alpha\)</span>, where each <span
class="math inline">\(V_\alpha\)</span> identifies naturally with <span
class="math inline">\(B\)</span>. We use this identification to define
the smooth structure on <span
class="math inline">\(p^{-1}(U)\)</span>.</p>
<p>Given a connected Lie group <span class="math inline">\(G\)</span>,
one obtains first a cover of manifolds <span class="math inline">\(p :
\tilde{G} \rightarrow G\)</span>. To define the group structure on <span
class="math inline">\(\tilde{G}\)</span>, one first selects an arbitrary
preimage <span class="math inline">\(\tilde{e} \in \tilde{G}\)</span> of
the identity element <span class="math inline">\(e \in G\)</span>. Using
the universal property, one obtains unique lifts <span
class="math inline">\(\tilde{m} : \tilde{G} \times \tilde{G} \rightarrow
\tilde{G}\)</span> and <span class="math inline">\(\tilde{i} : \tilde{G}
\rightarrow \tilde{G}\)</span> of the multiplication and inversion maps
<span class="math inline">\(m : G \times G \rightarrow G\)</span> and
<span class="math inline">\(i : G \rightarrow G\)</span> satisfying
<span class="math inline">\(\tilde{m}(\tilde{e},\tilde{e}) =
\tilde{e}\)</span> and <span class="math inline">\(\tilde{i}(\tilde{e})
= \tilde{e}\)</span>. One can now check that the usual axioms
(associativity, smoothness, etc.) are satisfied, and that <span
class="math inline">\(p : \tilde{G} \rightarrow G\)</span> is a covering
morphism. The kernel <span class="math inline">\(N\)</span> of <span
class="math inline">\(p\)</span> is obviously discrete, so by Lemma <a
href="#lemma:discrete-norma-implies-central" data-reference-type="ref"
data-reference="lemma:discrete-norma-implies-central">154</a>, it is
central.</p>
<p>One can also check, using the universal property, that <span
class="math inline">\(\pi_1(G) \cong N\)</span>: The isomorphism <span
class="math inline">\(j : \pi_1(G) \rightarrow N\)</span> is obtained by
defined by taking a homotopy class <span
class="math inline">\([\gamma]\)</span> of loops <span
class="math inline">\(\gamma\)</span> in <span
class="math inline">\(G\)</span> with basepoint <span
class="math inline">\(e\)</span>, using the universal property to lift
them uniquely to paths <span class="math inline">\(\tilde{\gamma} :
\tilde{G} \rightarrow \tilde{G}\)</span> with <span
class="math inline">\(\tilde{\gamma}(0) = \tilde{e}\)</span>, and
setting <span class="math inline">\(j([\gamma]) :=
\tilde{\gamma}(1)\)</span>. This is well-defined. Conversely, given
<span class="math inline">\(n \in N\)</span>, we can take a path <span
class="math inline">\(\tilde{\gamma}\)</span> in <span
class="math inline">\(\tilde{G}\)</span> from <span
class="math inline">\(\tilde{e}\)</span> to <span
class="math inline">\(n \in N\)</span> and project it down via <span
class="math inline">\(p\)</span> to obtain a loop <span
class="math inline">\(\gamma\)</span> in <span
class="math inline">\(G\)</span> based at the identity element <span
class="math inline">\(e \in G\)</span>. The maps <span
class="math inline">\(\pi_1(G) \rightarrow N\)</span> and <span
class="math inline">\(N \rightarrow \pi_1(G)\)</span> constructed in
this way are mutually inverse group homomorphisms.</p>
<p>For more details, I recommend consulting the first reference listed
on the course homepage.</p>
<h1 id="sec:org1288635">§21. Quotients of Lie groups</h1>
<div class="theorem">
<p><strong>Theorem 157</strong>. <em>Let <span
class="math inline">\(G\)</span> be a Lie group and <span
class="math inline">\(H\)</span> a Lie subgroup. There is a unique
smooth structure on the set <span class="math inline">\(G/H\)</span> so
that the natural map <span class="math inline">\(G \rightarrow
G/H\)</span> is a submersion, or equivalently, a quotient map in the
smooth category. If moreover <span class="math inline">\(H\)</span> is a
normal subgroup, then <span class="math inline">\(G/H\)</span> is
naturally a Lie group and <span class="math inline">\(G \rightarrow
G/H\)</span> is a surjective morphism of Lie groups. Moreover, the map
<span class="math inline">\(G \rightarrow G/H\)</span> is a locally
trivial fiber bundle with fiber <span class="math inline">\(H\)</span>
(and also what is known as a “principal <span
class="math inline">\(H\)</span>-bundle”). Moreover, if the Lie group
<span class="math inline">\(G\)</span> acts transitively on a smooth
manifold <span class="math inline">\(X\)</span> and if <span
class="math inline">\(H\)</span> is the stabilizer in <span
class="math inline">\(G\)</span> of some point <span
class="math inline">\(x \in X\)</span>, then the natural map <span
class="math inline">\(G/H \rightarrow X\)</span> given by <span
class="math inline">\(g H \mapsto gx\)</span> is a
diffeomorphism.</em></p>
</div>
<p>The final assertion that <span class="math inline">\(G/H \cong
X\)</span> is related to Exercise <a
href="#exercise-topological-groups-quotient-map-homeomorphism"
data-reference-type="ref"
data-reference="exercise-topological-groups-quotient-map-homeomorphism">11</a>;
its proof in the present setting requires the second-countability
assumption on our manifolds. We sketched the construction of the smooth
structure on <span class="math inline">\(G/H\)</span> in some detail in
lecture, leaving the verification of the properties as an exercise; see
the first reference on the course webpage for more details.</p>
<p>The argument here is very similar (basically “dual to”) that
concerning submanifolds given by Theorem <a
href="#thm:characterize-submanifold-smooth-structure"
data-reference-type="ref"
data-reference="thm:characterize-submanifold-smooth-structure">24</a>.
In this analogy, “immersion” is to “submanifold” as “submersion” is to
“quotient manifold.”</p>
<p>By an argument dual to that of Corollary <a
href="#prop:smoothness-preserved-codomain-pass-to-submfld"
data-reference-type="eqref"
data-reference="prop:smoothness-preserved-codomain-pass-to-submfld">\((25)\)</a>,
we know that a smooth surjection <span class="math inline">\(p : X
\rightarrow Y\)</span> is a submersion if and only if it is a
<em>quotient map</em> in the category of smooth manifolds, that is to
say, if and only if smooth maps of manifolds <span
class="math inline">\(Y \rightarrow Z\)</span> are in natural bijection
with smooth maps <span class="math inline">\(X \rightarrow Z\)</span>
that factor set-theoretically through <span
class="math inline">\(p\)</span>. (This is easy to see in local
coordinates, using the local description of submersions as surjective
linear maps.) The proof of uniqueness of smooth structure on <span
class="math inline">\(G/H\)</span> is then dual to that given in the
proof of Theorem <a
href="#thm:characterize-submanifold-smooth-structure"
data-reference-type="ref"
data-reference="thm:characterize-submanifold-smooth-structure">24</a>.</p>
<p>For existence, one first takes a small enough submanifold <span
class="math inline">\(S\)</span> of <span
class="math inline">\(G\)</span> that is transversal to <span
class="math inline">\(H\)</span> at the identity element (draw a
picture). By the inverse function theorem, the multiplication map <span
class="math inline">\(\mu : S \times H \rightarrow G\)</span> is then a
local diffeomorphism at the identity, and is in particular injective in
a neighborhood of the identity. (In a bit more detail: the
transversality assumption says that that the derivative <span
class="math inline">\(T_{(e,e)} \mu : T_e S \times \mathfrak{h}
\rightarrow \mathfrak{g}\)</span> is an isomorphism, hence by the
inverse function theorem, it is a diffeomorphism in a neighborhood of
the origin.)</p>
<p>It follows that if <span class="math inline">\(S\)</span> is small
enough, then <span class="math inline">\(\mu\)</span> is actually a
diffeomorphism onto its image: for else we may (as explained in more
detail in lecture) find arbitrarily small distinct <span
class="math inline">\(s_1,s_2 \in S\)</span> for which <span
class="math inline">\(s_1^{-1} s_2 \in H\)</span>, contrary to the local
injectivity of <span class="math inline">\(\mu\)</span>. In particular,
after shrinking <span class="math inline">\(S\)</span> as necessary, the
map of sets <span class="math inline">\(\pi : S \rightarrow G/H\)</span>
is injective. Denote by <span class="math inline">\(U \subseteq
G/H\)</span> the image of <span class="math inline">\(S\)</span> and by
<span class="math inline">\(g U\)</span> the image of the translate
<span class="math inline">\(g S\)</span> by an element <span
class="math inline">\(g \in G\)</span>. We equip <span
class="math inline">\(g U\)</span> with the smooth structure transferred
from <span class="math inline">\(g S\)</span>. Then <span
class="math inline">\(\pi\)</span> is a submersion over <span
class="math inline">\(g U\)</span>. The sets <span
class="math inline">\(g U\)</span> cover <span
class="math inline">\(G/H\)</span>, and the smooth structures on their
overlaps are compatible thanks to the uniqueness established before
(compare with the proof of Theorem <a
href="#thm:characterize-submanifold-smooth-structure"
data-reference-type="ref"
data-reference="thm:characterize-submanifold-smooth-structure">24</a>).
One can check using the definition of quotient maps that the natural map
<span class="math inline">\(G \times G/H \rightarrow G/H\)</span> is
smooth, and that if <span class="math inline">\(H\)</span> is normal,
then the induced multiplication map on <span
class="math inline">\(G/H\)</span> is smooth, so <span
class="math inline">\(G/H\)</span> is naturally a Lie group.</p>
<h1 id="sec:org245e5dc">§22. Homotopy exact sequence</h1>
<p>If <span class="math inline">\(G,H\)</span> are Lie groups with <span
class="math inline">\(G\)</span> connected, one has an exact sequence
<span class="math display">\[\pi_2(G/H) \rightarrow \pi_1(H) \rightarrow
\pi_1(G) \rightarrow \pi_1(G/H) \xrightarrow{\delta} H/H^0 \rightarrow
0\]</span> where <span class="math inline">\(\delta\)</span> sends the
homotopy class <span class="math inline">\([\gamma]\)</span> of a loop
<span class="math inline">\(\gamma : [0,1] \rightarrow H\)</span> based
at the identity element to <span class="math inline">\(\delta([\gamma])
:= \tilde{\gamma}(1)^{-1}\)</span>, where <span
class="math inline">\(\tilde{\gamma} : [0,1] \rightarrow G\)</span> is
the unique lift of <span class="math inline">\(\gamma\)</span> to a path
in <span class="math inline">\(G\)</span> satisfying <span
class="math inline">\(\tilde{\gamma}(0) = e\)</span>.</p>
<div class="corollary">
<p><strong>Corollary 158</strong>. <em>If <span
class="math inline">\(\pi_1(G/H) = \pi_2(G/H) = 0\)</span>, then <span
class="math inline">\(\pi_1(G) \cong \pi_1(H)\)</span>.</em></p>
</div>
<div class="corollary">
<p><strong>Corollary 159</strong>. <em>If <span
class="math inline">\(\pi_1(G) =0\)</span>, then <span
class="math inline">\(\pi_1(G/H) \cong H/H^0\)</span>.</em></p>
</div>
<p>We explained how this may be used to compute inductively the
fundamental groups of the classical groups; see the first reference on
the course webpage for more details.</p>
<h1 id="sec:org167c08b">§23. Cartan decomposition<span id="sec:cartan-decmop"
label="sec:cartan-decmop"></span></h1>
<p>Let <span class="math inline">\(G\)</span> be a real Lie subgroup of
<span class="math inline">\({\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span>
with the property that <span class="math inline">\(\Theta(G) =
G\)</span>, where <span class="math inline">\(\Theta :
{\mathop{\mathrm{GL}}}_N(\mathbb{C}) \rightarrow
{\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span> is the involution given by
inverse conjugate transpose: <span class="math display">\[\Theta(g) :=
{}^t \overline{g}^{-1}.\]</span> Then the set <span
class="math display">\[K := \{g \in G : \Theta(g) = g \} =
\mathop{\mathrm{U}}(N) \cap G\]</span> of elements in <span
class="math inline">\(G\)</span> fixed by <span
class="math inline">\(\Theta\)</span>, or equivalently, belonging to the
unitary rgoup, may be shown to be a real Lie subgroup with Lie algebra
<span class="math display">\[\mathfrak{k} = \{X \in \mathfrak{g} :
\theta(X) = X\}\]</span> where <span class="math inline">\(\theta := d
\Theta\)</span> is given by <span class="math display">\[\theta(X) := -
\overline{X}^t.\]</span> Set <span class="math display">\[\mathfrak{p}
:= \{X \in \mathfrak{g} : \theta(X) = - X\}.\]</span> Then <span
class="math inline">\(\mathfrak{g} = \mathfrak{k} \oplus
\mathfrak{p}\)</span>. In words, <span
class="math inline">\(\mathfrak{k}\)</span> consists of the
skew-hermitian elements of <span
class="math inline">\(\mathfrak{g}\)</span>, while <span
class="math inline">\(\mathfrak{p}\)</span> consists of the hermitian
elements of <span class="math inline">\(\mathfrak{g}\)</span>; the
assumption <span class="math inline">\(\Theta(G) = G\)</span> implies
also that <span class="math inline">\(\theta(\mathfrak{g}) =
\mathfrak{g}\)</span>, hence (easily) that such a decomposition
exists.</p>
<div id="example:cartan-decmop-complex-matrices" class="example">
<p><strong>Example 160</strong>. If <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, then <span
class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span> and <span
class="math inline">\(\mathfrak{p}\)</span> consists of all hermitian
matrices and <span class="math inline">\(\exp(\mathfrak{p})\)</span>
consists of all positive-definite hermitian matrices.</p>
<p>In particular, if <span class="math inline">\(n =1\)</span>, then
<span class="math inline">\(G = \mathbb{C}^\times, K = U(1)\)</span>,
and <span class="math inline">\(\mathfrak{p}\)</span> consists of all
<span class="math inline">\(1 \times 1\)</span> real matrices.</p>
</div>
<div id="example:cartan-decmop-real-matrices" class="example">
<p><strong>Example 161</strong>. If <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span>, then <span
class="math inline">\(K = \operatorname{O}(n)\)</span> and <span
class="math inline">\(\mathfrak{p}\)</span> consists of all symmetric
matrices and <span class="math inline">\(\exp(\mathfrak{p})\)</span>
consists of all positive-definite symmetric matrices.</p>
</div>
<div class="example">
<p><strong>Example 162</strong>. One of the homework problems this week
is to verify that if <span class="math inline">\(G =
\operatorname{O}(p,q)\)</span>, then <span class="math inline">\(K =
\operatorname{O}(p) \times \operatorname{O}(q)\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 163</strong>. We say that <span
class="math inline">\(G\)</span> is (real) <em>algebraic</em> if it may
be defined inside <span
class="math inline">\({\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span> by a
system of polynomial equations in the real and imaginary parts of group
elements and their inverses. (Every example we’ve seen has this
property.)</p>
</div>
<div id="thm:cartan-decomp" class="theorem">
<p><strong>Theorem 164</strong> (Cartan decomposition). <em>Let <span
class="math inline">\(G,K\)</span> be as above. Assume that <span
class="math inline">\(G\)</span> is algebraic. Then the natural map
<span class="math display">\[K \times \mathfrak{p} \rightarrow
G\]</span> <span class="math display">\[(k,Y) \mapsto k \exp(Y)\]</span>
is a diffeomorphism.</em></p>
</div>
<div class="remark">
<p><strong>Remark 165</strong>. If <span
class="math inline">\(G\)</span> has finitely many connected components,
then the assumption that <span class="math inline">\(G\)</span> is
algebraic turns out to hold automatically in this setup (TODO:
double-check this), but we probably won’t have time to prove this. In
any event, it’s true in all of the examples we’ve seen.</p>
</div>
<div id="example:polar-decomp" class="example">
<p><strong>Example 166</strong>. In the context of Example <a
href="#example:cartan-decmop-complex-matrices" data-reference-type="ref"
data-reference="example:cartan-decmop-complex-matrices">160</a>, this
amounts to the “polar decomposition” of an invertible complex matrix
<span class="math inline">\(g\)</span> as a product of a unitary matrix
<span class="math inline">\(k\)</span> and a positive-definite hermitian
matrix <span class="math inline">\(\exp(Y)\)</span>. In the special case
<span class="math inline">\(n = 1\)</span>, this is just the polar
decomposition of a nonzero complex numbers as <span
class="math inline">\(e^{i \theta} r\)</span> (writing <span
class="math inline">\(r = e^y, y \in \mathbb{R}\)</span>).</p>
</div>
<div class="corollary">
<p><strong>Corollary 167</strong>. <em>Let <span
class="math inline">\(G,K\)</span> be as above. Then <span
class="math inline">\(K\)</span> is a deformation retract of <span
class="math inline">\(G\)</span>. In particular, <span
class="math inline">\(\pi_i(G) \cong \pi_i(K)\)</span> for all <span
class="math inline">\(i \geq 0\)</span>.</em></p>
</div>
<p>(One of the homework problems involves applying this last corollary
in the special case <span class="math inline">\(i=0\)</span> to relate
the connected components of <span class="math inline">\(G\)</span> and
<span class="math inline">\(K\)</span>.)</p>
<div class="remark">
<p><strong>Remark 168</strong>. This corollary “explains” some of the
“coincidences” such as <span
class="math display">\[\pi_1({\mathop{\mathrm{SL}}}_2(\mathbb{R})) \cong
\mathbb{Z} \cong \pi_1(\mathop{\mathrm{SO}}(2)),\]</span> <span
class="math display">\[\pi_1({\mathop{\mathrm{SL}}}_n(\mathbb{R})) \cong
\mathbb{Z}/2 \cong \pi_1(\mathop{\mathrm{SO}}(n)) \text{ for } n \geq
3,\]</span> <span class="math display">\[\pi_1(\mathop{\mathrm{SU}}(n))
\cong \{0\} \cong \pi_1({\mathop{\mathrm{SL}}}_n(\mathbb{C})),\]</span>
<span class="math display">\[\pi_1(\mathop{\mathrm{U}}(n)) \cong
\mathbb{Z} \cong \pi_1({\mathop{\mathrm{GL}}}_n(\mathbb{C})),\]</span>
<span class="math display">\[\pi_1({\mathop{\mathrm{SO}}}_n(\mathbb{C}))
\cong \pi_1(\mathop{\mathrm{SO}}(n))\]</span> that we observed
empirically at the beginning of the lecture.</p>
</div>
<div class="remark">
<p><strong>Remark 169</strong>. Let <span
class="math inline">\(G\)</span> be a connected complex Lie group, and
suppose it has a compact real form <span
class="math inline">\(K\)</span>, so that <span
class="math inline">\(\mathfrak{g} \cong \mathfrak{k} \oplus i
\mathfrak{k}\)</span>. The point of this remark is to indicate briefly
(as is evident in all examples) why the Cartan decomposition should
always apply to <span class="math inline">\(G\)</span> and <span
class="math inline">\(K\)</span>. It turns out (as we’ll show later in
the course) that we may always realize <span
class="math inline">\(K\)</span> as a subgroup of <span
class="math inline">\(\mathop{\mathrm{U}}(N)\)</span> for some <span
class="math inline">\(N\)</span>. We can then realize <span
class="math inline">\(G\)</span> as a subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span> in
such a way that <span class="math inline">\(\mathfrak{g} = \mathfrak{k}
\oplus i \mathfrak{k}\)</span>; given what we’ve seen in the course, we
can verify this already in the special case <span
class="math inline">\(G\)</span> is simply-connected (by lifting the
inclusion map <span class="math inline">\(\mathfrak{g} \hookrightarrow
\mathfrak{g} \mathfrak{l}_N(\mathbb{C})\)</span>), and by the end of the
course we should also be able to reduce the general case to that special
one. Then <span class="math inline">\(K = G \cap
\mathop{\mathrm{U}}(N)\)</span>.</p>
</div>
<p>We briefly indicate the proof of Theorem <a href="#thm:cartan-decomp"
data-reference-type="ref" data-reference="thm:cartan-decomp">164</a>.
One basically takes the proof of the special case (see Example <a
href="#example:polar-decomp" data-reference-type="ref"
data-reference="example:polar-decomp">166</a>) concerning polar
decomposition on <span
class="math inline">\({\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span>
(perhaps seen in a linear algebra course?) and checks that it descends
to <span class="math inline">\(G\)</span>. So, let’s see. There are a
few things to check.</p>
<ol>
<li><p>The map <span class="math inline">\(K \times \mathfrak{p} \ni
(k,Y) \mapsto k \exp(Y) \in G\)</span> is bijective.</p></li>
<li><p>The map <span class="math inline">\(Y \mapsto \exp(Y)\)</span> is
a diffeomorphism onto its image.</p></li>
</ol>
<p>Using the first two assertions and the inverse function theorem, one
gets that the map <span class="math inline">\((k,Y) \mapsto k
\exp(Y)\)</span> is itself a diffeomorphism onto its image. To verify
the second assertion, we should first compute the differential of the
exponential map (a result of independent interest). The answer is that
for any <span class="math inline">\(X,Y \in \mathfrak{g}\)</span>, <span id="eq:diff-exp" class="math display">\[\label{eq:diff-exp}\tag{86}
  \exp(-X) \frac{d}{d t} \exp(X + t Y)|_{t=0}
  =
  \Psi({\mathop{\mathrm{ad}}}_X) Y\]</span> where <span
class="math display">\[\Psi(z) := \sum_{n=1}^{\infty}
\frac{(-z)^{n-1}}{n!}  = \frac{1 - \exp(-z)}{z}.\]</span> This is
obtained by applying Homework <a href="#hw:diff-exp"
data-reference-type="ref" data-reference="hw:diff-exp">9</a> to the map
<span class="math inline">\(f : \mathbb{R} \rightarrow
\mathfrak{g}\)</span> given by <span class="math inline">\(f(t) := X + t
Y\)</span>; one then has <span class="math inline">\(f(0) = X\)</span>
and <span class="math inline">\(f&#39;(0) = Y\)</span>, and so <a
href="#eq:diff-exp" data-reference-type="eqref"
data-reference="eq:diff-exp">\((86)\)</a> follows from Homework <a
href="#hw:diff-exp" data-reference-type="ref"
data-reference="hw:diff-exp">9</a>. It follows from the second
description of <span class="math inline">\(\Psi\)</span> that <span
class="math inline">\((d \exp)_X\)</span> is injective provided that
<span class="math inline">\({\mathop{\mathrm{ad}}}_X\)</span> has no
eigenvalues of the form <span class="math inline">\(2 \pi i k\)</span>
with <span class="math inline">\(k\)</span> a nonzero integer. Since
hermitian matrices have <em>real</em> eigenvalues (under the standard
representation as well as the adjoint representation), it follows in
particular that <span class="math inline">\(\exp : \mathfrak{p}
\rightarrow {\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span> is everywhere
regular. Finally, we observe that every positive hermitian matrix <span
class="math inline">\(g\)</span> may be written uniquely as the
exponential of a symmetric matrix: any such matrix is diagonal with
respect to some basis and has positive real entries on the diagonal,
etc. In summary, <span class="math inline">\(\exp : \mathfrak{p}
\rightarrow {\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span> is a
diffeomorphism onto its image, as required.</p>
<p>All that remains now is the bijectivity. We verify first the
injectivity, which will serve as useful motivation. Suppose that <span
class="math inline">\(g = k \exp(Y)\)</span>. Since <span
class="math inline">\(\Theta(k) = k\)</span> and <span
class="math inline">\(\Theta(\exp(Y)) = \exp(\theta(Y)) = \exp(-Y) =
\exp(Y)^{-1}\)</span> and <span class="math inline">\(\Theta\)</span> is
a homomorphism, it follows that <span class="math inline">\(g^{-1}
\Theta(g) = \exp(2 Y)\)</span>. Since <span class="math inline">\(\exp :
\mathfrak{p} \rightarrow \exp(\mathfrak{p})\)</span> is bijective, it
follows that <span class="math inline">\(Y\)</span> is uniquely
determined by <span class="math inline">\(g\)</span>, hence so is <span
class="math inline">\(k = g \exp(-Y)\)</span>.</p>
<p>We turn finally to surjectivity. Given <span class="math inline">\(g
\in G \leq {\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span>, we can verify
directly that <span class="math inline">\(\Theta(g)^{-1}
\Theta(g)\)</span> is a positive definite hermitian matrix, and so we
can define <span class="math inline">\(Y \in
\mathfrak{g}\mathfrak{l}_N(\mathbb{C})\)</span> to be the unique
hermitian matrix for which <span class="math inline">\(\exp(2 Y) =
\Theta(g)^{-1} \Theta(g)\)</span>. It is then not hard to verify that
<span class="math inline">\(k := g \exp(-Y)\)</span> is unitary, i.e.,
<span class="math inline">\(\Theta(k) = k\)</span>. This gives the
required decomposition in the Lie group <span
class="math inline">\({\mathop{\mathrm{GL}}}_N(\mathbb{C})\)</span>; the
problem is to show that in fact <span class="math inline">\(k \in
K\)</span> and <span class="math inline">\(Y \in \mathfrak{p}\)</span>,
or equivalently, that <span class="math inline">\(k \in G\)</span> and
<span class="math inline">\(Y \in \mathfrak{g}\)</span>. Since <span
class="math inline">\(\exp(\mathfrak{g}) \subseteq G\)</span> and
because of the way <span class="math inline">\(k\)</span> was defined,
it will suffice to verify that <span class="math inline">\(Y \in
\mathfrak{g}\)</span>. What we know (from our assumptions <span
class="math inline">\(g \in G\)</span> and <span
class="math inline">\(\Theta(G) = G\)</span>) is that <span
class="math inline">\(\exp(2 Y) \in G\)</span>. Since <span
class="math inline">\(G\)</span> is a group, we can raise the last
assertion to any integer power <span class="math inline">\(t \in
\mathbb{Z}\)</span> to see that <span class="math inline">\(\exp(2 t Y)
\in G\)</span>. Since <span class="math inline">\(Y\)</span> is
hermitian, we may choose a basis with respect to which it is diagonal
and suppose that <span class="math inline">\(Y =
\mathop{\mathrm{diag}}(y_1,\dotsc,y_N)\)</span> for some real numbers
<span class="math inline">\(y_1,\dotsc,y_N \in \mathbb{R}\)</span>.
Since <span class="math inline">\(G\)</span> was assumed to be algebraic
(defined by polynomial equations), the condition <span
class="math inline">\(\exp(2 t Y) \in G\)</span> is then a system of
polynomial equations involving the positive real numbers <span
class="math inline">\(\exp(2 t y_1), \dotsc, \exp(2 t y_N)\)</span>.
Since this polynomial system is satisfied for all integers <span
class="math inline">\(t\)</span>, one can show (see below) that it is
satisfied also for all real numbers <span
class="math inline">\(t\)</span>. Thus <span
class="math inline">\(\exp(2 t Y) \in G\)</span> for all <span
class="math inline">\(t \in \mathbb{R}\)</span>. By differentiating this
last fact we deduce as required that <span class="math inline">\(Y \in
\mathfrak{g}\)</span>.</p>
<p>For completeness, we record the algebraic fact that we used in the
proof:</p>
<div class="exercise">
<p><strong>Exercise 26</strong>. Let <span
class="math inline">\(a_1,\dotsc,a_n \in \mathbb{R}\)</span> and let
<span class="math inline">\(F \in \mathbb{R}[x_1,\dotsc,x_n]\)</span> be
a polynomial satisfying <span id="eq:condition-on-F-vanishes-at-integers-exp-stuff" class="math display">\[\label{eq:condition-on-F-vanishes-at-integers-exp-stuff}\tag{87}
    F(e^{a_1 t},\dotsc,e^{a_n t})
    = 0\]</span> for all <span class="math inline">\(t \in
\mathbb{Z}\)</span>. Show that <a
href="#eq:condition-on-F-vanishes-at-integers-exp-stuff"
data-reference-type="eqref"
data-reference="eq:condition-on-F-vanishes-at-integers-exp-stuff">\((87)\)</a>
holds also for all <span class="math inline">\(t \in
\mathbb{R}\)</span>.</p>
</div>
<p>(We apply this with <span class="math inline">\(n := 2 N\)</span> and
<span class="math inline">\((a_1,\dotsc,a_n) :=
(y_1,\dotsc,y_N,-y_1,\dotsc,-y_N)\)</span>.)</p>
<h1 id="sec:orgc67fbf4">§24. BCHD</h1>
<p>Let <span class="math inline">\(G_1, G_2\)</span> be Lie groups.</p>
<div class="definition">
<p><strong>Definition 170</strong>. We say that <span
class="math inline">\(G_1,G_2\)</span> are <em>locally isomorphic</em>
if there are open neighborhoods <span class="math inline">\(U_i
\subseteq G_i\)</span> of the identity elements and a diffeomorphism
<span class="math inline">\(f : U_1 \xrightarrow{\cong } U_2\)</span> so
that whenever <span class="math inline">\(x,y,x y \in U_1\)</span>, one
has <span class="math inline">\(f(xy)=f(x)f(y)\)</span>. In that case,
<span class="math inline">\(f\)</span> is said to be (guess!) a
<em>local isomorphism</em>.</p>
</div>
<div id="example:local-isom" class="example">
<p><strong>Example 171</strong>.  </p>
<ol>
<li><p>Any covering homomorphism <span class="math inline">\(f : G_1
\rightarrow G_2\)</span> induces a local isomorphism.</p></li>
<li><p>If <span class="math inline">\(G_1\)</span> is the connected
component of <span class="math inline">\(G_2\)</span>, then the
inclusion <span class="math inline">\(G_1 \hookrightarrow G_2\)</span>
defines a local isomorphism.</p></li>
<li><p>The relation of being locally isomorphic is obviously an
equivalence relation, i.e., is reflexive and transitive. In verifying
this it is convenient to note that one can always shrink the subsets
<span class="math inline">\(U_1,U_2\)</span> suitably.</p></li>
</ol>
</div>
<div id="thm:local-isom-iff-lie-alg-isom" class="theorem">
<p><strong>Theorem 172</strong>. <em><span
class="math inline">\(G_1,G_2\)</span> are locally isomorphic if and
only if <span
class="math inline">\(\mathfrak{g}_1,\mathfrak{g}_2\)</span> are
isomorphic.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The forward direction is easy: given <span
class="math inline">\(f : U_1 \rightarrow U_2\)</span> with inverse
<span class="math inline">\(f^{-1} : U_2 \rightarrow U_1\)</span> as in
the definition of “locally isomorphic,” the differentials at the
identity <span class="math inline">\(d f : \mathfrak{g}_1 \rightarrow
\mathfrak{g}_2\)</span> and <span class="math inline">\(d (f^{-1}) :
\mathfrak{g}_2 \rightarrow \mathfrak{g}_1\)</span> define morphisms of
Lie algebras (by the same proof as in §<a
href="#sec:diff-morphism-is-morphism" data-reference-type="ref"
data-reference="sec:diff-morphism-is-morphism">14.4</a>)
which are mutually inverse.</p>
<p>The converse direction is more subtle, but follows from what we have
seen already. Namely, let <span class="math inline">\(G_1^0\)</span>
denote the connected component and <span
class="math inline">\(\widetilde{G_1^0}\)</span> its simply-connected
covering group. Then <span class="math inline">\(\mathfrak{g}_1 =
\mathop{\mathrm{Lie}}(G_1) = \mathop{\mathrm{Lie}}(G_1^0) =
\mathop{\mathrm{Lie}}(\widetilde{G_1^0})\)</span>. Let <span
class="math inline">\(\phi : \mathfrak{g}_1 \rightarrow
\mathfrak{g}_2\)</span> be an an isomorphism. Then <span
class="math inline">\(\phi\)</span> is of the form <span
class="math inline">\(d f\)</span> for some <span
class="math inline">\(f : \widetilde{G_1^0} \rightarrow G_2\)</span>.
Since <span class="math inline">\(\phi\)</span> is an isomorphism, we
know by (for instance) Exercise <a href="#exercise:covering-morphisms"
data-reference-type="ref"
data-reference="exercise:covering-morphisms">25</a> that <span
class="math inline">\(f\)</span> is a covering morphism. By Example <a
href="#example:local-isom" data-reference-type="ref"
data-reference="example:local-isom">171</a>, it follows that <span
class="math inline">\(G_1\)</span> is locally isomorphic to <span
class="math inline">\(G_1^0\)</span> which is in turn locally isomorphic
to <span class="math inline">\(\widetilde{G_1^0}\)</span> which is
finally (via <span class="math inline">\(f\)</span>) locally isomorphic
to <span class="math inline">\(G_2\)</span>, as required. ◻</p>
</span></div>
<p>It is natural to ask for a more “local” proof of Theorem <a
href="#thm:local-isom-iff-lie-alg-isom" data-reference-type="ref"
data-reference="thm:local-isom-iff-lie-alg-isom">172</a> that does not
require topological considerations or global constructions involving
universal covers, etc. The BCHD formula gives such a proof. To motivate
that, recall that <span class="math inline">\(\exp : \mathfrak{g}
\rightarrow G\)</span> is a local diffeomorphism near the origin; for
this reason, it makes sense to define for small enough <span
class="math inline">\(x,y \in \mathfrak{g}\)</span> the quantity <span
class="math display">\[x \ast y := \log(\exp(x) \exp(y)).\]</span> (We
explained this in somewhat more detail in class.) Thus <span
class="math inline">\(x \ast y\)</span> is the group law on <span
class="math inline">\(G\)</span> expressed in local coordinates defined
via the exponential map. One has identities like <span
class="math display">\[x \ast (y \ast z) = (x \ast y) \ast z\]</span>
whenever all involved quantities make sense (e.g., whenever <span
class="math inline">\(x,y,z\)</span> are all small enough). We also have
<span class="math display">\[x \ast (-x) = 0,\]</span> etc. If <span
class="math inline">\(G\)</span> is abelian, then <span
class="math inline">\(x \ast y = x + y\)</span>. In general, it is
somewhat more complicated. (See the homework problems this week for some
examples where it isn’t too complicated.)</p>
<div id="exercise:star-product-commutes-with-differentials-of-morphisms"
class="exercise">
<p><strong>Exercise 27</strong>. If <span class="math inline">\(\phi :
\mathfrak{g} \rightarrow \mathfrak{h}\)</span> is the differential of
some morphism of Lie groups <span class="math inline">\(G \rightarrow
H\)</span> and <span class="math inline">\(x,y \in \mathfrak{g}\)</span>
are small enough, then <span class="math display">\[\phi(x) \ast \phi(y)
= \phi(x \ast y).\]</span></p>
</div>
<p>Suppose now temporarily that <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{R})\)</span>, so that <span
class="math inline">\(\mathfrak{g} = M_n(\mathbb{R})\)</span>. Using the
series expansions <span class="math inline">\(\log(z) = \sum_{m \geq 1}
(-1)^{m-1} (z-1)^m/m\)</span> and <span class="math inline">\(\exp(x) =
\sum_{p \geq 0} x^p/p!\)</span>, we obtain <span
class="math display">\[\exp(x) \exp(y) - 1 = \sum _{\substack{
      p,q \geq 0: \\
      (p,q) \neq (0,0) } } \frac{x^p y^q}{p! q!}\]</span> and thus <span id="eq:BCHD-naive" class="math display">\[\label{eq:BCHD-naive}\tag{88}
  x \ast y
  = \sum_{m \geq 1}
  \frac{(-1)^{m-1}}{m}
  \sum _{\substack{
      p_1,q_1,\dotsc,p_m,q_m \geq 0  \\  
      (p_j,q_j) \neq (0,0)
    }
  }
  \frac{x^{p_1} y^{q_1} \dotsb x^{p_m} y^{q_m}}{
    p_1! q_1! \dotsb p_m! q_m!}.\]</span> For <span
class="math inline">\(n \geq 1\)</span>, let <span
class="math inline">\(z_n\)</span> denote the <span
class="math inline">\(n\)</span>th homogeneous component of the sum on
the RHS, so that <span id="eq:bchd-homogeneous-components" class="math display">\[\label{eq:bchd-homogeneous-components}\tag{89}
  x \ast y = \sum_{n \geq 1} z_n.\]</span> If we play around for a bit
(as done in class), we find quickly that <span
class="math display">\[z_1 = x + y,\]</span> <span
class="math display">\[z_2 = \frac{1}{2} [xy]\]</span> where <span
class="math inline">\([x y] := [x,y]\)</span>. The verification of this
involved a “miraculous” coincidence of the shape <span
class="math display">\[\left( \frac{x^2}{2} + x y + \frac{y^2}{2}
\right) - \frac{1}{2} (x^2 + x y + y x + y^2) = \frac{x y - y
x}{2}.\]</span> We indicated that with more work one can show that <span
class="math display">\[z_3 = \frac{1}{12} ([x [x y]] + [y [y
x]])\]</span> and <span class="math display">\[z_4 = \frac{1}{24}
[y[x[yx]]].\]</span></p>
<div id="thm:BCH" class="theorem">
<p><strong>Theorem 173</strong> (BCH “formula”). <em>Let <span
class="math inline">\(G\)</span> be a Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Then for small enough <span
class="math inline">\(x,y \in \mathfrak{g}\)</span>, the identity <a
href="#eq:bchd-homogeneous-components" data-reference-type="eqref"
data-reference="eq:bchd-homogeneous-components">\((89)\)</a>
holds for some degree <span class="math inline">\(n\)</span> Lie
polynomial <span class="math inline">\(z_n\)</span> in <span
class="math inline">\(x,y\)</span> (i.e., <span
class="math inline">\(z_n\)</span> is a linear combination of iterated
<span class="math inline">\(n\)</span>-fold commutators as
above).</em></p>
</div>
<p>There is a more explicit version of this:</p>
<div id="thm:BCHD" class="theorem">
<p><strong>Theorem 174</strong> (BCHD formula). <em>Let <span
class="math inline">\(G\)</span> be a Lie group with Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Then for small enough <span
class="math inline">\(x,y \in \mathfrak{g}\)</span>, the identity <a
href="#eq:bchd-homogeneous-components" data-reference-type="eqref"
data-reference="eq:bchd-homogeneous-components">\((89)\)</a>
holds with <span id="eq:BCHD" class="math display">\[\label{eq:BCHD}\tag{90}
    z_n
    = \frac{1}{n}
    \sum_{m \geq 1}
    \frac{(-1)^{m-1}}{m}
    \sum _{\substack{
        p_1,q_1,\dotsc,p_m,q_m \geq 0  \\  
        (p_j,q_j) \neq (0,0) \\
        p_1+q_1+\dotsb+p_m+q_m=n
      }
    }
    \frac{[x^{p_1} y^{q_1} \dotsb x^{p_m} y^{q_m}]}{
      p_1! q_1! \dotsb p_m! q_m!}\]</span> where, for instance, <span
class="math display">\[:= [x[x[x[y[y[x[x[x[x y]]]]]].\]</span></em></p>
</div>
<p>The similarity between <a href="#eq:BCHD-naive"
data-reference-type="eqref"
data-reference="eq:BCHD-naive">\((88)\)</a> and <a
href="#eq:BCHD" data-reference-type="eqref"
data-reference="eq:BCHD">\((90)\)</a> is no coincidence:</p>
<div class="exercise">
<p><strong>Exercise 28</strong>. Convince yourself that the problem
involving commutators on Homework <a href="#hw:all-about-Ad"
data-reference-type="ref" data-reference="hw:all-about-Ad">6</a> (known
as something like <em>Dynkin’s lemma</em>) allows one to deduce Theorem
<a href="#thm:BCHD" data-reference-type="ref"
data-reference="thm:BCHD">174</a> from Theorem <a href="#thm:BCH"
data-reference-type="ref" data-reference="thm:BCH">173</a>.</p>
</div>
<p>To prove Theorem <a href="#thm:BCH" data-reference-type="ref"
data-reference="thm:BCH">173</a>, define <span
class="math display">\[f(t) := x \ast t y\]</span> for small <span
class="math inline">\(t \in \mathbb{R}\)</span>. Then <span
class="math inline">\(f\)</span> is smooth, and <span
class="math display">\[x \ast y = f(1) = f(0) + \int_{t=0}^1 f&#39;(t)
\, d t.\]</span> Since <span class="math inline">\(\exp f(t) = \exp(x)
\exp(t y)\)</span> we have <span class="math inline">\(\partial_t \exp
f(t) = f(t) y\)</span> and thus by Homework <a href="#hw:diff-exp"
data-reference-type="ref" data-reference="hw:diff-exp">9</a>, <span
class="math display">\[y = \exp(-f(t)) \partial_t \exp(f(t)) =
\Psi({\mathop{\mathrm{ad}}}_{f(t)}) f&#39;(t),\]</span> where <span
class="math display">\[\Psi(z) = \sum_{m=1}^{\infty}
\frac{(-z)^{m-1}}{m!}  = \frac{1 - \exp(-z)}{z}.\]</span> We form the
inverse power series <span class="math display">\[\Psi(z)^{-1} =
\frac{z}{1 - \exp(-z)} = 1 + \frac{z}{2} + \dotsb.\]</span> We then have
<span class="math display">\[f&#39;(t) =
\Psi({\mathop{\mathrm{ad}}}_{f(t)})^{-1} y.\]</span> Using Exercise <a
href="#exercise:star-product-commutes-with-differentials-of-morphisms"
data-reference-type="ref"
data-reference="exercise:star-product-commutes-with-differentials-of-morphisms">27</a>,
we have <span class="math display">\[{\mathop{\mathrm{ad}}}_{f(t)} =
{\mathop{\mathrm{ad}}}_{x} \ast {\mathop{\mathrm{ad}}}_{t y} =
\log(e^{\mathop{\mathrm{ad}}(x)} e^{t
\mathop{\mathrm{ad}}(y)})),\]</span> hence <span
class="math display">\[\Psi({\mathop{\mathrm{ad}}}_{f(t)})^{-1} =
\psi(e^{\mathop{\mathrm{ad}}(x)} e^{t \mathop{\mathrm{ad}}(y)})\]</span>
where <span class="math display">\[\psi(w) := \Psi(\log(w))^{-1} =
\frac{w \log w}{w - 1} = 1 + (w-1)/2 + \dotsb\]</span> (whose
coefficients are what are called Bernoulli numbers). In summary, <span
class="math display">\[x \ast y = x + \int_{t=0}^1
\psi(e^{\mathop{\mathrm{ad}}(x)} e^{t \mathop{\mathrm{ad}}(y)}) y \, d
t.\]</span> We can now expand the integrand out into a power series and
integrate term-by-term; we then obviously get an analytic expression of
the required form. (In fact, it’s not too hard to push this analysis a
bit further to derive <a href="#eq:BCHD" data-reference-type="eqref"
data-reference="eq:BCHD">\((90)\)</a> directly, without using Dynkin’s
trick; just expand everything out.)</p>
<div class="remark">
<p><strong>Remark 175</strong>. The most “conceptual” perspective on the
BCH theorem in its qualitative form may be found in Serre’s book on Lie
algebras and Lie groups in one of the final chapters on Lie algebras;
see also around p72 of the book by Onischik–Vinberg–Gourbatsevich.</p>
</div>
<p>Note that Theorem <a href="#thm:local-isom-iff-lie-alg-isom"
data-reference-type="ref"
data-reference="thm:local-isom-iff-lie-alg-isom">172</a> follows
directly from the BCHD formula: if <span class="math inline">\(x,y \in
\mathfrak{g}_i\)</span> are small enough then the product <span
class="math inline">\(\exp(x) \exp(y)\)</span> is determined entirely by
the Lie bracket on <span class="math inline">\(\mathfrak{g}_i\)</span>,
so an isomorphism <span class="math inline">\(\mathfrak{g}_1 \cong
\mathfrak{g}_2\)</span> obviously lifts to a local isomorphism between
neighborhoods of the identity elements in <span
class="math inline">\(G_1,G_2\)</span>.</p>
<p>There is a lot more to say about the BCHD formula; a taste is given
on the homework set for this lecture. For some problems it may help to
note that for any fixed norm <span class="math inline">\(|.|\)</span> on
<span class="math inline">\(\mathfrak{g}\)</span> and <span
class="math inline">\(x,y\)</span> small enough, one has <span
class="math display">\[x \ast y = O(|x|\,|y|).\]</span></p>
<p>Next lecture we should state some further consequences of BCHD.</p>
<h1 id="sec:orgdccc169">§25. Some more ways to produce and detect Lie
groups</h1>
<h2 id="sec:org1d479ae">§25.1. Summary</h2>
<p>Recall that we have called a subgroup <span
class="math inline">\(H\)</span> of a Lie group <span
class="math inline">\(G\)</span> a <em>Lie subgroup</em> if it is a
submanifold, and that for this to hold, it suffices to verify that <span
class="math inline">\(H\)</span> is locally a submanifold near the
identity element of <span class="math inline">\(G\)</span>. Checking
this condition over and over again eventually becomes tedious, so we ask
for some more systematic ways to detect it. Here are a few, to be
developed in detail throughout this section:</p>
<ol>
<li><p>It was observed in §<a href="#sec:lie-subgroups-are-closed"
data-reference-type="ref"
data-reference="sec:lie-subgroups-are-closed">11.5</a>
that Lie subgroups are automatically closed. Much more interestingly and
perhaps surpririnsgly, the converse is true over <span
class="math inline">\(k = \mathbb{R}\)</span>: any closed subgroup <span
class="math inline">\(H\)</span> of a <em>real</em> Lie group <span
class="math inline">\(G\)</span> is automatically a Lie subgroup
(Theorem <a href="#thm:closed-implies-lie" data-reference-type="ref"
data-reference="thm:closed-implies-lie">176</a>). This is very powerful,
and implies most of the criteria discussed below.</p>
<p>This criterion does not apply directly to complex Lie groups: for
instance a real Lie subgroup of a complex Lie group is seldom a complex
Lie subgroup (think <span class="math inline">\(\mathbb{R}
\hookrightarrow \mathbb{C}\)</span> or <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R}) \hookrightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>). But it’s not hard to
verify (e.g., by inspecting the proof of what we are talking about) that
if <span class="math inline">\(H\)</span> is a real Lie subgroup of a
complex Lie group <span class="math inline">\(G\)</span> with the
property that <span class="math inline">\(\mathfrak{h}\)</span> is a
complex vector space of <span
class="math inline">\(\mathfrak{g}\)</span>, then <span
class="math inline">\(H\)</span> is a complex Lie subgroup of <span
class="math inline">\(G\)</span>. A fairly good rule of thumb is that if
a subgroup <span class="math inline">\(H\)</span> of a complex Lie group
<span class="math inline">\(G\)</span> has the properties</p>
<ol>
<li><p><span class="math inline">\(H\)</span> is closed, and</p></li>
<li><p>the definition of <span class="math inline">\(H\)</span> does not
make reference to the real numbers, complex conjugation or similar
“non-holomorphic” notions,</p></li>
</ol>
<p>then <span class="math inline">\(H\)</span> is probably a complex Lie
subgroup.</p>
<p>Some of the methods used to prove the criteria to be given below are
of independent interest, even in the real case, because they give
convenient ways to compute Lie algebras in many common
situations.</p></li>
<li><p>“Stabilizers” of any sort (of points in a manifold, of vectors in
a representation, etc.) are, in practice, obviously closed, hence are
Lie subgroups by the previous item. Moreover,their Lie algebras tend to
be “the obvious thing.” Many subgroups can be somehow interpreted as
stabilizers:</p>
<ol>
<li><p>kernels of morphisms of Lie groups,</p></li>
<li><p>stabilizers of subspaces in representations,</p></li>
<li><p>intersections of Lie subgroups,</p></li>
<li><p>etc.</p></li>
</ol></li>
<li><p>An interesting result that does not follow from the above
criteria is that in a <em>simply-connected</em> Lie group <span
class="math inline">\(G\)</span>, the commutator subgroup <span
class="math inline">\(G&#39; := [G,G]\)</span> is a Lie subgroup. This
conclusion fails in general, although it remains true that the
commutator subgroup is an <em>immersed</em> Lie subgroup.</p></li>
<li><p>Given a Lie subgroup <span class="math inline">\(H\)</span> of a
Lie group <span class="math inline">\(G\)</span>, one can naturally
construct the quotient manifold <span
class="math inline">\(G/H\)</span>; if <span
class="math inline">\(H\)</span> is normal, then <span
class="math inline">\(G/H\)</span> is also a Lie group.</p></li>
</ol>
<h2 id="sec:orgd737096">§25.2. Closed subgroups of real Lie groups</h2>
<h3 id="sec:org018f0b5">§25.2.1. Statement of the key result</h3>
<div id="thm:closed-implies-lie" class="theorem">
<p><strong>Theorem 176</strong>. <em>Let <span
class="math inline">\(G\)</span> be a real Lie group, and let <span
class="math inline">\(H \subseteq G\)</span> be a subset. The following
are equivalent:</em></p>
<ol>
<li><p><em><span class="math inline">\(H\)</span> is a closed subgroup
of <span class="math inline">\(G\)</span>, that is to say,</em></p>
<ol>
<li><p><em><span class="math inline">\(H\)</span> is a closed subset of
<span class="math inline">\(G\)</span>, and</em></p></li>
<li><p><em><span class="math inline">\(e \in H\)</span>, and <span
class="math inline">\(h^{-1}, h_1 h_2 \in H\)</span> whenever <span
class="math inline">\(h,h_1,h_2 \in H\)</span>.</em></p></li>
</ol></li>
<li><p><em><span class="math inline">\(H\)</span> is a Lie subgroup of
<span class="math inline">\(G\)</span>, that is to say,</em></p>
<ol>
<li><p><em><span class="math inline">\(H\)</span> is a submanifold of
<span class="math inline">\(G\)</span>, and</em></p></li>
<li><p><em><span class="math inline">\(e \in H\)</span>, and <span
class="math inline">\(h^{-1}, h_1 h_2 \in H\)</span> whenever <span
class="math inline">\(h, h_1,h_2 \in H\)</span>.</em></p></li>
</ol></li>
</ol>
</div>
<h3 id="sec:org3cf56ab">§25.2.2. A toy example</h3>
<p>One can already illustrate the basic idea behind Theorem <a
href="#thm:closed-implies-lie" data-reference-type="ref"
data-reference="thm:closed-implies-lie">176</a> in the case <span
class="math inline">\(G = \mathbb{R}\)</span>, where it amounts to the
following:</p>
<div class="theorem">
<p><strong>Theorem 177</strong>. <em>Let <span
class="math inline">\(H\)</span> be a closed subgroup of the real line
<span class="math inline">\(\mathbb{R}\)</span>. Then exactly one of the
following possibilities occur:</em></p>
<ul>
<li><p><em><span class="math inline">\(H = \mathbb{R}\)</span>,
or</em></p></li>
<li><p><em><span class="math inline">\(H\)</span> is discrete, or
equivalently, one has <span
class="math inline">\((-\varepsilon,\varepsilon) \cap H = \{0\}\)</span>
for some <span class="math inline">\(\varepsilon&gt;
0\)</span>.</em></p></li>
</ul>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If the second possibility does not occur, then we can
find a sequence <span class="math inline">\(x_n \in H\)</span> with
<span class="math inline">\(x_n \rightarrow 0\)</span> and <span
class="math inline">\(x_n \neq 0\)</span>. Let <span
class="math inline">\(x \in \mathbb{R}\)</span> be given. We can find a
sequence of reals <span class="math inline">\(c_n\)</span> so that <span
class="math inline">\(c_n x_n \rightarrow x\)</span>; for instance, one
can take <span class="math inline">\(c_n = x/x_n\)</span>. But since
<span class="math inline">\(x_n \rightarrow 0\)</span>, the conclusion
<span class="math inline">\(c_n x_n \rightarrow x\)</span> is unaffected
by rounding <span class="math inline">\(c_n\)</span> to the nearest
integer. We can thus find a sequence of <em>integers</em> <span
class="math inline">\(c_n\)</span> so that <span
class="math inline">\(c_n x_n \rightarrow x\)</span>. Since <span
class="math inline">\(H\)</span> is a subgroup, we then have <span
class="math inline">\(c_n x_n \in H\)</span> for all <span
class="math inline">\(n\)</span>. Since <span
class="math inline">\(H\)</span> is closed, it follows that <span
class="math inline">\(x \in H\)</span>. Since <span
class="math inline">\(x\)</span> was arbitrary, we conclude as required
that <span class="math inline">\(H = \mathbb{R}\)</span>. ◻</p>
</span></div>
<h3 id="sec:org5574bc9">§25.2.3. Proof of the key result</h3>
<div class="proof">
<p><em>Proof of Theorem <a href="#thm:closed-implies-lie"
data-reference-type="ref"
data-reference="thm:closed-implies-lie">176</a>.</em> Thanks to ??? and
???, all we need to show is that if <span
class="math inline">\(H\)</span> is a closed subgroup of <span
class="math inline">\(G\)</span>, then <span
class="math inline">\(H\)</span> is locally a submanifold of <span
class="math inline">\(G\)</span> at the identity. Let <span
class="math inline">\(\mathfrak{g}\)</span> denote the Lie algebra of
<span class="math inline">\(\mathfrak{g}\)</span>. Set <span
class="math display">\[\mathfrak{h} := \left\{ x \in \mathfrak{g} :
\exists c_n \in \mathbb{R}, x_n \in \mathfrak{g} \cap \exp^{-1}(H)
\text{ so that } x_n \rightarrow 0, c_n x_n \rightarrow x
\right\}.\]</span> Two quick remarks before continuing with the
proof:</p>
<ul>
<li><p>If we somehow knew already that <span
class="math inline">\(H\)</span> were a Lie subgroup, then <span
class="math inline">\(\mathfrak{h}\)</span> would of course be its Lie
algebra, as any <span class="math inline">\(x_n\)</span> in the
definition would belong to <span
class="math inline">\(\mathfrak{h}\)</span> for <span
class="math inline">\(n\)</span> large enough.</p></li>
<li><p>A good “enemy scenario” to keep in mind is when <span
class="math inline">\(G = (\mathbb{R} /\mathbb{Z})^2\)</span> and <span
class="math inline">\(H\)</span> is the image of the map <span
class="math inline">\(x \mapsto (x, \alpha x)\)</span>, where <span
class="math inline">\(\alpha \in \mathbb{R} - \mathbb{Q}\)</span>. Then
<span class="math inline">\(H\)</span> is a subgroup (indeed, an
immersed Lie subgroup), but fails to be closed. The set <span
class="math inline">\(\mathfrak{h}\)</span> defined as above is all of
<span class="math inline">\(\mathfrak{g}\)</span>, and so has nothing to
do with the Lie algebra of <span class="math inline">\(H\)</span>. The
argument to follow will need to rule out this scenario.</p></li>
</ul>
<p>We show now that</p>
<div class="center">
<p><span class="math inline">\(\mathfrak{h}\)</span> is a vector
subspace of <span class="math inline">\(\mathfrak{g}\)</span> for which
<span class="math inline">\(\exp(\mathfrak{h}) \subseteq H\)</span>.</p>
</div>
<ol>
<li><p>It is clear that <span
class="math inline">\(\mathfrak{h}\)</span> is stable under scalar
multiplication.</p></li>
<li><p>Let <span class="math inline">\(x \in \mathfrak{h}\)</span>, so
that <span class="math inline">\(x = \lim c_n x_n\)</span> for some
<span class="math inline">\(c_n, x_n\)</span> as in the definition of
<span class="math inline">\(\mathfrak{h}\)</span>. The condition <span
class="math inline">\(x_n \rightarrow 0\)</span> implies that rounding
<span class="math inline">\(c_n\)</span> to the nearest integer does not
affect the condition <span class="math inline">\(c_n x_n \rightarrow
x\)</span>, so we may assume without loss of generality that <span
class="math inline">\(c_n \in \mathbb{Z}\)</span>. Since <span
class="math inline">\(H\)</span> is a closed subgroup, we then have
<span class="math inline">\(\exp (x) = \lim \exp(x_n)^{c_n} \in
H\)</span>.</p></li>
<li><p>Let <span class="math inline">\(x,y \in \mathfrak{h}\)</span>.
For <span class="math inline">\(n\)</span> large enough, set <span
class="math inline">\(z_n := \log(\exp(x/n) \exp(y/n))\)</span>. By the
previous item, <span class="math inline">\(\exp(z_n) = \exp(x/n)
\exp(y/n) \in H\)</span>. As we’ve seen earlier in the course (during
the discussion of the exponential map; what we need here also follows
easily from BCH), we have <span class="math inline">\(z_n = x/n + y/n +
O(1/n^2)\)</span>, hence <span class="math inline">\(z_n \rightarrow
0\)</span> and <span class="math inline">\(n z_n \rightarrow x +
y\)</span>. Therefore <span class="math inline">\(x + y \in
\mathfrak{h}\)</span>.</p></li>
</ol>
<p>Let <span class="math inline">\(\mathfrak{h} &#39; \leq
\mathfrak{g}\)</span> be any vector space complement to <span
class="math inline">\(\mathfrak{h}\)</span>, so that <span
class="math inline">\(\mathfrak{g} = \mathfrak{h} \oplus \mathfrak{h}
&#39;\)</span>. The map <span class="math inline">\(\mathfrak{g} =
\mathfrak{h} \oplus \mathfrak{h} &#39; \ni (v,w) \mapsto \exp(v)
\exp(w)\)</span> has derivative <span class="math inline">\(1\)</span>
at the origin, hence is a local diffeomorphism. There is thus a small
open neighborhood <span class="math inline">\(U\)</span> of the identity
element in <span class="math inline">\(G\)</span> and a smooth chart
<span class="math display">\[(\alpha,\alpha &#39; ) : U \rightarrow
\mathfrak{h} \oplus \mathfrak{h}&#39;\]</span> characterized by the
identity <span class="math display">\[g = \exp(\alpha(g))
\exp(\alpha&#39;(g)) \text{ for all }g \in U.\]</span> We claim that if
<span class="math inline">\(U\)</span> is small enough, then <span
class="math display">\[U \cap H = \{g \in U : \alpha&#39;(g) =
0\}.\]</span> This shows that <span class="math inline">\(H\)</span> is
locally a submanifold of <span class="math inline">\(G\)</span> at the
identity, as required.</p>
<p>To prove the claim, note first that if <span
class="math inline">\(\alpha &#39;(g) = 0\)</span>, then <span
class="math inline">\(g = \exp(\alpha(g)) \in \exp(\mathfrak{h})
\subseteq H\)</span>. This establish one inclusion.</p>
<p>Conversely, if the reverse inclusion fails for arbitrarily small
<span class="math inline">\(U\)</span>, then we can find a sequence
<span class="math inline">\(h_n \in U \cap H\)</span> with <span
class="math inline">\(h_n \rightarrow 1\)</span> so that <span
class="math inline">\(\alpha &#39;(h_n) \neq 0\)</span>. Set <span
class="math display">\[x_n := \alpha &#39;(h_n).\]</span> Since <span
class="math inline">\(\exp(x_n)\)</span> belongs to the group generated
by <span class="math inline">\(h \in H\)</span> and <span
class="math inline">\(\exp(\alpha(h_n)) \in \exp(\mathfrak{h}) \subseteq
H\)</span>, it belongs to <span class="math inline">\(H\)</span>, and so
<span class="math display">\[x_n \in \mathfrak{h} &#39; \cap
\exp^{-1}(H), \quad x_n \rightarrow 0, x_n \neq 0.\]</span> By passing
to a subsequence, we have <span class="math inline">\(|x_n|^{-1} x_n
\rightarrow x\)</span> for some nonzero <span class="math inline">\(x
\in \mathfrak{h} &#39;\)</span>, but then also <span
class="math inline">\(x \in \mathfrak{h}\)</span>; since <span
class="math inline">\(\mathfrak{h} \cap \mathfrak{h} &#39; = 0\)</span>,
we obtain the required contradiction. ◻</p>
</div>
<p>A simple corollary that already illustrates the basic idea is the
following:</p>
<div id="cor:classification-vector-subspaces" class="corollary">
<p><strong>Corollary 178</strong>. <em>Let <span
class="math inline">\(H\)</span> be a closed subgroup of <span
class="math inline">\(\mathbb{R}^n\)</span>. Then there is a vector
space <span class="math inline">\(V \leq \mathbb{R}^n\)</span> and an
open neighborhood <span class="math inline">\(0 \in U \subseteq
\mathbb{R}^n\)</span> so that <span class="math inline">\(H \cap U = V
\cap U\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We take <span class="math inline">\(G :=
\mathbb{R}^n\)</span> and note that <span
class="math inline">\(\mathfrak{g} = \mathbb{R}^n\)</span> and that the
exponential map <span class="math inline">\(\mathfrak{g} \rightarrow
G\)</span> is the identity. The conclusion then follows from Theorem <a
href="#thm:closed-implies-lie" data-reference-type="ref"
data-reference="thm:closed-implies-lie">176</a>. ◻</p>
</span></div>
<div class="exercise">
<p><strong>Exercise 29</strong>. Write down a direct proof of Corollary
<a href="#cor:classification-vector-subspaces" data-reference-type="ref"
data-reference="cor:classification-vector-subspaces">178</a>. (The proof
of Theorem <a href="#thm:closed-implies-lie" data-reference-type="ref"
data-reference="thm:closed-implies-lie">176</a> simplifies a bit in this
special case while retaining its basic flavor; it is instructive to work
out exactly how it simplifies.)</p>
</div>
<h2 id="sec:orgca48d81">§25.3. Stabilizers<span id="sec:detect-lie-stabilizers"
label="sec:detect-lie-stabilizers"></span></h2>
<h3 id="sec:org9ced8a6">§25.3.1. The basic result<span id="sec:stab-basic-result"
label="sec:stab-basic-result"></span></h3>
<p>Let <span class="math inline">\(M\)</span> be a manifold and <span
class="math inline">\(G\)</span> a Lie group acting on <span
class="math inline">\(M\)</span>, i.e., equipped with a smooth map <span
class="math inline">\(G \times M \rightarrow M\)</span> satisfying the
usual requirements of an action (see Definition <a
href="#defn:lie-group" data-reference-type="ref"
data-reference="defn:lie-group">59</a>). Let <span
class="math inline">\(x \in M\)</span>. Consider the orbit map <span
class="math inline">\(\alpha : G \rightarrow M\)</span> given by <span
class="math inline">\(\alpha(g) := g x\)</span>. A crucial property of
this map is that it has <em>constant rank</em>. Indeed, its rank at
<span class="math inline">\(g_2\)</span> is the same as its rank at
<span class="math inline">\(g_1 g_2\)</span> thanks to the identity
<span class="math inline">\(\alpha(g_1 g_2) = \alpha(g_1)
\alpha(g_2)\)</span> and the fact that <span
class="math inline">\(\alpha(g_1)\)</span> is a diffeomorphism. Using
the constant rank theorem from multivariable calculus, it follows that
<span class="math inline">\(\alpha\)</span> is linearizable in a
neighborhood of any point of <span class="math inline">\(G\)</span>, and
in particular, near the identity element. It follows that <span
class="math display">\[{\mathop{\mathrm{Stab}}}_G(x) = \{g \in G :
\alpha(g) = x\}\]</span> is a submanifold of <span
class="math inline">\(G\)</span>, hence a Lie subgroup, with Lie algebra
<span class="math display">\[{\mathop{\mathrm{stab}}}_\mathfrak{g}(x) :=
\{X \in \mathfrak{g} : d \alpha(X) = 0\}.\]</span></p>
<h3 id="sec:org93667ef">§25.3.2. Application to kernels</h3>
<p>If <span class="math inline">\(f : G \rightarrow H\)</span> is a
morphism of Lie groups, then we may regard <span
class="math inline">\(G\)</span> as acting on <span
class="math inline">\(H\)</span> via <span class="math inline">\(g \cdot
x := f(g) x\)</span>. The stabilizer of the identity element of <span
class="math inline">\(H\)</span> under this action is then the kernel of
<span class="math inline">\(f\)</span>, so by the result of the previous
section, <span class="math display">\[\ker(f) = \{g \in G : f(g) =
e\}\]</span> is a Lie subgroup of <span class="math inline">\(G\)</span>
with Lie algebra <span class="math display">\[\ker(d f) : \{X \in
\mathfrak{g} : d f (X) = 0 \}.\]</span></p>
<h3 id="sec:org79033ad">§25.3.3. Application to preimages<span
id="sec:stab-appl-preimages"
label="sec:stab-appl-preimages"></span></h3>
<p>Given a morphism <span class="math inline">\(f : G \rightarrow
H\)</span> of Lie groups and a Lie subgroup <span
class="math inline">\(H_1\)</span> of <span
class="math inline">\(H\)</span>, the preimage <span
class="math inline">\(f^{-1}(H_1)\)</span> may be interpreted as the
stabilizer in <span class="math inline">\(G\)</span> of the identity
element in the quotient manifold <span
class="math inline">\(H/H_1\)</span> under the action afforded by <span
class="math inline">\(f\)</span>. Thus <span
class="math inline">\(f^{-1}(H_1)\)</span> is a Lie subgroup of <span
class="math inline">\(G\)</span> with Lie algebra <span
class="math inline">\((d f)^{-1}(\mathfrak{h}_1) \leq
\mathfrak{g}\)</span>.</p>
<h3 id="sec:org60c2f88">§25.3.4. Application to intersections</h3>
<p>If <span class="math inline">\(H_1, H_2\)</span> are Lie subgroups of
a Lie group <span class="math inline">\(G\)</span>, then <span
class="math inline">\(H_1 \cap H_2\)</span> is the preimage of <span
class="math inline">\(H_2\)</span> under the inclusion map <span
class="math inline">\(H_1 \hookrightarrow G\)</span>, and is thus itself
a Lie subgroup.</p>
<h3 id="sec:orgc9b1def">§25.3.5. Application to stabilizers of vectors or
subspaces in representations</h3>
<p>Let <span class="math inline">\(G\)</span> be a Lie group and <span
class="math inline">\(R : G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
a representation. For <span class="math inline">\(v \in V\)</span>, we
know by §<a href="#sec:stab-basic-result" data-reference-type="ref"
data-reference="sec:stab-basic-result">25.3.1</a> that
<span class="math inline">\({\mathop{\mathrm{Stab}}}_G(v)\)</span> is a
Lie subgroup with Lie algebra <span
class="math inline">\({\mathop{\mathrm{stab}}}_G(v)\)</span>. For a
subspace <span class="math inline">\(U\)</span> of <span
class="math inline">\(V\)</span>, we can apply the considerations of §<a
href="#sec:stab-basic-result" data-reference-type="ref"
data-reference="sec:stab-basic-result">25.3.1</a> to a
suitable Grassmannian manifold (consisting of subspaces of <span
class="math inline">\(V\)</span> of given dimension) to see that <span id="eq:defn-stabilizer-subspace-subgroup" class="math display">\[\label{eq:defn-stabilizer-subspace-subgroup}\tag{91}
  \{g \in G : R(g) U \subseteq U\}\]</span> is a Lie subgroup of <span
class="math inline">\(G\)</span> with Lie algebra <span
class="math display">\[\{X \in \mathfrak{g} : d R(X) U \subseteq U
\}.\]</span> Alternatively, we can note that <span
class="math inline">\(\{g \in \mathop{\mathrm{GL}}(V) : g U \subseteq
U\}\)</span> is a Lie subgroup of <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> (consisting of
block upper-triangular matrices); it follows then from from the
discussion of §<a href="#sec:stab-appl-preimages"
data-reference-type="ref"
data-reference="sec:stab-appl-preimages">25.3.3</a>
that its preimage <a href="#eq:defn-stabilizer-subspace-subgroup"
data-reference-type="eqref"
data-reference="eq:defn-stabilizer-subspace-subgroup">\((91)\)</a>
is a Lie subgroup of <span class="math inline">\(G\)</span> with Lie
algebra as indicated.</p>
<h2 id="sec:orge98ecbb">§25.4. Commutator subgroups</h2>
<p>For a general Lie group <span class="math inline">\(G\)</span>, the
subgroup <span class="math inline">\(G&#39; := [G,G]\)</span> of
commutators need not be closed, hence need not be a Lie subgroup. But if
<span class="math inline">\(G\)</span> is <em>simply-connected</em>,
then <span class="math inline">\(G&#39;\)</span> is indeed a Lie
subgroup. To see this, denote by <span
class="math inline">\(\mathfrak{g}\)</span> the Lie algebra of <span
class="math inline">\(G\)</span> and by <span
class="math inline">\(\mathfrak{g}&#39; :=
[\mathfrak{g},\mathfrak{g}]\)</span> the subalgebra generated by the
commutators. Then <span class="math inline">\(\mathfrak{g} /
\mathfrak{g} &#39;\)</span> is an abelian Lie algebra, hence is the Lie
algebra of a vector space <span class="math inline">\(V\)</span>. Since
<span class="math inline">\(G\)</span> is simply-connected, the natural
Lie algebra morphism <span class="math inline">\(d f : \mathfrak{g}
\rightarrow \mathfrak{g} / \mathfrak{g} &#39;\)</span> lifts to a Lie
group morphism <span class="math inline">\(f : G \rightarrow V\)</span>.
Then <span class="math inline">\(\ker(f)\)</span> is a Lie subgroup with
Lie algebra <span class="math inline">\(\mathfrak{g} &#39;\)</span>;
moreover, it is clear that <span class="math inline">\(\ker(f) \supseteq
G&#39;\)</span>. In the opposite direction, we can play around with
commutators of paths near the identity in <span
class="math inline">\(G\)</span> and the inverse function theorem to see
that <span class="math inline">\(G&#39;\)</span> contains a neighborhood
of the identity in <span class="math inline">\(\ker(f)\)</span>. It
follows that <span class="math inline">\(G&#39;\)</span> and <span
class="math inline">\(\ker(f)\)</span> coincide near the identity. In
particular, <span class="math inline">\(G&#39;\)</span> is a Lie
subgroup.</p>
<p>In fact, since <span class="math inline">\(G/\ker(f) \cong V\)</span>
is a vector space, it follows from the short exact sequence <span
class="math inline">\(\dotsb \rightarrow \pi_1(G/\ker(f)) \rightarrow
\pi_0(\ker(f)) \rightarrow 0\)</span> that <span
class="math inline">\(\pi_0(\ker(f)) = 0\)</span>, i.e., that <span
class="math inline">\(\ker(f)\)</span> is connected. So we actually have
<span class="math inline">\(G&#39; = \ker(f)\)</span>.</p>
<h1 id="sec:org1df5b23">§26. Immersed Lie subgroups</h1>
<p>We’ve described thus far a fair bit of the basic Lie-theoretic
dictionary: simply-connected Lie groups correspond to Lie algebras, etc.
We’ve also seen that for a Lie group <span
class="math inline">\(G\)</span>, the connected Lie subgroups <span
class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span> are determined by their Lie algebras
<span class="math inline">\(\mathfrak{h} \leq \mathfrak{g}\)</span>.
It’s natural to ask which <span
class="math inline">\(\mathfrak{h}\)</span> arise in this way. The
subtlety of the problem can be seen by considering simple examples such
as <span class="math inline">\(G = \mathbb{R}^2\)</span> and <span
class="math inline">\(G = (\mathbb{R}/\mathbb{Z})^2\)</span>, as in
lecture.</p>
<p>An easier question is to ask whether arbitrary Lie subalgebras <span
class="math inline">\(\mathfrak{h} \leq \mathfrak{g}\)</span> of the Lie
algebra <span class="math inline">\(\mathfrak{g}\)</span> of a Lie group
<span class="math inline">\(G\)</span> correspond to “something”
involving <span class="math inline">\(G\)</span>. The answer is that
they are in natural bijection with <em>connected immersed Lie
subgroups</em> <span class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span> (recall Definition <a
href="#defn:immersed-lie-subgroup" data-reference-type="ref"
data-reference="defn:immersed-lie-subgroup">63</a>, which I’ve gone back
in the notes and modified since we started the course in order to make
things work here). By definition, the latter are abstract subgroups
<span class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span> with the property that there exists a
manifold structure on <span class="math inline">\(H\)</span> with
respect to which <span class="math inline">\(H\)</span> is a Lie group
and so that the inclusion <span class="math inline">\(H \rightarrow
G\)</span> is an injective (immersive) morphism of Lie groups.</p>
<p>To put it a bit more verbosely: a subset <span
class="math inline">\(H\)</span> of a Lie group <span
class="math inline">\(G\)</span> is an immersed Lie subgroup if there
exists a Lie group <span class="math inline">\(\hat{H}\)</span> and an
injective immersion <span class="math inline">\(\iota : \hat{H}
\rightarrow G\)</span> with image <span
class="math inline">\(H\)</span>. In that case <span
class="math inline">\(d \iota : \mathop{\mathrm{Lie}}(\hat{H})
\rightarrow \mathfrak{g}\)</span> is an injective morphism of Lie
algebras whose image <span class="math inline">\(\mathfrak{h}\)</span>
we define to be the Lie algebra of <span
class="math inline">\(H\)</span>. This gives one direction of the above
correspondence.</p>
<p>The reverse direction is more subtle: given a subalgebra <span
class="math inline">\(\mathfrak{h}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span>, one takes for <span
class="math inline">\(H\)</span> the subgroup generated by the image of
<span class="math inline">\(\mathfrak{h}\)</span> under the exponential
map. One then attempts to define a manifold structure on <span
class="math inline">\(H\)</span> to be that generated for small open
<span class="math inline">\(0 \in U \subseteq \mathfrak{h}\)</span> and
<span class="math inline">\(h \in H\)</span> by the charts <span
class="math inline">\(h \exp(U) \ni h \exp(X) \mapsto X \in
U\)</span>.</p>
<p>Another part of the correspondence is that the Lie group structure on
any immersed Lie subgroup <span class="math inline">\(H \leq G\)</span>
is uniquely determined by the subset <span
class="math inline">\(H\)</span>.</p>
<p>See Chapter 1, Sections 2.4 and 5.3 of the first reference on the
course page for more details.</p>
<h1 id="sec:org0fe80c3">§27. Simple Lie groups</h1>
<p>Recall that a subset <span class="math inline">\(H\)</span> of an
abstract group <span class="math inline">\(G\)</span> is called</p>
<ul>
<li><p>a <em>subgroup</em> if <span class="math inline">\(e \in
H\)</span> and <span class="math inline">\(h_1,h_2 \in H \implies h_1
h_2 \in H\)</span> and <span class="math inline">\(h \in H \implies
h^{-1} \in H\)</span>, and is in that case called</p></li>
<li><p><em>normal</em> if <span class="math inline">\(g H g^{-1}
\subseteq H\)</span> for all <span class="math inline">\(g \in
G\)</span>,</p></li>
<li><p><em>trivial</em> if <span class="math inline">\(H =
\{1\}\)</span>,</p></li>
<li><p><em>proper</em> if <span class="math inline">\(H \neq
G\)</span>,</p></li>
</ul>
<p>and that <span class="math inline">\(G\)</span> is called
<em>simple</em> if it has no nontrivial proper normal subgroups. For Lie
theory, a slightly modified definition turns out to be convenient.</p>
<div class="definition">
<p><strong>Definition 179</strong>. Let <span
class="math inline">\(\mathfrak{g}\)</span> be a Lie algebra, thus <span
class="math inline">\(\mathfrak{g}\)</span> is a vector space (over
<span class="math inline">\(\mathbf{k} = \mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span>, say) equipped with a bracket
operation <span class="math inline">\([,]\)</span> that is bilinear,
antisymmetric, and satisfies the Jacobi identity. A vector subspace
<span class="math inline">\(\mathfrak{h}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> is called</p>
<ul>
<li><p>a <em>subalgebra</em> if <span
class="math inline">\([\mathfrak{h},\mathfrak{h}] \subseteq
\mathfrak{h}\)</span>, and is</p></li>
<li><p>an <em>ideal</em> if <span
class="math inline">\([\mathfrak{g},\mathfrak{h}] \subseteq
\mathfrak{h}\)</span>.</p></li>
</ul>
<p>Here <span class="math inline">\([\mathfrak{g},\mathfrak{h}]\)</span>
denotes the span of the commutators <span
class="math inline">\([x,y]\)</span> with <span class="math inline">\(x
\in \mathfrak{g}, y \in \mathfrak{h}\)</span>. It is clear that an ideal
is a subalgebra.</p>
<p>We denote the relationship that <span
class="math inline">\(\mathfrak{h}\)</span> is an ideal of <span
class="math inline">\(\mathfrak{g}\)</span> symbolically by <span
class="math inline">\(\mathfrak{h} \triangleleft
\mathfrak{g}\)</span>.</p>
</div>
<p>Henceforth denote by <span class="math inline">\(G\)</span> a
<em>connected</em> Lie group and by <span
class="math inline">\(\mathfrak{g}\)</span> its Lie algebra. Recall that
there is a natural bijection <span class="math display">\[\{ \text{
subalgebras } \mathfrak{h} \text{ of } \mathfrak{g} \} \cong \{ \text{
connected virtual Lie subgroups $H$ of $G$ } \}\]</span> given in the
forward direction by <span class="math inline">\(\mathfrak{h} \mapsto H
:= \langle \exp_G(\mathfrak{h}) \rangle\)</span>.</p>
<div id="exe:normal-vs-ideal" class="exercise">
<p><strong>Exercise 30</strong>. Let <span
class="math inline">\(H\)</span> be a connected virtual Lie subgroup of
<span class="math inline">\(G\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span>. The following are
equivalent:</p>
<ol>
<li><p><span class="math inline">\(H\)</span> is a normal subgroup of
<span class="math inline">\(G\)</span>.</p></li>
<li><p><span class="math inline">\(\mathfrak{h}\)</span> is an ideal in
<span class="math inline">\(\mathfrak{g}\)</span>.</p></li>
</ol>
<p>[Use the standard differentiation/exponentiation technique.]</p>
</div>
<div class="definition">
<p><strong>Definition 180</strong>. <span
class="math inline">\(\mathfrak{g}\)</span> is <em>abelian</em> if <span
class="math inline">\([\mathfrak{g},\mathfrak{g}]=0\)</span>.</p>
</div>
<div id="exe:abelian-lie-alg-lie-gp" class="exercise">
<p><strong>Exercise 31</strong>. <span class="math inline">\(G\)</span>
is abelian if and only if <span
class="math inline">\(\mathfrak{g}\)</span> is abelian. [Use the
standard differentiation/exponentiation technique.]</p>
</div>
<div class="definition">
<p><strong>Definition 181</strong>. <span
class="math inline">\(\mathfrak{g}\)</span> is <em>simple</em> if it is
non-abelian and has no nontrivial proper ideals.</p>
</div>
<div class="definition">
<p><strong>Definition 182</strong>. <span
class="math inline">\(G\)</span> is <em>simple</em> if it is non-abelian
it has no nontrivial proper normal connected virtual Lie subgroups.</p>
</div>
<div class="lemma">
<p><strong>Lemma 183</strong>. The following are equivalent:</p>
<ol>
<li><p><span class="math inline">\(G\)</span> is simple.</p></li>
<li><p><span class="math inline">\(\mathfrak{g}\)</span> is
simple.</p></li>
<li><p>Every proper normal subgroup of <span
class="math inline">\(G\)</span> is discrete.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The equivalence of (i) and (ii) is immediate from
Exercise <a href="#exe:normal-vs-ideal" data-reference-type="ref"
data-reference="exe:normal-vs-ideal">30</a>. It is clear that (iii)
implies (i): if every proper normal subgroup of <span
class="math inline">\(G\)</span> is discrete, and if <span
class="math inline">\(H\)</span> is a proper normal connected virtual
Lie subgroup, then <span class="math inline">\(H\)</span> is in
particular a proper normal subgroup, hence is discrete; since <span
class="math inline">\(H\)</span> is then discrete and connected, it is
trivial, and since <span class="math inline">\(H\)</span> was arbitrary
we conclude that <span class="math inline">\(G\)</span> is simple.</p>
<p>The interesting implication is thus that (i) and (ii) imply (iii). To
see that, let <span class="math inline">\(K\)</span> be a normal
subgroup of <span class="math inline">\(G\)</span> that is not discrete;
we wish to show that <span class="math inline">\(K = G\)</span>. The
closure <span class="math inline">\(\overline{K}\)</span> of <span
class="math inline">\(K\)</span> is (by continuity) a closed normal
subgroup of <span class="math inline">\(G\)</span>. Since <span
class="math inline">\(K\)</span> is not discrete, neither is <span
class="math inline">\(\overline{K}\)</span>, hence neither is the
connected component <span class="math inline">\(\overline{K}^0\)</span>.
Since <span class="math inline">\(\overline{K}^0\)</span> is a
characteristic subgroup of <span
class="math inline">\(\overline{K}\)</span>, it is a closed normal
subgroup of <span class="math inline">\(G\)</span>, hence a non-discrete
normal Lie subgroup of <span class="math inline">\(G\)</span>; since
<span class="math inline">\(G\)</span> is simple, the only possibility
is that <span class="math inline">\(\overline{K}^0 = G\)</span>, hence
<span class="math inline">\(\overline{K} = G\)</span>.</p>
<p>In summary, <span class="math inline">\(K\)</span> is dense in <span
class="math inline">\(G\)</span>. We claim that there is <span
class="math inline">\(k \in K\)</span> and <span class="math inline">\(X
\in \mathfrak{g}\)</span> so that <span
class="math inline">\(\mathop{\mathrm{Ad}}(k) X \neq X\)</span>. If not,
then it would follow by continuity that <span
class="math inline">\(\mathop{\mathrm{Ad}}(G)\)</span> is trivial, hence
that <span class="math inline">\(\mathfrak{g}\)</span> is abelian,
contrary to our assumption that <span
class="math inline">\(\mathfrak{g}\)</span> is simple, hence
non-abelian.</p>
<p>Consider the curve <span class="math inline">\(\gamma(t) :=
(k,\exp_G(t X))\)</span>, where <span class="math inline">\((,)\)</span>
denotes the commutator. We then have <span class="math inline">\(\gamma
(0) = e\)</span>, <span class="math inline">\(\gamma(t) \in K\)</span>
for all <span class="math inline">\(t\)</span>, and <span
class="math inline">\(Y := \gamma &#39;(0) = \mathop{\mathrm{Ad}}(k) X -
X \neq 0\)</span>. Since <span
class="math inline">\(\mathfrak{g}\)</span> is simple, its center <span
class="math inline">\(\mathfrak{z}(\mathfrak{g}) = \{ Z \in \mathfrak{g}
: [Z,\mathfrak{g}] = 0\}\)</span> is trivial (for else its center would
be a nontrivial ideal, hence <span
class="math inline">\(\mathfrak{g}\)</span> would coincide with its
center, i.e., <span class="math inline">\(\mathfrak{g}\)</span> would be
abelian; contradiction). In particular, <span
class="math inline">\([Y,\mathfrak{g}] \neq 0\)</span>. It follows by
the standard differentiate/exponentiate technique that the subspace
<span class="math inline">\(\mathfrak{a}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> spanned by <span
class="math inline">\(\mathop{\mathrm{Ad}}(G) Y\)</span> is a nonzero
ideal (check this). Since <span
class="math inline">\(\mathfrak{g}\)</span> is simple, it follows that
<span class="math inline">\(\mathfrak{a} = \mathfrak{g}\)</span>. We can
thus find <span class="math inline">\(g_1,\dotsc,g_n \in G\)</span>,
where <span class="math inline">\(n = \dim(G)\)</span>, so that the
elements <span class="math inline">\(\mathop{\mathrm{Ad}}(g_1)
\gamma&#39;(0),\dotsc,\mathop{\mathrm{Ad}}(g_n) \gamma &#39;(0)\)</span>
span <span class="math inline">\(\mathfrak{g}\)</span>. Also, the curves
<span class="math inline">\(t \mapsto \mathop{\mathrm{Ad}}(g_j) \exp(t
X)\)</span> all lie in <span class="math inline">\(K\)</span>, since
<span class="math inline">\(\exp(tX) \in K\)</span> and <span
class="math inline">\(K\)</span> is normal. The map <span
class="math display">\[(t_1,\dotsc,t_n) \mapsto
(\mathop{\mathrm{Ad}}(g_1) \exp(t_1 X) ) \dotsb
(\mathop{\mathrm{Ad}}(g_n) \exp(t_n X) )\]</span> then has differntial
at <span class="math inline">\((0,\dotsc,0)\)</span> given by an
invertible linear map, hence (by the inverse function theorem) defines a
local diffeomorphism; since its image lies in <span
class="math inline">\(K\)</span>, we deduce that <span
class="math inline">\(K\)</span> contains a neighborhood of the identity
in <span class="math inline">\(G\)</span>, and since <span
class="math inline">\(G\)</span> is connected, it follows that <span
class="math inline">\(K = G\)</span>, as required. ◻</p>
</span></div>
<p>Thus apart from excluding abelian examples and possible discrete
normal subgroups, the notions of a connected Lie group being simple as
an abstract group or simple as a Lie group are the same.</p>
<p>In the rest of the lecture, we described which classical Lie
groups/algebras are simple and what the isomorphisms between them are.
This will be discussed in subsequent lectures.</p>
<h1 id="sec:org0a0c43a">§28. Simplicity of the special linear group<span
id="sec:simplicity-sln" label="sec:simplicity-sln"></span></h1>
<h2 id="sec:orge7b7a5c">§28.1. Some linear algebra<span id="sec:some-lin-alg"
label="sec:some-lin-alg"></span></h2>
<p>Let <span class="math inline">\(V\)</span> be a complex vector space
(not necessarily finite-dimensional, for now). Given an operator <span
class="math inline">\(x \in \mathop{\mathrm{End}}(V)\)</span> and <span
class="math inline">\(\lambda \in \mathbb{C}\)</span>, we may define the
<em>eigenspace</em> <span class="math display">\[V^\lambda := \{v \in V
: x v = \lambda v\}.\]</span></p>
<div id="lem:lin-indep-eigenspaces" class="lemma">
<p><strong>Lemma 184</strong>. The spaces <span
class="math inline">\(V^{\lambda}\)</span> are linearly independent,
that is to say, if <span class="math inline">\(n \geq 1\)</span> and
<span class="math inline">\(\lambda_1,\dotsc,\lambda_n\)</span> are
distinct complex numbers and <span class="math inline">\(v_1 \in
V^{\lambda_1}, \dotsc, v_n \in V^{\lambda_n}\)</span> satisfy <span
class="math inline">\(v_1 + \dotsb + v_n = 0\)</span>, then <span
class="math inline">\(v_1 = \dotsb = v_n = 0\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We induct on <span class="math inline">\(n\)</span>.
When <span class="math inline">\(n = 1\)</span>, the required conclusion
is clear: if <span class="math inline">\(v_1 \in V^{\lambda_1}\)</span>
satisfies <span class="math inline">\(v_1 = 0\)</span>, then certainly
<span class="math inline">\(v_1 = 0\)</span>. Suppose now that <span
class="math inline">\(n \geq 2\)</span>, and let <span
class="math inline">\(v_1, \in V^{\lambda_1}, \dotsc,v_n \in
V^{\lambda_n}\)</span> with <span class="math inline">\(v_1 + \dotsb +
v_n = 0\)</span>. Then certainly <span class="math display">\[0 =
\lambda_n(v_1 + \dotsb + v_n)\]</span> and also <span
class="math display">\[0 = x (v_1 + \dotsb + v_n) = \lambda_1 v_1 +
\dotsb + \lambda_n v_n,\]</span> hence upon taking differences, <span
class="math display">\[(\lambda_1 - \lambda_n) v_1 + (\lambda_2 -
\lambda_n) v_2 + \dotsb + (\lambda_{n-1} - \lambda_n) v_{n-1} =
0.\]</span> By our inductive hypothesis, <span
class="math inline">\((\lambda_j - \lambda_n) v_j = 0\)</span> for <span
class="math inline">\(j = 1,\dotsc,n-1\)</span>. Since <span
class="math inline">\(\lambda_j \neq \lambda_n\)</span>, it follows that
<span class="math inline">\(v_1 = \dotsb = v_{n-1} = 0\)</span> and
hence also that <span class="math inline">\(v_n = 0\)</span>, as
required. ◻</p>
</span></div>
<p>Thus the sum <span class="math inline">\(\sum_{\lambda \in
\mathbb{C}} V^\lambda\)</span> is in fact a direct sum <span
class="math inline">\(\oplus V^\lambda\)</span>.</p>
<div class="definition">
<p><strong>Definition 185</strong>. An operator <span
class="math inline">\(x \in \mathop{\mathrm{End}}(V)\)</span> is
<em>semisimple</em> (or <em>diagonalizable</em>, or <em>completely
reducible</em>; depending upon my mood I alternate between the various
terminologies) if <span class="math display">\[V = \oplus_{\lambda \in
\mathbb{C}} V^\lambda.\]</span></p>
</div>
<p>Assume henceforth that <span class="math inline">\(V\)</span> is
<em>finite-dimensional</em>.</p>
<div class="definition">
<p><strong>Definition 186</strong>. For <span class="math inline">\(x
\in \mathop{\mathrm{End}}(V)\)</span>, we say that a subspace <span
class="math inline">\(W \leq V\)</span> is <span
class="math inline">\(x\)</span>-invariant if <span
class="math inline">\(x W \subseteq W\)</span>.</p>
</div>
<div id="exe:characterizations-of-semisimplicity-of-a-boring-old-matrix"
class="exercise">
<p><strong>Exercise 32</strong>. The following are equivalent:</p>
<ol>
<li><p><span class="math inline">\(x\)</span> is semisimple.</p></li>
<li><p>There is a basis of <span class="math inline">\(V\)</span> with
respect to which <span class="math inline">\(x\)</span> is represented
by a diagonal matrix.</p></li>
<li><p>In the Jordan decomposition of <span
class="math inline">\(x\)</span> as a sum of Jordan blocks Jordan blocks
<span class="math display">\[\begin{pmatrix}
        \lambda  &amp; 1 &amp;  &amp;  &amp; \\
           &amp; \lambda   &amp; 1 &amp; &amp; \\
           &amp; &amp; \dotsb   &amp; \dotsb &amp; \\
           &amp; &amp; &amp;  \lambda    &amp;  1\\
           &amp; &amp; &amp;      &amp;  \lambda
      \end{pmatrix}
,\]</span> only <span class="math inline">\(1 \times 1\)</span> blocks
appear.</p></li>
<li><p>The characteristic polynomial and minimal polynomial of <span
class="math inline">\(x\)</span> are the same.</p></li>
<li><p>Every <span class="math inline">\(x\)</span>-invariant subspace
<span class="math inline">\(W \leq V\)</span> has an <span
class="math inline">\(x\)</span>-invariant complement <span
class="math inline">\(W&#39;\)</span>, i.e., a subspace <span
class="math inline">\(W&#39; \leq V\)</span> for which <span
class="math inline">\(V = W \oplus W&#39;\)</span>.</p></li>
<li><p>The minimal polynomial of <span class="math inline">\(x\)</span>
is squarefree, i.e., of the form <span class="math inline">\((X - a_1)
\dotsb (X - a_r)\)</span> for some <em>distinct</em> complex numbers
<span class="math inline">\(a_1,\dotsc,a_r\)</span>.</p></li>
<li><p>There exists a squarefree polynomial that annihilates <span
class="math inline">\(x\)</span>.</p></li>
</ol>
<p>(1) iff (2): take as the basis for <span
class="math inline">\(V\)</span> a union of arbitrary bases of <span
class="math inline">\(V^\lambda\)</span>. (2) iff (3): clear. (3) iff
(4): clear. (1) iff (5): argue as in the proof of Lemma <a
href="#lem:compl-red-vs-complements" data-reference-type="ref"
data-reference="lem:compl-red-vs-complements">110</a>. It is clear that
(4), (6) and (7) are equivalent.</p>
</div>
<div id="exercise:restriction-of-semisimple-is-semisimple"
class="exercise">
<p><strong>Exercise 33</strong>. Suppose <span class="math inline">\(x
\in \mathop{\mathrm{End}}(V)\)</span> is semisimple.</p>
<ol>
<li><p>For each eigenvalue <span class="math inline">\(\lambda\)</span>
of <span class="math inline">\(x\)</span>, let <span
class="math inline">\(W^\lambda\)</span> be a subspace of the <span
class="math inline">\(\lambda\)</span>-eigenspace <span
class="math inline">\(V^\lambda\)</span> of <span
class="math inline">\(x\)</span>. Verify that <span
class="math inline">\(\oplus_{\lambda} W^\lambda\)</span> is an <span
class="math inline">\(x\)</span>-invariant subspace of <span
class="math inline">\(V\)</span>.</p></li>
<li><p>Let <span class="math inline">\(W \leq V\)</span> be an <span
class="math inline">\(x\)</span>-invariant subspace. Show that <span
class="math inline">\(W\)</span> is of the form <span
class="math inline">\(\oplus_{\lambda} W^\lambda\)</span>, where <span
class="math inline">\(W^\lambda = W \cap V^\lambda\)</span> is a
subspace of <span class="math inline">\(V^\lambda\)</span>. [Hint: one
can either appeal to the previous lemma or argue as in the proof of
Lemma <a href="#lem:lin-indep-eigenspaces" data-reference-type="ref"
data-reference="lem:lin-indep-eigenspaces">184</a>; other arguments are
probably also possible.]</p></li>
<li><p>Let <span class="math inline">\(W \leq V\)</span> be an <span
class="math inline">\(x\)</span>-invariant subspace.</p></li>
<li><p>Show that <span class="math inline">\(x|_W\)</span> is
semisimple.</p></li>
</ol>
</div>
<div id="thm:commuting-semisimple-operators" class="theorem">
<p><strong>Theorem 187</strong>. <em>Let <span
class="math inline">\(x_1,\dotsc,x_n \in
\mathop{\mathrm{End}}(V)\)</span> be semisimple commuting elements. Then
there is a basis of <span class="math inline">\(V\)</span> with respect
to which all of <span class="math inline">\(x_1,\dotsc,x_n\)</span> are
diagonalizable.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We induct on <span class="math inline">\(n\)</span>.
For <span class="math inline">\(n = 1\)</span>, everything is clear, so
suppose <span class="math inline">\(n \geq 2\)</span>. Let <span
class="math inline">\(V = \oplus V^\lambda\)</span> be the decomposition
of <span class="math inline">\(V\)</span> into eigenspaces for <span
class="math inline">\(x_1\)</span>. For <span class="math inline">\(j
\in \{2..n\}\)</span>, we claim that <span class="math inline">\(x_j
V^\lambda \subseteq V^\lambda\)</span>. Indeed, for <span
class="math inline">\(v \in V^\lambda\)</span>, we have <span
class="math inline">\(x_1 x_j v = x_j x_1 v = x_j \lambda v = \lambda
x_j v\)</span>, hence <span class="math inline">\(x_j v \in
V^\lambda\)</span>, as required. By Exercise <a
href="#exercise:restriction-of-semisimple-is-semisimple"
data-reference-type="ref"
data-reference="exercise:restriction-of-semisimple-is-semisimple">33</a>,
the restrictions to <span class="math inline">\(V^\lambda\)</span> of
the operators <span class="math inline">\(x_2,\dotsc,x_n\)</span> are
semisimple (and commuting), hence by our inductive hypothesis may be
simultaneously diagonalized; we now conclude by taking a union over
<span class="math inline">\(\lambda\)</span> of bases of <span
class="math inline">\(V^\lambda\)</span> with respect to which the <span
class="math inline">\(x_1,\dotsc,x_n\)</span> are diagonalized. ◻</p>
</span></div>
<h2 id="sec:org77c4374">§28.2. Recap on <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span></h2>
<p>Recall that <span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> has
the basis elements <span class="math display">\[H =
\begin{pmatrix}
    1 &amp;  \\
      &amp; -1
  \end{pmatrix}
,
  \quad
  X =
\begin{pmatrix}
    &amp; 1 \\
    &amp;
  \end{pmatrix}
,
  \quad
  Y =
\begin{pmatrix}
    &amp;  \\
    1 &amp;
  \end{pmatrix}\]</span> which satisfy the relations <span
class="math display">\[= H, \quad \mathop{\mathrm{ad}}(H) X = 2 X, \quad
\mathop{\mathrm{ad}}(H) Y = -2 Y.\]</span> We can view <span
class="math display">\[\mathfrak{h} = \mathbb{C} X \oplus \mathbb{C} H
\oplus \mathbb{C} Y\]</span> as the eigenspace decomposition of <span
class="math inline">\(\mathop{\mathrm{ad}}(H)\)</span> with eigenvalues
<span class="math inline">\(2, 0, -2\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 188</strong>. <em>Let <span
class="math inline">\(\rho : \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> be a finite-dimensional
representation. Then <span class="math inline">\(\rho(H)\)</span> is
semisimple.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since <span class="math inline">\(V\)</span>
decomposes as a direct sum of the irreducible representations <span
class="math inline">\(W_m\)</span>, we may assume <span
class="math inline">\(V = W_m\)</span>. Then the elements <span
class="math inline">\(x^m, x^{m-1} y, \dotsc, y^m\)</span> give a basis
of <span class="math inline">\(V\)</span> with respect to which <span
class="math inline">\(\rho(H)\)</span> is diagonal. ◻</p>
</span></div>
<p>We record for future reference that the element <span id="eq:weyl-element-via-exponentials-sl2" class="math display">\[\label{eq:weyl-element-via-exponentials-sl2}\tag{92}
  w := e^{-X} e^Y e^{-X} =
\begin{pmatrix}
    &amp; -1 \\
    1 &amp;
  \end{pmatrix}
\in {\mathop{\mathrm{SL}}}_2(\mathbb{C})\]</span> has the property that
<span id="eq:weyl-element-via-expoenntials-sl2-acting-as-reflection" class="math display">\[\label{eq:weyl-element-via-expoenntials-sl2-acting-as-reflection}\tag{93}
  Ad(w) H = - H.\]</span></p>
<h2 id="sec:org67e3030">§28.3. Reformulation in terms of representations of
abelian Lie algebras</h2>
<p>In this section all Lie algebras are finite-dimensional over the
complex numbers and all vector spaces are complex and
finite-dimensional. Recall that a Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span> is <em>abelian</em> if <span
class="math inline">\([\mathfrak{h},\mathfrak{h}] = 0\)</span>.</p>
<p>Let <span class="math inline">\(\mathfrak{h}\)</span> be an abelian
Lie algebra and <span class="math inline">\(\rho : \mathfrak{h}
\rightarrow \mathop{\mathrm{End}}(V)\)</span> a representation. Let
<span class="math inline">\(\mathfrak{h}^* :=
\mathop{\mathrm{Hom}}(\mathfrak{h},\mathbb{C})\)</span> denote the dual
vector space. For <span class="math inline">\(\lambda \in
\mathfrak{h}^*\)</span>, define the <em>eigenspace</em> <span
class="math display">\[V^\lambda := \{v \in V : H v = \lambda v \text{
for all }H \in \mathfrak{h} \}\]</span> where we abbreviate <span
class="math inline">\(H v := \rho(H) v\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 189</strong>. The spaces <span
class="math inline">\(V^\lambda\)</span> are linearly independent, i.e.,
<span class="math inline">\(\sum_{\lambda \in \mathbb{C}} V^\lambda =
\oplus_{\lambda \in \mathbb{C}} V^\lambda\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Same proof as Lemma <a
href="#lem:lin-indep-eigenspaces" data-reference-type="ref"
data-reference="lem:lin-indep-eigenspaces">184</a>. ◻</p>
</span></div>
<div class="lemma">
<p><strong>Lemma 190</strong>. Let <span
class="math inline">\(\mathfrak{h}\)</span> be an abelian Lie algebra
and <span class="math inline">\(\rho : \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> a representation. The following are
equivalent:</p>
<ol>
<li><p><span class="math inline">\(\rho(H)\)</span> is semisimple for
all <span class="math inline">\(H \in \mathfrak{h}\)</span>.</p></li>
<li><p>There is a basis of <span class="math inline">\(V\)</span> with
respect to which every element of <span
class="math inline">\(\rho(\mathfrak{h})\)</span> is diagonal.</p></li>
<li><p><span class="math inline">\(V = \oplus
V^\lambda\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Take a basis <span
class="math inline">\(H_1,\dotsc,H_n\)</span> and consider <span
class="math inline">\(x_1 := \rho(H_1), \dotsc, x_n := \rho(H_n) \in
\mathop{\mathrm{End}}(V)\)</span>. If each <span
class="math inline">\(x_j\)</span> is semisimple, then Theorem <a
href="#thm:commuting-semisimple-operators" data-reference-type="ref"
data-reference="thm:commuting-semisimple-operators">187</a> tells us
that there is a basis with respect to which they are (and hence every
element of <span class="math inline">\(\rho(\mathfrak{h})\)</span> is)
diagonal. The converse and the equivalence with <span
class="math inline">\(V = \oplus V^\lambda\)</span> are left to the
reader. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 191</strong>. We say that a representation <span
class="math inline">\(\rho : \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> of an abelian Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span> is <em>semisimple</em> if
teh equivalent conditions of the previous lemma are satisfied.</p>
</div>
<div class="definition">
<p><strong>Definition 192</strong>. Let <span class="math inline">\(\rho
: \mathfrak{h} \rightarrow \mathop{\mathrm{End}}(V)\)</span> be a
representation of an abelian Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span>. A <em>weight</em> of <span
class="math inline">\(\rho\)</span> is an element <span
class="math inline">\(\lambda \in \mathfrak{h}^*\)</span> for which
<span class="math inline">\(V^\lambda \neq 0\)</span>. The space <span
class="math inline">\(V^\lambda\)</span> is then called the <em>weight
space of weight <span class="math inline">\(\lambda\)</span></em>. (The
definition is most interesting when <span
class="math inline">\(\rho\)</span> is semisimple, so that <span
class="math inline">\(V = \oplus V^\lambda\)</span>.)</p>
</div>
<div class="example">
<p><strong>Example 193</strong>. Let <span class="math inline">\(V =
\mathbb{C}^n\)</span>, let <span
class="math inline">\(\mathfrak{h}\)</span> be the space of diagonal
matrices in <span class="math inline">\(M_n(\mathbb{C}) =
\mathop{\mathrm{End}}(V)\)</span>, and let <span
class="math inline">\(\rho : \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> be the identity map. Then the weights
of <span class="math inline">\(\rho\)</span> are the functionals <span
class="math inline">\(\lambda_1,\dotsc,\lambda_n : \mathfrak{h}
\rightarrow \mathbb{C}\)</span> giving diagonal coordinates on <span
class="math inline">\(\mathfrak{h}\)</span>, i.e., <span
class="math display">\[H =
    \begin{pmatrix}
      \lambda_1(H) &amp;  &amp;  \\
             &amp; \dotsb  &amp;  \\
             &amp;  &amp; \lambda_n(H)
    \end{pmatrix}
.\]</span> The corresponding weight spaces <span
class="math inline">\(V^{\lambda_j}\)</span> are the one-dimensional
subspaces <span class="math inline">\(\mathbb{C} e_j\)</span> spanned by
the standard basis elements <span
class="math inline">\(e_1,\dotsc,e_n\)</span> of <span
class="math inline">\(\mathbb{C}^n\)</span>.</p>
</div>
<h2 id="sec:orgccb748c">§28.4. Roots of an abelian subalgebra<span
id="sec:roots-of-abelian-subalgebra"
label="sec:roots-of-abelian-subalgebra"></span></h2>
<p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a Lie
algebra (always finite-dimensional and over the complex numbers, for the
present purposes) and <span class="math inline">\(\mathfrak{h} \leq
\mathfrak{g}\)</span> an abelian subalgebra.</p>
<p>Recall that adjoint representation <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span> given by <span
class="math inline">\(\mathop{\mathrm{ad}}(X) Y := [X,Y]\)</span>. We
restrict this to <span class="math inline">\(\mathfrak{h}\)</span> to
obtain a representation <span
class="math display">\[\mathop{\mathrm{ad}}: \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g}).\]</span> The set <span
class="math inline">\(R\)</span> of <em>roots</em> of the pair <span
class="math inline">\((\mathfrak{g},\mathfrak{h})\)</span> is defined to
be the set of nonzero weights of this representation. (We might more
verbosely write <span class="math inline">\(R =
R(\mathfrak{g},\mathfrak{h})\)</span> when we wish to make explicit the
dependence.) In other words, for <span class="math inline">\(\lambda \in
\mathfrak{h}^*\)</span>, set <span
class="math display">\[\mathfrak{g}^\lambda := \left\{ X \in
\mathfrak{g} : [H,X] = \lambda(H) X \text{ for all } H \in \mathfrak{h}
\right\}.\]</span> Then <span class="math display">\[R = \{\alpha \in
\mathfrak{h}^* - \{0\} : \mathfrak{g}^\alpha
  \neq 0 \}.\]</span> For <span class="math inline">\(\alpha \in
R\)</span>, we call <span
class="math inline">\(\mathfrak{g}^\alpha\)</span> the corresponding
<em>root space</em>.</p>
<div class="exercise">
<p><strong>Exercise 34</strong>. Write <span class="math inline">\(0 \in
\mathfrak{h}^*\)</span>. Then <span class="math display">\[\mathfrak{h}
\subseteq \mathfrak{g}^0.\]</span></p>
</div>
<p>Here is a very useful general observation:</p>
<div id="lem:commutators-of-root-spaces" class="lemma">
<p><strong>Lemma 194</strong>. For any <span
class="math inline">\(\alpha,\beta \in \mathfrak{h}^*\)</span>, one has
<span class="math display">\[\subseteq \mathfrak{g}^{\alpha +
\beta}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> <span> <strong>It is probably easier to work this out
as an exercise than to read the proof.</strong> </span> It suffices to
show for all <span class="math inline">\(X \in
\mathfrak{g}^\alpha\)</span> and <span class="math inline">\(Y \in
\mathfrak{g}^\beta\)</span> that <span class="math inline">\([X,Y] \in
\mathfrak{g}^{\alpha + \beta}\)</span>, i.e., that for all <span
class="math inline">\(H \in \mathfrak{h}\)</span>, one has <span
class="math inline">\(\mathop{\mathrm{ad}}(H)[X,Y] = (\alpha + \beta)(H)
[X,Y]\)</span>. This follows from the Jacobi identity in the form <span
class="math display">\[\mathop{\mathrm{ad}}(H) [X,Y] =
[\mathop{\mathrm{ad}}(H) X, Y] + [X,\mathop{\mathrm{ad}}(H) Y],\]</span>
like so: <span class="math display">\[\mathop{\mathrm{ad}}(H)[X,Y] =
[\alpha(H) X, Y] = [X,\beta(H) Y]
    = (\alpha(H) + \beta(H))[X,Y]
    = (\alpha + \beta)(H)[X,Y].\]</span> ◻</p>
</span></div>
<p>More generally:</p>
<div id="lem:general-commutation-root-spaces-on-weight-spaces"
class="lemma">
<p><strong>Lemma 195</strong>. Let <span class="math inline">\(\rho :
\mathfrak{g} \rightarrow \mathop{\mathrm{End}}(V)\)</span> be any linear
representation. For <span class="math inline">\(\lambda \in
\mathfrak{h}^*\)</span>, set <span class="math inline">\(V^\lambda :=
\{v \in V : \rho(H) v = \lambda(H) v \text{ for all } v \in
V\}\)</span>. Let <span class="math inline">\(\alpha, \lambda \in
\mathfrak{h}^*\)</span>. Then <span
class="math display">\[\rho(\mathfrak{g}^\alpha) V^\lambda \subseteq
V^{\alpha + \lambda}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This is essentially the same proof as the previous
lemma, but with the adjoint representation replaced by <span
class="math inline">\(\rho\)</span>; it should also remind the reader of
stuff we did awhile ago involving raising/lowering operators acting on
representations of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>:</p>
<p><span> <strong>It is probably easier to work this out as an exercise
than to read the proof.</strong> </span> Let <span
class="math inline">\(X \in \mathfrak{g}^\alpha\)</span> and <span
class="math inline">\(v \in V^\lambda\)</span>. To establish the
required membership <span class="math inline">\(\rho(X) v \in V^{\alpha
+ \lambda}\)</span>, we must verify for each <span
class="math inline">\(H \in \mathfrak{h}\)</span> that <span
class="math inline">\(\rho(H) \rho(X) v = (\alpha + \lambda)(H) \rho(X)
v\)</span>. Indeed, <span class="math display">\[\rho(H) \rho(X) =
\rho([H,X]) + \rho(X) \rho(H).\]</span> Since <span
class="math inline">\([H,X] = \alpha(H) X\)</span> and <span
class="math inline">\(\rho\)</span> is linear, we have <span
class="math display">\[\rho([H,X]) v = \rho(\alpha(H) X) v = \alpha(H)
\rho(X) v.\]</span> Since <span class="math inline">\(\rho(H) v =
\lambda(H) v\)</span> by assumption and <span
class="math inline">\(\rho(X)\)</span> is linear, we have <span
class="math display">\[\rho(X) \rho(H) v = \rho(X) \lambda(H) v =
\lambda(H) \rho(X) v.\]</span> Summing up, we obtain <span
class="math display">\[\rho(H) \rho(X) = \alpha(H) \rho(X) v +
\lambda(H) \rho(X) v,\]</span> which simplifies to give the required
identity. ◻</p>
</span></div>
<p>In other words, weight spaces <span
class="math inline">\(V^\lambda\)</span> are permuted by root spaces
<span class="math inline">\(\mathfrak{g}^\alpha\)</span> and root spaces
<span class="math inline">\(\mathfrak{g}^\alpha,
\mathfrak{g}^\beta\)</span> interact nicely with respect to the
commutator. Note that Lemma <a href="#lem:commutators-of-root-spaces"
data-reference-type="ref"
data-reference="lem:commutators-of-root-spaces">194</a> is the
specialization of <a
href="#lem:general-commutation-root-spaces-on-weight-spaces"
data-reference-type="ref"
data-reference="lem:general-commutation-root-spaces-on-weight-spaces">195</a>
to the adjoint representation.</p>
<h2 id="sec:orgca2a787">§28.5. The roots of the special linear Lie algebra<span
id="sec:roots-sln" label="sec:roots-sln"></span></h2>
<p>Let <span class="math inline">\(\mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>. Let
<span class="math inline">\(\mathfrak{h} \leq \mathfrak{g}\)</span> be
the subspace of diagonal matrices. One has <span
class="math inline">\(\dim(\mathfrak{h}) = n-1\)</span>. Every element
<span class="math inline">\(H \in \mathfrak{h}\)</span> is of the form
<span id="eqn:elements-cartan-slNC" class="math display">\[\label{eqn:elements-cartan-slNC}\tag{97}
  H =
  \begin{pmatrix}
    \lambda_1(H) &amp;  &amp;  \\
           &amp; \dotsb  &amp;  \\
           &amp;  &amp; \lambda_n(H)
  \end{pmatrix}\]</span> with <span class="math inline">\(\lambda_1(H) +
\dotsb + \lambda_n(H) = 0\)</span>. The functionals <span
class="math inline">\(\lambda_1,\dotsc,\lambda_n \in
\mathfrak{h}^*\)</span> defined by <a href="#eqn:elements-cartan-slNC"
data-reference-type="eqref"
data-reference="eqn:elements-cartan-slNC">\((97)\)</a>
span <span class="math inline">\(\mathfrak{h}^*\)</span> and satisfy the
relation <span class="math inline">\(\lambda_1 + \dotsb + \lambda_n =
0\)</span>.</p>
<p>For <span class="math inline">\(j,k \in \{1..n\}\)</span>, let <span
class="math inline">\(E_{j k} \in M_n(\mathbb{C})\)</span> denote the
elementary matrix with entries <span class="math inline">\((E_{j k})_{m
n} := \delta_{j m} \delta_{k n}\)</span>. If <span
class="math inline">\(j \neq k\)</span>, then <span
class="math inline">\(E_{j k} \in \mathfrak{g}\)</span>. One has in
general <span class="math inline">\(E_{j j} - E_{k k} \in
\mathfrak{g}\)</span>, but <span class="math inline">\(E_{j j} \neq
\mathfrak{g}\)</span> (by the trace condition). In general, <span id="eq:commutators-of-elementary-matrices" class="math display">\[\label{eq:commutators-of-elementary-matrices}\tag{98}
[E_{i j}, E_{k l}]
  = \delta_{j k} E_{i l}
  - \delta_{i l} E_{k j}.\]</span></p>
<p>For <span class="math inline">\(H \in \mathfrak{h}\)</span> and any
<span class="math inline">\(j,k\)</span>, we compute directly that <span
class="math inline">\(H E_{j k} = \lambda_j(H) E_{j k}\)</span> and
<span class="math inline">\(E_{j k} H = \lambda_k(H) E_{j k}\)</span>,
hence <span class="math display">\[\mathop{\mathrm{ad}}(H) E_{j k}
  = (\lambda_j(H) - \lambda_k(H)) E_{j k}.\]</span> Thus for all <span
class="math inline">\(j \neq k\)</span>, we see that <span
class="math inline">\(\lambda_j - \lambda_k\)</span> is a root. Observe
also that <span id="eq:h-self-centralizing-slN" class="math display">\[\label{eq:h-self-centralizing-slN}\tag{100}
  \mathfrak{g}^0 = \mathfrak{h};\]</span> said another way, <span
class="math inline">\(\mathfrak{h}\)</span> is a <em>maximal</em>
abelian subalgebra of <span class="math inline">\(\mathfrak{g}\)</span>.
Since <span id="eqn:decomp-into-roots-slNC" class="math display">\[\label{eqn:decomp-into-roots-slNC}\tag{101}
  \mathfrak{g} = \mathfrak{h} \oplus (\oplus_{j \neq k}
  \mathbb{C} E_{j k})\]</span> we see that <span id="eq:roots-of-slN" class="math display">\[\label{eq:roots-of-slN}\tag{102}
  R = \{\lambda_j - \lambda_k : j \neq k\}.\]</span> We may rewrite <a
href="#eqn:decomp-into-roots-slNC" data-reference-type="eqref"
data-reference="eqn:decomp-into-roots-slNC">\((101)\)</a>
in either of the forms <span id="eqn:decomp-into-roots-slNC-2" class="math display">\[\label{eqn:decomp-into-roots-slNC-2}\tag{103}
  \mathfrak{g} = \oplus_{\lambda \in \mathbb{C}}
  \mathfrak{g}^\lambda\]</span> or <span id="eqn:decomp-into-roots-slNC-3" class="math display">\[\label{eqn:decomp-into-roots-slNC-3}\tag{104}
  \mathfrak{g} = \mathfrak{h} \oplus (\oplus_{\alpha \in R}
  \mathfrak{g}^\alpha).\]</span> In particular:</p>
<div id="lem:adjoint-action-cartan-slNC-is-semisimple" class="lemma">
<p><strong>Lemma 196</strong>. <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span> is semisimple.</p>
</div>
<div id="lem:roots-span" class="lemma">
<p><strong>Lemma 197</strong>. The set <span
class="math inline">\(R\)</span> of roots spans <span
class="math inline">\(\mathfrak{h}^*\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We must verify that if <span class="math inline">\(H
\in \mathfrak{h}\)</span> satisfies <span
class="math inline">\(\alpha(H) = 0\)</span> for all <span
class="math inline">\(\alpha \in R\)</span>, then <span
class="math inline">\(H = 0\)</span>. Indeed, given such an <span
class="math inline">\(H\)</span>, we have (by taking <span
class="math inline">\(\alpha = \lambda_j - \lambda_k\)</span>) that
<span class="math inline">\(\lambda_j(H) = \lambda_k(H)\)</span> for all
<span class="math inline">\(i \neq j\)</span>, hence all the entries of
<span class="math inline">\(H\)</span> are the same; since <span
class="math inline">\(H\)</span> has trace zero, it follows as required
that <span class="math inline">\(H = 0\)</span>. ◻</p>
</span></div>
<p>For <span class="math inline">\(\alpha = \lambda_j - \lambda_k \in
R\)</span>, the corresponding root space is <span
class="math display">\[\mathfrak{g}^{\alpha} = \mathbb{C} X_\alpha
\text{ where } X_\alpha := E_{j k}.\]</span> Note that <span id="eq:negative-roots-are-roots" class="math display">\[\label{eq:negative-roots-are-roots}\tag{105}
  \alpha \in R \implies - \alpha \in R\]</span> since indeed <span
class="math inline">\(-\alpha = \lambda_k - \lambda_j\)</span> for <span
class="math inline">\(\alpha = \lambda_j - \lambda_k\)</span>, but that
<span class="math display">\[\text{ $n \alpha \notin R$ for any $n \in
\mathbb{Z} - \{\pm 1\}$.}\]</span> Define <span
class="math inline">\(Y_\alpha := E_{k j} \in
\mathfrak{g}^{-\alpha}\)</span>; by <a
href="#eq:commutators-of-elementary-matrices"
data-reference-type="eqref"
data-reference="eq:commutators-of-elementary-matrices">\((98)\)</a>,
the element <span class="math display">\[H_\alpha :=
[X_\alpha,Y_\alpha]\]</span> is given explicitly by <span
class="math inline">\(H_\alpha = E_{j j} - E_{k k} \in
\mathfrak{h}\)</span> and satisfies <span
class="math display">\[\alpha(H_\alpha) = 2\]</span> because <span
class="math inline">\(\alpha(H_\alpha) = (\lambda_j - \lambda_k)(E_{j j}
- E_{k k}) = 1 - (-1) = 2\)</span>. (One has here that <span
class="math inline">\(Y_{\alpha} = X_{-\alpha}\)</span>, but what
matters most is that they both span the same one-dimensional space.) One
has <span class="math display">\[H_{-\alpha} = - H_\alpha \text{ for all
} \alpha \in R.\]</span> It is easy to see that <span id="eq:coroots-span-cartan-slNC" class="math display">\[\label{eq:coroots-span-cartan-slNC}\tag{106}
  \sum_{\alpha \in R} \mathbb{C} H_\alpha = \mathfrak{h},\]</span> but
that the sum is not direct for <span class="math inline">\(n &gt;
2\)</span>.</p>
<div id="lem:root-space-commutation-relations" class="lemma">
<p><strong>Lemma 198</strong>. Each <span
class="math inline">\(\mathfrak{g}^{\alpha}\)</span> is one-dimensional.
For all <span class="math inline">\(\alpha,\beta \in R\)</span>, <span
class="math display">\[=
\begin{cases}
      \mathfrak{g}^{\alpha + \beta} &amp; \text{ if } \alpha + \beta \in
R \\
      \mathbb{C} H_\alpha  &amp; \text{ if } \alpha + \beta = 0 \\
      0 &amp; \text{ otherwise.}
    \end{cases}\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This reduces to an explicit computation using <a
href="#eq:commutators-of-elementary-matrices"
data-reference-type="eqref"
data-reference="eq:commutators-of-elementary-matrices">\((98)\)</a>.
It is instructive to note the consistency with the conclusion <span
class="math inline">\([\mathfrak{g}^\alpha, \mathfrak{g}^\beta]
\subseteq \mathfrak{g}^{\alpha + \beta}\)</span> of Lemma <a
href="#lem:commutators-of-root-spaces" data-reference-type="ref"
data-reference="lem:commutators-of-root-spaces">194</a> and the identity
<a href="#eq:h-self-centralizing-slN" data-reference-type="eqref"
data-reference="eq:h-self-centralizing-slN">\((100)\)</a>. ◻</p>
</span></div>
<p>Here are some basic consequences:</p>
<div id="lem:compositions-of-ad-stuff" class="lemma">
<p><strong>Lemma 199</strong>. </p>
<ol>
<li><p>If <span class="math inline">\(\alpha,\beta,\alpha+\beta\)</span>
are all roots, then the map <span
class="math display">\[\mathop{\mathrm{ad}}(X_\beta) :
\mathfrak{g}^\alpha \rightarrow \mathfrak{g}^{\alpha+\beta}\]</span> is
an isomorphism (of one-dimensional vector spaces).</p></li>
<li><p>If <span class="math inline">\(\alpha,\beta,\alpha-\beta\)</span>
are all roots, then the map <span
class="math display">\[\mathop{\mathrm{ad}}(Y_\beta) :
\mathfrak{g}^\alpha \rightarrow \mathfrak{g}^{\alpha-\beta}\]</span> is
an isomorphism (of one-dimensional vector spaces).</p></li>
<li><p>For any roots <span class="math inline">\(\alpha,\beta\)</span>,
the composition <span
class="math display">\[\mathop{\mathrm{ad}}(X_\beta) \circ
\mathop{\mathrm{ad}}(X_\alpha) : \mathfrak{g}^{-\alpha} \rightarrow
\mathfrak{g}^{\beta}\]</span> is an isomorphism (of one-dimensional
vector spaces) if and only if <span
class="math inline">\(\beta(H_\alpha) \neq 0\)</span>.</p></li>
<li><p>For any roots <span class="math inline">\(\alpha,\beta\)</span>,
the composition <span
class="math display">\[\mathop{\mathrm{ad}}(Y_\beta) \circ
\mathop{\mathrm{ad}}(Y_\alpha) : \mathfrak{g}^{\alpha} \rightarrow
\mathfrak{g}^{-\beta}\]</span> is an isomorphism (of one-dimensional
vector spaces) if and only if <span
class="math inline">\(\beta(H_\alpha) \neq 0\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The first two assertions are immediate from Lemma <a
href="#lem:root-space-commutation-relations" data-reference-type="ref"
data-reference="lem:root-space-commutation-relations">198</a>. For the
third assertion, we factor the map of interest as <span
class="math display">\[\mathfrak{g}^{-\alpha}
\xrightarrow{\mathop{\mathrm{ad}}(X_\alpha)} \mathbb{C} H_\alpha
\xrightarrow{\mathop{\mathrm{ad}}(X_\beta)} \rightarrow
\mathfrak{g}^{\beta}\]</span> and observe (using Lemma <a
href="#lem:root-space-commutation-relations" data-reference-type="ref"
data-reference="lem:root-space-commutation-relations">198</a>) that
<span class="math inline">\(\mathop{\mathrm{ad}}(X_\alpha) :
\mathfrak{g}^{-\alpha} \rightarrow \mathbb{C} H_\alpha\)</span> is
always an isomorphism of one-dimensional vector spaces and noting that
<span class="math inline">\(\mathop{\mathrm{ad}}(X_\beta) H_\alpha =
-[H_\alpha,X_\beta] = - \beta(H_\alpha) X_\beta\)</span>, which vanishes
if and only if <span class="math inline">\(\beta(H_\alpha) =
0\)</span>.</p>
<p>The proof of the fourth assertion is similar: we factor the map <span
class="math inline">\(\mathfrak{g}^{\alpha} \rightarrow
\mathfrak{g}^{-\beta}\)</span> in question as <span
class="math display">\[\mathfrak{g}^{\alpha}
\xrightarrow{\mathop{\mathrm{ad}}(Y_\alpha)} \mathbb{C} H_\alpha
\xrightarrow{\mathop{\mathrm{ad}}(Y_\beta)} \rightarrow
\mathfrak{g}^{-\beta},\]</span> observe that the first map in this
composition is always an automorphism, and then observe that the second
map sends <span class="math inline">\(H_\alpha\)</span> to <span
class="math inline">\([Y_\beta,H_\alpha] = - [H_\alpha,Y_\beta] =
\beta(H_\alpha) Y_\beta\)</span>. ◻</p>
</span></div>
<p>One can check directly using <a href="#eq:roots-of-slN"
data-reference-type="eqref"
data-reference="eq:roots-of-slN">\((102)\)</a> that for all
<span class="math inline">\(\alpha,\beta \in R\)</span>, <span id="eq:orthogonality-equivalence" class="math display">\[\label{eq:orthogonality-equivalence}\tag{107}
  \beta(H_\alpha) = 0
  \iff \alpha(H_\beta) = 0.\]</span></p>
<div id="defn:orthogonal-roots" class="definition">
<p><strong>Definition 200</strong>. Two roots <span
class="math inline">\(\alpha, \beta\)</span> are called
<em>orthogonal</em> if either of the equivalent conditions <a
href="#eq:orthogonality-equivalence" data-reference-type="eqref"
data-reference="eq:orthogonality-equivalence">\((107)\)</a>
hold. They are called <em>non-orthogonal</em> if <span
class="math inline">\(\beta(H_\alpha) \neq 0\)</span> (equivalently,
<span class="math inline">\(\alpha(H_\beta) \neq 0\)</span>).</p>
</div>
<p>Explicitly, if <span class="math inline">\(\alpha = \lambda_i -
\lambda_j\)</span> and <span class="math inline">\(\beta = \lambda_k -
\lambda_l\)</span>, then <span
class="math inline">\(\alpha,\beta\)</span> are orthogonal if and only
if <span class="math inline">\(\{i,j\} \cap \{k,l\} =
\emptyset\)</span>.</p>
<div id="lem:condition-for-chain-of-root-maps-not-to-vanish"
class="lemma">
<p><strong>Lemma 201</strong>. Suppose given roots <span
class="math inline">\(\beta, \alpha_1, \dotsc, \alpha_r \in R\)</span>
with the property that <span class="math inline">\(\beta + \alpha_1 +
\dotsb + \alpha_r\)</span> is a root and that for each <span
class="math inline">\(s = 1,2,\dotsc,r\)</span>, the partial sum <span
class="math inline">\(\beta + \alpha_1 + \dotsb + \alpha_s\)</span> is
either a root, or is zero, and if it is zero that the roots <span
class="math inline">\(\alpha_s, \alpha_{s+1}\)</span> are
non-orthogonal. Then the compositions <span
class="math display">\[\mathfrak{g}^\beta \xrightarrow{X_{\alpha_1}}
\mathfrak{g}^{\beta+\alpha_1} \xrightarrow{X_{\alpha_2}} \dotsb
\xrightarrow{X_{\alpha_{r}}} \mathfrak{g}^{\beta+\alpha_r}\]</span>
<span class="math display">\[\mathfrak{g}^{\beta+\alpha_r}
\xrightarrow{Y_{\alpha_r}} \dotsb \xrightarrow{Y_{\alpha_2}}
\mathfrak{g}^{\beta+\alpha_1} \xrightarrow{Y_{\alpha_{1}}}
\mathfrak{g}^{\beta}\]</span> (where we abbreviate <span
class="math inline">\(\xrightarrow{X}\)</span> for <span
class="math inline">\(\xrightarrow{\mathop{\mathrm{ad}}(X)}\)</span>,
etc) are isomorphisms of one-dimensional vector spaces.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Follows immediately by repeated application of Lemma
<a href="#lem:compositions-of-ad-stuff" data-reference-type="ref"
data-reference="lem:compositions-of-ad-stuff">199</a>. ◻</p>
</span></div>
<h2 id="sec:org952f7d3">§28.6. The simplicity of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span></h2>
<p>Set <span class="math inline">\(\mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>. Let
<span class="math inline">\(\mathfrak{h}\)</span> denote its diagonal
subalgebra, and <span class="math inline">\(R\)</span> the set of roots
for <span
class="math inline">\((\mathfrak{g},\mathfrak{h})\)</span>.</p>
<div id="lemma:clean-way-to-get-simplicity" class="lemma">
<p><strong>Lemma 202</strong>. Set <span
class="math display">\[\lambda_{\max} := \lambda_1 - \lambda_n \in
R.\]</span> Let <span class="math inline">\(\beta \in R\)</span>. Then
there is a nonnegative integer <span class="math inline">\(r \geq
0\)</span> and roots <span
class="math inline">\(\alpha_1,\dotsc,\alpha_r\)</span> so that <span
class="math display">\[\beta + \alpha_1 + \dotsb + \alpha_r =
\lambda_{\max}\]</span> and so that for <span class="math inline">\(s
\in \{1..r-1\}\)</span>, the partial sum <span
class="math inline">\(\beta + \alpha_1 + \dotsb + \alpha_s\)</span> is
either a root, or zero, and if it is zero, then the roots <span id="eq:nonvanishing-required-for-simplicity" class="math display">\[\label{eq:nonvanishing-required-for-simplicity}\tag{108}
    \alpha_{s+1}(H_{\alpha_s}) \neq 0,
    \quad
    \alpha_{s}(H_{\alpha_{s+1}}) \neq 0,\]</span> i.e., the roots <span
class="math inline">\(\alpha_s, \alpha_{s+1}\)</span> are non-orthogonal
in the sense of Definition <a href="#defn:orthogonal-roots"
data-reference-type="ref"
data-reference="defn:orthogonal-roots">200</a>. (We can always take
<span class="math inline">\(r \leq 2\)</span>, but that doesn’t matter
so much.)</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Write <span class="math inline">\(\beta = \lambda_j -
\lambda_k\)</span>. The proof is basically to stare at the diagrams
<span class="math display">\[\lambda_j - \lambda_k
\xrightarrow{\lambda_k - \lambda_n} \lambda_j - \lambda_n
\xrightarrow{\lambda_1 - \lambda_j} \lambda_1 - \lambda_n\]</span> and
<span class="math display">\[\lambda_j - \lambda_k
\xrightarrow{\lambda_1 - \lambda_j} \lambda_1 - \lambda_k
\xrightarrow{\lambda_k - \lambda_n} \lambda_1 - \lambda_n.\]</span> We
omit <span class="math inline">\(\xrightarrow{\mu}\)</span> from the
above diagrams if <span class="math inline">\(\mu = 0\)</span>. What
needs to be checked is that for each <span
class="math inline">\(j,k\)</span>, at least one of the above diagrams
has the property that whenever it looks like <span
class="math display">\[\lambda_j - \lambda_k \xrightarrow{\mu } 0
\xrightarrow{\nu}, \lambda_1 - \lambda_n,\]</span> the roots <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(\nu\)</span> are non-orthogonal, i.e., satisfy
<span class="math inline">\(\mu(H_\nu) \neq 0\)</span>.</p>
<p>We turn to the details:</p>
<ul>
<li><p>If <span class="math inline">\(k = n\)</span> and <span
class="math inline">\(j = 1\)</span>, we take <span
class="math inline">\(r = 0\)</span>.</p></li>
<li><p>If <span class="math inline">\(k = n\)</span> and <span
class="math inline">\(j &gt; 1\)</span>, we take <span
class="math inline">\(r := 1\)</span> and <span
class="math inline">\(\alpha_1 := \lambda_1 - \lambda_j \in R\)</span>;
then <span class="math inline">\(\beta + \alpha_1 =
\lambda_{\max}\)</span>.</p></li>
<li><p>If <span class="math inline">\(k &lt; n\)</span> and <span
class="math inline">\(j = 1\)</span>, we take <span
class="math inline">\(r := 1\)</span> and <span
class="math inline">\(\alpha_1 := \lambda_k - \lambda_n \in R\)</span>;
then <span class="math inline">\(\beta + \alpha_1 =
\lambda_{\max}\)</span>.</p></li>
<li><p>If <span class="math inline">\(k &lt; n\)</span> and <span
class="math inline">\(1 &lt; j &lt; n\)</span>, we take <span
class="math inline">\(r := 2\)</span> and <span
class="math inline">\(\alpha_1 := \lambda_k - \lambda_n \in R\)</span>
and <span class="math inline">\(\alpha_2 := \lambda_1 - \lambda_j \in
R\)</span>. Then <span class="math inline">\(\beta + \alpha_1 + \alpha_2
= \lambda_{\max}\)</span>. The partial sum <span
class="math inline">\(\beta + \alpha_1 = \lambda_j - \lambda_n\)</span>
is always a root, since <span class="math inline">\(j &lt;
n\)</span>.</p></li>
<li><p>If <span class="math inline">\(k &lt; n\)</span> and <span
class="math inline">\(j = n\)</span>, we take <span
class="math inline">\(r := 2\)</span> and <span
class="math inline">\(\alpha_1 := \lambda_1 - \lambda_j \in R\)</span>
and <span class="math inline">\(\alpha_2 := \lambda_k - \lambda_n \in
R\)</span>. Then <span class="math inline">\(\beta + \alpha_1 + \alpha_2
= \lambda_{\max}\)</span>. The partial sum <span
class="math inline">\(\beta + \alpha_1 = \lambda_1 - \lambda_k\)</span>
is either a root or zero; it is zero iff <span class="math inline">\(k =
1\)</span>, in which case <span
class="math display">\[\alpha_2(H_{\alpha_1}) = (\lambda_k -
\lambda_n)(E_{1 1} - E_{j j}) = 2 \neq 0,\]</span> <span
class="math display">\[\alpha_1(H_{\alpha_2}) = (\lambda_1 -
\lambda_j)(E_{k k} - E_{n n}) = 2 \neq 0,\]</span> so the roots <span
class="math inline">\(\alpha_1,\alpha_2\)</span> are non-orthogonal in
that case, as required.</p></li>
</ul>
<p> ◻</p>
</span></div>
<div id="thm:simplicity-slNC" class="theorem">
<p><strong>Theorem 203</strong>. <em><span
class="math inline">\(\mathfrak{g}\)</span> is simple.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> In lecture we gave a more “brute force” proof; here
we will clean it up a bit by appeal to Lemmas <a
href="#lem:compositions-of-ad-stuff" data-reference-type="ref"
data-reference="lem:compositions-of-ad-stuff">199</a> and <a
href="#lemma:clean-way-to-get-simplicity" data-reference-type="ref"
data-reference="lemma:clean-way-to-get-simplicity">202</a>.</p>
<p>Let <span class="math inline">\(\mathfrak{a} \leq
\mathfrak{g}\)</span> be a nonzero ideal, or equivalently, an <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{g})\)</span>-invariant
subspace. We must show that <span class="math inline">\(\mathfrak{a} =
\mathfrak{g}\)</span>.</p>
<p>Suppose first that <span class="math inline">\(\mathfrak{a} \subseteq
\mathfrak{h}\)</span>, and let <span class="math inline">\(0 \neq H \in
\mathfrak{a}\)</span> be given. Since the set <span
class="math inline">\(R\)</span> of roots spans <span
class="math inline">\(\mathfrak{h}^*\)</span> (Lemma <a
href="#lem:roots-span" data-reference-type="ref"
data-reference="lem:roots-span">197</a>), we can find <span
class="math inline">\(\alpha \in R\)</span> so that <span
class="math inline">\(\alpha(H) \neq 0\)</span>. But then <span
class="math inline">\(X_\alpha \in \mathfrak{g}^\alpha\)</span> (see §<a
href="#sec:roots-sln" data-reference-type="ref"
data-reference="sec:roots-sln">28.5</a>) has the property
that <span class="math inline">\([H,X_\alpha] = \alpha(H)
X_\alpha\)</span> is a nonzero element of <span
class="math inline">\(\mathfrak{g}^\alpha\)</span>. On the other hand,
we have <span class="math inline">\([H,X_\alpha] \in \mathfrak{a}
\subseteq \mathfrak{h}\)</span> because <span
class="math inline">\(\mathfrak{a}\)</span> is an ideal. Since <span
class="math inline">\(\mathfrak{h} \cap \mathfrak{g}^\alpha =
0\)</span>, we obtain the required contradiction.</p>
<p>Suppose next that <span class="math inline">\(\mathfrak{a}\)</span>
is not contained in <span class="math inline">\(\mathfrak{h}\)</span>.
By the semisimplicity of <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span> (see Lemma <a
href="#lem:adjoint-action-cartan-slNC-is-semisimple"
data-reference-type="ref"
data-reference="lem:adjoint-action-cartan-slNC-is-semisimple">196</a>)
and the fact that <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{h})\)</span>-semisimplicity
is preserved upon passage to <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{h})\)</span>-invariant
subspaces (see Exercise <a
href="#exercise:restriction-of-semisimple-is-semisimple"
data-reference-type="ref"
data-reference="exercise:restriction-of-semisimple-is-semisimple">33</a>),
we have <span class="math display">\[\mathfrak{a} = (\mathfrak{a} \cap
\mathfrak{h})
    \oplus (\oplus_{\alpha \in R}
    \mathfrak{a} \cap \mathfrak{g}^\alpha ).\]</span> Since <span
class="math inline">\(\mathfrak{a}\)</span> is not contained in <span
class="math inline">\(\mathfrak{h}\)</span>, there is some <span
class="math inline">\(\beta \in R\)</span> for which have <span
class="math inline">\(\mathfrak{a}\)</span> intersects and hence
contains the one-dimensional space <span
class="math inline">\(\mathfrak{g}^\beta\)</span>.</p>
<p>We claim now with notation as in Lemma <a
href="#lemma:clean-way-to-get-simplicity" data-reference-type="ref"
data-reference="lemma:clean-way-to-get-simplicity">202</a> that <span
class="math inline">\(\mathfrak{g}^{\lambda_{\max}} \subseteq
\mathfrak{a}\)</span>. To see this, let us write <span id="eq:from-beta-to-largest-root" class="math display">\[\label{eq:from-beta-to-largest-root}\tag{110}
    \beta + \alpha_1 + \dotsb + \alpha_r
    = \lambda_{\max}\]</span> as in Lemma <a
href="#lemma:clean-way-to-get-simplicity" data-reference-type="ref"
data-reference="lemma:clean-way-to-get-simplicity">202</a>. We know that
<span class="math inline">\(\mathfrak{a}\)</span> is an ideal, i.e., is
<span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{g})\)</span>-invariant,
and that <span class="math inline">\(\mathfrak{a}\)</span> contains
<span class="math inline">\(\mathfrak{g}^\beta\)</span>, so it will
suffice to show that the composition <span
class="math display">\[\mathfrak{g}^\beta \xrightarrow{X_{\alpha_1}}
    \mathfrak{g}^{\beta+\alpha_1}
    \xrightarrow{X_{\alpha_2}} \dotsb
    \xrightarrow{X_{\alpha_{r-1}}}
    \mathfrak{g}^{\beta+\alpha_1+\dotsb+\alpha_{r-1}}
    \xrightarrow{X_{\alpha_r}}
    \mathfrak{g}^{\lambda_{\max}}\]</span> is an isomorphism (because
then <span class="math inline">\(\mathfrak{a} \supseteq
\mathfrak{g}^{\lambda_{\max}}\)</span>), which follows from Lemma <a
href="#lem:condition-for-chain-of-root-maps-not-to-vanish"
data-reference-type="ref"
data-reference="lem:condition-for-chain-of-root-maps-not-to-vanish">201</a>.</p>
<p>Now let <span class="math inline">\(\beta \in R\)</span> be
arbitrary; we will show that <span class="math inline">\(\mathfrak{a}
\supseteq \mathfrak{g}^\beta\)</span>. We again write <a
href="#eq:from-beta-to-largest-root" data-reference-type="eqref"
data-reference="eq:from-beta-to-largest-root">\((110)\)</a>
as in Lemma <a href="#lemma:clean-way-to-get-simplicity"
data-reference-type="ref"
data-reference="lemma:clean-way-to-get-simplicity">202</a>. Since we
already know that <span class="math inline">\(\mathfrak{a} \supseteq
\mathfrak{g}^{\lambda_{\max}}\)</span> and since <span
class="math inline">\(\mathfrak{a}\)</span> is <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{g})\)</span>-stable,
it will suffice to show that the composition <span
class="math display">\[\mathfrak{g}^{\lambda_{\max}}
    \xrightarrow{Y_{\alpha_r}}
    \mathfrak{g}^{\beta+\alpha_1+\dotsb+\alpha_{r-1}}
    \xrightarrow{Y_{\alpha_{r-1}}}
    \dotsb
    \xrightarrow{Y_{\alpha_2}}
    \mathfrak{g}^{\beta+\alpha_1}
    \xrightarrow{Y_{\alpha_1}}
    \mathfrak{g}^\beta\]</span> is an isomorphism, which follows again
from <a href="#eq:nonvanishing-required-for-simplicity"
data-reference-type="eqref"
data-reference="eq:nonvanishing-required-for-simplicity">\((108)\)</a>
and Lemma <a href="#lem:compositions-of-ad-stuff"
data-reference-type="ref"
data-reference="lem:compositions-of-ad-stuff">199</a>.</p>
<p>In summary, we have seen that <span
class="math inline">\(\mathfrak{a}\)</span> contains <span
class="math inline">\(\mathfrak{g}^\alpha\)</span> and hence <span
class="math inline">\(X_\alpha\)</span> for all <span
class="math inline">\(\alpha \in R\)</span>; since <span
class="math inline">\(\mathfrak{a}\)</span> is an ideal, it contains
also <span class="math inline">\([X_\alpha,Y_\alpha] =
H_\alpha\)</span>. Since the <span
class="math inline">\(H_\alpha\)</span> span <span
class="math inline">\(\mathfrak{h}\)</span> (see <a
href="#eq:coroots-span-cartan-slNC" data-reference-type="eqref"
data-reference="eq:coroots-span-cartan-slNC">\((106)\)</a>
and surrounding), we have <span class="math inline">\(\mathfrak{a}
\supseteq \mathfrak{h}\)</span>. Thus <span
class="math inline">\(\mathfrak{a} \supseteq \mathfrak{h} \oplus
(\oplus_{\alpha \in R} \mathfrak{g}^\alpha)\)</span>, i.e., <span
class="math inline">\(\mathfrak{a} =\mathfrak{g}\)</span>, as
required. ◻</p>
</span></div>
<h2 id="sec:orgd32f640">§28.7. The proof given in lecture</h2>
<p>Here are some notes indicating the more “brute force” approach to
Theorem <a href="#thm:simplicity-slNC" data-reference-type="ref"
data-reference="thm:simplicity-slNC">203</a> presented in lecture. It
may be instructive to compare this approach to that above (they differ
primarily in notation).</p>
<p>With notation as in the proof of Theorem <a
href="#thm:commuting-semisimple-operators" data-reference-type="ref"
data-reference="thm:commuting-semisimple-operators">187</a>, set <span
class="math display">\[\Gamma := \{\alpha \in R : \mathfrak{a} \cap
\mathfrak{g}^\alpha \neq 0 \}.\]</span> Then <span
class="math inline">\(\mathfrak{a} \supseteq \oplus_{\alpha \in \Gamma}
\mathfrak{g}^\alpha\)</span>. The key step in the proof was to show that
if <span class="math inline">\(\Gamma\)</span> is nonempty, then <span id="eq:gamma-equals-R" class="math display">\[\label{eq:gamma-equals-R}\tag{113}
  \Gamma = R.\]</span> To see this, let <span
class="math inline">\(\beta \in \Gamma\)</span> be given. Suppose that
<span class="math inline">\(\beta = \lambda_i - \lambda_j\)</span> with
<span class="math inline">\(i &gt; j\)</span>; a similar but slightly
simpler argument applies if instead <span class="math inline">\(i &lt;
j\)</span>. We have <span class="math display">\[=
\begin{cases}
    E_{i n} &amp; \text{ if } i \neq n, \\
    E_{i n} - E_{j j} &amp; \text{ if } i = n,
  \end{cases}\]</span> and in either case it follows that <span
class="math display">\[]
  = E_{1 n}.\]</span> Since <span
class="math inline">\(\mathfrak{a}\)</span> is an ideal, we deduce that
<span class="math inline">\(E_{1 n} \in \mathfrak{a}\)</span>, i.e.,
<span class="math display">\[\lambda_1  - \lambda_n \in
\Gamma.\]</span></p>
<p>Now let <span class="math inline">\(\alpha \in R\)</span> be
arbitrary, say <span class="math inline">\(\alpha = \lambda_j -
\lambda_k\)</span>. If <span class="math inline">\(j &lt; k\)</span>,
then we have <span class="math display">\[= E_{1 k},\]</span> hence
<span class="math inline">\(\lambda_1 - \lambda_k \in \Gamma\)</span>,
and <span class="math display">\[= E_{j k}\]</span> hence <span
class="math inline">\(\lambda_j - \lambda_k \in \Gamma\)</span>, as
required. Suppose instead that <span class="math inline">\(j &gt;
k\)</span>. If <span class="math inline">\(k = 1\)</span>, then we have
<span class="math display">\[= E_{n n} - E_{1 1}\]</span> and hence
<span class="math display">\[]
  = - 2 E_{n 1},\]</span> hence <span class="math inline">\(\lambda_n -
\lambda_1 \in \Gamma\)</span>, as required. In the remaining case that
<span class="math inline">\(j &gt; k &gt; 1\)</span>, we have <span
class="math display">\[= E_{1 k}\]</span> and hence <span
class="math display">\[]
  = E_{j k},\]</span> hence <span class="math inline">\(\lambda_j -
\lambda_k \in \Gamma\)</span>, as required.</p>
<h1 id="sec:orgdbcaaaf">§29. Classification of the classical simple complex
Lie algebras<span id="sec:classify-classical-simple-algebras"
label="sec:classify-classical-simple-algebras"></span></h1>
<h2 id="sec:org4260801">§29.1. Recap<span
id="sec:recap-classification-includes-better-defn-of-orthogonal-gp"
label="sec:recap-classification-includes-better-defn-of-orthogonal-gp"></span></h2>
<p>We’ve seen in lecture that the Lie algebra <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
is simple (<span class="math inline">\(n \geq 2\)</span>), and on the
homework that <span
class="math inline">\(\mathfrak{s}\mathfrak{p}_{2n}(\mathbb{C})\)</span>
is simple (<span class="math inline">\(n \geq 1\)</span>). Similar
arguments imply that <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{2n+1}(\mathbb{C})\)</span>
is simple for <span class="math inline">\(n \geq 1\)</span> and that
<span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{2n}(\mathbb{C})\)</span>
is simple for <span class="math inline">\(n \geq 3\)</span>; the handout
(§<a href="#sec:dynkin-diagrams-classical-examples"
data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>)
from lecture (available now also on the course homepage) describes the
root systems, and I’ll leave it as an exercise to adapt the techniques
used to prove the simplicity of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
and <span
class="math inline">\(\mathfrak{s}\mathfrak{p}_{2n}(\mathbb{C})\)</span>
to the orthogonal case. There is one trick in that case which is very
handy. Recall from §<a href="#sec:low-rank-exceptional-isomorphisms"
data-reference-type="ref"
data-reference="sec:low-rank-exceptional-isomorphisms">18.5</a>
the notion of a <em>quadratic space</em> over <span
class="math inline">\(\mathbb{C}\)</span>, and that any <span
class="math inline">\(n\)</span>-dimensional quadratic space is
isomorphic to the standard one. It is convenient to equip <span
class="math inline">\(\mathbb{C}^{2 n}\)</span> with the structure of a
quadratic space for which the associated non-degenerate symmetric
bilinear form <span class="math inline">\(\langle , \rangle\)</span>
(denoted <span class="math inline">\(B\)</span> in §<a
href="#sec:low-rank-exceptional-isomorphisms" data-reference-type="ref"
data-reference="sec:low-rank-exceptional-isomorphisms">18.5</a>)
is given by <span class="math display">\[\langle x,y \rangle
  = \sum_{i=1}^n
  (x_i y_{n+i} + x_{n+i} y_{i})\]</span> and <span
class="math inline">\(\mathbb{C}^{2n+1}\)</span> that for which <span
class="math display">\[\langle x,y \rangle
  = \sum_{i=1}^n
  (x_i y_{n+i} + x_{n+i} y_{i})
  + x_{2n+1} y_{2 n+1}.\]</span> It is then easy to see that <span
class="math inline">\({\mathop{\mathrm{SO}}}_{m}(\mathbb{C}) := \{g \in
{\mathop{\mathrm{SL}}}_m(\mathbb{C}): \langle g x, g y \rangle \text{ for
all } x,y \in \mathbb{C}^m\}\)</span>, when defined with respect to the
above inner products, contains in the case <span class="math inline">\(m
= 2 n\)</span> the diagonal subgroup <span class="math inline">\(H =
\{\mathop{\mathrm{diag}}(z_1,\dotsc,z_n,z_1^{-1},\dotsc,z_n^{-1}) :
z_1,\dotsc,z_n \in \mathbb{C}^\times\}\)</span> and in the case <span
class="math inline">\(m = 2 n+ 1\)</span> the diagonal subgroup <span
class="math inline">\(H =
\{\mathop{\mathrm{diag}}(z_1,\dotsc,z_n,z_1^{-1},\dotsc,z_n^{-1},1) :
z_1,\dotsc,z_n \in \mathbb{C}^\times\}\)</span> whose Lie algebras <span
class="math inline">\(\mathfrak{h}\)</span> are given respectively by
<span class="math inline">\(\mathfrak{h} =
\{\mathop{\mathrm{diag}}(Z_1,\dotsc,Z_n,-Z_1,\dotsc,-Z_n) :
Z_1,\dotsc,Z_n \in \mathbb{C}\}\)</span> and <span
class="math inline">\(\mathfrak{h} =
\{\mathop{\mathrm{diag}}(Z_1,\dotsc,Z_n,-Z_1,\dotsc,-Z_n,0) :
Z_1,\dotsc,Z_n \in \mathbb{C}\}\)</span>. The Lie algebra of <span
class="math inline">\(\mathfrak{g}\)</span> is described on the handout
(§<a href="#sec:dynkin-diagrams-classical-examples"
data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>)
and will not be repeated here.</p>
<h2 id="sec:org617bb1c">§29.2. Classical simple complex Lie algebras</h2>
<div class="definition">
<p><strong>Definition 204</strong>. By a <em>classical simple complex
Lie algebra</em> we shall mean a complex Lie algebra of one of the
following forms:</p>
<ul>
<li><p><span class="math inline">\(A_n :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_{n+1}(\mathbb{C})\)</span>
for <span class="math inline">\(n \geq 1\)</span>,</p></li>
<li><p><span class="math inline">\(B_n :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{2n+1}(\mathbb{C})\)</span>
for <span class="math inline">\(n \geq 1\)</span>,</p></li>
<li><p><span class="math inline">\(C_n :=
\mathfrak{s}\mathfrak{p}_{2n}(\mathbb{C})\)</span> for <span
class="math inline">\(n \geq 1\)</span>,</p></li>
<li><p><span class="math inline">\(D_n :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{2n}(\mathbb{C})\)</span> for
<span class="math inline">\(n \geq 3\)</span>.</p></li>
</ul>
</div>
<div class="remark">
<p><strong>Remark 205</strong>. <span class="math inline">\(D_2 \cong
A_1 \times A_1\)</span> is not simple (it is a direct sum of two simple
Lie algebras). <span class="math inline">\(D_1 =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_2(\mathbb{C})\)</span> is not
simple (it is abelian).</p>
</div>
<p>Recall that our motivating goal for the past few lectures has been to
prove the following theorem:</p>
<div id="thm:classify-complex-simple-classical" class="theorem">
<p><strong>Theorem 206</strong>. <em>There are no isomorphisms between
the classical simple complex Lie algebras except possibly those of the
form <span id="eqn:exceptional-isoms-1" class="math display">\[\label{eqn:exceptional-isoms-1}\tag{119}
    A_1 \cong B_1 \cong C_1,\]</span> <span id="eqn:exceptional-isoms-2" class="math display">\[\label{eqn:exceptional-isoms-2}\tag{120}
    B_2 \cong C_2,\]</span> <span id="eqn:exceptional-isoms-3" class="math display">\[\label{eqn:exceptional-isoms-3}\tag{121}
    A_3 \cong D_3.\]</span></em></p>
</div>
<div class="remark">
<p><strong>Remark 207</strong>. In fact, the isomorphisms <a
href="#eqn:exceptional-isoms-1" data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-1">\((119)\)</a>,
<a href="#eqn:exceptional-isoms-2" data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-2">\((120)\)</a>
and <a href="#eqn:exceptional-isoms-3" data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-3">\((121)\)</a>
all hold. We have proven that <span class="math inline">\(A_1 \cong
B_1\)</span>. It is immediate from the definition that <span
class="math inline">\(A_1 \cong C_1\)</span>. We have not yet proven the
exceptional isomorphisms <a href="#eqn:exceptional-isoms-2"
data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-2">\((120)\)</a>
and <a href="#eqn:exceptional-isoms-3" data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-3">\((121)\)</a>,
but they exist, and are not inordinately complicated to establish.</p>
</div>
<div class="remark">
<p><strong>Remark 208</strong>. We may reformulate Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a> in terms
of the simply-connected complex Lie groups having the indicated Lie
algebras.</p>
</div>
<div class="remark">
<p><strong>Remark 209</strong>. We record some motivation for caring
about Theorem <a href="#thm:classify-complex-simple-classical"
data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a>.</p>
<ol>
<li><p>It’s interesting in its own right; it’s natural to ask for a
complete list of isomorphisms between some naturally occurring
groups.</p></li>
<li><p>The techniques involved in the proof (roots, weights,
reflections, Dynkin diagrams, ...) are very important in all of Lie
theory and its applications in other fields of mathematics. The specific
groups involved are also universally important. Our primary goal is
really to introduce those techniques by application to a motivating
problem.</p></li>
<li><p>Theorem <a href="#thm:classify-complex-simple-classical"
data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a> is weaker
than the full classification theorem for <em>all</em> complex simple Lie
algebras (not just the classical ones), which says that the above list
is complete with five exceptions, denoted <span
class="math inline">\(G_2, F_4, E_6, E_7, E_8\)</span>. That full
classification is not inordinately difficult, but would probably take
most of a semester to present properly, and it’s very easy to get lost
in the middle of it and lose the big picture. On the other hand, we
should be able to complete the proof of Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a> in a
couple lectures.</p></li>
<li><p>It takes a lot of experience to gain intuition for working with
roots, weights, reflections, etc. It seems best to introduce them as
explicitly as possible. That way, many properties that would normally
require laborious and unenlightening proofs can be discovered by
inspection; one can then later learn proofs of such properties that
apply more generally.</p></li>
</ol>
</div>
<h2 id="sec:orgaf78e16">§29.3. How to classify them (without worrying about why
it works)<span id="sec:how-to-classify"
label="sec:how-to-classify"></span></h2>
<p>We now outline the structure of the proof of Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a>. Let
<span class="math inline">\(\mathfrak{g}\)</span> be a classical simple
complex Lie algebra. We will attach to <span
class="math inline">\(\mathfrak{g}\)</span> a certain oriented
multigraph, called a <em>Dynkin diagram</em>. (See the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>)
for what these look like in all cases. We explained in class how
coincidences between “small” Dynkin diagrams explain all of the
exceptional isomorphisms <a href="#eqn:exceptional-isoms-1"
data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-1">\((119)\)</a>,
<a href="#eqn:exceptional-isoms-2" data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-2">\((120)\)</a>
and <a href="#eqn:exceptional-isoms-3" data-reference-type="eqref"
data-reference="eqn:exceptional-isoms-3">\((121)\)</a>.)</p>
<p>The procedure by which we will attach the Dynkin diagram will involve
several choices. To make the proof of Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a> rigorous,
we will later have to go back and check that these choices did not
affect the final result.</p>
<p>Let us note right away that because <span
class="math inline">\(\mathfrak{g}\)</span> is simple, its center
(equivalently, the kernel of <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span>) is trivial. Indeed, <span
class="math inline">\(\mathfrak{g}\)</span> is non-abelian (by the
definition of “simple”), so the center <span
class="math inline">\(\mathfrak{z}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> satisfies <span
class="math inline">\(\mathfrak{z} \neq \mathfrak{g}\)</span>. On the
other hand, the center is an ideal; since <span
class="math inline">\(\mathfrak{g}\)</span> is simple, we must have
<span class="math inline">\(\mathfrak{z} = 0\)</span>. In other words,
<span id="eq:adjoint-map-is-injective" class="math display">\[\label{eq:adjoint-map-is-injective}\tag{122}
  \mathop{\mathrm{ad}}: \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})
  \text{ is injective.}\]</span></p>
<ol>
<li><p>First, introduce the following definition:</p>
<div id="defn:cartan-subalgebra-of-simple-lie-algebra"
class="definition">
<p><strong>Definition 210</strong>. Let <span
class="math inline">\(\mathfrak{g}\)</span> be a simple complex Lie
algebra (the case that <span class="math inline">\(\mathfrak{g}\)</span>
is “classical” is all we will use for now). A <em>Cartan
subalgebra</em><a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> of <span
class="math inline">\(\mathfrak{g}\)</span> is a subalgebra <span
class="math inline">\(\mathfrak{h}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> for which</p>
<ol>
<li><p><span class="math inline">\(\mathfrak{h}\)</span> is
abelian,</p></li>
<li><p><span class="math inline">\(\mathfrak{h}\)</span> consists
entirely of <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span>-semisimple elements
(that is to say, for each <span class="math inline">\(X \in
\mathfrak{h}\)</span>, the linear endomorphism <span
class="math inline">\({\mathop{\mathrm{ad}}}_X \in
\mathop{\mathrm{End}}(\mathfrak{h})\)</span> is diagonalizable, i.e.,
admits a basis of eigenvectors), and</p></li>
<li><p><span class="math inline">\(\mathfrak{h}\)</span> is its own
centralizer: if <span class="math inline">\(X \in \mathfrak{g}\)</span>
satisfies <span class="math inline">\([X,H] = 0\)</span> for all <span
class="math inline">\(H \in \mathfrak{h}\)</span>, then <span
class="math inline">\(X \in \mathfrak{h}\)</span>.</p></li>
</ol>
</div>
<p>For example, the subalgebra <span
class="math inline">\(\mathfrak{h}\)</span> defined on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>)
is a Cartan subalgebra, and it turns out that all other Cartan
subalgebras are “conjugate” to it; we will explain this more in a bit.
The following definition thus depends only upon <span
class="math inline">\(\mathfrak{g}\)</span>, not upon <span
class="math inline">\(\mathfrak{h}\)</span>:</p>
<div class="definition">
<p><strong>Definition 211</strong>. The <em>rank</em> of <span
class="math inline">\(\mathfrak{g}\)</span> is defined to the dimension
of <span class="math inline">\(\mathfrak{h}\)</span>.</p>
</div>
<p>Let <span class="math inline">\(R\)</span> denote the set of roots
for <span class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{h}
\rightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span>, thus <span
class="math inline">\(R\)</span> is the set of all nonzero <span
class="math inline">\(\alpha \in \mathfrak{h}^*\)</span> for which the
subspace <span class="math inline">\(\mathfrak{g}^\alpha := \{X \in
\mathfrak{g} : [H,X] = \alpha(H) X \text{ for all } H \in
\mathfrak{h}\}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> is nonzero. We describe
<span class="math inline">\(R\)</span> explicitly on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>).</p>
<p>For example, for <span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>, we
can take for <span class="math inline">\(\mathfrak{h}\)</span> the
standard diagonal subalgebra. We saw in the lecture on the simplicity of
<span class="math inline">\(\mathfrak{g}\)</span> that <span
class="math inline">\(\mathfrak{h}\)</span> consists entirely of <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span>-semisimple elements;
indeed, <span id="eq:more-root-space-decmop-yippee" class="math display">\[\label{eq:more-root-space-decmop-yippee}\tag{123}
    \mathfrak{g} = \mathfrak{h} \oplus (\oplus_{\alpha \in R}
\mathfrak{g}^\alpha)\]</span> where each space on the RHS is an
eigenspace for <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{h})\)</span>. It is
clear that <span class="math inline">\(\mathfrak{h}\)</span> is its own
centralizer. Indeed, suppose <span class="math inline">\(Z \in
\mathfrak{g}\)</span> commutes with every element of <span
class="math inline">\(\mathfrak{h}\)</span>. We can decompose <span
class="math inline">\(Z\)</span> using <a
href="#eq:more-root-space-decmop-yippee" data-reference-type="eqref"
data-reference="eq:more-root-space-decmop-yippee">\((123)\)</a>
as a sum <span class="math inline">\(Z_0 + \sum_{\alpha \in R}
Z_\alpha\)</span>, where <span class="math inline">\(Z_0 \in
\mathfrak{h}\)</span> and <span class="math inline">\(Z_\alpha \in
\mathfrak{g}^\alpha\)</span>. For each <span class="math inline">\(H \in
\mathfrak{h}\)</span>, we have <span class="math inline">\([H,Z] =
0\)</span>, by assumption; on the other hand, <span id="eq:eigenspace-decomp-relevant-fro-checking-maximality" class="math display">\[\label{eq:eigenspace-decomp-relevant-fro-checking-maximality}\tag{124}
[H,Z]
    = [H,Z_0] + \sum_{\alpha \in R} [H,Z_\alpha]
    = \sum_{\alpha \in R} \alpha(H) Z_\alpha.\]</span> Since the <span
class="math inline">\(Z_\alpha\)</span> are linearly independent of one
another (as they belong to distinct root spaces), we must have <span
class="math inline">\(\alpha(H) Z_\alpha = 0\)</span> for all <span
class="math inline">\(H \in \mathfrak{h}\)</span>. Since each root <span
class="math inline">\(\alpha \in R\)</span> is nonzero, we can find
<span class="math inline">\(H \in \mathfrak{h}\)</span> so that <span
class="math inline">\(\alpha(H) \neq 0\)</span>, thus <span
class="math inline">\(Z_\alpha = 0\)</span> for all <span
class="math inline">\(\alpha \in R\)</span> and thus <span
class="math inline">\(Z = Z_0\)</span> belongs to <span
class="math inline">\(\mathfrak{h}\)</span>. Since <span
class="math inline">\(Z\)</span> was arbitrary, we conclude that <span
class="math inline">\(\mathfrak{h} \subseteq \mathfrak{h}
&#39;\)</span>, as required.</p>
<p>More generally, one can verify that the subaglebras <span
class="math inline">\(\mathfrak{h}\)</span> defined on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>)
in the cases <span class="math inline">\(A_n,B_n,C_n,D_n\)</span> are in
fact Cartan subalgebras. One sees also that <span
class="math inline">\(A_n, B_n, C_n, D_n\)</span> have rank <span
class="math inline">\(n\)</span>. This explains the indexing.</p>
<p>We observe (by inspecting each family) that the set <span
class="math inline">\(R\)</span> of roots for <span
class="math inline">\((\mathfrak{h},\mathfrak{g})\)</span> has the
following properties (noted earlier for <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
and <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{p}}}}_{2n}(\mathbb{C})\)</span>):</p>
<ol>
<li><p>For <span class="math inline">\(\alpha \in R\)</span>, one has
<span class="math inline">\(\{n \in \mathbb{Z} : n \alpha \in R\} =
\{\pm 1\}\)</span>.</p></li>
<li><p><span class="math inline">\(\dim \mathfrak{g}^\alpha = 1\)</span>
for all <span class="math inline">\(\alpha \in R\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X_\alpha \in
\mathfrak{g}^\alpha\)</span> be nonzero, so that <span
class="math inline">\(\mathfrak{g}^\alpha = \mathbb{C}
X_\alpha\)</span>. There exists a unique <span
class="math inline">\(Y_\alpha \in \mathfrak{g}^{-\alpha}\)</span> so
that the element <span class="math inline">\(H_\alpha \in
\mathfrak{h}\)</span> defined by <span class="math inline">\(H_\alpha :=
[X_\alpha,Y_\alpha]\)</span> satisfies <span
class="math inline">\(\alpha(H_\alpha) = 2\)</span>.</p></li>
<li><p>For all <span class="math inline">\(\alpha,\beta \in R\)</span>,
<span class="math display">\[=
\begin{cases}
        \mathfrak{g}^{\alpha + \beta} &amp; \text{ if } \alpha + \beta
\in R \\
        \mathbb{C} H_\alpha  &amp; \text{ if } \alpha + \beta = 0 \\
        0 &amp; \text{ otherwise.}
      \end{cases}\]</span></p></li>
</ol>
<p>Explicit choices for the <span class="math inline">\(X_\alpha,
Y_\alpha, H_\alpha\)</span> in all cases are given on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>).</p></li>
<li><p>Next, we introduce the following definition:</p>
<div class="definition">
<p><strong>Definition 212</strong>. A <em>base</em> (or <em>simple
system</em> or <em>system of simple roots</em>) <span
class="math inline">\(S \subseteq R\)</span> is a subset with the
following properties:</p>
<ol>
<li><p><span class="math inline">\(S\)</span> is a basis of <span
class="math inline">\(\mathfrak{h}^*\)</span>.</p></li>
<li><p>For each <span class="math inline">\(\beta \in R\)</span>, if one
writes <span id="eq:decomp-in-terms-of-simple-roots" class="math display">\[\label{eq:decomp-in-terms-of-simple-roots}\tag{125}
        \beta = \sum_{\alpha \in S} c_\alpha \alpha\]</span> with <span
class="math inline">\(c_\alpha \in \mathbb{C}\)</span> (as one can,
because <span class="math inline">\(S\)</span> is a basis), then the
<span class="math inline">\(c_\alpha\)</span> are integers and all have
the same sign (i.e., either <span class="math inline">\(c_\alpha \geq
0\)</span> for all <span class="math inline">\(\alpha\)</span> or <span
class="math inline">\(c_\alpha \leq 0\)</span> for all <span
class="math inline">\(\alpha\)</span>).</p></li>
</ol>
</div>
<p>On the handout (§<a href="#sec:dynkin-diagrams-classical-examples"
data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>),
an explicit choice of a simple system <span
class="math inline">\(S\)</span> is given for each of the classical
complex simple Lie algebras. There are in fact many possible choices,
and we will have to argue later that they are all “sufficiently
equivalent” for the purposes of the construction to follow.</p>
<p>The set of <em>positive roots</em> (with respect to the given simple
system <span class="math inline">\(S\)</span>) is the set <span
class="math inline">\(R^+\)</span> consisting of all <span
class="math inline">\(\beta \in R\)</span> for which in the
decomposition <a href="#eq:decomp-in-terms-of-simple-roots"
data-reference-type="eqref"
data-reference="eq:decomp-in-terms-of-simple-roots">\((125)\)</a>,
one has <span class="math inline">\(c_\alpha \geq 0\)</span> for all
<span class="math inline">\(\alpha \in S\)</span>. The set <span
class="math inline">\(R^-\)</span> of <em>negative roots</em> is defined
analogously. One has <span class="math inline">\(R = R^+ \sqcup
R^-\)</span> and <span class="math inline">\(R^- = (-R^+) := \{- \alpha
: \alpha \in R^+\}\)</span>. It’s worth going through the examples and
seeing what <span class="math inline">\(R^+\)</span> looks like. For
example, in the case <span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span> and
for the standard choice of <span class="math inline">\(S\)</span>
recorded on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>),
<span class="math inline">\(R^+\)</span> consists of those <span
class="math inline">\(\alpha\)</span> for which the corresponding root
space <span class="math inline">\(\mathfrak{g}^\alpha\)</span> belongs
to the space of strictly upper-triangular matrices; by contrast, the
negative roots correspond to strictly lower-triangular root
spaces.</p></li>
<li><p>One now writes down the <em>Cartan matrix</em> <span
class="math inline">\(N = (\alpha(H_\beta))_{\alpha,\beta \in
S}\)</span>. This is straightforward, but it’s worth working through all
of the examples to make sure you understand it. Two Cartan matrices are
<em>equivalent</em> if one is obtained from the other by relabeling the
indices. (There is no preferred ordering among elements of the finite
set <span class="math inline">\(S\)</span>, so this is a natural notion
of equivalence.)</p></li>
<li><p>Finally, for convenience, one converts the Cartan matrix into a
<em>Dynkin diagram</em>. This is a finite graph whose vertices are given
by the elements of <span class="math inline">\(S\)</span>. (It is
convenient in practice because most entries of the Cartan matrix turn
out to be zero.) Given distinct elements <span
class="math inline">\(\alpha, \beta \in S\)</span>, one sees by
inspection that the ordered pair of integers <span
class="math inline">\((\alpha(H_\beta), \beta(H_\alpha))\)</span> is of
the following form:</p>
<ol>
<li><p><span class="math inline">\((0,0)\)</span>: in this case we draw
<em>no</em> edges connecting <span
class="math inline">\(\alpha,\beta\)</span>.</p></li>
<li><p><span class="math inline">\((-1,-1)\)</span>: in this case we
draw one undirected edge between <span
class="math inline">\(\alpha,\beta\)</span>.</p></li>
<li><p><span class="math inline">\((-2,-1)\)</span>: in this case we
draw a double edge directed from <span
class="math inline">\(\alpha\)</span> to <span
class="math inline">\(\beta\)</span>; see the handout</p></li>
<li><p><span class="math inline">\((-1,-2)\)</span>: in this case we
draw a double edge directed from <span
class="math inline">\(\beta\)</span> to <span
class="math inline">\(\alpha\)</span>; see the handout</p></li>
<li><p><span class="math inline">\((-3,-1)\)</span>: in this case we
draw a triple edge directed from <span
class="math inline">\(\alpha\)</span> to <span
class="math inline">\(\beta\)</span>; this case doesn’t occur for
classical Lie algebras (but does for the exceptional Lie algebra <span
class="math inline">\(G_2\)</span>)</p></li>
<li><p><span class="math inline">\((-1,-3)\)</span>: in this case we
draw a triple edge directed from <span
class="math inline">\(\beta\)</span> to <span
class="math inline">\(\alpha\)</span>; same comments apply.</p></li>
</ol>
<p>It is obvious that the Dynkin diagram determines the Cartan matrix
(and vice-versa, of course). Dynkin diagrams are nicer to work with
because their equivalences are easier to spot.</p></li>
</ol>
<p>To complete the proof of Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a>, we need
to check that the Dynkin diagram (up to equivalence, i.e., relabeling of
the vertices) is independent of the choice of Cartan subalgebra <span
class="math inline">\(\mathfrak{h}\)</span> and simple system <span
class="math inline">\(S\)</span> made in the above construction. This
will occupy the next several sections.</p>
<div class="exercise">
<p><strong>Exercise 35</strong>. Show that if <span
class="math inline">\(\mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_m(\mathbb{C})\)</span> is
defined using the <em>standard</em> scalar product <span
class="math inline">\(\langle x,y \rangle := \sum_{i=1}^m x_i
y_i\)</span> on <span class="math inline">\(\mathbb{C}^m\)</span> (as
opposed to that in §<a
href="#sec:recap-classification-includes-better-defn-of-orthogonal-gp"
data-reference-type="ref"
data-reference="sec:recap-classification-includes-better-defn-of-orthogonal-gp">29.1</a>),
so that <span class="math inline">\(\mathfrak{g} = \{X \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_m(\mathbb{C}) : X^t + X =
0\}\)</span>, then <span class="math inline">\(\mathfrak{g}\)</span>
contains no nonzero diagonal elements, but that the following subalgebra
<span class="math inline">\(\mathfrak{h}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> is a Cartan subalgebra (see
Definition <a href="#defn:cartan-subalgebra-of-simple-lie-algebra"
data-reference-type="ref"
data-reference="defn:cartan-subalgebra-of-simple-lie-algebra">210</a>):
if <span class="math inline">\(m = 2 n\)</span>, then <span
class="math display">\[\mathfrak{h} = \left\{
      \begin{pmatrix}
        0 &amp; i \lambda_1  &amp; &amp; &amp; &amp; &amp; &amp; \\
        -i \lambda_1 &amp; 0 &amp; &amp; &amp; &amp; &amp; &amp;  \\
          &amp; &amp; 0 &amp; i \lambda_2  &amp; &amp; &amp; &amp;    \\
          &amp; &amp; -i \lambda_2 &amp; 0  &amp; &amp; &amp; &amp;  \\
          &amp; &amp; &amp; &amp; \ddots &amp;    &amp; &amp;    \\
          &amp; &amp; &amp; &amp;  &amp; \ddots   &amp; &amp;  \\
          &amp; &amp; &amp; &amp; &amp; &amp; 0 &amp; i \lambda_n    \\
          &amp; &amp; &amp; &amp; &amp; &amp; -i \lambda_n &amp; 0
      \end{pmatrix}
,
    \right\}\]</span> while if <span class="math inline">\(m = 2 n +
1\)</span>, then <span class="math display">\[\mathfrak{h} = \left\{
      \begin{pmatrix}
        0 &amp; i \lambda_1  &amp; &amp; &amp; &amp; &amp; &amp; &amp;
\\
        -i \lambda_1 &amp; 0 &amp; &amp; &amp; &amp; &amp; &amp;
&amp;  \\
          &amp; &amp; 0 &amp; i \lambda_2  &amp; &amp; &amp; &amp;
&amp;   \\
          &amp; &amp; -i \lambda_2 &amp; 0  &amp; &amp; &amp;
&amp;  &amp; \\
          &amp; &amp; &amp; &amp; \ddots &amp;    &amp; &amp;  &amp;  \\
          &amp; &amp; &amp; &amp;  &amp; \ddots   &amp; &amp; &amp;  \\
          &amp; &amp; &amp; &amp; &amp; &amp; 0 &amp; i \lambda_n
&amp;   \\
          &amp; &amp; &amp; &amp; &amp; &amp; -i \lambda_n &amp; 0 &amp;
\\
          &amp; &amp; &amp; &amp; &amp; &amp;  &amp;  &amp; 0
      \end{pmatrix}
.
    \right\}\]</span></p>
</div>
<h2 id="sec:orga54764a">§29.4. Dynkin diagrams of classical simple Lie
algebras<span id="sec:dynkin-diagrams-classical-examples"
label="sec:dynkin-diagrams-classical-examples"></span></h2>
<p>As an exercise, reproduce the following in private.</p>
<p><span class="math inline">\(A_{n-1} :
{\mathop{\mathrm{SL}}}_{n}(\mathbb{C}), \mathop{\mathrm{SU}}(n),
\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_{n}(\mathbb{C}) = \{a \in
M_n(\mathbb{C}): \mathop{\mathrm{trace}}(a) = 0\}\)</span></p>
<p><span class="math inline">\(\varepsilon_i := E_{i i}\)</span>, <span
class="math display">\[\mathfrak{h} = \left\{ \sum_{i=1}^n a_i
\varepsilon_i : \sum a_i = 0 \right\} = \left\{ H =
    \begin{pmatrix}
      \lambda_1(H) &amp;  &amp;  \\
             &amp; \dotsb  &amp;  \\
             &amp;  &amp; \lambda_n(H)
    \end{pmatrix}
    : \lambda_1(H) + \dotsb + \lambda_n(H) = 0 \right\}\]</span> <span
class="math display">\[\mathfrak{h}^* = \frac{\mathbb{C} \lambda_1
\oplus \dotsb \oplus \mathbb{C} \lambda_n}{ \mathbb{C} (\lambda_1 +
\dotsb + \lambda_n) }, \quad R = \left\{ \pm (\lambda_j - \lambda_k) : j
&lt; k \right\}\]</span> <span class="math display">\[X_{\lambda_j -
\lambda_k} = E_{j k}, \quad Y_{\lambda_j - \lambda_k} = E_{k j}, \quad
H_{\lambda_j - \lambda_k} = \varepsilon_j - \varepsilon_k \quad (j \neq
k)\]</span> <span class="math display">\[S = \left\{ \lambda_1 -
\lambda_2, \lambda_2 - \lambda_3, \dotsc, \lambda_{n-1} - \lambda_n
\right\}, \quad R^+ = \left\{ (\lambda_j - \lambda_k) : j &lt; k
\right\}\]</span> <span class="math display">\[N =
(\alpha(H_\beta))_{\alpha,\beta \in S} =
  \begin{pmatrix}
    2 &amp; -1 &amp;  &amp; &amp; \\
    -1 &amp; 2 &amp; -1 &amp; &amp; \\
      &amp; -1 &amp; 2 &amp; -1 &amp; \\
      &amp; &amp; -1 &amp; 2 &amp; -1 \\
      &amp; &amp; &amp; -1 &amp; 2
  \end{pmatrix}
  \quad
  \bgroup \begin{tikzpicture}[decoration={markings,mark=at position 0.7
with {\arrow{&gt;}}}]
    \draw[thin] (.35cm*1,.35cm*0) -- (.35cm*2,.35cm*0);; \draw[thin]
(.35cm*2,.35cm*0) -- (.35cm*3,.35cm*0);; \draw[thin] (.35cm*3,.35cm*0)
-- (.35cm*4,.35cm*0);; \draw[thin] (.35cm*4,.35cm*0) --
(.35cm*5,.35cm*0); \foreach \x in {1,...,5} { \fill (.35cm*\x,.35cm*0)
circle (.04cm); }
  \end{tikzpicture}\egroup
  \quad (A_5)\]</span> e.g., <span class="math inline">\((\lambda_{j+1}
- \lambda_j)(H_{\lambda_{j} - \lambda_{j-1}}) = -1\)</span> and <span
class="math inline">\((\lambda_{j} - \lambda_{j-1})(H_{\lambda_{j+1} -
\lambda_{j}}) =-1\)</span></p>
<hr />
<p><span class="math inline">\(B_{n}:
{\mathop{\mathrm{Spin}}}_{2n+1}(\mathbb{C}),
\mathop{\mathrm{Spin}}(2n+1),\)</span><a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>
<span class="math display">\[\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{2n+1}(\mathbb{C}) = \left\{
\begin{pmatrix}
    a &amp; b  &amp; x \\
    c &amp; -a^t &amp; y \\
    -y^t &amp; - x^t &amp; 0
  \end{pmatrix}
\in M_{2n+1}(\mathbb{C}) :
  \begin{split}
    a,b,c \in M_{n \times n}(\mathbb{C}),
    \\
    x,y \in M_{n \times 1}(\mathbb{C}),
    b^t = -b, c^t = -c
  \end{split}
\right\}\]</span></p>
<p><span class="math inline">\(\varepsilon_i := E_{i i} -
E_{n+i,n+i}\)</span>, <span class="math display">\[\mathfrak{h} =
\mathbb{C} \varepsilon_1 \oplus \dotsb \oplus \mathbb{C} \varepsilon_n =
\left\{ H =
\begin{pmatrix}
    \lambda_1(H) &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0  \\
    0 &amp; \dotsb &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0  \\
    0 &amp; 0 &amp; \lambda_n(H) &amp; 0 &amp; 0 &amp; 0 &amp; 0  \\
    0 &amp; 0 &amp; 0 &amp; -\lambda_1(H) &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \dotsb &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -\lambda_n(H) &amp; 0  \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
  \end{pmatrix}
\right\}\]</span> <span class="math display">\[\mathfrak{h}^* =
\mathbb{C} \lambda_1 \oplus \dotsb \oplus \mathbb{C} \lambda_n, \quad R
= \left\{ \pm (\lambda_j \pm \lambda_k) : j &lt; k \right\} \sqcup
\left\{ \pm \lambda_j \right\}\]</span> <span
class="math display">\[X_{\lambda_j - \lambda_k} = E_{j k} -
E_{n+k,n+j}, \quad Y_{\lambda_j - \lambda_k} = E_{k j} - E_{n+j,n+k},
\quad H_{\lambda_j - \lambda_k} = \varepsilon_j - \varepsilon_k \quad (j
\neq k)\]</span> <span class="math display">\[X_{\lambda_j + \lambda_k}
= E_{j,n+k} - E_{k,n+j}, \quad Y_{\lambda_j + \lambda_k} = - E_{n+j, k}
+ E_{n+k,j}, \quad H_{\lambda_j + \lambda_k} = \varepsilon_j +
\varepsilon_k \quad (j &lt; k)\]</span> <span
class="math display">\[X_{-\lambda_j - \lambda_k} = E_{n+j,k} -
E_{n+k,j}, \quad Y_{-\lambda_j - \lambda_k} = -E_{j, n+k} + E_{k,n+j},
\quad H_{-\lambda_j - \lambda_k} = -\varepsilon_j - \varepsilon_k \quad
(j &lt; k)\]</span> <span class="math display">\[X_{\lambda_j} = E_{j,2
n + 1} - E_{2n+1,n+j} \quad Y_{\lambda_j} = 2(E_{2 n + 1,j} -
E_{n+j,2n+1}), \quad H_{\lambda_j} = 2 \varepsilon_j\]</span> <span
class="math display">\[X_{-\lambda_j} = E_{2 n + 1,j} - E_{n+j,2n+1}
\quad Y_{-\lambda_j} = 2(E_{j,2 n + 1} - E_{2n+1,n+j}), \quad
H_{-\lambda_j} = -2 \varepsilon_j\]</span> <span
class="math display">\[S = \left\{ \lambda_1 - \lambda_2, \lambda_2 -
\lambda_3, \dotsc, \lambda_{n-1} - \lambda_n, \lambda_n \right\}, \quad
R^+ = \left\{ (\lambda_j \pm \lambda_k) : j &lt; k \right\} \sqcup
\left\{ \lambda_j \right\}\]</span> <span class="math display">\[N =
(\alpha(H_\beta))_{\alpha,\beta \in S} =
  \begin{pmatrix}
    2 &amp; -1 &amp;  &amp; &amp; \\
    -1 &amp; 2 &amp; -1 &amp; &amp; \\
      &amp; -1 &amp; 2 &amp; -1 &amp; \\
      &amp; &amp; -1 &amp; 2 &amp; -2 \\
      &amp; &amp; &amp; -1 &amp; 2
  \end{pmatrix}
  \quad
  \bgroup \begin{tikzpicture}[decoration={markings,mark=at position 0.7
with {\arrow{&gt;}}}]
    \draw[thin] (.35cm*1,.35cm*0) -- (.35cm*2,.35cm*0);; \draw[thin]
(.35cm*2,.35cm*0) -- (.35cm*3,.35cm*0);; \draw[thin] (.35cm*3,.35cm*0)
-- (.35cm*4,.35cm*0);; \draw[double,postaction={decorate}]
(.35cm*4,.35cm*0) -- (.35cm*5,.35cm*0);; \foreach \x in {1,...,5} {
\fill (.35cm*\x,.35cm*0) circle (.04cm); }
  \end{tikzpicture}\egroup
  \quad (B_5)\]</span> e.g., <span
class="math inline">\((\lambda_{n})(H_{\lambda_{n-1} - \lambda_{n}}) =
-1\)</span> and <span class="math inline">\((\lambda_{n-1} -
\lambda_n)(H_{\lambda_{n}}) = -2\)</span>.</p>
<hr />
<p><span class="math inline">\(C_{n}:
{\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C}), \mathop{\mathrm{Sp}}(2n), \quad
\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{p}}}}_{2n}(\mathbb{C}) = \left\{
\begin{pmatrix}
  a &amp; b \\
  c &amp; -a^t
\end{pmatrix}
\in M_{2n}(\mathbb{C}) : b^t = b, c^t = c
\right\}\)</span>,</p>
<p><span class="math inline">\(\varepsilon_i := E_{i i} -
E_{n+i,n+i}\)</span>, <span class="math display">\[\mathfrak{h} =
\mathbb{C} \varepsilon_1 \oplus \dotsb \oplus \mathbb{C} \varepsilon_n =
\left\{ H =
\begin{pmatrix}
    \lambda_1(H) &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; \dotsb &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; \lambda_n(H) &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; -\lambda_1(H) &amp; 0 &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \dotsb &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -\lambda_n(H)
  \end{pmatrix}
\right\}\]</span> <span class="math display">\[\mathfrak{h}^* =
\mathbb{C} \lambda_1 \oplus \dotsb \oplus \mathbb{C} \lambda_n, \quad R
= \left\{ \pm (\lambda_j \pm \lambda_k) : j &lt; k \right\} \sqcup
\left\{ \pm 2 \lambda_j \right\}\]</span> <span
class="math display">\[X_{\lambda_j - \lambda_k} = E_{j k} -
E_{n+k,n+j}, \quad Y_{\lambda_j - \lambda_k} = E_{k j} - E_{n+j,n+k},
\quad H_{\lambda_j - \lambda_k} = \varepsilon_j - \varepsilon_k \quad (j
\neq k)\]</span> <span class="math display">\[X_{\lambda_j + \lambda_k}
= E_{j,n+k} + E_{k,n+j}, \quad Y_{\lambda_j + \lambda_k} = E_{n+j, k} +
E_{n+k,j}, \quad H_{\lambda_j + \lambda_k} = \varepsilon_j +
\varepsilon_k \quad (j &lt; k)\]</span> <span
class="math display">\[X_{-\lambda_j - \lambda_k} = E_{n+j,k} +
E_{n+k,j}, \quad Y_{-\lambda_j - \lambda_k} = E_{j, n+k} + E_{k,n+j},
\quad H_{-\lambda_j - \lambda_k} = -\varepsilon_j - \varepsilon_k \quad
(j &lt; k)\]</span> <span class="math display">\[X_{2 \lambda_j} =
E_{j,n+j}, \quad Y_{2 \lambda_j} = E_{n+j,j}, \quad H_{2 \lambda_j} =
\varepsilon_j\]</span> <span class="math display">\[X_{-2 \lambda_j} =
E_{n+j,j}, \quad Y_{-2 \lambda_j} = E_{j,n+j}, \quad H_{-2 \lambda_j} =
-\varepsilon_j\]</span> <span class="math display">\[S = \left\{
\lambda_1 - \lambda_2, \lambda_2 - \lambda_3, \dotsc, \lambda_{n-1} -
\lambda_n, 2 \lambda_n \right\}, \quad R^+ = \left\{ (\lambda_j \pm
\lambda_k) : j &lt; k \right\} \sqcup \left\{ 2 \lambda_j
\right\}\]</span> <span class="math display">\[N =
(\alpha(H_\beta))_{\alpha,\beta \in S} =
  \begin{pmatrix}
    2 &amp; -1 &amp;  &amp; &amp; \\
    -1 &amp; 2 &amp; -1 &amp; &amp; \\
      &amp; -1 &amp; 2 &amp; -1 &amp; \\
      &amp; &amp; -1 &amp; 2 &amp; -1 \\
      &amp; &amp; &amp; -2 &amp; 2
  \end{pmatrix}
  \quad
  \bgroup \begin{tikzpicture}[decoration={markings,mark=at position 0.7
with {\arrow{&gt;}}}]
    \draw[thin] (.35cm*1,.35cm*0) -- (.35cm*2,.35cm*0);; \draw[thin]
(.35cm*2,.35cm*0) -- (.35cm*3,.35cm*0);; \draw[thin] (.35cm*3,.35cm*0)
-- (.35cm*4,.35cm*0);; \draw[double,postaction={decorate}]
(.35cm*5,.35cm*0) -- (.35cm*4,.35cm*0);; \foreach \x in {1,...,5} {
\fill (.35cm*\x,.35cm*0) circle (.04cm); }
  \end{tikzpicture}\egroup
  \quad (C_5)\]</span> e.g., <span class="math inline">\((2
\lambda_{n})(H_{\lambda_{n-1} - \lambda_{n}}) = -2\)</span> and <span
class="math inline">\((\lambda_{n-1} - \lambda_n)(H_{2 \lambda_{n}}) =
-1\)</span></p>
<hr />
<p><span class="math display">\[D_{n}:
{\mathop{\mathrm{Spin}}}_{2n}(\mathbb{C}),
\mathop{\mathrm{Spin}}(2n),\footnote{ Defined via the scalar product
$\langle x,y \rangle := \sum_{j=1}^n (x_j y_{n+j} + x_{n+j} y_j)$.  }
\quad \mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{o}}}}_{2n}(\mathbb{C}) = \left\{
\begin{pmatrix}
  a &amp; b   \\
  c &amp; -a^t
\end{pmatrix}
\in M_{2n}(\mathbb{C}) :
b^t = -b, c^t = -c
\right\},\]</span> <span class="math inline">\(\varepsilon_i := E_{i i}
- E_{n+i,n+i}\)</span>, <span class="math display">\[\mathfrak{h} =
\mathbb{C} \varepsilon_1 \oplus \dotsb \oplus \mathbb{C} \varepsilon_n =
\left\{ H =
\begin{pmatrix}
    \lambda_1(H) &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; \dotsb &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; \lambda_n(H) &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; -\lambda_1(H) &amp; 0 &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; \dotsb &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -\lambda_n(H)
  \end{pmatrix}
\right\}\]</span> <span class="math display">\[\mathfrak{h}^* =
\mathbb{C} \lambda_1 \oplus \dotsb \oplus \mathbb{C} \lambda_n, \quad R
= \left\{ \pm (\lambda_j \pm \lambda_k) : j &lt; k \right\}\]</span>
<span class="math display">\[X_{\lambda_j - \lambda_k} = E_{j k} -
E_{n+k,n+j}, \quad Y_{\lambda_j - \lambda_k} = E_{k j} - E_{n+j,n+k},
\quad H_{\lambda_j - \lambda_k} = \varepsilon_j - \varepsilon_k \quad (j
\neq k)\]</span> <span class="math display">\[X_{\lambda_j + \lambda_k}
= E_{j,n+k} - E_{k,n+j}, \quad Y_{\lambda_j + \lambda_k} = - E_{n+j, k}
+ E_{n+k,j}, \quad H_{\lambda_j + \lambda_k} = \varepsilon_j +
\varepsilon_k \quad (j &lt; k)\]</span> <span
class="math display">\[X_{-\lambda_j - \lambda_k} = E_{n+j,k} -
E_{n+k,j}, \quad Y_{-\lambda_j - \lambda_k} = -E_{j, n+k} + E_{k,n+j},
\quad H_{-\lambda_j - \lambda_k} = -\varepsilon_j - \varepsilon_k \quad
(j &lt; k)\]</span> <span class="math display">\[S = \left\{ \lambda_1 -
\lambda_2, \lambda_2 - \lambda_3, \dotsc, \lambda_{n-2} - \lambda_{n-1},
\lambda_{n-1} - \lambda_n, \lambda_{n-1} + \lambda_n \right\}, \quad R^+
= \left\{ (\lambda_j \pm \lambda_k) : j &lt; k \right\}\]</span> <span
class="math display">\[N = (\alpha(H_\beta))_{\alpha,\beta \in S} =
  \begin{pmatrix}
    2 &amp; -1 &amp;  &amp; &amp; \\
    -1 &amp; 2 &amp; -1 &amp; &amp; \\
      &amp; -1 &amp; 2 &amp; -1 &amp; -1 \\
      &amp; &amp; -1 &amp; 2 &amp; 0 \\
      &amp; &amp; -1 &amp; 0 &amp; 2
  \end{pmatrix}
  \quad
  \bgroup \begin{tikzpicture}[decoration={markings,mark=at position 0.7
with {\arrow{&gt;}}}]
    \foreach \x in {1,...,3} { \fill (.35cm*\x,.35cm*0) circle (.04cm);
} \fill (.35cm*3.5,.35cm*.9) circle (.04cm); \fill (.35cm*3.5,.35cm*-.9)
circle (.04cm); \fill (.35cm*1,.35cm*0) circle (.04cm); \draw[thin]
(.35cm*1,.35cm*0) -- (.35cm*2,.35cm*0); \draw[thin] (.35cm*2,.35cm*0) --
(.35cm*3,.35cm*0); \draw[thin] (.35cm*3,.35cm*0) --
(.35cm*3.5,.35cm*.9); \draw[thin] (.35cm*3,.35cm*0) --
(.35cm*3.5,.35cm*-.9);
  \end{tikzpicture}\egroup
  \quad (D_5)\]</span> e.g., <span class="math inline">\((\lambda_{n-2}
- \lambda_{n-1})(H_{\lambda_{n-1} - \lambda_{n}}) = (\lambda_{n-2} -
\lambda_{n-1})(H_{\lambda_{n-1} + \lambda_{n}}) = (\lambda_{n-1} -
\lambda_{n})(H_{\lambda_{n-2} - \lambda_{n-1}}) = (\lambda_{n-1} +
\lambda_{n})(H_{\lambda_{n-2} - \lambda_{n-1}}) = -1\)</span> and <span
class="math inline">\((\lambda_{n-1} - \lambda_n)(H_{\lambda_{n-1} +
\lambda_n}) = (\lambda_{n-1} + \lambda_n)(H_{\lambda_{n-1} - \lambda_n})
= 0\)</span></p>
<h2 id="sec:org395e74a">§29.5. Classical algebras come with faithful
representations and are cut out by anti-involutions<span
id="sec:classical-action" label="sec:classical-action"></span></h2>
<p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a classical
simple complex Lie algebra. Then <span
class="math inline">\(\mathfrak{g}\)</span> comes equipped with a
defining faithful representation <span
class="math inline">\(\mathfrak{g} \hookrightarrow
\mathop{\mathrm{End}}(V)\)</span>, where <span class="math inline">\(V =
\mathbb{C}^{n+1}, \mathbb{C}^{2 n+1}, \mathbb{C}^{2 n}, \mathbb{C}^{2
n}\)</span> according as <span class="math inline">\(\mathfrak{g} = A_n,
B_n, C_n, D_n\)</span>.</p>
<p>We now record a property of <span
class="math inline">\(\mathfrak{g}\)</span> that will allow us to give
“ad hoc” proofs of some assertions in the sections to follow. Set <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}(V) :=
\{x \in \mathop{\mathrm{End}}(V) : \mathop{\mathrm{trace}}(x) =
0\}\)</span>. There is a linear anti-involution <span
class="math inline">\(\sigma : \mathop{\mathrm{End}}(V) \rightarrow
\mathop{\mathrm{End}}(V)\)</span> for which <span id="eqn:sigma-preserves-trace" class="math display">\[\label{eqn:sigma-preserves-trace}\tag{126}
  \mathop{\mathrm{trace}}(\sigma(x)) = \mathop{\mathrm{trace}}(x) \text{
for all } x \in \mathop{\mathrm{End}}(V)\]</span> and <span id="eqn:g-is-what-sigma-anti-fixes" class="math display">\[\label{eqn:g-is-what-sigma-anti-fixes}\tag{127}
  \mathfrak{g}
  = \{x \in \mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}(V) : \sigma(x) =
-x\}.\]</span> Namely:</p>
<ol>
<li><p>If <span class="math inline">\(\mathfrak{g} = A_n\)</span>, then
we take for <span class="math inline">\(\sigma\)</span> the identity
map.</p></li>
<li><p>If <span class="math inline">\(\mathfrak{g} = B_n, C_n,
D_n\)</span>, we take <span class="math display">\[\sigma(x) := J^{-1}
x^t J\]</span> where <span class="math display">\[J =
    \begin{pmatrix}
      0_{n \times n} &amp; 1_{n \times n} &amp; 0_{n \times 1} \\
      1_{n \times n} &amp; 0_{n \times n} &amp; 0_{n \times 1} \\
      0_{1 \times n} &amp; 0_{1 \times n} &amp; 1_{1 \times 1}
    \end{pmatrix}
    \text{ if } \mathfrak{g} = B_n,\]</span> <span
class="math display">\[J =
    \begin{pmatrix}
      0_{n \times n} &amp; 1_{n \times n} \\
      -1_{n \times n} &amp; 0_{n \times n}
    \end{pmatrix}
    \text{ if } \mathfrak{g} = C_n,\]</span> <span
class="math display">\[J =
    \begin{pmatrix}
      0_{n \times n} &amp; 1_{n \times n} \\
      1_{n \times n} &amp; 0_{n \times n}
    \end{pmatrix}
    \text{ if } \mathfrak{g} = D_n,\]</span></p></li>
</ol>
<p>By “linear anti-involution” we mean that <span
class="math display">\[\sigma(a x+ b y) = a \sigma(x) + b \sigma(y),
\quad \sigma(x y) = \sigma(y) \sigma(x), \quad \sigma(\sigma(x)) =
x.\]</span></p>
<h2 id="sec:org67896e3">§29.6. Diagonalization in classical Lie algebras<span
id="sec:classical-lie-alg-diagonalization"
label="sec:classical-lie-alg-diagonalization"></span></h2>
<p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a classical
simple complex Lie algebra and let <span class="math inline">\(g
\hookrightarrow \mathop{\mathrm{End}}(V)\)</span> be as in §<a
href="#sec:classical-action" data-reference-type="ref"
data-reference="sec:classical-action">29.5</a>. Let
<span class="math inline">\(G\)</span> denote a simply-connected complex
Lie group having Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. (Thus <span
class="math inline">\(G\)</span> is one of <span
class="math inline">\({\mathop{\mathrm{SL}}}_{n+1}(\mathbb{C}),
{\mathop{\mathrm{Spin}}}_{2n+1}(\mathbb{C}),
{\mathop{\mathrm{Sp}}}_{2n}(\mathbb{C}),
{\mathop{\mathrm{Spin}}}_{2n}(\mathbb{C})\)</span> according as we are in
case <span class="math inline">\(A_n,B_n,C_n,D_n\)</span>.) Let <span
class="math inline">\(x \in \mathfrak{g}\)</span>. We can think of it as
a linear transformation <span class="math inline">\(x : V \rightarrow
V\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 213</strong>. If <span class="math inline">\(x : V
\rightarrow V\)</span> is semisimple, then there exists <span
class="math inline">\(g \in G\)</span> so that <span
class="math inline">\(\mathop{\mathrm{Ad}}(g) x \in \mathfrak{g}
\subseteq \mathop{\mathrm{End}}(V)\)</span> is diagonal, i.e.,
represented by a diagonal matrix with respect to the standard basis of
<span class="math inline">\(V\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Suppose first that <span
class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>. Let
<span class="math inline">\(\mathcal{B} = (v_1,\dotsc,v_n)\)</span> be a
basis of eigenvectors for <span class="math inline">\(x\)</span>. Let
<span class="math inline">\(g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> be the “change of basis
matrix” from <span class="math inline">\(\mathcal{B}\)</span> to the
standard basis. Then <span class="math inline">\(g x g^{-1}\)</span> is
diagonal. This conclusion is unaffected by replacing <span
class="math inline">\(g\)</span> with a scalar multiple; by doing so, we
may arrange that <span class="math inline">\(g\)</span> belongs to <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span>.</p>
<p>TODO (or Exercise): discussion of other cases. ◻</p>
</span></div>
<h2 id="sec:org00974ae">§29.7. Semisimplicity of elements of classical Lie
algebras</h2>
<p>Let <span class="math inline">\(\mathfrak{g} \hookrightarrow
\mathop{\mathrm{End}}(V)\)</span> be as in §<a
href="#sec:classical-action" data-reference-type="ref"
data-reference="sec:classical-action">29.5</a>. We
have seen (see <a href="#eq:adjoint-map-is-injective"
data-reference-type="eqref"
data-reference="eq:adjoint-map-is-injective">\((122)\)</a>)
that <span class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{g}
\hookrightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span> is another
faithful representation. Given an element <span class="math inline">\(x
\in \mathfrak{g}\)</span>, it thus makes sense to compare properties of
the linear transformation <span class="math inline">\(x : V \rightarrow
V\)</span> with those of <span
class="math inline">\({\mathop{\mathrm{ad}}}_x : \mathfrak{g} \rightarrow
\mathfrak{g}\)</span>. The following comparison will be of particular
use (see §<a href="#sec:some-lin-alg" data-reference-type="ref"
data-reference="sec:some-lin-alg">28.1</a> to refresh the
terminology):</p>
<div id="lem:classical-simple-semisimple-iff-ad-semisimple"
class="lemma">
<p><strong>Lemma 214</strong>. <span class="math inline">\(x : V
\rightarrow V\)</span> is semisimple if and only if <span
class="math inline">\({\mathop{\mathrm{ad}}}_x : \mathfrak{g} \rightarrow
\mathfrak{g}\)</span> is semisimple.</p>
</div>
<p>For the proof, it will be convenient to recall a standard fact from
linear algebra:</p>
<div id="thm:jordan-decomp" class="theorem">
<p><strong>Theorem 215</strong>. <em>Let <span class="math inline">\(x
\in \mathop{\mathrm{End}}(V)\)</span> be a linear endomorphism of a
finite-dimensional complex vector space <span
class="math inline">\(V\)</span>. Then there exist unique <span
class="math inline">\(s,n \in \mathop{\mathrm{End}}(V)\)</span> so
that</em></p>
<ol>
<li><p><em><span class="math inline">\(s\)</span> is
semisimple,</em></p></li>
<li><p><em><span class="math inline">\(n\)</span> is nilpotent,
and</em></p></li>
<li><p><em><span class="math inline">\([s,n] = 0\)</span>.</em></p></li>
</ol>
<p><em>Moreover, there exist polynomials <span
class="math inline">\(S\)</span> and <span
class="math inline">\(N\)</span> (depending upon <span
class="math inline">\(x\)</span>) so that <span
class="math inline">\(S(0) = 0 = N(0)\)</span> and <span
class="math inline">\(s = S(x)\)</span> and <span
class="math inline">\(n = N(x)\)</span> and so that <span
class="math inline">\(S,T\)</span> are both odd (i.e., they are sums of
monomials of odd degree).</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> See for instance p40 of the book by Serre on the
course reference. The final condition is not stated there, but may be
obtained by inspection of the proof. (We note that the “existence” may
be obtained by taking for <span class="math inline">\(s\)</span> the
“diagonal part” and <span class="math inline">\(n\)</span> the
“off-diagonal part” of the Jordan normal form of <span
class="math inline">\(x\)</span>.) ◻</p>
</span></div>
<p>We turn to the proof of Lemma <a
href="#lem:classical-simple-semisimple-iff-ad-semisimple"
data-reference-type="ref"
data-reference="lem:classical-simple-semisimple-iff-ad-semisimple">214</a>
(which wasn’t presented correctly in lecture). Before embarking, we note
that the same conclusion holds for any simple complex Lie algebra but
with a slightly more complicated proof; since we are focusing on the
classical case for now, we will freely make use of the assumption that
<span class="math inline">\(\mathfrak{g}\)</span> is classical. <em>This
proof is not particularly important</em>; I am including it here only
because it is short and suffices for our present focused goal of
classifying <em>classical</em> simple complex Lie algebras. (I’ll also
remark that it may be possible to check it by hand more simply than how
I have argued here.)</p>
<p>We observe first that it is easy to see that any <span
class="math inline">\(x \in \mathfrak{g}\)</span> for which <span
class="math inline">\(x :V \rightarrow V\)</span> is semisimple has the
property that <span class="math inline">\({\mathop{\mathrm{ad}}}_x :
\mathfrak{g} \rightarrow \mathfrak{g}\)</span> is semisimple: we may
assume (by §<a href="#sec:classical-lie-alg-diagonalization"
data-reference-type="ref"
data-reference="sec:classical-lie-alg-diagonalization">29.6</a>)
that <span class="math inline">\(x\)</span> is diagonal, in which case
the required conclusion is clear by the root space decomposition as
computed explicitly in the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>).
It remains to establish the converse.</p>
<p>Let <span class="math inline">\(\sigma\)</span> be the
anti-involution discussed in §<a href="#sec:classical-action"
data-reference-type="ref"
data-reference="sec:classical-action">29.5</a> that
defines <span class="math inline">\(\mathfrak{g}\)</span>. Let <span
class="math inline">\(x \in \mathfrak{g}\)</span> be any element.
Consider its Jordan decomposition <span class="math inline">\(x = s +
n\)</span> in <span
class="math inline">\(\mathop{\mathrm{End}}(V)\)</span>. Write <span
class="math inline">\(s = S(x), n = N(x)\)</span> as above. Since <span
class="math inline">\(S,N\)</span> are odd, we have <span
class="math inline">\(\sigma(S(x)) = S(\sigma(x)) = - S(x)\)</span> and
<span class="math inline">\(\sigma(N(x)) = N(\sigma(x)) = -
N(x)\)</span>, whence <span class="math inline">\(s,n\)</span> also
belong to <span class="math inline">\(\mathfrak{g}\)</span>.</p>
<p>We’ve seen already that as <span class="math inline">\(s\)</span> is
semisimple, so is <span
class="math inline">\({\mathop{\mathrm{ad}}}_s\)</span>. Moreover, since
<span class="math inline">\(n\)</span> is nilpotent, it’s not hard to
see that also <span
class="math inline">\({\mathop{\mathrm{ad}}}_n\)</span> is nilpotent: if
<span class="math inline">\(n^m = 0\)</span> for some <span
class="math inline">\(m \in \mathbb{Z}_{\geq 1}\)</span>, then for any
<span class="math inline">\(y \in \mathfrak{g}\)</span>, we have <span
class="math inline">\({\mathop{\mathrm{ad}}}_n^{2 m}(y) =
[n,[n,\dotsc,[n,y]]] = 0\)</span>, since when we expand out in terms of
monomials, we always have at least <span
class="math inline">\(m\)</span> copies of <span
class="math inline">\(n\)</span> occurring consecutievly.</p>
<p>Finally, since <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span> is a Lie algebra
morphism, we have <span
class="math inline">\([{\mathop{\mathrm{ad}}}_s,{\mathop{\mathrm{ad}}}_n] =
{\mathop{\mathrm{ad}}}_{[s,n]} = {\mathop{\mathrm{ad}}}_0 = 0\)</span>.</p>
<p>In summary, <span class="math inline">\({\mathop{\mathrm{ad}}}_s,
{\mathop{\mathrm{ad}}}_n\)</span> satisfy we see that the decomposition
<span class="math inline">\({\mathop{\mathrm{ad}}}_x =
{\mathop{\mathrm{ad}}}_s + {\mathop{\mathrm{ad}}}_n\)</span> satisfies the
assumptions of Theorem <a href="#thm:jordan-decomp"
data-reference-type="ref"
data-reference="thm:jordan-decomp">215</a>.</p>
<p>Assume finally that <span
class="math inline">\({\mathop{\mathrm{ad}}}_x\)</span> is semisimple.
Then (by the uniqueness assertion of Theorem <a
href="#thm:jordan-decomp" data-reference-type="ref"
data-reference="thm:jordan-decomp">215</a>) we must have <span
class="math inline">\({\mathop{\mathrm{ad}}}_x =
{\mathop{\mathrm{ad}}}_s\)</span> and <span
class="math inline">\({\mathop{\mathrm{ad}}}_n = 0\)</span>; since <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span> is injective, we
must have <span class="math inline">\(n = 0\)</span>; therefore <span
class="math inline">\(x = s\)</span> is semisimple, as required.</p>
<h2 id="sec:orgf4e7f31">§29.8. Conjugacy of Cartan subalgebras</h2>
<p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a classical
simple complex Lie algebra. Here’s the key to showing the independence
of the constructions given above with respect to the choice of <span
class="math inline">\(\mathfrak{h}\)</span>:</p>
<div id="lem:conj-cartan-classical-case" class="lemma">
<p><strong>Lemma 216</strong>. For any two Cartan subalgebras <span
class="math inline">\(\mathfrak{h}, \mathfrak{h} &#39;\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span>, there exists <span
class="math inline">\(g \in G\)</span> so that <span
class="math inline">\(\mathop{\mathrm{Ad}}(g) \mathfrak{h} =
\mathfrak{h} &#39;\)</span>. (Here we can take for <span
class="math inline">\(G\)</span> any Lie group having <span
class="math inline">\(\mathfrak{g}\)</span> as its Lie algebra; the
simply-connected one will do. One could alternatively and more naturally
take for <span class="math inline">\(G\)</span> the <em>inner
automorphism group</em> <span
class="math inline">\(\mathop{\mathrm{Int}}(\mathfrak{g}) := \langle
\exp({\mathop{\mathrm{ad}}}_X) : X \in \mathfrak{g} \rangle \leq
\mathop{\mathrm{Aut}}(\mathfrak{g}) \leq
\mathop{\mathrm{GL}}(\mathfrak{g})\)</span> as defined in lecture.)</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Recall from §<a href="#sec:classical-action"
data-reference-type="ref"
data-reference="sec:classical-action">29.5</a> the
embedding <span class="math inline">\(\mathfrak{g} \hookrightarrow
\mathop{\mathrm{End}}(V)\)</span>. We have seen in §<a
href="#lem:classical-simple-semisimple-iff-ad-semisimple"
data-reference-type="ref"
data-reference="lem:classical-simple-semisimple-iff-ad-semisimple">214</a>
that an element <span class="math inline">\(x \in \mathfrak{g}\)</span>,
regarded as a linear transformation <span class="math inline">\(x : V
\rightarrow V\)</span>, is semisimple if and only if <span
class="math inline">\({\mathop{\mathrm{ad}}}_x : \mathfrak{g} \rightarrow
\mathfrak{g}\)</span> is semisimple.</p>
<p>We turn to the proof. It will suffice to consider the case that <span
class="math inline">\(\mathfrak{h}\)</span> is the standard diagonal
Cartan subalgebra and <span class="math inline">\(\mathfrak{h}
&#39;\)</span> is arbitrary. Since the elements of <span
class="math inline">\(\mathfrak{h} &#39;\)</span> are all commuting and
<span class="math inline">\(\mathop{\mathrm{ad}}\)</span>-semisimple, we
may simultaneously diagonalize their adjoint action as a sum of
eigenspaces, i.e., we may write down a root space decomposition of <span
class="math inline">\(\mathfrak{h} &#39;\)</span>; see §<a
href="#sec:roots-of-abelian-subalgebra" data-reference-type="ref"
data-reference="sec:roots-of-abelian-subalgebra">28.4</a>,
and recall that elements of <span
class="math inline">\(\mathfrak{h}&#39;\)</span> are <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span>-semisimple). Let
<span class="math inline">\(Z \in \mathfrak{h}&#39;\)</span> be any
element with the property that <span class="math inline">\(\alpha
&#39;(Z) \neq 0\)</span> for all roots <span
class="math inline">\(\alpha &#39;\)</span> of <span
class="math inline">\(\mathfrak{h} &#39;\)</span>. (Such an element
exists because each <span class="math inline">\(\alpha &#39;\)</span> is
nonzero, and so its kernel has codimension one, and a finite union of
codimension one subspaces of a vector space over an infinite field is
properly contained in that vector space.) Then the only elements of
<span class="math inline">\(\mathfrak{g}\)</span> that commute with
<span class="math inline">\(Z\)</span> are those in <span
class="math inline">\(\mathfrak{h} &#39;\)</span> (compare with
discussion surrounding <a
href="#eq:eigenspace-decomp-relevant-fro-checking-maximality"
data-reference-type="eqref"
data-reference="eq:eigenspace-decomp-relevant-fro-checking-maximality">\((124)\)</a>).
By §<a href="#sec:classical-lie-alg-diagonalization"
data-reference-type="ref"
data-reference="sec:classical-lie-alg-diagonalization">29.6</a>,
there is an element <span class="math inline">\(g \in G\)</span> (the
simply-connected complex Lie group having Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>) for which <span
class="math inline">\(g Z g^{-1} := \mathop{\mathrm{Ad}}(g) Z \in
\mathfrak{h}\)</span>. Thus every <span class="math inline">\(H \in
\mathfrak{h}\)</span> commutes with <span class="math inline">\(g Z
g^{-1}\)</span>. It follows that <span class="math inline">\(Z\)</span>
commutes with <span class="math inline">\(g^{-1} H g\)</span> for all
<span class="math inline">\(H \in \mathfrak{h}\)</span>. By the property
of <span class="math inline">\(Z\)</span> just mentioned, it follows
that <span class="math inline">\(\mathop{\mathrm{Ad}}(g^{-1})
\mathfrak{h} \subseteq \mathfrak{h} &#39;\)</span>, hence <span
class="math inline">\(\mathfrak{h} \subseteq \mathop{\mathrm{Ad}}(g)
\mathfrak{h} &#39;\)</span>. By the maximality condition in the
definitino of “Cartan subalgebra,” it follows that <span
class="math inline">\(\mathfrak{h} = \mathop{\mathrm{Ad}}(g)
\mathfrak{h} &#39;\)</span>, as required. ◻</p>
</span></div>
<h2 id="sec:org8b90669">§29.9. Interpretation of Cartan matrix in terms of
inner products<span id="sec:cartan-via-inner-products"
label="sec:cartan-via-inner-products"></span></h2>
<p>Let <span class="math inline">\(\mathfrak{g}\)</span> be one of <span
class="math inline">\(A_n, B_n, C_n, D_n\)</span>. We can think of <span
class="math inline">\(\mathfrak{h}^*\)</span> as a subspace of <span
class="math inline">\(\mathbb{C}^n\)</span> by writing each <span
class="math inline">\(\lambda \in \mathfrak{h}^*\)</span> in the form
<span class="math inline">\(\lambda = l_1 \lambda_1 + \dotsb + l_n
\lambda_n\)</span> and associating to <span
class="math inline">\(\lambda\)</span> the element <span
class="math inline">\((l_1,\dotsc,l_n) \in \mathbb{C}^n\)</span>. In the
case <span class="math inline">\(\mathfrak{g} = A_n\)</span>, we have
<span class="math inline">\(\lambda_1 + \dotsb + \lambda_n = 0\)</span>,
so there is some ambiguity in this assignment; we pin it down by
requiring that <span class="math inline">\(l_1 + \dotsb + l_n =
0\)</span>. Using this assignment, we can define an inner product by the
formula <span class="math display">\[(\lambda,\mu) := l_1 m_1 + \dotsb +
l_n m_n \text{ if } \lambda = \sum l_i \lambda_i, \mu = \sum m_j
\lambda_j.\]</span> By inspection of the formulas on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>),
we have <span class="math display">\[\alpha(H_\beta) = 2
\frac{(\alpha,\beta)}{(\beta,\beta)}.\]</span> (We will explain this
properly later; for now, we stick to the narrow goal of classifying the
classical simple complex Lie algebras.) Thus the Cartan matrix can be
described in terms of inner products involving the simple roots.</p>
<h2 id="sec:orgecfb737">§29.10. Independence with respect to the choice of
simple system</h2>
<p>In the context of §<a href="#sec:how-to-classify"
data-reference-type="ref"
data-reference="sec:how-to-classify">29.3</a>, suppose
<span class="math inline">\(S, S&#39; \subseteq R\)</span> are two
simple systems. We want to know that the Cartan matrices <span
class="math inline">\(N, N&#39;\)</span> that they define are equivalent
(i.e., that they coincide after relabeling the indices).</p>
<p>We will do this as follows:</p>
<div id="prop:existence-of-weyl-element-relating-two-simple-systems"
class="proposition">
<p><strong>Proposition 217</strong>. <em>Let <span
class="math inline">\(S, S&#39; \subseteq R\)</span> be simple systems.
There is a linear transformation <span class="math inline">\(w :
\mathfrak{h}^* \rightarrow \mathfrak{h}^*\)</span> that is orthogonal
with respect to the pairing <span class="math inline">\((,)\)</span> on
<span class="math inline">\(\mathfrak{h}^*\)</span> defined in §<a
href="#sec:cartan-via-inner-products" data-reference-type="ref"
data-reference="sec:cartan-via-inner-products">29.9</a>
and for which <span class="math inline">\(w S =
S&#39;\)</span>.</em></p>
</div>
<p>Assuming Proposition <a
href="#prop:existence-of-weyl-element-relating-two-simple-systems"
data-reference-type="ref"
data-reference="prop:existence-of-weyl-element-relating-two-simple-systems">217</a>,
we may complete the proof of Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a> as
follows: We need to check that <span class="math inline">\(N,
N&#39;\)</span> are equivalent. Let <span class="math inline">\(\alpha ,
\beta \in S\)</span>. Then <span class="math display">\[\begin{align}
  \alpha(H_\beta)
  &amp;=
    2 \frac{(\alpha,\beta)}{(\beta,\beta)}
  \\
  &amp;=
    2 \frac{(w \alpha,w \beta)}{(w \beta,w\beta)}
  \\
  &amp;=
    (w \alpha)(H_{w \beta}).
\end{align}\]</span> Since <span class="math inline">\(w
\alpha\)</span> traverses <span class="math inline">\(S&#39;\)</span> as
<span class="math inline">\(\alpha\)</span> traverses <span
class="math inline">\(S\)</span>, we deduce that <span
class="math inline">\(N\)</span> and <span
class="math inline">\(N&#39;\)</span> are equivalent, as required.</p>
<p>To complete the proof of Theorem <a
href="#thm:classify-complex-simple-classical" data-reference-type="ref"
data-reference="thm:classify-complex-simple-classical">206</a>, it
remains only to prove Proposition <a
href="#prop:existence-of-weyl-element-relating-two-simple-systems"
data-reference-type="ref"
data-reference="prop:existence-of-weyl-element-relating-two-simple-systems">217</a>,
i.e., to produce <span class="math inline">\(w\)</span>. We do so as
follows. For each <span class="math inline">\(\alpha \in R\)</span>, let
<span class="math inline">\(s_\alpha : \mathfrak{h}^* \rightarrow
\mathfrak{h}^*\)</span> denote the linear transformation given by <span
class="math display">\[s_\alpha \lambda := \lambda - \langle
\lambda|\alpha \rangle \alpha,\]</span> where <span
class="math display">\[\langle \lambda|\alpha \rangle :=
\lambda(H_\alpha) = 2 \frac{(\lambda,\alpha)}{(\alpha,\alpha)}.\]</span>
Geometrically, <span class="math inline">\(s_\alpha\)</span> is a
reflection with respect to the hyperplane orthogonal to <span
class="math inline">\(\alpha\)</span>. It follows by inspection of the
formulas on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>)
that <span id="eq:root-reflections-preserve-roots" class="math display">\[\label{eq:root-reflections-preserve-roots}\tag{128}
  s_\alpha(R) = R
  \text{ for all } \alpha \in R.\]</span> We will see that this is an
astonishingly powerful condition; we will explain it properly in due
course.</p>
<p>The <span class="math inline">\(s_\alpha\)</span> may be described as
follows, as detailed in lecture:</p>
<ul>
<li><p>If <span class="math inline">\(\alpha = \lambda_j -
\lambda_k\)</span>, then <span class="math inline">\(s_\alpha :
\lambda_j \mapsto \lambda_k, \lambda_k \mapsto \lambda_j\)</span> (with
all other <span class="math inline">\(\lambda_i\)</span> left fixed)
Here and henceforth we assume that <span class="math inline">\(j \neq
k\)</span>.</p></li>
<li><p>If <span class="math inline">\(\alpha = \lambda_j +
\lambda_k\)</span>, then <span class="math inline">\(s_\alpha :
\lambda_j \mapsto - \lambda_k, \lambda_k \mapsto -\lambda_j\)</span>
(with all other <span class="math inline">\(\lambda_i\)</span> left
fixed).</p></li>
<li><p>If <span class="math inline">\(\alpha = \lambda_j\)</span> or
<span class="math inline">\(2 \lambda_j\)</span>, then <span
class="math inline">\(s_\alpha : \lambda_j \mapsto -\lambda_j\)</span>
(with all other <span class="math inline">\(\lambda_i\)</span> left
fixed).</p></li>
</ul>
<div id="defn:weyl-gp-alg" class="definition">
<p><strong>Definition 218</strong>. Let <span
class="math inline">\(W\)</span> be the group generated by the root
reflections <span class="math inline">\(s_\alpha\)</span> for <span
class="math inline">\(\alpha \in R\)</span>; it is called the <em>Weyl
group</em> and is finite, as it is a subgroup of the permutation group
of the spanning set <span class="math inline">\(R\)</span> for <span
class="math inline">\(\mathfrak{h}^*\)</span>. Since it is generated by
reflections, it consists of orthogonal transformations.</p>
</div>
<p>As we explained in lecture, it is described as follows:</p>
<ul>
<li><p><span class="math inline">\(A_n\)</span>: one has <span
class="math inline">\(|W| = n!\)</span>; for each permutation <span
class="math inline">\(j \mapsto j&#39;\)</span> of <span
class="math inline">\((1,2,\dotsc,n)\)</span>, one has the element <span
class="math inline">\(w \in W\)</span> given bye <span
class="math inline">\(\lambda_j \mapsto
\lambda_{j&#39;}\)</span>.</p></li>
<li><p><span class="math inline">\(B_n\)</span>: one has <span
class="math inline">\(|W| = 2^n n!\)</span>; for each permutation <span
class="math inline">\(j \mapsto j&#39;\)</span> of <span
class="math inline">\((1,2,\dotsc,n)\)</span> and collection of signs
<span class="math inline">\(\pm\)</span> (indexed by <span
class="math inline">\(j\)</span>), one has the element <span
class="math inline">\(w \in W\)</span> given by <span
class="math inline">\(\lambda_j \mapsto \pm
\lambda_{j&#39;}\)</span>.</p></li>
<li><p><span class="math inline">\(C_n\)</span>: same description as for
<span class="math inline">\(B_n\)</span>.</p></li>
<li><p><span class="math inline">\(D_n\)</span>: same description as for
<span class="math inline">\(B_n,C_n\)</span>, except require that the
product of all signs be <span class="math inline">\(+1\)</span> (i.e.,
that the number of minus signs be even).</p></li>
</ul>
<p>Now let <span class="math inline">\(S \subseteq R\)</span> be a
simple system. Let <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span> denote the
<span class="math inline">\(\mathbb{R}\)</span>-span of <span
class="math inline">\(R\)</span>, or equivalently, the <span
class="math inline">\(\mathbb{R}\)</span>-span of the elements <span
class="math inline">\(\lambda_1,\dotsc,\lambda_n\)</span>; it is a real
vector space of dimension <span
class="math inline">\(\dim_\mathbb{C}(\mathfrak{h}^*)\)</span>.</p>
<div id="defn:partial-order-induced-by-simple-system"
class="definition">
<p><strong>Definition 219</strong>. An element <span
class="math inline">\(\lambda \in h_\mathbb{R}^*\)</span> is said to be
<em><span class="math inline">\(S\)</span>-nonnegative</em> (or simply
<em>nonnegative</em> when the simple system <span
class="math inline">\(S\)</span> is clear by context), denoted <span
class="math inline">\(\lambda \geq 0\)</span>, if when we write <span
class="math inline">\(\lambda = \sum_{\alpha \in S} c_\alpha
\alpha\)</span> with each <span class="math inline">\(c_\alpha \in
\mathbb{R}\)</span>, then we actually have <span
class="math inline">\(c_\alpha \geq 0\)</span> fro all <span
class="math inline">\(\alpha \in S\)</span>.</p>
<p>Given <span class="math inline">\(\lambda, \mu \in
h_\mathbb{R}^*\)</span>, we say that <span
class="math inline">\(\lambda\)</span> is <em><span
class="math inline">\(S\)</span>-higher than</em> <span
class="math inline">\(\mu\)</span> (or simply <em>higher than <span
class="math inline">\(\mu\)</span></em> when <span
class="math inline">\(S\)</span> is clear), denoted <span
class="math inline">\(\lambda \geq \mu\)</span>, if <span
class="math inline">\(\lambda - \mu\)</span> is nonnegative.</p>
<p>We write <span class="math inline">\(\lambda &gt; \mu\)</span> if
<span class="math inline">\(\lambda \geq \mu\)</span> and <span
class="math inline">\(\lambda \neq \mu\)</span>, etc.</p>
</div>
<div id="rmk-partial-order-but-can-compare-after-refelcting"
class="remark">
<p><strong>Remark 220</strong>. Note that <span
class="math inline">\(\lambda \geq \mu\)</span> defines a <em>partial
order</em> on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span>: there are
plenty of pairs of elements that are incomparable. On the other hand,
for any <span class="math inline">\(\lambda \in
\mathfrak{h}_\mathbb{R}^*\)</span> and <span
class="math inline">\(\alpha \in R\)</span>, the elements <span
class="math inline">\(\lambda\)</span> and <span
class="math inline">\(s_\alpha \lambda\)</span> are always comparable:
one has <span class="math inline">\(\lambda \geq s_\alpha
\lambda\)</span> if and only if <span class="math inline">\(\langle
\lambda|\alpha \rangle \alpha \geq 0\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 221</strong>. <span
class="math inline">\(R^+\)</span> is precisely the set of <span
class="math inline">\(S\)</span>-nonnegative elements of <span
class="math inline">\(R\)</span>.</p>
</div>
<div id="defn:dominant" class="definition">
<p><strong>Definition 222</strong>. An element <span
class="math inline">\(\lambda \in \mathfrak{h}_\mathbb{R}^*\)</span> is
said to be <em><span class="math inline">\(S\)</span>-dominant</em> (or
simply <em>dominant</em>, when the simple system <span
class="math inline">\(S\)</span> is clear by context) provided that any
of the following evidently equivalent conditions are satisfied:</p>
<ol>
<li><p><span class="math inline">\(\lambda(H_\alpha) \geq 0\)</span> for
all <span class="math inline">\(\alpha \in S\)</span>.</p></li>
<li><p><span class="math inline">\((\lambda, \alpha) \geq 0\)</span> for
all <span class="math inline">\(\alpha \in S\)</span>.</p></li>
<li><p><span class="math inline">\((\lambda, \alpha) \geq 0\)</span> for
all <span class="math inline">\(\alpha \in R^+\)</span>.</p></li>
<li><p><span class="math inline">\(\lambda(H_\alpha) \geq 0\)</span> for
all <span class="math inline">\(\alpha \in R^+\)</span>.</p></li>
<li><p><span class="math inline">\((\lambda, \alpha) \leq 0\)</span> for
all <span class="math inline">\(\alpha \in R^-\)</span>.</p></li>
<li><p><span class="math inline">\(\lambda(H_\alpha) \leq 0\)</span> for
all <span class="math inline">\(\alpha \in R^-\)</span>.</p></li>
<li><p><span class="math inline">\(\lambda \geq s_\alpha
\lambda\)</span> for all <span class="math inline">\(\alpha \in
S\)</span>.</p></li>
<li><p><span class="math inline">\(\lambda \geq s_\alpha
\lambda\)</span> for all <span class="math inline">\(\alpha \in
R\)</span>.</p></li>
</ol>
<p>[The following equivalences are clear: <span
class="math inline">\((1) \iff (2), (3) \iff (4), (5) \iff (6)\)</span>.
We have <span class="math inline">\((2) \iff (3) \iff (5)\)</span> by
linearity of the inner product. We have <span class="math inline">\((1)
\iff (7)\)</span> and <span class="math inline">\((4),(6) \iff
(7)\)</span> by definition of <span
class="math inline">\(s_\alpha\)</span> and the partial relation “<span
class="math inline">\(\geq\)</span>.”]</p>
</div>
<div class="definition">
<p><strong>Definition 223</strong>. An element <span
class="math inline">\(\lambda \in \mathfrak{h}^*_\mathbb{R}\)</span> is
<em>regular</em> if <span class="math inline">\((\lambda,\alpha) \neq
0\)</span> for all <span class="math inline">\(\alpha \in
R\)</span>.</p>
</div>
<p>It is easy to see that regular dominant elements exist: they are just
those elements belonging to a suitable “upper-right quadrant” (TODO:
explain better).</p>
<div class="example">
<p><strong>Example 224</strong>. Supopse <span
class="math inline">\(S\)</span> is the “standard” simple system
described on the handout (§<a
href="#sec:dynkin-diagrams-classical-examples" data-reference-type="ref"
data-reference="sec:dynkin-diagrams-classical-examples">29.4</a>).
Then it’s easy to see that the elements <span
class="math inline">\(\lambda = \sum l_i \lambda_i \in
\mathfrak{h}^*_\mathbb{R}\)</span> that are <span
class="math inline">\(S\)</span>-dominant are precisely those satisfying
the following conditions in the respective cases:</p>
<ol>
<li><p><span class="math inline">\(l_1 \geq l_2 \geq l_3 \geq \dotsb
\geq l_{n-1} \geq l_n\)</span></p></li>
<li><p><span class="math inline">\(l_1 \geq l_2 \geq l_3 \geq \dotsb
\geq l_{n-1} \geq l_n \geq 0\)</span></p></li>
<li><p><span class="math inline">\(l_1 \geq l_2 \geq l_3 \geq \dotsb
\geq l_{n-1} \geq l_n \geq 0\)</span></p></li>
<li><p><span class="math inline">\(l_1 \geq l_2 \geq l_3 \geq \dotsb
\geq l_{n-1} \geq |l_n|\)</span></p></li>
</ol>
<p>The regular dominant elements are those for which every “<span
class="math inline">\(\geq\)</span>” is actually a strict inequality
“<span class="math inline">\(&gt;\)</span>.”</p>
</div>
<div id="lem:recover-S-from-dominant-element" class="lemma">
<p><strong>Lemma 225</strong>. Let <span
class="math inline">\(S\)</span> be a simple system with associated set
<span class="math inline">\(R^+\)</span> of positive roots. Let <span
class="math inline">\(\lambda\)</span> be regular and <span
class="math inline">\(S\)</span>-dominant. Then <span
class="math inline">\(R^+ = \{\alpha \in R : (\alpha,\lambda) &gt;
0\}\)</span>. Moreover, <span class="math inline">\(S\)</span> is the
set of elements <span class="math inline">\(\alpha \in R^+\)</span> that
are <em>indecomposable</em> in the sense that one cannot write <span
class="math inline">\(\alpha = \beta_1 + \dotsb + \beta_k\)</span> for
some <span class="math inline">\(\beta_1,\dotsc,\beta_k \in R^+\)</span>
with <span class="math inline">\(k \geq 2\)</span>.</p>
<p>In particular, <span class="math inline">\(S\)</span> is determined
by any regular <span class="math inline">\(S\)</span>-dominant element
<span class="math inline">\(\lambda\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The first assertion is clear: if <span
class="math inline">\(\alpha \in R\)</span> satisfies <span
class="math inline">\((\alpha,\lambda) &gt; 0\)</span>, then in the
decomposition <span class="math inline">\(\alpha = \sum_{\beta \in S}
c_\beta \beta\)</span> (where the <span
class="math inline">\(c_\beta\)</span> are integers all of the same
sign, and <span class="math inline">\((\beta,\lambda) &gt; 0\)</span>)
we deduce that each <span class="math inline">\(c_\beta \geq 0\)</span>,
etc. The second assertion follows immediately from the definition of
“simple system.” ◻</p>
</span></div>
<p>We can now prove Proposition <a
href="#prop:existence-of-weyl-element-relating-two-simple-systems"
data-reference-type="ref"
data-reference="prop:existence-of-weyl-element-relating-two-simple-systems">217</a>.
Let <span class="math inline">\(S_0, S_1\)</span> be two simple systems;
we want to show that there is <span class="math inline">\(w \in
W\)</span> so that <span class="math inline">\(w S_1 = S_0\)</span>. Let
<span class="math inline">\(\lambda\)</span> be regular and <span
class="math inline">\(S_1\)</span>-dominant. Choose <span
class="math inline">\(w \in W\)</span> so that <span
class="math inline">\(w \lambda\)</span> is <em>maximal</em> with
respect to the partial order given by Definition <a
href="#defn:partial-order-induced-by-simple-system"
data-reference-type="ref"
data-reference="defn:partial-order-induced-by-simple-system">219</a>
<em>with respect to the simple system <span
class="math inline">\(S_0\)</span></em>. Thus, in paricular, <span
class="math inline">\(s_\alpha w \lambda \leq w \lambda\)</span> for all
<span class="math inline">\(\alpha \in R\)</span> (cf. Remark <a
href="#rmk-partial-order-but-can-compare-after-refelcting"
data-reference-type="ref"
data-reference="rmk-partial-order-but-can-compare-after-refelcting">220</a>).
Actually, we must have <span class="math inline">\(s_\alpha w \lambda
&lt; w \lambda\)</span>: for if instead we had <span
class="math inline">\(s_\alpha w \lambda = w \lambda\)</span>, then we’d
have <span class="math inline">\(\lambda = w^{-1} s_\alpha w \lambda =
s_{w^{-1} \alpha} \lambda\)</span> and so <span
class="math inline">\((w^{-1} \alpha, \lambda) = 0\)</span>, contrary to
the assumption that <span class="math inline">\(\lambda\)</span> is
regular. It follows from the equivalence of the various conditions in
Definition <a href="#defn:dominant" data-reference-type="ref"
data-reference="defn:dominant">222</a> that <span
class="math inline">\(w \lambda\)</span> is <span
class="math inline">\(S_0\)</span>-dominant.</p>
<p>In summary, <span class="math inline">\(\lambda\)</span> is <span
class="math inline">\(S_1\)</span>-dominant and <span
class="math inline">\(w \lambda\)</span> is <span
class="math inline">\(S_0\)</span>-dominant. Using Lemma <a
href="#lem:recover-S-from-dominant-element" data-reference-type="ref"
data-reference="lem:recover-S-from-dominant-element">225</a>, it follows
easily that <span class="math inline">\(w S_1 = S_0\)</span>, as
required. TODO: explain more.</p>
<p>We record a few other facts of independent interest. (Most of these
assertions can be deduced by inspection for the “standard” simple system
and then deduced for general simple systems from the fact that the Weyl
group acts transitively on them; there are also more natural but
lengthier proofs that apply more generally.)</p>
<ol>
<li><p>Let <span class="math inline">\(S\)</span> be a simple system.
Then the Weyl group is generated by the root reflections <span
class="math inline">\(s_\alpha\)</span>, <span
class="math inline">\(\alpha \in S\)</span>.</p></li>
<li><p>A <em>Weyl chamber</em> is a connected component <span
class="math inline">\(C\)</span> of the set <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{reg}}} :=
\{\lambda \in \mathfrak{h}_\mathbb{R}: (\alpha, \lambda ) \neq 0 \text{
for all } \alpha \in R\}\)</span> of regular elements. The set of simple
systems <span class="math inline">\(S\)</span> is in natural (<span
class="math inline">\(W\)</span>-equivariant) bijection with the set of
Weyl chambers:</p>
<ol>
<li><p>Given <span class="math inline">\(S\)</span>, one takes for <span
class="math inline">\(C\)</span> the set <span class="math inline">\(C
:= \{\lambda \in \mathfrak{h}_\mathbb{R} : (\alpha,\lambda) &gt; 0
\text{ for all } \alpha \in S\}\)</span> of regular <span
class="math inline">\(S\)</span>-dominant elements; that set is called
(naturally) the <em><span class="math inline">\(S\)</span>-dominant Weyl
chamber</em>. (The <span class="math inline">\(S\)</span>-dominant Weyl
chamber is, of course, a Weyl chamber: it is connected, or even
path-connected by straight line segments; it is also maximal among
connceted subsets, by (say) the intermediate value theorem.)</p></li>
<li><p>Given <span class="math inline">\(C\)</span>, one takes for <span
class="math inline">\(S\)</span> the set of indecomposable elements in
<span class="math inline">\(R^+ := \{\alpha \in R : (\alpha,\lambda)
&gt; 0 \}\)</span>.</p></li>
</ol></li>
<li><p>The Weyl group acts <em>simply transitively</em> on the set of
Weyl chambers, for each pair <span class="math inline">\(S,
S&#39;\)</span> of simple systems there exists a unique <span
class="math inline">\(w \in W\)</span> for which <span
class="math inline">\(w S = S&#39;\)</span>. In particular, if <span
class="math inline">\(w \in W\)</span> satisfies <span
class="math inline">\(w S = S\)</span> for some simple system <span
class="math inline">\(S\)</span>, then <span class="math inline">\(w =
1\)</span>. (This follows from the argument given above, together with
the empirical observation that the only <span class="math inline">\(w
\in W\)</span> which stabilizes the “standard” Weyl chamber is <span
class="math inline">\(w = 1\)</span>.)</p></li>
<li><p>The Weyl group acts <em>simply transitively</em> on the set of
simple systems, for each pair <span class="math inline">\(S,
S&#39;\)</span> of simple systems there exists a unique <span
class="math inline">\(w \in W\)</span> for which <span
class="math inline">\(w S = S&#39;\)</span>. In particular, if <span
class="math inline">\(w \in W\)</span> satisfies <span
class="math inline">\(w S = S\)</span> for some simple system <span
class="math inline">\(S\)</span>, then <span class="math inline">\(w =
1\)</span>. This follows from the previous few points.</p></li>
<li><p>Let <span class="math inline">\(S\)</span> be a simple system.
For each <span class="math inline">\(\lambda \in
\mathfrak{h}_\mathbb{R}^*\)</span> there exists a <em>unique</em> <span
class="math inline">\(w \in W\)</span> so that <span
class="math inline">\(w \lambda\)</span> is <span
class="math inline">\(S\)</span>-dominant.</p></li>
</ol>
<p>In lecture, we presented (some of) the above material in a slightly
different order; namely, we first stated the bijection between simple
systems and Weyl chambers (after working out enough examples to make it
seem obvious).</p>
<h1 id="sec:orgbc4b3b3">§30. Why simple Lie algebras give rise to root
systems</h1>
<h2 id="sec:orgca704ad">§30.1. Overview<span
id="sec:overview:simple-lie-alg-induce-root-systems"
label="sec:overview:simple-lie-alg-induce-root-systems"></span></h2>
<p>In the previous section, we explained how Dynkin diagrams may be used
to classify the classical complex simple Lie algebras <span
class="math inline">\(A_n,B_n,C_n,D_n\)</span>. That explanation
involved a fair number of “empirical observations:”</p>
<ol>
<li><p>We observed (without “explanation”) that Cartan subalgebras <span
class="math inline">\(\mathfrak{h}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> exist and are
unique.</p></li>
<li><p>We observed that the root spaces <span
class="math inline">\(\mathfrak{g}^\alpha\)</span> of <span
class="math inline">\(\mathfrak{h}\)</span> are one-dimensional and
satisfy <span class="math display">\[\alpha \in R \implies \{n \in
\mathbb{Z} : n \alpha \in R\} = \{\pm 1\}.\]</span> We observed also
that there exist <span class="math inline">\(X_\alpha \in
\mathfrak{g}^\alpha, Y_\alpha \in \mathfrak{g}^{-\alpha}\)</span> and
<span class="math inline">\(H_\alpha \in \mathfrak{h}\)</span> so that
<span class="math display">\[= H_\alpha\]</span> and <span
class="math display">\[\alpha(H_\alpha) = 2\]</span> and <span
class="math display">\[=
\begin{cases}
      \mathfrak{g}^{\alpha+\beta} &amp; \alpha + \beta \in R \\
      \mathbb{C} H_\alpha  &amp; \alpha + \beta = 0 \\
      0 &amp; \text{otherwise.}
    \end{cases}\]</span></p></li>
<li><p>We observed the relation <span class="math display">\[\langle
\beta | \alpha \rangle := \beta(H_\alpha) = 2
\frac{(\beta,\alpha)}{(\alpha,\alpha)}\]</span> for any <span
class="math inline">\(\alpha, \beta \in R\)</span>.</p></li>
<li><p>We observed that the root reflections <span
class="math inline">\(s_\alpha : \mathfrak{h}^* \rightarrow
\mathfrak{h}^*\)</span> defined for <span class="math inline">\(\alpha
\in R\)</span> by <span class="math display">\[s_\alpha (\beta) := \beta
- \langle \beta|\alpha \rangle \alpha,\]</span> satisfy <span
class="math inline">\(s_\alpha(R) = R\)</span>.</p></li>
</ol>
<p>We would like now to go back and “explain” the above observations a
bit more “conceptually.” This will involve an application of some
properties of representations of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
that we established long ago.</p>
<p>For the remainder of this section, “Lie algebra” always means “over
the complex numbers.”</p>
<h2 id="sec:org60618cb">§30.2. The basic theorem on Cartan subalgebras</h2>
<p>Recall Definition <a
href="#defn:cartan-subalgebra-of-simple-lie-algebra"
data-reference-type="ref"
data-reference="defn:cartan-subalgebra-of-simple-lie-algebra">210</a>;
it applies to any simple Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>.</p>
<div id="thm:cartan-subalgebras" class="theorem">
<p><strong>Theorem 226</strong>. <em></em></p>
<ol>
<li><p><em>There exists a Cartan subalgebra <span
class="math inline">\(\mathfrak{h} \leq
\mathfrak{g}\)</span>.</em></p></li>
<li><p><em>Any two Cartan subalgebras <span
class="math inline">\(\mathfrak{h}, \mathfrak{h} &#39;\)</span> are
conjugate in the sense that for any Lie group <span
class="math inline">\(G\)</span> with <span
class="math inline">\(\mathop{\mathrm{Lie}}(G) = \mathfrak{g}\)</span>
(such as the inner automorphism group <span class="math inline">\(G =
\mathop{\mathrm{Int}}(\mathfrak{g})\)</span> as defined in Lemma <a
href="#lem:conj-cartan-classical-case" data-reference-type="ref"
data-reference="lem:conj-cartan-classical-case">216</a>), there exists
<span class="math inline">\(g \in G\)</span> so that <span
class="math inline">\(\mathop{\mathrm{Ad}}(g) \mathfrak{h} &#39; =
\mathfrak{h}\)</span>.</em></p></li>
<li><p><em>There is a scalar product <span
class="math inline">\((,)\)</span> on <span
class="math inline">\(\mathfrak{g}\)</span> (i.e., a non-degenerate
symmetric bilinear form <span class="math inline">\(\mathfrak{g} \otimes
\mathfrak{g} \rightarrow \mathbb{C}\)</span>) and a real form <span
class="math inline">\(\mathfrak{h}_\mathbb{R} \leq \mathfrak{h}\)</span>
with the following properties:</em></p>
<ol>
<li><p><em>The roots <span class="math inline">\(\alpha\)</span> of
<span class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{h}
\rightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span> satisfy <span
class="math inline">\(\alpha(\mathfrak{h}_\mathbb{R}) \subseteq
\mathbb{R}\)</span>.</em></p></li>
<li><p><em>The restriction of <span class="math inline">\((,)\)</span>
to <span class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span> is
real-valued and positive-definite.</em></p></li>
<li><p><em><span class="math inline">\((,)\)</span> is <span
class="math inline">\(\mathfrak{g}\)</span>-invariant, i.e., for all
<span class="math inline">\(x,y,z \in \mathfrak{g}\)</span>, <span
class="math display">\[([z,x],y) + (x,[z,y]) = 0.\]</span> (Think of
this condition as the “<span class="math inline">\(t = 0\)</span>
derivative” of a condition like <span class="math inline">\((e^{t z} x,
e^{t z} y) = (x,y)\)</span>.)</em></p></li>
</ol></li>
</ol>
</div>
<div class="example">
<p><strong>Example 227</strong>. </p>
<ol>
<li><p>One can take <span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>, <span
class="math inline">\(\mathfrak{h} \leq \mathfrak{g}\)</span> the
diagonal subalgebra, <span class="math inline">\(\mathfrak{h}_\mathbb{R}
\leq \mathfrak{h}\)</span> the real Lie subalgebra consisting of
elements with real entries, and <span class="math inline">\((x,y) :=
\mathop{\mathrm{trace}}(x y)\)</span> for <span
class="math inline">\(x,y \in \mathfrak{g}\)</span>. Similar choices
apply for all of the classical simple algebras.</p></li>
<li><p>For any simple <span class="math inline">\(\mathfrak{g}\)</span>,
it turns out that one can take <span class="math inline">\((x,y) :=
\mathop{\mathrm{trace}}({\mathop{\mathrm{ad}}}_x
{\mathop{\mathrm{ad}}}_y)\)</span> (which is called the <em>Killing
form</em>).</p></li>
</ol>
</div>
<p>As noted earlier, Theorem <a href="#thm:cartan-subalgebras"
data-reference-type="ref"
data-reference="thm:cartan-subalgebras">226</a> is easy to establish for
the classical simple algebras. We will not prove it in general for the
following reasons:</p>
<ol>
<li><p>The proof might take a couple weeks, and I think that it is not
as interesting or useful as the other topics that I plan to cover in the
remaining time.</p></li>
<li><p>The conclusion is not difficult in the primary examples of
interest (the classical families). We may thus interpret it as telling
us that we might as well have <em>defined</em> a simple Lie algebra to
be a simple Lie algebra in the ordinary sense with the additional
property that it possesses a Cartan subalgebra satisfying the above
properties; such a definition would apply to the primary examples of
interest, and the above theorem may be interpreted as giving a weaker
condition under which it holds.</p></li>
</ol>
<p>A good reference for the proof of Theorem <a
href="#thm:cartan-subalgebras" data-reference-type="ref"
data-reference="thm:cartan-subalgebras">226</a> is Chapter 3 of Serre’s
<em>Complex semisimple Lie algebras</em>.</p>
<p>In the following sections, we will include in some hypotheses phrases
like “Let <span class="math inline">\(\mathfrak{g}\)</span> be a simple
Lie algebra (that satisfies the Cartan subalgebra theorem).” Theorem <a
href="#thm:cartan-subalgebras" data-reference-type="ref"
data-reference="thm:cartan-subalgebras">226</a> says that the
parenthetical hypothesis is unnecessary; we include it only to keep
track of what we have actually proven in the course.</p>
<h2 id="sec:orgc2613cc">§30.3. Abstract root systems</h2>
<div id="defn:abstract-root-system" class="definition">
<p><strong>Definition 228</strong>. Let <span
class="math inline">\(V\)</span> be a finite-dimensional real inner
product space. A <em>root system</em> is a subset <span
class="math inline">\(R\)</span> of <span
class="math inline">\(V\)</span> such that</p>
<ol>
<li><p><span class="math inline">\(R\)</span> is finite;</p></li>
<li><p><span class="math inline">\(R\)</span> does not contain <span
class="math inline">\(0\)</span>;</p></li>
<li><p>for any <span class="math inline">\(\alpha,\beta \in R\)</span>,
the quantity <span class="math display">\[\langle \beta|\alpha \rangle
:= 2\frac{(\beta,\alpha)}{(\alpha,\alpha)}\]</span> is an
integer;</p></li>
<li><p>for any <span class="math inline">\(\alpha \in R\)</span>, the
map <span class="math display">\[s_\alpha : V \rightarrow V\]</span>
<span class="math display">\[s_\alpha(\lambda) := \lambda - \langle
\lambda | \alpha \rangle \alpha\]</span> satisfies <span
class="math inline">\(s_\alpha(R) = R\)</span>.</p></li>
</ol>
<p>We say that <span class="math inline">\(R\)</span> is
<em>reduced</em> if for all <span class="math inline">\(\alpha \in
R\)</span>, <span id="eq:reduced-axiom-1" class="math display">\[\label{eq:reduced-axiom-1}\tag{129}
    \{n \in \mathbb{R} : n \alpha \in R\} = \{\pm 1\}.\]</span> The
notion of an <em>isomorphism of root systems</em> is clear.<a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
</div>
<p>In §<a href="#sec:classify-classical-simple-algebras"
data-reference-type="ref"
data-reference="sec:classify-classical-simple-algebras">29</a>,
we saw several examples of root systems (without referring to them by
that name).</p>
<div id="ex:disj-union-root-systems" class="example">
<p><strong>Example 229</strong>. Let <span class="math inline">\(R_1
\subseteq V_1, R_2 \subseteq V_2\)</span> be two root systems. We may
regard <span class="math inline">\(V_1, V_2\)</span> as being embedded
in the direct sum inner product space <span class="math inline">\(V :=
V_1 \oplus V_2\)</span> by the maps <span class="math inline">\(v_1
\mapsto (v_1,0)\)</span>, <span class="math inline">\(v_2 \mapsto
(0,v_2)\)</span>. We may then define their <em>disjoint union</em> <span
class="math inline">\(R_1 \cup R_2 \subset V\)</span> to be the set of
images of <span class="math inline">\(R_1,R_2\)</span> under such maps.
It is easily seen to define a root system.</p>
</div>
<div class="definition">
<p><strong>Definition 230</strong>. A root system <span
class="math inline">\(R\)</span> is <em>irreducible</em> if it is not
isomorphic to a disjoint union of nonempty root systems.</p>
</div>
<h2 id="sec:org44a29a8">§30.4. Illustration of the root system axioms</h2>
<p>The root system axioms have a number of consequences; we illustrate a
few of them here, referring to the second reference by Serre on the
course homepage for details and further discussion.</p>
<p>As illustration, let us first verify that the axiom <a
href="#eq:reduced-axiom-1" data-reference-type="eqref"
data-reference="eq:reduced-axiom-1">\((129)\)</a> can be
weakened (assuming the other axioms) to <span id="eq:reduced-axiom-2" class="math display">\[\label{eq:reduced-axiom-2}\tag{130}
  \alpha \in R \implies 2 \alpha \notin R.\]</span> To that end, suppose
<span class="math inline">\(\alpha, c \alpha \in R\)</span> for some
nonzero scalar <span class="math inline">\(c \in \mathbb{R}\)</span>.
Then the quantities <span class="math display">\[\langle c \alpha |
\alpha \rangle = 2 c, \quad \langle \alpha | c \alpha \rangle = 2
c^{-1}\]</span> are both integers, hence <span id="eqn:limited-possibilities-for-c-in-root-system" class="math display">\[\label{eqn:limited-possibilities-for-c-in-root-system}\tag{131}
  c \in \{\pm 1/2, \pm 1, \pm 2\}.\]</span> It is clear that <a
href="#eq:reduced-axiom-2" data-reference-type="eqref"
data-reference="eq:reduced-axiom-2">\((130)\)</a> and <a
href="#eqn:limited-possibilities-for-c-in-root-system"
data-reference-type="eqref"
data-reference="eqn:limited-possibilities-for-c-in-root-system">\((131)\)</a>
imply <a href="#eq:reduced-axiom-1" data-reference-type="eqref"
data-reference="eq:reduced-axiom-1">\((129)\)</a>.</p>
<p>As our next illustration:</p>
<div id="lem:possibilities-for-inner-products-roots" class="lemma">
<p><strong>Lemma 231</strong>. Let <span
class="math inline">\(\alpha,\beta\)</span> be non-proportional roots
(i.e., elements of the given root system <span
class="math inline">\(R\)</span> that are not multiples of one another).
Then the unordered pair of integers <span
class="math inline">\(\{\langle \alpha|\beta \rangle, \langle
\beta|\alpha \rangle\}\)</span> is of the form <span
class="math inline">\(\{0,0\}\)</span> or <span
class="math inline">\(\{\varepsilon, \varepsilon n\}\)</span> for some
<span class="math inline">\(\varepsilon\in \{\pm 1\}\)</span> and <span
class="math inline">\(n \in \{1,2,3\}\)</span>; in other words, it
belongs to the following list:</p>
<ul>
<li><p><span class="math inline">\(\{0,0\}\)</span></p></li>
<li><p><span class="math inline">\(\{1,1\}\)</span></p></li>
<li><p><span class="math inline">\(\{1,2\}\)</span></p></li>
<li><p><span class="math inline">\(\{1,3\}\)</span></p></li>
<li><p><span class="math inline">\(\{-1,-1\}\)</span></p></li>
<li><p><span class="math inline">\(\{-1,-2\}\)</span></p></li>
<li><p><span class="math inline">\(\{-1,-3\}\)</span></p></li>
</ul>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By elementary geometry, we have <span
class="math inline">\(\langle \alpha |\beta \rangle \langle \beta |
\alpha \rangle = 4 \cos^2(\phi)\)</span>, where <span
class="math inline">\(\pm \phi\)</span> denotes the angle between the
vectors <span class="math inline">\(\alpha,\beta\)</span>. Since <span
class="math inline">\(\alpha,\beta\)</span> are non-proportional, we
have <span class="math inline">\(\cos^2(\phi) &lt; 1\)</span>. If <span
class="math inline">\(\cos(\phi) = 0\)</span>, then <span
class="math inline">\(\alpha,\beta\)</span> are orthogonal and so both
quantities are zero. Otherwise <span class="math inline">\(\langle
\alpha|\beta \rangle\)</span> and <span class="math inline">\(\langle
\beta|\alpha \rangle\)</span> are integers whose product belongs to
<span class="math inline">\(\{1,2,3\}\)</span>, for which the only
possibilities are those listed. ◻</p>
</span></div>
<div id="lem:inner-products-between-roots-predict-other-roots"
class="lemma">
<p><strong>Lemma 232</strong>. Suppose that <span
class="math inline">\(\alpha,\beta\)</span> are non-proportional
roots.</p>
<ul>
<li><p>If <span class="math inline">\((\alpha,\beta) &lt; 0\)</span>,
then <span class="math inline">\(\alpha + \beta\)</span> is a
root.</p></li>
<li><p>If <span class="math inline">\((\alpha,\beta) &gt; 0\)</span>,
then <span class="math inline">\(\alpha - \beta\)</span> is a
root.</p></li>
</ul>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> In the first case, we see from Lemma <a
href="#lem:possibilities-for-inner-products-roots"
data-reference-type="ref"
data-reference="lem:possibilities-for-inner-products-roots">231</a> that
after possibly swapping <span class="math inline">\(\alpha\)</span> and
<span class="math inline">\(\beta\)</span>, we have <span
class="math inline">\(\langle \beta |\alpha \rangle = -1\)</span> (and
<span class="math inline">\(\langle \alpha | \beta \rangle = -
n\)</span> for some <span class="math inline">\(n \in
\{1,2,3\}\)</span>). Then <span class="math inline">\(s_\alpha(\beta) =
\beta - \left\langle \beta | \alpha \right\rangle \alpha = \beta +
\alpha\)</span> is a root thanks to the axiom <span
class="math inline">\(s_\alpha(R) = R\)</span>. A similar argument
applies in the second case. ◻</p>
</span></div>
<p>We may define a <em>base</em> (or <em>simple system</em>) exactly as
before to be a subset <span class="math inline">\(S\)</span> of <span
class="math inline">\(R\)</span> that is a basis for the underlying
inner product space <span class="math inline">\(V\)</span> with the
property that for each <span class="math inline">\(\alpha \in
R\)</span>, the coefficients <span
class="math inline">\(c_\beta\)</span> in the expansion <span
class="math inline">\(\alpha = \sum_{\beta \in S} c_\beta \beta\)</span>
either all belong to <span class="math inline">\(\mathbb{Z}_{\geq
0}\)</span> or all belong to <span
class="math inline">\(\mathbb{Z}_{\leq 0}\)</span>. One can show
directly from the root system axioms that bases exist and have the
properties established previously for the classical families and on the
homeworks; see the second reference by Serre on the course webpage for
more details. We note for now just that the observation from the
homework that <span class="math inline">\((\alpha,\beta) \leq 0\)</span>
for <span class="math inline">\(\alpha,\beta \in S\)</span> follows from
Lemma <a href="#lem:inner-products-between-roots-predict-other-roots"
data-reference-type="ref"
data-reference="lem:inner-products-between-roots-predict-other-roots">232</a>:
if otherwise <span class="math inline">\((\alpha,\beta) &gt; 0\)</span>,
then <span class="math inline">\(\alpha - \beta\)</span> would be a
root, contrary to the defining property of the simple system <span
class="math inline">\(S\)</span>.</p>
<p>One can likewise define the Weyl group <span
class="math inline">\(W\)</span> of a root system to be the subgroup of
the orthogonal group of <span class="math inline">\(V\)</span> generated
by the root reflections <span class="math inline">\(s_\alpha\)</span>;
the properties we established previously for the root systems arising
from classical families can also be established directly from the root
system axioms (see Serre for details).</p>
<p>Finally, one can attach to each reduced root system a Cartan matrix
and a Dynkin diagram; the diagram turns out to be connected if and only
if the root system is irreducible, and one can show (by elaborate
application of the root system axioms) that all irreducible reduced root
systems belong either to the classical families <span
class="math inline">\(A_n, B_n, C_n, D_n\)</span> or belong to an
exceptional set <span
class="math inline">\(\{G_2,F_2,E_6,E_7,E_8\}\)</span>.</p>
<h2 id="sec:orgfacc967">§30.5. Simple Lie algebras give rise to root
systems<span id="sec:simple-lie-alg-give-roots"
label="sec:simple-lie-alg-give-roots"></span></h2>
<p>The “unexplained observations” recorded in §<a
href="#sec:overview:simple-lie-alg-induce-root-systems"
data-reference-type="ref"
data-reference="sec:overview:simple-lie-alg-induce-root-systems">30.1</a>
are all contained in the following result, which is our next target:</p>
<div id="thm:main-theorem-on-roots-of-simple-algebras" class="theorem">
<p><strong>Theorem 233</strong>. <em>Let <span
class="math inline">\(\mathfrak{g}\)</span> be a simple Lie algebra
(that satisfies the Cartan subalgebra theorem). Let <span
class="math inline">\(\mathfrak{h}\)</span> be a Cartan subalgebra. Let
<span class="math inline">\(R \subseteq
\mathfrak{h}_\mathbb{R}^*\)</span> be the set of roots for <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{h} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span>. Then <span
class="math inline">\(R\)</span> is a reduced root system.
Moreover:</em></p>
<ol>
<li><p><em>For each <span class="math inline">\(\alpha \in R\)</span>,
one has <span class="math inline">\(\dim \mathfrak{g}^\alpha =
1\)</span>.</em></p></li>
<li><p><em>For each <span class="math inline">\(\alpha \in R\)</span>
there is a unique <span class="math inline">\(H_\alpha \in
\mathfrak{h}_\mathbb{R}\)</span> with <span
class="math inline">\(\alpha(H_\alpha) = 2\)</span> so that for each
nonzero <span class="math inline">\(X_\alpha \in
\mathfrak{g}^\alpha\)</span> there is a unique <span
class="math inline">\(Y_\alpha \in \mathfrak{g}^{-\alpha}\)</span> so
that <span class="math inline">\(H_\alpha =
[X_\alpha,Y_\alpha]\)</span>.</em></p></li>
<li><p><em>One has <span class="math display">\[=
\begin{cases}
        \mathfrak{g}^{\alpha+\beta} &amp; \alpha + \beta \in R \\
        \mathbb{C} H_\alpha  &amp; \alpha + \beta = 0 \\
        0 &amp; \text{otherwise.}
      \end{cases}\]</span></em></p></li>
</ol>
</div>
<div class="remark">
<p><strong>Remark 234</strong>. We will discuss the proof of Theorem <a
href="#thm:main-theorem-on-roots-of-simple-algebras"
data-reference-type="ref"
data-reference="thm:main-theorem-on-roots-of-simple-algebras">233</a> in
detail for the following reasons:</p>
<ol>
<li><p>Although the proof gives us nothing “new” for the classical
families (we have already checked all of the conclusions by hand), it
tells us <em>why</em> they are true, gives a less computational
explanation, etc.</p></li>
<li><p>The techniques involved in the proof of Theorem <a
href="#thm:main-theorem-on-roots-of-simple-algebras"
data-reference-type="ref"
data-reference="thm:main-theorem-on-roots-of-simple-algebras">233</a>
are of general use.</p></li>
<li><p>The proof of Theorem <a
href="#thm:main-theorem-on-roots-of-simple-algebras"
data-reference-type="ref"
data-reference="thm:main-theorem-on-roots-of-simple-algebras">233</a>
will give us the opportunity to apply some properties of representations
of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
that we established earlier in the course.</p></li>
</ol>
</div>
<div class="remark">
<p><strong>Remark 235</strong>. One can also establish the following
complements to Theorem <a
href="#thm:main-theorem-on-roots-of-simple-algebras"
data-reference-type="ref"
data-reference="thm:main-theorem-on-roots-of-simple-algebras">233</a></p>
<ol>
<li><p>The root systems arising from simple Lie algebras are
irreducible.</p></li>
<li><p>Two simple Lie algebras are isomorphic if and only if their
associated root systems are isomorphic.</p></li>
<li><p>Every irreducible reduced root system arises from a (unique)
simple Lie algebra.</p></li>
</ol>
<p>We might discuss the first couple of these if we have time; see the
second reference by Serre on the course homepage for further discussion
of the final point.</p>
</div>
<h2 id="sec:org3ce571d">§30.6. Some stuff about scalar products and inner
products<span id="sec:some-stuff-about-scalar-products"
label="sec:some-stuff-about-scalar-products"></span></h2>
<p>Let <span class="math inline">\(\mathfrak{g}\)</span> be a simple Lie
algebra (that satisfies the Cartan subalgebra theorem). Let <span
class="math inline">\(\mathfrak{h}\)</span> be a Cartan subalgebra, and
let <span class="math inline">\((,)\)</span> be an invariant scalar
product on <span class="math inline">\(\mathfrak{g}\)</span> that is
real-valued and positive-definite on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span>. Since <span
class="math inline">\((,)\)</span> is nondegenerate, it induces a linear
isomorphism <span class="math inline">\(\mathfrak{g} \rightarrow
\mathfrak{g}^*\)</span> given by <span class="math inline">\(x \mapsto
(x,\cdot)\)</span>. We can thus transfer <span
class="math inline">\((,)\)</span> to an scalar product (also denoted
<span class="math inline">\((,)\)</span>) on <span
class="math inline">\(\mathfrak{g}^*\)</span> by requiring that <span
class="math inline">\(((x,\cdot),(y,\cdot)) = (x,y)\)</span> for all
<span class="math inline">\(x,y \in \mathfrak{g}\)</span>. We may
restrict the scalar product <span class="math inline">\((,)\)</span> on
<span class="math inline">\(\mathfrak{g}^*\)</span> to <span
class="math display">\[\mathfrak{h}_\mathbb{R}^* :=
{\mathop{\mathrm{Hom}}}_\mathbb{R}(\mathfrak{h}_\mathbb{R},\mathbb{R})
\cong \{\lambda \in \mathfrak{h}^* : \lambda(h_\mathbb{R}) \subseteq
\mathbb{R}\}.\]</span> Since the scalar product that we started with on
<span class="math inline">\(\mathfrak{g}\)</span> has positive-definite
restriction to <span
class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span>, we know also
that the scalar product on <span
class="math inline">\(\mathfrak{g}^*\)</span> that we just defined has
positive-definite restriction to <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span>, hence defines
an inner product on that space.</p>
<p>In what follows, we shall always regard <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span> as an inner
product space with respect to an inner product as constructed above.</p>
<h2 id="sec:org573a7f4">§30.7. Some recap on <span
class="math inline">\(\mathop{\mathrm{SL}}(2)\)</span></h2>
<p>Let’s recall a few facts we learned long ago. Recall the standard
basis elements <span class="math display">\[H =
\begin{pmatrix}
    1 &amp;  \\
      &amp; -1
  \end{pmatrix}
  ,
  \quad
  X =
\begin{pmatrix}
    &amp; 1 \\
    &amp;
  \end{pmatrix}
  ,
  \quad
  Y =
\begin{pmatrix}
    &amp;  \\
    1 &amp;
  \end{pmatrix}\]</span> of <span class="math inline">\(\mathfrak{g} :=
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>, and
that any finite-dimensional representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> breaks up into weight spaces
<span class="math inline">\(V = \oplus_{m \in \mathbb{C}} V[m]\)</span>
where <span class="math inline">\(V[m] := \{v \in V : H v = m
v\}\)</span>. (In other words, <span class="math inline">\(H\)</span>
acts semisimply in any finite-dimensional representation. We proved this
awhile ago. Another quick proof: we can first decompose with respect to
the action of the diagonal subgroup of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>, since the latter
is compact; the Lie algebra of that subgroup is generated by <span
class="math inline">\(H\)</span>, so we get a decomposition with respect
to <span class="math inline">\(H\)</span>.)</p>
<p>Recall that the <span class="math inline">\(m\)</span> for which
<span class="math inline">\(V[m] \neq 0\)</span> are called the
<em>weights</em> of <span class="math inline">\(V\)</span>; the spaces
<span class="math inline">\(V[m]\)</span> are then called <em>weight
spaces</em>.</p>
<p>The set of weights of the irreducible representations <span
class="math inline">\(W_m\)</span> of dimension <span
class="math inline">\(m+1\)</span> is <span class="math display">\[\{-m,
-m+2,\dotsc,m-4,m-2,m\}.\]</span> The set of weights of a direct sum of
several copies of <span class="math inline">\(W_m\)</span> is the union
of the sets of weights of the <span class="math inline">\(W_m\)</span>
that occur. Since any such <span class="math inline">\(V\)</span> is
isomorphic to such a finite direct sum, we know a lot about the set of
weights.</p>
<div id="lem:sl2-recap-1" class="lemma">
<p><strong>Lemma 236</strong>. The weights are integers. An integer
<span class="math inline">\(m\)</span> is a weight if and only if <span
class="math inline">\(-m\)</span> is a weight.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This follows (among other ways) from the
classification: <span class="math inline">\(V\)</span> is a finite
direct sum of copies of the <span class="math inline">\(W_m\)</span>,
and each of those irreducible representations has the above
property. ◻</p>
</span></div>
<div id="lem:sl2-recap-2" class="lemma">
<p><strong>Lemma 237</strong>. If the weights of <span
class="math inline">\(V\)</span> all have the same parity (i.e., are all
even or all odd), then the set of weights is of the form <span
class="math display">\[\{-m, -m + 2, \dotsc, m-4, m-2, m\}\]</span> for
some <span class="math inline">\(m \in \mathbb{Z}_{\geq 0}\)</span>.</p>
<p>In that case, let <span class="math inline">\(\ell\)</span> be any
weight of <span class="math inline">\(V\)</span>. Let <span
class="math inline">\(p,q \geq 0\)</span> be the largest positive
integers for which <span class="math inline">\(\ell - 2 p\)</span> and
<span class="math inline">\(\ell + 2 q\)</span> are weights. Then <span
class="math display">\[\ell = p- q.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The first assertion follows from the classification.
For the second assertion, we must have <span class="math inline">\(\ell
- 2 p = - m\)</span> and <span class="math inline">\(\ell + 2 q =
m\)</span>, whence <span class="math inline">\(2 \ell = 2 (p -
q)\)</span>, as required. ◻</p>
</span></div>
<div id="lem:sl2-recap-3" class="lemma">
<p><strong>Lemma 238</strong>. If <span class="math inline">\(m,
m+2\)</span> are weights of <span class="math inline">\(V\)</span>, then
the maps <span class="math inline">\(X : V[m] \rightarrow
V[m+2]\)</span> and <span class="math inline">\(Y : V[m+2] \rightarrow
V[m]\)</span> are not identically zero.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Again follows by reducing to the irreducible case and
then inspecting. ◻</p>
</span></div>
<div id="lem:sl2-recap-4" class="lemma">
<p><strong>Lemma 239</strong>. Suppose <span
class="math inline">\(V\)</span> has the following properties:</p>
<ol>
<li><p>The weights of <span class="math inline">\(V\)</span> are all
even.</p></li>
<li><p><span class="math inline">\(V[0]\)</span> is
one-dimensional.</p></li>
<li><p><span class="math inline">\(V[2]\)</span> is nonzero.</p></li>
<li><p>There exists a nonzero element <span class="math inline">\(v \in
V[2]\)</span> such that <span class="math inline">\(X v =
0\)</span>.</p></li>
</ol>
<p>Then the set of weights is <span
class="math inline">\(\{-2,0,2\}\)</span> and each weight space is
one-dimensional.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The first three conditions tell us that we must have
<span class="math inline">\(V \cong W_m\)</span> for some even integer
<span class="math inline">\(m \geq 2\)</span>. The fourth condition
implies that <span class="math inline">\(m = 2\)</span>. ◻</p>
</span></div>
<h2 id="sec:orgfd608b2">§30.8. Proof of Theorem <a
href="#thm:main-theorem-on-roots-of-simple-algebras"
data-reference-type="ref"
data-reference="thm:main-theorem-on-roots-of-simple-algebras">233</a></h2>
<p>Let notation and assumptions be as in the statement of that theorem.
Let <span class="math inline">\((,)\)</span> denote a <span
class="math inline">\(\mathfrak{g}\)</span>-invariant scalar product on
<span class="math inline">\(\mathfrak{g}\)</span> whose restriction to
<span class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span> is
real-valued and positive-definite. (We will only use this final property
of the inner product at one point in the proof to follow, and it could
be avoided at the cost of a bit more work.) As in §<a
href="#sec:some-stuff-about-scalar-products" data-reference-type="ref"
data-reference="sec:some-stuff-about-scalar-products">30.6</a>,
let <span class="math inline">\((,)\)</span> denote also the inner
product induced on <span class="math inline">\(\mathfrak{g}^*\)</span>
by duality, whose restriction to <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span> is then
real-valued and positive-definite. (Revisit the examples of classical
families.) Since <span class="math inline">\(\mathfrak{h}\)</span> is a
Cartan subalgebra, we have a root space decomposition <span
class="math display">\[\mathfrak{g} = \mathfrak{h} \oplus
(\oplus_{\alpha \in R} \mathfrak{g}^\alpha)\]</span> for some finite set
<span class="math inline">\(R \subseteq \mathfrak{h}_\mathbb{R}^* -
\{0\}\)</span> of roots. Here <span class="math inline">\([H,X] =
\alpha(H) X\)</span> for all <span class="math inline">\(H \in
\mathfrak{h}, X \in \mathfrak{g}^\alpha\)</span>.</p>
<p>We verify first that <span class="math display">\[\begin{cases}
    \subseteq \mathfrak{g}^{\alpha+\beta} &amp; \text{ if } \alpha +
\beta \in R \\
    \subseteq \mathfrak{h} &amp; \text{ if } \alpha + \beta =0 \\
    = \{0\} &amp; \text{otherwise.}
  \end{cases}\]</span> This is the same verification we’ve done by now
many times: for <span class="math inline">\(x \in \mathfrak{g}^\alpha, y
\in \mathfrak{g}^\beta, H \in \mathfrak{h}\)</span>, we have by the
Jacobi identity <span class="math display">\[]
  = [[H, x],y] +[x,[H, y]] = \alpha(H) [x,y] + \beta(H) [x,y] = (\alpha
+ \beta)(H) [x,y],\]</span> giving what we want.</p>
<p>We show next that <span class="math display">\[(\mathfrak{g}^\alpha,
\mathfrak{g}^\beta) = 0 \text{ unless } \alpha + \beta = 0.\]</span>
Indeed, assume <span class="math inline">\(\alpha + \beta \neq
0\)</span>. We must show for <span class="math inline">\(x \in
\mathfrak{g}^\alpha, y \in \mathfrak{g}^\beta\)</span> that <span
class="math inline">\((x,y) = 0\)</span>. Choose <span
class="math inline">\(H \in \mathfrak{h}\)</span> so that <span
class="math inline">\((\alpha + \beta)(z) \neq 0\)</span>. By the <span
class="math inline">\(\mathfrak{g}\)</span>-invariance of <span
class="math inline">\((,)\)</span>, we then have <span
class="math display">\[0 = ([H,x],y) + (x,[H,y]) = (\alpha + \beta)(H)
\cdot (x,y),\]</span> hence <span class="math inline">\((x,y) =
0\)</span>, as required.</p>
<p>As a consequence, we see that the decomposition <span
class="math display">\[\mathfrak{g} = \mathfrak{h} \oplus (\oplus_{\pm
\alpha \in R}
  \mathfrak{g}^{\alpha} \oplus \mathfrak{g}^{-\alpha})\]</span> is
orthogonal with respect to <span class="math inline">\((,)\)</span>. In
particular:</p>
<ol>
<li><p><span class="math inline">\((,)\)</span> has non-degenerate
restriction to <span class="math inline">\(\mathfrak{h} \times
\mathfrak{h}\)</span>, although this follows already from our
assumptions.</p></li>
<li><p><span class="math inline">\((,)\)</span> induces a duality
between <span class="math inline">\(\mathfrak{g}^\alpha\)</span> and
<span class="math inline">\(\mathfrak{g}^{-\alpha}\)</span>. In
particular, <span class="math inline">\(\alpha \in R\)</span> if and
only if <span class="math inline">\(- \alpha \in R\)</span>.</p></li>
</ol>
<p>Let <span class="math inline">\(\mathfrak{h}^* \ni \lambda \mapsto
u_\lambda \in \mathfrak{h}\)</span> denote the isomorphism induced by
<span class="math inline">\((,)\)</span>, so that <span
class="math inline">\(\mu(u_\lambda) = \langle \lambda,\mu
\rangle\)</span> for all <span class="math inline">\(\mu \in
\mathfrak{h}^*\)</span>. We claim next that <span id="eqn:key-relation-inner-product-commutators" class="math display">\[\label{eqn:key-relation-inner-product-commutators}\tag{136}
[x,y] = (x,y) u_\alpha.\]</span> For the proof, let <span
class="math inline">\(H \in \mathfrak{h}\)</span>; since <span
class="math inline">\((,)\)</span> has nondegenerate restriction to
<span class="math inline">\(\mathfrak{h}\)</span>, it will suffice to
verify that <span class="math display">\[(H,[x,y]) = (H,(x,y)
u_\alpha).\]</span> Since the <span
class="math inline">\(\mathfrak{g}\)</span>-invariance gives <span
class="math inline">\((H,[x,y]) = ([H,x],y) = \alpha(H) (x,y)\)</span>
and the linearity gives <span class="math inline">\((H,(x,y) u_\alpha) =
(H,u_\alpha) (x,y) = \alpha(H) (x,y)\)</span>, we are done.</p>
<p>Note in particular that for <span class="math inline">\(\alpha \in
\mathfrak{h}_\mathbb{R}^* - \{0\}\)</span>, one has <span
class="math display">\[0 &lt; (\alpha,\alpha) =
\alpha(u_\alpha).\]</span> Hence for each <span
class="math inline">\(\alpha \in R \subseteq \mathfrak{h}_\mathbb{R}^* -
\{0\}\)</span>, it makes sense to define <span
class="math display">\[H_\alpha := 2 \frac{u_\alpha}{(\alpha,\alpha)}
\in \mathfrak{h}_\mathbb{R}.\]</span> With this definition, we then have
<span class="math display">\[\alpha(H_\alpha) = 2.\]</span> Moreover,
let us fix a nonzero element <span class="math inline">\(X_\alpha \in
\mathfrak{g}^\alpha\)</span>. Since <span
class="math inline">\(\mathfrak{g}^{-\alpha}\)</span> is in duality with
<span class="math inline">\(\mathfrak{g}^\alpha\)</span>, there then
exists <span class="math inline">\(Y_\alpha \in
\mathfrak{g}^{-\alpha}\)</span> so that <span
class="math inline">\((X_\alpha,Y_\alpha) = 2 /
(\alpha,\alpha)\)</span>. By <a
href="#eqn:key-relation-inner-product-commutators"
data-reference-type="eqref"
data-reference="eqn:key-relation-inner-product-commutators">\((136)\)</a>,
it follows that <span class="math display">\[= H_\alpha,\]</span> which
is consistent with what we stipulated in the classical examples.</p>
<p>Now let <span class="math inline">\(\mathfrak{s}_\alpha \leq
\mathfrak{g}\)</span> denote the three-dimensional vector subspace <span
class="math display">\[\mathfrak{s}_\alpha := \mathbb{C} X_\alpha \oplus
\mathbb{C} H_\alpha \oplus \mathbb{C} Y_\alpha.\]</span> Recall that
<span class="math inline">\([X_\alpha,X_\alpha] = [Y_\alpha,Y_\alpha] =
[H_\alpha,H_\alpha] = 0\)</span> and <span
class="math inline">\([H_\alpha,X_\alpha] = 2 X_\alpha\)</span>, <span
class="math inline">\([H_\alpha,Y_\alpha] = -2 Y_\alpha\)</span>, <span
class="math inline">\([X_\alpha,Y_\alpha] = H_\alpha\)</span>. It
follows that the map <span class="math display">\[\phi_\alpha :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}) \rightarrow
\mathfrak{s}_\alpha \subseteq \mathfrak{g}\]</span> given by sending the
standard basis elements <span class="math display">\[H =
\begin{pmatrix}
    1 &amp;  \\
      &amp; -1
  \end{pmatrix}
  ,
  \quad
  X =
\begin{pmatrix}
    &amp; 1 \\
    &amp;
  \end{pmatrix}
  ,
  \quad
  Y =
\begin{pmatrix}
    &amp;  \\
    1 &amp;
  \end{pmatrix}\]</span> in the evident way (<span
class="math inline">\(H,X,Y \mapsto H_\alpha,X_\alpha,Y_\alpha\)</span>)
is an isomorphism of Lie algebras.</p>
<div id="lem:root-spaces-one-dimensional" class="lemma">
<p><strong>Lemma 240</strong>. Let <span class="math inline">\(\alpha
\in R\)</span>. Then <span class="math inline">\(\dim
\mathfrak{g}^\alpha = 1\)</span> and <span class="math inline">\(\{n \in
\mathbb{Z} : n \alpha \in R \} = \{\pm 1 \}\)</span>. In particular,
<span class="math inline">\(2 \alpha \notin R\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Set <span class="math display">\[V := \mathbb{C}
H_\alpha \oplus (\oplus_{n \in \mathbb{Z}_{\neq 0}} \mathfrak{g}^{n
\alpha}),\]</span> where by convention <span
class="math inline">\(\mathfrak{g}^{n \alpha} := 0\)</span> if <span
class="math inline">\(n \alpha \notin R\)</span>. Observe that <span
class="math inline">\(V\)</span> is stable under <span
class="math inline">\(\mathfrak{s}_\alpha\)</span>; this follows from
what was shown above, together with the observation that <span
class="math inline">\(H_{n \alpha} \in \mathbb{C} H_\alpha\)</span> for
all <span class="math inline">\(n\)</span>. We may thus regard <span
class="math inline">\(V\)</span> as a representation of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>
via the map <span class="math inline">\(\phi_\alpha\)</span>.
Equivalently, the map <span class="math inline">\(\rho :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}) \rightarrow
\mathop{\mathrm{End}}(V)\)</span> is given for <span
class="math inline">\(x \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> and
<span class="math inline">\(v \in V\)</span> by <span
class="math display">\[\rho(x) v := [\phi_\alpha(x),v].\]</span> The
possibly nonzero weight spaces are <span class="math inline">\(V[0] =
\mathbb{C} H_\alpha\)</span>, which is one-dimensional, and <span
class="math inline">\(V[2 n] = \mathfrak{g}^{n \alpha}\)</span> for
<span class="math inline">\(n \neq 0\)</span>. We observe that <span
class="math inline">\(V[2]\)</span> is nonzero (since it contains <span
class="math inline">\(X_\alpha\)</span>) and that there exists <span
class="math inline">\(v \in V[2]\)</span> for which <span
class="math inline">\(\rho(X) v = 0\)</span> (take <span
class="math inline">\(v := X_\alpha\)</span> and use that <span
class="math inline">\([X_\alpha,X_\alpha] = 0\)</span>). Lemma <a
href="#lem:sl2-recap-4" data-reference-type="ref"
data-reference="lem:sl2-recap-4">239</a> applies, telling us that <span
class="math inline">\(V \cong W_2\)</span>. The various conclusions
follow from the description of the weight spaces of <span
class="math inline">\(W_2\)</span>. ◻</p>
</span></div>
<p>For <span class="math inline">\(\alpha \in R\)</span> and <span
class="math inline">\(\lambda \in \mathfrak{h}^*\)</span>, set <span
class="math display">\[\langle \lambda|\alpha \rangle :=
\lambda(H_\alpha)\]</span> and define the root reflection <span
class="math display">\[s_\alpha : \mathfrak{h}^* \rightarrow
\mathfrak{h}^*\]</span> by <span
class="math display">\[s_\alpha(\lambda) := \lambda - \langle
\lambda|\alpha \rangle \alpha.\]</span> Observe that <span
class="math inline">\(s_\alpha(s_\alpha(\lambda)) =
\lambda\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 241</strong>. <span class="math display">\[\langle
\lambda|\alpha \rangle = 2
\frac{(\lambda,\alpha)}{(\alpha,\alpha)}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Well, by definition, we have <span
class="math display">\[u_\alpha = \frac{2}{(\alpha,\alpha)}
H_\alpha.\]</span> If we apply <span
class="math inline">\(\lambda\)</span> to both sides, we get <span
class="math display">\[(\lambda,\alpha) = \lambda(u_\alpha) = 2
\frac{\lambda(H_\alpha)}{(\alpha,\alpha)},\]</span> which rearranges to
<span class="math display">\[\lambda(H_\alpha) = 2
\frac{(\lambda,\alpha)}{(\alpha,\alpha)},\]</span> as required. ◻</p>
</span></div>
<div id="lem:alpha-string-thru-beta-description" class="lemma">
<p><strong>Lemma 242</strong>. Let <span class="math inline">\(\alpha,
\beta \in R\)</span>. Then <span class="math inline">\(\beta(H_\alpha)
\in \mathbb{Z}\)</span> and <span class="math inline">\(s_\alpha(\beta)
\in R\)</span>. Thus <span class="math inline">\(s_\alpha(R) =
R\)</span>.</p>
<p>Moreover, let <span class="math inline">\(p,q \geq 0\)</span> be the
largest nonnegative integers for which <span class="math inline">\(\beta
- q \alpha\)</span> and <span class="math inline">\(\beta + p
\alpha\)</span> are roots. Then <span class="math inline">\(\beta + k
\alpha\)</span> is a root for all integers <span class="math inline">\(k
\in \{-q..p\}\)</span>, and we have <span
class="math inline">\(\beta(H_\alpha) = p- q\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We argue as in the proof of Lemma <a
href="#lem:root-spaces-one-dimensional" data-reference-type="ref"
data-reference="lem:root-spaces-one-dimensional">240</a>, but now with
<span class="math display">\[V := \oplus_{k \in \mathbb{Z}}
\mathfrak{g}^{\beta + k \alpha},\]</span> regarded as an <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>-module
via <span class="math inline">\(\phi_\alpha\)</span> as before. The
element <span class="math inline">\(H \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> acts
on <span class="math inline">\(\mathfrak{g}^{\beta + k \alpha}\)</span>
by the eigenvalues <span class="math inline">\((\beta + k
\alpha)(H_\alpha) = \beta(H_\alpha) + 2 k\)</span>; in particular, <span
class="math inline">\(\beta(H_\alpha)\)</span> is an <span
class="math inline">\(H\)</span>-weight of <span
class="math inline">\(V\)</span>. By Lemma <a href="#lem:sl2-recap-2"
data-reference-type="ref" data-reference="lem:sl2-recap-2">237</a>
(applied to <span class="math inline">\(\ell :=
\beta(H_\alpha)\)</span>), we have <span
class="math inline">\(\beta(H_\alpha) = p - q \in \mathbb{Z}\)</span>.
The <span class="math inline">\(H\)</span>-weight of <span
class="math inline">\(\mathfrak{g}^{\beta - \beta(H_\alpha)
\alpha}\)</span> is <span class="math inline">\(\beta(H_\alpha) - 2
\beta(H_\alpha) = - \beta(H_\alpha)\)</span>, which shows that <span
class="math inline">\(\mathfrak{g}^{\beta - \beta(H_\alpha) \alpha} \neq
0\)</span>, or equivalently, that <span
class="math inline">\(s_\alpha(\beta) \in R\)</span>. ◻</p>
</span></div>
<div class="lemma">
<p><strong>Lemma 243</strong>. Let <span
class="math inline">\(\alpha,\beta \in R\)</span> such that <span
class="math inline">\(\alpha + \beta \in R\)</span>. Then <span
class="math inline">\([\mathfrak{g}^\alpha,\mathfrak{g}^\beta] =
\mathfrak{g}^{\alpha+\beta}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since the root spaces are all one-dimensional, it
suffices to show that the map <span
class="math inline">\({\mathop{\mathrm{ad}}}_{X_\alpha} :
\mathfrak{g}^\beta \rightarrow \mathfrak{g}^{\alpha+\beta}\)</span> is
nonzero. This follows from Lemma <a href="#lem:sl2-recap-3"
data-reference-type="ref" data-reference="lem:sl2-recap-3">238</a> upon
taking <span class="math inline">\(V = \oplus \mathfrak{g}^{\beta + k
\alpha}\)</span> as above. ◻</p>
</span></div>
<p>All assertions in Theorem <a
href="#thm:main-theorem-on-roots-of-simple-algebras"
data-reference-type="ref"
data-reference="thm:main-theorem-on-roots-of-simple-algebras">233</a>
have now been established. (The uniqueness of <span
class="math inline">\(Y_\alpha\)</span> follows from the
one-dimensionality of <span
class="math inline">\(\mathfrak{g}^{-\alpha}\)</span>.)</p>
<div class="remark">
<p><strong>Remark 244</strong>. Lemma <a
href="#lem:inner-products-between-roots-predict-other-roots"
data-reference-type="ref"
data-reference="lem:inner-products-between-roots-predict-other-roots">232</a>
was proved using only the root system axioms. It may be alternatively
deduced “directly” from Lemma <a
href="#lem:alpha-string-thru-beta-description" data-reference-type="ref"
data-reference="lem:alpha-string-thru-beta-description">242</a>.</p>
</div>
<h1 id="sec:org96d3081">§31. Serre relations and applications</h1>
<h2 id="sec:orgd6370a3">§31.1. Generators and relations for simple complex Lie
algebras</h2>
<p>Recall from §<a href="#sec:simple-lie-alg-give-roots"
data-reference-type="ref"
data-reference="sec:simple-lie-alg-give-roots">30.5</a>
and following that one can<a href="#fn8" class="footnote-ref"
id="fnref8" role="doc-noteref"><sup>8</sup></a> attach root systems to
simple Lie algebras over <span
class="math inline">\(\mathbb{C}\)</span>. We also mentioned briefly
that root systems can be classified in terms of their Cartan matrices,
or equivalently, their Dynkin diagrams.</p>
<p>Conversely, it turns out that one go the other direction: if the root
systems of a pair <span class="math inline">\(\mathfrak{g}_1,
\mathfrak{g}_2\)</span> of simple Lie algebras over <span
class="math inline">\(\mathbb{C}\)</span> are isomorphic, then so are
<span class="math inline">\(\mathfrak{g}_1\)</span> and <span
class="math inline">\(\mathfrak{g}_2\)</span>. One can prove this fairly
directly (see p184 of Onishchik–Vinberg), but a particularly convincing
way to see it is via the following theorem of Serre:</p>
<div id="thm:serre-relations" class="theorem">
<p><strong>Theorem 245</strong>. <em>Let <span
class="math inline">\(\mathfrak{h}\)</span> be a Cartan subalgebra with
associated root system <span class="math inline">\(R\)</span>, let <span
class="math inline">\(S\)</span> be any simple subsystem, and let <span
class="math inline">\(N = (N_{\alpha \beta})_{\alpha,\beta \in
S}\)</span> be the Cartan matrix (thus <span
class="math inline">\(N_{\alpha \beta} := \alpha(H_\beta)\)</span>,
say). Then <span class="math inline">\(\mathfrak{g}\)</span> is
generated as a Lie algebra by the symbols <span
class="math inline">\(H_\alpha, X_\alpha, Y_\alpha\)</span> (<span
class="math inline">\(\alpha \in S\)</span>) subject only to the
relations: for all <span class="math inline">\(\alpha,\beta \in
S\)</span>, <span class="math display">\[= N_{\alpha \beta} X_\beta,
\quad [H_\alpha,Y_\beta] = N_{\alpha \beta} Y_\beta, \quad
[X_\alpha,Y_\alpha] = H_\alpha;\]</span> for distinct <span
class="math inline">\(\alpha,\beta \in S\)</span>, <span
class="math display">\[= 0, \quad
{\mathop{\mathrm{ad}}}_{X_\alpha}^{-N_{\alpha \beta}+1}(X_\beta) = 0,
\quad {\mathop{\mathrm{ad}}}_{Y_\alpha}^{-N_{\alpha \beta}+1}(Y_\beta) =
0.\]</span></em></p>
</div>
<p>The meaning of this is hopefully clear by analogy to presentations
and relations for groups; for a more precise statement, see either
Onishchik–Vinberg or Serre.</p>
<p>Theorem <a href="#thm:serre-relations" data-reference-type="ref"
data-reference="thm:serre-relations">245</a> immediately implies that
the isomorphism class of a simple Lie algebra over <span
class="math inline">\(\mathbb{C}\)</span> depends only upon its Cartan
matrix. It has many other applications to be discussed shortly.</p>
<h2 id="sec:org051a3bb">§31.2. Semisimple complex Lie algebras</h2>
<p>These play a central role in the theory. They admit several
equivalent definitions. The most convenient one for our immediate
purposes is the following:</p>
<div class="definition">
<p><strong>Definition 246</strong>. A Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> over <span
class="math inline">\(\mathbb{C}\)</span> is <em>semisimple</em> if it
is isomorphic to a finite direct sum of simple Lie algebras, or
equivalently, if <span class="math inline">\(\mathfrak{g}\)</span> is
the direct sum of some finite collection of simple ideals.</p>
</div>
<p>We can define Cartan subalgebras <span
class="math inline">\(\mathfrak{h}\)</span> of semisimple Lie algebras
<span class="math inline">\(\mathfrak{g}\)</span> over <span
class="math inline">\(\mathbb{C}\)</span> just as we did in the simple
case. Moreover, if <span class="math inline">\(\mathfrak{g} = \oplus
\mathfrak{g}_i\)</span> with <span
class="math inline">\(\mathfrak{g}_i\)</span> simple and containing a
Cartan subalgebra <span class="math inline">\(\mathfrak{h}_i\)</span>,
then we can take <span class="math inline">\(\mathfrak{h} = \oplus
\mathfrak{h}_i\)</span>. We can likewise associate root systems in the
semisimple case just as in the simple case. The only difference is that
now the root systems we obtain are not irreducible; instead, they
decompose as finite disjoint unions (in the sense of Example <a
href="#ex:disj-union-root-systems" data-reference-type="ref"
data-reference="ex:disj-union-root-systems">229</a>) of irreducible root
systems, corresponding to the decomposition of the semisimple Lie
algebra as a finite direct sum of simple Lie algebras.</p>
<p>The bijection between:</p>
<ul>
<li><p>simple Lie algebras over <span
class="math inline">\(\mathbb{C}\)</span></p></li>
<li><p>irreducible reduced root systems</p></li>
<li><p>connected Dynkin diagrams</p></li>
</ul>
<p>induces one between:</p>
<ul>
<li><p>semisimple Lie algebras over <span
class="math inline">\(\mathbb{C}\)</span></p></li>
<li><p>reduced root systems</p></li>
<li><p>Dynkin diagrams</p></li>
</ul>
<p>The Serre relations apply just as well in the semisimple case.</p>
<p>There is a nontrivial equivalence which seems worth mentioning up
front:</p>
<div class="theorem">
<p><strong>Theorem 247</strong>. <em><span
class="math inline">\(\mathfrak{g}\)</span> is semisimple if and only if
<span class="math inline">\(\mathfrak{g}\)</span> contains no abelian
ideals.</em></p>
</div>
<p>Thus being semisimple is in some sense the “opposite” of being
abelian. There are other nice criteria for checking semisimplicity of
<span class="math inline">\(\mathfrak{g}\)</span> that one can read
about in any of the course references (e.g., either by Serre). One says
that there should exist a bilinear form on <span
class="math inline">\(\mathfrak{g}\)</span> that is <span
class="math inline">\({\mathop{\mathrm{ad}}}_\mathfrak{g}\)</span>-invariant
and non-degenerate. For the classical examples, the trace form <span
class="math inline">\((x,y) := trace(xy)\)</span> is easily seen to have
such properties. Using this criterion, one can give “another” proof that
(say) <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
is simple (see §<a href="#sec:simplicity-sln" data-reference-type="ref"
data-reference="sec:simplicity-sln">28</a>) by
computing the Cartan matrix and checking that the Dynkin diagram is
<em>connected</em>.</p>
<h2 id="sec:orgdfba908">§31.3. Reductive complex Lie algebras</h2>
<p>Here is another definition which admits many equivalent
characterizations; we again give that which is more convenient for our
immediate purposes.</p>
<div class="definition">
<p><strong>Definition 248</strong>. Let <span
class="math inline">\((\mathfrak{g}_i)_{i \in I}\)</span> be a family of
Lie algebras. The <em>direct sum Lie algebra</em> is the direct sum
vector space <span class="math inline">\(\mathfrak{g} := \oplus_{i \in
I} \mathfrak{g}_i\)</span> equipped with the Lie bracket characterized
by:</p>
<ul>
<li><p>for <span class="math inline">\(i \in I\)</span> and <span
class="math inline">\(x,y \in \mathfrak{g}_i \hookrightarrow
\mathfrak{g}\)</span>, one has <span
class="math inline">\([x,y]_{\mathfrak{g}} :=
[x,y]_{\mathfrak{g}_i}\)</span>;</p></li>
<li><p>for <span class="math inline">\(i \neq j \in I\)</span> and <span
class="math inline">\(x \in \mathfrak{g}_i, y \in
\mathfrak{g}_j\)</span>, one has <span
class="math inline">\([x,y]_{\mathfrak{g}} := 0\)</span>.</p></li>
</ul>
<p>It has the universal property: <span
class="math inline">\(\mathop{\mathrm{Hom}}(\oplus \mathfrak{g}_i,
\mathfrak{h}) = \prod
\mathop{\mathrm{Hom}}(\mathfrak{g}_i,\mathfrak{h})\)</span> for all Lie
algebras <span class="math inline">\(\mathfrak{h}\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 249</strong>. A finite-dimensional Lie algebra
<span class="math inline">\(\mathfrak{g}\)</span> over <span
class="math inline">\(\mathbb{C}\)</span> is <em>reductive</em> if it is
a direct sum of an abelian Lie algebra and a semisimple Lie algebra.</p>
</div>
<p>For example, <span
class="math inline">\(\mathfrak{g}\mathfrak{l}_n(\mathbb{C})\)</span> is
reductive (it is the direct sum of <span
class="math inline">\(\sl_n(\mathbb{C})\)</span> and the central
subalgebra <span class="math inline">\(\mathfrak{z}\)</span> consisting
of scalar matrices), but not semisimple (it contains the abelian ideal
<span class="math inline">\(\mathfrak{z}\)</span>).</p>
<p>Abelian Lie algebras over any field are classified by their
dimension, so the classification of semisimple Lie algebras readily
induces a classification of reductive Lie algebras.</p>
<p>Here’s a handy and clarifying lemma, proved in lecture and left here
as an exercise (ask me if it’s unclear):</p>
<div id="lem:reductive-iff-reducible" class="lemma">
<p><strong>Lemma 250</strong>. A complex Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> is reductive if and only if
its adjoint representation <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{g} \rightarrow
\mathop{\mathrm{End}}(\mathfrak{g})\)</span> is completely
reducible.</p>
</div>
<p>We can define Cartan subalgebras <span
class="math inline">\(\mathfrak{h}\)</span> of reductive Lie algebras
<span class="math inline">\(\mathfrak{g}\)</span> just as we did in the
semisimple case. (They always contain the center <span
class="math inline">\(\mathfrak{z}\)</span>.) We can also define the set
<span class="math inline">\(R\)</span> of roots. The only difference
with the semisimple case is now that the roots <span
class="math inline">\(R\)</span> need not span <span
class="math inline">\(\mathfrak{h}^*\)</span>. For example, if <span
class="math inline">\(\mathfrak{g}\)</span> is abelian, then <span
class="math inline">\(R = \emptyset\)</span>.</p>
<h2 id="sec:orgdfd4c01">§31.4. Compact complex Lie groups</h2>
<p>We don’t talk about these much. There’s a good reason:</p>
<div class="theorem">
<p><strong>Theorem 251</strong>. <em>Any compact connected complex Lie
group <span class="math inline">\(G\)</span> is abelian.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Consider <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\)</span>. It is a holomorphic
matrix-valued function. Since <span class="math inline">\(G\)</span> is
compact, it is bounded. By Liouville’s theorem, it must be constant. But
it preserves the identity, and so must be trivial. Since <span
class="math inline">\(G\)</span> is connected, we conclude that it must
be abelian. ◻</p>
</span></div>
<p>Such <span class="math inline">\(G\)</span> typically go instead by
the name “abelian variety” and have an interesting theory orthogonal to
the primary aims of this course.</p>
<h2 id="sec:orgc85f06b">§31.5. Compact real Lie algebras</h2>
<p>From now on, when I write “compact Lie group,” I mean “compact real
Lie group.”</p>
<p>Think of your favorite compact Lie group <span
class="math inline">\(K\)</span> (e.g., <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>). Consider its Lie algebra <span
class="math inline">\(\mathfrak{k}\)</span>. How would you go about
telling just from <span class="math inline">\(\mathfrak{k}\)</span> that
<span class="math inline">\(K\)</span> was compact?</p>
<div class="definition">
<p><strong>Definition 252</strong>. Let <span
class="math inline">\(\mathfrak{k}\)</span> be a real Lie algebra.
(Every Lie algebra here and for the rest of the course should be assumed
finite-dimensional.) We call <span
class="math inline">\(\mathfrak{k}\)</span> <em>compact</em> if it
admits an <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{k})\)</span>-invariant
inner product, that is to say, a positive definite symmetric bilinear
form <span class="math inline">\((,) : \mathfrak{k} \otimes \mathfrak{k}
\rightarrow \mathbb{R}\)</span> with the property that <span
class="math display">\[([z,x],y) + (x,[z,y]) = 0\]</span> for all <span
class="math inline">\(x,y,z \in \mathfrak{k}\)</span>.</p>
</div>
<div class="lemma">
<p><strong>Lemma 253</strong>. Let <span
class="math inline">\(K\)</span> be a compact Lie group. Then <span
class="math inline">\(\mathfrak{k}\)</span> is compact.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Start with any inner product <span
class="math inline">\((,)_0\)</span> on <span
class="math inline">\(\mathfrak{k}\)</span>. Average it under <span
class="math inline">\(\mathop{\mathrm{Ad}}(K)\)</span> with respect to
an invariant measure, as in the discussion of the unitary trick earlier
in the course. Call <span class="math inline">\((,)\)</span> the
averaged inner product so obtained (it is still an inner product). Then
<span class="math inline">\((,)\)</span> is <span
class="math inline">\(\mathop{\mathrm{Ad}}(K)\)</span>-invariant, by
construction. By differentiating, we see that it is <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{k})\)</span>-invariant,
as required. ◻</p>
</span></div>
<div id="example:abelian-real-is-compact" class="example">
<p><strong>Example 254</strong>. If <span
class="math inline">\(\mathfrak{k}\)</span> is an abelian real Lie
algebra, then it is compact. This is easy to see directly.
Alternatively, we can write <span class="math inline">\(\mathfrak{k} =
\mathbb{R}^n\)</span> and apply the Lemma to <span
class="math inline">\(K = (\mathbb{R}/\mathbb{Z})^n\)</span>.</p>
</div>
<h2 id="sec:org00eed09">§31.6. Complex reductive vs. compact real Lie
algebras</h2>
<p>Recall our discussion of complexifications and real forms from §<a
href="#sec:unitary-trick" data-reference-type="ref"
data-reference="sec:unitary-trick">17</a>.</p>
<p>We include the following mainly as a bridge from our discussion of
complex simple Lie algebras to our next target (compact Lie groups).</p>
<div class="theorem">
<p><strong>Theorem 255</strong>. </p>
<ol>
<li><p><em>Let <span class="math inline">\(\mathfrak{k}\)</span> be a
compact real Lie algebra. Then its complexification <span
class="math inline">\(\mathfrak{k}_\mathbb{C} := \mathfrak{k} \otimes
\mathbb{C}\)</span> is a reductive complex Lie algebra.</em></p></li>
<li><p><em>Let <span class="math inline">\(\mathfrak{g}\)</span> be a
complex reductive Lie algebra. Then it has a compact real form <span
class="math inline">\(\mathfrak{k}\)</span>.</em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol>
<li><p>By Lemma <a href="#lem:reductive-iff-reducible"
data-reference-type="ref"
data-reference="lem:reductive-iff-reducible">250</a>, we have to show
that the adjoint representation <span
class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{k} _\mathbb{C}
\rightarrow \mathop{\mathrm{End}}(\mathfrak{k}_\mathbb{C})\)</span> is
completely reducible. By linear algebra (cf. Example <a
href="#ex:complex-vs-real-reps" data-reference-type="ref"
data-reference="ex:complex-vs-real-reps">126</a>), it suffices to show
that <span class="math inline">\(\mathop{\mathrm{ad}}: \mathfrak{k}
\rightarrow \mathop{\mathrm{End}}(\mathfrak{k})\)</span> is completely
reducible. To that end, we make use of the existence of a <span
class="math inline">\(\mathfrak{k}\)</span>-invariant inner product and
argue using orthogonal complements as in Example <a
href="#example:invariant-inner-product-implies-complete-irreducibility"
data-reference-type="ref"
data-reference="example:invariant-inner-product-implies-complete-irreducibility">111</a>.</p></li>
<li><p>Note first that if result holds for <span
class="math inline">\(\mathfrak{g}_1\)</span> and <span
class="math inline">\(\mathfrak{g}_2\)</span>, then it also holds for
their direct sum (take <span class="math inline">\(\mathfrak{k}_1 \oplus
\mathfrak{k}_2 \subseteq \mathfrak{g}_1 \oplus \mathfrak{g}_2\)</span>).
Since <span class="math inline">\(\mathfrak{g}\)</span> is reductive, it
suffices to consider separately the case that <span
class="math inline">\(\mathfrak{g}\)</span> is abelian and the case that
<span class="math inline">\(\mathfrak{g}\)</span> is semisimple (or
indeed, simple). The abelian case is easy (see Example <a
href="#example:abelian-real-is-compact" data-reference-type="ref"
data-reference="example:abelian-real-is-compact">254</a>), so we focus
henceforth on the semisimple case.</p>
<p>Think of the prototypical example <span
class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>. How
would one go about “discovering” the compact real form <span
class="math inline">\(\mathfrak{k} =
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span>? Well, we have
<span class="math display">\[\mathfrak{k} = \{Z \in \mathfrak{g} :
\sigma(Z) = Z\},\]</span> where <span class="math inline">\(\sigma(Z) :=
-\overline{Z}^t\)</span>. On the standard basis elements <span
class="math inline">\(X,Y,H\)</span> this involution is given by <span
class="math display">\[\sigma(X) = -Y, \quad \sigma(Y) = -X, \quad
\sigma(H) = -H.\]</span> It is anti-linear in the sense that <span id="eq:anti-linearity-of-sigma" class="math display">\[\label{eq:anti-linearity-of-sigma}\tag{137}
      \sigma(t Z) = \overline{t} \sigma(Z) \text{ for all }
      t \in \mathbb{C}, Z \in \mathfrak{g}.\]</span> Also, let’s note in
this case for the modified Killing form <span id="eq:modified-killing-form" class="math display">\[\label{eq:modified-killing-form}\tag{138}
      (x,y) := -\mathop{\mathrm{trace}}(\mathop{\mathrm{ad}}(x)
\mathop{\mathrm{ad}}(\sigma(y)))\]</span> on <span
class="math inline">\(\mathfrak{g}\)</span>, the basis <span
class="math inline">\(X,Y,H\)</span> is orthogormal (i.e., <span
class="math inline">\((X,Y) = (X,H) = (Y,H) = 0\)</span>), and also
<span class="math inline">\((X,X) = (Y,Y) = (H,H) = 2\)</span>. Thus
<span class="math inline">\((,)\)</span> is positive-definite; it is
also clearly <span
class="math inline">\(\mathfrak{k}\)</span>-invariant. (Note: I defined
<span class="math inline">\((,)\)</span> incorrectly in lecture.)</p>
<p>This suggests the general strategy. Let <span
class="math inline">\(\mathfrak{g}\)</span> be a semisimple Lie algebra.
We use the Serre relations. It thus has generators <span
class="math inline">\(X_\alpha, Y_\alpha, H_\alpha\)</span> (<span
class="math inline">\(\alpha \in S\)</span>) satisfying some explicit
relations. We try to define an anti-linear involution <span
class="math inline">\(\sigma\)</span> on <span
class="math inline">\(\mathfrak{g}\)</span> by requiring that <a
href="#eq:anti-linearity-of-sigma" data-reference-type="eqref"
data-reference="eq:anti-linearity-of-sigma">\((137)\)</a>
hold and that on the generators, one has <span
class="math display">\[\sigma(X_\alpha) = -Y_\alpha, \quad
\sigma(Y_\alpha) = -X_\alpha, \quad \sigma(H_\alpha) =
-H_\alpha.\]</span> To check that this definition makes sense (i.e.,
extends from the generators to a real Lie algebra automorphism), we just
need to check that it preserves the Serre relations, which is clear. By
Remark <a href="#rmk:real-forms-vs-involutions"
data-reference-type="ref"
data-reference="rmk:real-forms-vs-involutions">132</a>, we know that
<span class="math inline">\(\mathfrak{k} := \{X \in \mathfrak{g} :
\sigma(X) = X\}\)</span> is a real form. We now define <span
class="math inline">\((,)\)</span> on <span
class="math inline">\(\mathfrak{g}\)</span> by <a
href="#eq:modified-killing-form" data-reference-type="eqref"
data-reference="eq:modified-killing-form">\((138)\)</a>
and check that it is positive definite on <span
class="math inline">\(\mathfrak{k}\)</span> to see that <span
class="math inline">\(\mathfrak{k}\)</span> is compact.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h1 id="sec:orge2e02c5">§32. The center and fundamental group of a compact
Lie group<span id="sec:center-pi1-compact"
label="sec:center-pi1-compact"></span></h1>
<p>We spent most of the lecture stating and motivating the truth of one
theorem.</p>
<p>We record the key definitions here for now; we will have more to say
about them later.</p>
<p>Let <span class="math inline">\(K\)</span> be a compact Lie group.
Let <span class="math inline">\(\mathfrak{k} :=
\mathop{\mathrm{Lie}}(K)\)</span>; it is a compact real Lie algebra. Let
<span class="math inline">\(\mathfrak{g}\)</span> denote its
complexification; it is a reductive complex Lie algebra. Let <span
class="math inline">\(\mathfrak{h} \leq \mathfrak{g}\)</span> be a
Cartan subalgebra, and suppose that <span
class="math inline">\(\mathfrak{t} = \mathfrak{k} \cap
\mathfrak{t}\)</span> is a real form of <span
class="math inline">\(\mathfrak{h}\)</span>, thus <span
class="math inline">\(\dim_\mathbb{R}(\mathfrak{t}) =
\dim_\mathbb{C}(\mathfrak{h})\)</span>; we can arrange this using the
presentation given by the Serre generators, for instance. Define <span
class="math inline">\(\mathfrak{h}_\mathbb{R} := i \mathfrak{t}\)</span>
and <span class="math inline">\(\mathfrak{h}_\mathbb{Z} :=
\ker(e)\)</span>, where <span class="math inline">\(e :
\mathfrak{h}_\mathbb{R} \rightarrow K\)</span> is the map <span
class="math inline">\(e(x) := \exp(2 \pi i x)\)</span>. Let <span
class="math inline">\(R\)</span> be the root system of <span
class="math inline">\(\mathfrak{h}\)</span>. Then <span
class="math inline">\(R \subseteq \mathfrak{h}_\mathbb{R}^*\)</span>.
Set <span class="math inline">\(R^\wedge := \{\alpha^\wedge : \alpha \in
R\}\)</span>, where <span class="math inline">\(\alpha^\wedge =
H_\alpha\)</span>. Set <span
class="math display">\[\mathfrak{h}_\mathbb{R}^* :=
{\mathop{\mathrm{Hom}}}_\mathbb{R}(\mathfrak{h}_\mathbb{R},\mathbb{R})
\cong \{\lambda \in \mathfrak{h}^* : \lambda(\mathfrak{h}_\mathbb{R})
\subseteq \mathbb{R} \}\]</span> and <span
class="math display">\[\mathfrak{h}_\mathbb{Z}^* :=
{\mathop{\mathrm{Hom}}}_\mathbb{Z}(\mathfrak{h}_\mathbb{Z},\mathbb{Z})
\cong \{\lambda \in \mathfrak{h}_{\mathbb{R}}^* :
\lambda(\mathfrak{h}_\mathbb{Z}) \subseteq \mathbb{Z} \} \cong \{\lambda
\in \mathfrak{h}^* : \lambda(\mathfrak{h}_\mathbb{Z}) \subseteq
\mathbb{Z} \}.\]</span> We then have <span
class="math display">\[\mathbb{Z} R
  \subseteq \mathfrak{h}_\mathbb{Z}^*
  \subseteq (\mathbb{Z} R^\wedge)^*\]</span> (called respectively the
<em>root lattice</em>, the <em>integers</em>, and the <em>weight
lattice</em>) and <span class="math display">\[\mathbb{Z} R^\wedge
  \subseteq \mathfrak{h}_\mathbb{Z}
  \subseteq (\mathbb{Z} R)^*,\]</span> (called respectively the
<em>coroot lattice</em>, the <em>integers</em>, and the <em>coweight
lattice</em>), where <span class="math inline">\(\mathbb{Z} R\)</span>
denotes the <span class="math inline">\(\mathbb{Z}\)</span>-span of
<span class="math inline">\(R\)</span>, <span
class="math inline">\(\mathbb{Z} R^\wedge\)</span> denotes the <span
class="math inline">\(\mathbb{Z}\)</span>-span of <span
class="math inline">\(R^\wedge\)</span>, <span
class="math display">\[(\mathbb{Z} R^\wedge)^* := \{\lambda \in
\mathfrak{h}_\mathbb{R}^* : \lambda(R^\wedge) \subseteq \mathbb{Z}
\}\]</span> and <span class="math display">\[(\mathbb{Z} R)^* := \{H \in
\mathfrak{h}_\mathbb{R} : R(H) \subseteq \mathbb{Z} \}.\]</span>
Pontryagin duality for finite abelian groups give us non-canonical
isomorphisms <span class="math display">\[\mathfrak{h}_\mathbb{Z}/
  \mathbb{Z} R^\wedge
  \cong (\mathbb{Z} R)^* /  \mathfrak{h}_\mathbb{Z}^*,
  \quad
  (\mathbb{Z} R)^*
  / \mathfrak{h}_\mathbb{Z}
  \cong
  \mathfrak{h}_\mathbb{Z}^*
  /
  \mathbb{Z} R.\]</span></p>
<div class="theorem">
<p><strong>Theorem 256</strong>. <em>The induced map <span
class="math inline">\(e : (\mathbb{Z} R)^* / \mathfrak{h}_\mathbb{Z}
\rightarrow \mathop{\mathrm{Center}}(K)\)</span> given by <span
class="math inline">\(e(x) := \exp(2 \pi i x)\)</span> is a well-defined
isomorphism.</em></p>
<p><em>The map <span class="math inline">\(f : \mathfrak{h}_\mathbb{Z} /
\mathbb{Z} R^\wedge \rightarrow \pi_1(K)\)</span>, sending <span
class="math inline">\(H\)</span> to the homotopy class <span
class="math inline">\([\gamma]\)</span> of the path <span
class="math inline">\(\gamma\)</span> given by <span
class="math inline">\(\gamma(t) := e(t H)\)</span>, is a well-defined
isomorphism.</em></p>
</div>
<p>We then explained in detail how this “recovers” the fact that <span
class="math inline">\(\pi_1(\mathop{\mathrm{SU}}(n)) =\{1\}\)</span>,
<span
class="math inline">\(\mathop{\mathrm{Center}}(\mathop{\mathrm{SU}}(n))
\cong \mathbb{Z}/n\)</span>.</p>
<p>The theorem will take a bit of preparation to prove; we start in the
next section.</p>
<h1 id="sec:orga4a1522">§33. Tori in compact Lie groups<span
id="sec:tori-compact-lie-gps"
label="sec:tori-compact-lie-gps"></span></h1>
<h2 id="sec:org2b9a950">§33.1. Basic definitions</h2>
<div class="definition">
<p><strong>Definition 257</strong>. A <em>torus</em> is a Lie group
isomorphic to <span class="math inline">\(T^k :=
(\mathbb{R}/\mathbb{Z})^k\)</span> for some <span
class="math inline">\(k \in \mathbb{Z}_{\geq 0}\)</span>.</p>
</div>
<div id="lem:Characterize-tori" class="lemma">
<p><strong>Lemma 258</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group. The following are
equivalent.</p>
<ol>
<li><p><span class="math inline">\(G\)</span> is a torus.</p></li>
<li><p><span class="math inline">\(G\)</span> is connected, compact and
abelian.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The forward direction is clear. Conversely, suppose
<span class="math inline">\(G\)</span> is connected, compact, and
abelian.</p>
<p>Since <span class="math inline">\(G\)</span> is connected and
abelian, we know (by part of Homework <a href="#hw:3-lie-first"
data-reference-type="ref" data-reference="hw:3-lie-first">3</a>) that
<span class="math inline">\(\exp : \mathfrak{g} \rightarrow G\)</span>
is a surjective homomorphism with discrete kernel <span
class="math inline">\(\Gamma\)</span>, thus <span
class="math inline">\(G \cong \mathfrak{g} / \Gamma\)</span>. Since
<span class="math inline">\(G\)</span> is compact, the subgroup <span
class="math inline">\(\Gamma\)</span> is discrete and cocompact. Fix an
isomorphism <span class="math inline">\(\mathfrak{g} \cong
\mathbb{R}^k\)</span>. One can show easily that every discrete cocompact
subgroup of <span class="math inline">\(\mathbb{R}^k\)</span> is given
by <span class="math inline">\(\mathbb{Z}^k\)</span> after a change of
coordinates. Thus <span class="math inline">\(G \cong
T^k\)</span>. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 259</strong>. Let <span
class="math inline">\(G\)</span> be a Lie group. A <em>torus in <span
class="math inline">\(G\)</span></em> is a closed subgroup <span
class="math inline">\(T \leq G\)</span> (hence a Lie subgroup) that is a
torus.</p>
</div>
<div class="remark">
<p><strong>Remark 260</strong>. Let <span
class="math inline">\(T\)</span> be a torus, let <span
class="math inline">\(G\)</span> be a Lie group, and let <span
class="math inline">\(j : T \rightarrow G\)</span> be a morphism of Lie
groups. Since <span class="math inline">\(T\)</span> is compact,
connected, and abelian, so is its image under <span
class="math inline">\(T\)</span>. Thus <span
class="math inline">\(j(T)\)</span> is a torus. In particular, immersed
Lie subgroups that are isomorphic to tori are in fact closed subgroups.
This explains why we restrict to closed subgroups in the previous
definition.</p>
</div>
<p>Hence let <span class="math inline">\(K\)</span> be a compact
connected Lie group with Lie algebra <span
class="math inline">\(\mathfrak{k}\)</span>.</p>
<div class="definition">
<p><strong>Definition 261</strong>. A <em>maximal torus</em> in <span
class="math inline">\(K\)</span> is a torus <span
class="math inline">\(T \leq K\)</span> that is not properly contained
in any torus in <span class="math inline">\(K\)</span>.</p>
</div>
<div class="exercise">
<p><strong>Exercise 36</strong>. The following are equivalent for a
closed connected subgroup <span class="math inline">\(T\)</span> of
<span class="math inline">\(K\)</span>:</p>
<ol>
<li><p><span class="math inline">\(T\)</span> is a torus.</p></li>
<li><p><span class="math inline">\(\mathfrak{t} :=
\mathop{\mathrm{Lie}}(T)\)</span> is an abelian subalgebra of <span
class="math inline">\(\mathfrak{k}\)</span>.</p></li>
</ol>
</div>
<p>Recall from a long time ago that if <span class="math inline">\(H_1,
H_2\)</span> are two connected Lie subgroups of the same Lie group,
then</p>
<ul>
<li><p><span class="math inline">\(\mathfrak{h}_1 =
\mathfrak{h}_2\)</span> if and only if <span class="math inline">\(H_1 =
H_2\)</span>,</p></li>
<li><p><span class="math inline">\(\mathfrak{h}_1 \subseteq
\mathfrak{h}_2\)</span> if and only if <span class="math inline">\(H_1
\subseteq H_2\)</span>,</p></li>
</ul>
<p>etc.</p>
<div id="lem:maximal-tori-vs-maximal-abelian-subalgebras" class="lemma">
<p><strong>Lemma 262</strong>. The following are equivalent for a closed
connected subgroup <span class="math inline">\(T\)</span> of <span
class="math inline">\(K\)</span>:</p>
<ol>
<li><p><span class="math inline">\(T\)</span> is a maximal
torus.</p></li>
<li><p><span class="math inline">\(\mathfrak{t} :=
\mathop{\mathrm{Lie}}(T)\)</span> is a maximal abelian subalgebra of
<span class="math inline">\(\mathfrak{k}\)</span> (i.e., an abelian
subalgebra that is not properly contained in any abelian
subalgebra.)</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Suppose <span class="math inline">\(T\)</span> is a
maximal torus. Let <span class="math inline">\(\mathfrak{t} &#39;
\supseteq \mathfrak{t}\)</span> be an abelian subalgebra that contains
<span class="math inline">\(\mathfrak{t}\)</span>. Suppose there exists
<span class="math inline">\(X \in \mathfrak{t}&#39; -
\mathfrak{t}\)</span>. Since <span class="math inline">\(\mathfrak{t}
&#39;\)</span> is abelian, we have <span
class="math inline">\([X,\mathfrak{t}] = 0\)</span>. Since <span
class="math inline">\(T\)</span> is connected, it follows (by the usual
differentiation/exponentiation technique) that the group <span
class="math display">\[H := \{e^{y X} t : y \in \mathbb{R}, t \in
T\}\]</span> is abelian. It is also connected. Hence its closure <span
class="math inline">\(\overline{H}\)</span> is abelian, connected, and
closed inside the compact Lie group <span
class="math inline">\(K\)</span>, hence compact, hence a torus (Lemma <a
href="#lem:Characterize-tori" data-reference-type="ref"
data-reference="lem:Characterize-tori">258</a>). By Theorem <a
href="#thm:closed-implies-lie" data-reference-type="ref"
data-reference="thm:closed-implies-lie">176</a>, <span
class="math inline">\({H}\)</span> is a Lie subgroup, so we may consider
its Lie algebra <span class="math inline">\(\mathfrak{h}\)</span>;
clearly <span class="math inline">\(\mathfrak{h}\)</span> contains <span
class="math inline">\(X\)</span> and <span
class="math inline">\(\mathfrak{t}\)</span>. Therefore the torus <span
class="math inline">\(H\)</span> has Lie algebra <span
class="math inline">\(\mathfrak{h}\)</span> properly containing <span
class="math inline">\(\mathfrak{t}\)</span>. By the old result recalled
above characterizing containments between closed Lie subgroups in terms
of containments of their Lie algebras, we deduce that <span
class="math inline">\(\overline{H}\)</span> is a torus properly
containing <span class="math inline">\(T\)</span>, which contradicts the
assumed maximality of <span class="math inline">\(T\)</span>.</p>
<p>Conversely, if <span class="math inline">\(\mathfrak{t}\)</span> is a
maximal abelian subalgebra and <span
class="math inline">\(T&#39;\)</span> is a torus properly containing
<span class="math inline">\(T\)</span>, then (by the same old fact
recalled above) its Lie algebra <span class="math inline">\(\mathfrak{t}
&#39;\)</span> properly contains <span
class="math inline">\(\mathfrak{t}\)</span> and is abelian,
contradicting the assumed maximality of <span
class="math inline">\(\mathfrak{t}\)</span>. ◻</p>
</span></div>
<div id="cor:self-centralizing-algebra-of-maximal-torus"
class="corollary">
<p><strong>Corollary 263</strong>. <em>Let <span class="math inline">\(T
\leq K\)</span> be a maximal torus in a compact Lie group. Let <span
class="math inline">\(\mathfrak{t} \leq \mathfrak{k}\)</span> be the
induced inclusion of LIe algebras. Then <span
class="math inline">\(\mathfrak{t}\)</span> is self-centralizing: <span
class="math inline">\(\{X \in \mathfrak{g} : [X,\mathfrak{t}] = 0\} =
\mathfrak{t}\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Otherwise there is <span class="math inline">\(X \in
\mathfrak{g}\)</span> so that <span
class="math inline">\([X,\mathfrak{t}] = 0\)</span>, hence <span
class="math inline">\(\mathfrak{t} &#39; := \mathbb{R} X +
\mathfrak{t}\)</span> is an abelian subalgebra of <span
class="math inline">\(\mathfrak{k}\)</span> that properly contains <span
class="math inline">\(\mathfrak{t}\)</span>. By Lemma <a
href="#lem:maximal-tori-vs-maximal-abelian-subalgebras"
data-reference-type="ref"
data-reference="lem:maximal-tori-vs-maximal-abelian-subalgebras">262</a>,
this does not happen. ◻</p>
</span></div>
<h2 id="sec:org56989a6">§33.2. Characters of tori</h2>
<div class="definition">
<p><strong>Definition 264</strong>. Let <span
class="math inline">\(T\)</span> be a torus. A <em>character</em> of
<span class="math inline">\(T\)</span> is a continuous homomorphism
<span class="math inline">\(\chi : T \rightarrow \mathbb{C}^{(1)} := \{z
\in \mathbb{C}^\times : |z| = 1\}\)</span>. The character group of <span
class="math inline">\(T\)</span> is the group <span
class="math inline">\(\mathfrak{X}(T)\)</span> consisting of all
characters; the group law is given by multiplication.</p>
</div>
<div class="lemma">
<p><strong>Lemma 265</strong>. Let <span
class="math inline">\(T\)</span> be a torus and let <span
class="math inline">\(R : T \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
be a representation on a finite-dimensional complex vector space. Then
<span class="math inline">\(V\)</span> decomposes as a direct sum of
invariant one-dimensional subspaces on which <span
class="math inline">\(T\)</span> acts by characters of <span
class="math inline">\(T\)</span>.</p>
<p>More precisely, one has <span class="math inline">\(V = \oplus_\chi
V^\chi\)</span>, where <span class="math inline">\(\chi\)</span>
traverses the set of characters of <span
class="math inline">\(T\)</span> and <span class="math inline">\(V^\chi
:= \{v \in V : R(t) = \chi(t) v\}\)</span>. Any subspace of <span
class="math inline">\(V^\chi\)</span> is invariant; by choosing a basis
for each <span class="math inline">\(V^\chi\)</span>, we obtain a
decomposition of <span class="math inline">\(V\)</span> as a sum of
one-dimensional invariant (irreducible) subspaces.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By §<a href="#sec:linear-reductivity-compact-groups"
data-reference-type="ref"
data-reference="sec:linear-reductivity-compact-groups">16.8</a>,
the representation is completely reducible. To complete the proof, we
just need to show that any irreducible representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\(T\)</span> is one-dimensional. To that end, it
suffices to show that each <span class="math inline">\(t \in T\)</span>
acts on <span class="math inline">\(V\)</span> by some scalar <span
class="math inline">\(\lambda\)</span>.</p>
<p>Indeed, let <span class="math inline">\(t_0 \in T\)</span> be given.
Since <span class="math inline">\(R(t_0) \in
\mathop{\mathrm{GL}}(V)\)</span> is a cmoplex matrix, it has some
(nonzero) eigenvector <span class="math inline">\(v_0 \in V\)</span> and
some eigenvalue <span class="math inline">\(\lambda \in
\mathbb{C}\)</span>. Consider the eigenspace <span
class="math inline">\(W := \{v \in V : R(t_0) v = \lambda v \}\)</span>.
Our goal is to show that <span class="math inline">\(W = V\)</span>.
Since <span class="math inline">\(V\)</span> is irreducible and <span
class="math inline">\(W\)</span> is nonzero (after all, it contains
<span class="math inline">\(v_0\)</span>), it sufficse to show that
<span class="math inline">\(W\)</span> is invariant. Here we use the
commutativity of <span class="math inline">\(T\)</span>: if <span
class="math inline">\(t \in T\)</span>, then <span
class="math inline">\(R(t_0) R(t) = R(t_0 t) = R(t t_0) = R(t)
R(t_0)\)</span>, hence for <span class="math inline">\(v \in V\)</span>,
we have <span class="math inline">\(R(t_0) R(t) v = R(t) \lambda v =
\lambda R(t) v\)</span>, hence <span class="math inline">\(R(t) v \in
W\)</span>, and so <span class="math inline">\(W\)</span> is <span
class="math inline">\(R(t)\)</span>-invariant, as required. ◻</p>
</span></div>
<div id="lem:characters-of-the-reals" class="lemma">
<p><strong>Lemma 266</strong>. Any continuous homomorphism <span
class="math inline">\(\chi : \mathbb{R} \rightarrow
\mathbb{C}^{(1)}\)</span> is of the form <span
class="math inline">\(\chi(x) = e(\xi x) := e^{2 \pi i \xi x}\)</span>
for some unique <span class="math inline">\(\xi \in
\mathbb{R}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> One can certainly do this directly, but we might as
well deduce it from stuff we’ve seen in class:</p>
<p>It is clear that <span class="math inline">\(x \mapsto e(\xi
x)\)</span> is a character for each <span class="math inline">\(\xi \in
\mathbb{R}\)</span>, and that for <span class="math inline">\(\xi_1 \neq
\xi_2\)</span>, the characters obtained in this way are distinct.</p>
<p>Conversely, recall that shortly after we proved the “closed subgroups
are Lie subgroups” theorem, we indicated in class and assigned on the
homework that continuous homomorphisms between Lie groups are
automatically smooth, hence determined by their differentials. In
particular, <span class="math inline">\(\chi : \mathbb{R} \rightarrow
\mathbb{C}^{(1)}\)</span> is determined by <span
class="math display">\[d \chi : \mathbb{R} =
\mathop{\mathrm{Lie}}(\mathbb{R}) \rightarrow i \mathbb{R} =
\mathop{\mathrm{Lie}}(\mathbb{C}^{(1)}),\]</span> which is then of the
form <span class="math inline">\(2 \pi i \xi\)</span> for some <span
class="math inline">\(\xi \in \mathbb{R}\)</span>, etc. ◻</p>
</span></div>
<p>One obtains an analogous classifciation of the characters of <span
class="math inline">\(\mathbb{R}^k\)</span> by taking products. From
this we deduce:</p>
<div id="lem:char-gp-of-Tk" class="lemma">
<p><strong>Lemma 267</strong>. The character group of <span
class="math inline">\(T^k\)</span> is isomorphic to <span
class="math inline">\(\mathbb{Z}^k\)</span>: to each <span
class="math inline">\(\xi = (\xi_1,\dotsc,\xi_k) \in
\mathbb{Z}^k\)</span> one associates the character <span
class="math inline">\(T^k = (\mathbb{R}/\mathbb{Z})^k \ni x =
(x_1,\dotsc,x_k) \mapsto e(\sum \xi_i x_i) \in
\mathbb{C}^{(1)}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> A character of <span
class="math inline">\(T^k\)</span> pulls back under the surjective
homomorphism <span class="math inline">\(\mathbb{R}^k \rightarrow
T^k\)</span> to a character of <span
class="math inline">\(\mathbb{R}^k\)</span>, which is in turn classified
by real numbers <span
class="math inline">\((\xi_1,\dotsc,\xi_k)\)</span>; conversely, such
real numbers induce a character of <span
class="math inline">\(T^k\)</span> precisely when they are all
integers. ◻</p>
</span></div>
<p>Let <span class="math inline">\(T\)</span> be a torus. Let <span
class="math inline">\(\mathfrak{t}\)</span> denote its Lie algebra and
<span class="math inline">\(\mathfrak{h} := \mathfrak{t}
\otimes_{\mathbb{R}} \mathbb{C}\)</span> the complexification thereof.
Set <span class="math inline">\(\mathfrak{h}_{\mathbb{R}} := i
\mathfrak{t} \leq \mathfrak{h}\)</span>. The map <span
class="math inline">\(e : \mathfrak{h}_\mathbb{R} \rightarrow T\)</span>
given by <span class="math inline">\(e(X) := \exp(2 \pi i X)\)</span> is
a surjective homomorphism with discrete cocompact kernel.</p>
<p>Let <span class="math inline">\(\chi : T \rightarrow
\mathbb{C}^{(1)}\)</span> be a character of <span
class="math inline">\(T\)</span>; as discussed above, it is smooth, so
we can consider its differential <span class="math inline">\(d \chi :
\mathfrak{t} \rightarrow i \mathbb{R}\)</span>, which identifies with a
linear map <span class="math inline">\(d \chi : \mathfrak{h}_\mathbb{R}
\rightarrow \mathbb{R}\)</span>. <span class="math inline">\(\chi(e(H))
= e(\lambda(H))\)</span> for some <span class="math inline">\(\lambda
\in \mathfrak{h}_\mathbb{R}^*\)</span>. Conversely, such a <span
class="math inline">\(\lambda\)</span> defines a character <span
class="math inline">\(\chi\)</span> if and only if it vanishes on <span
class="math inline">\(\mathfrak{h}_\mathbb{Z} := \ker(e :
\mathfrak{h}_\mathbb{R} \rightarrow T)\)</span>, i.e., if and only if it
belnogs to <span
class="math inline">\(\mathfrak{h}_\mathbb{Z}^*\)</span> as defined
earlier. In summary:</p>
<div class="lemma">
<p><strong>Lemma 268</strong>. Let <span
class="math inline">\(T\)</span> be a torus. Let <span
class="math inline">\(\mathfrak{h}_\mathbb{R} := i
\mathfrak{t}\)</span>, as above, so that <span class="math inline">\(e :
\mathfrak{h}_\mathbb{R} / \mathfrak{h}_\mathbb{Z} \rightarrow T\)</span>
is an isomorphism.</p>
<p>Then <span class="math inline">\(\mathfrak{X}(T) \cong
\mathfrak{h}_\mathbb{Z}^*\)</span> via the bijection <span
class="math inline">\(\chi \hookrightarrow \lambda\)</span>
characterized by <span class="math inline">\(2 \pi \lambda = d
\chi\)</span> and <span class="math inline">\(\chi(e(H)) =
e(\lambda(H))\)</span> for all <span class="math inline">\(H \in
\mathfrak{h}_\mathbb{R}^*\)</span>.</p>
</div>
<div id="defn:char-associated-to-functional" class="definition">
<p><strong>Definition 269</strong>. For <span
class="math inline">\(\lambda \in \mathfrak{h}_\mathbb{Z}^*\)</span>,
denote by <span class="math inline">\(e^\lambda\)</span> the character
of <span class="math inline">\(T\)</span> associated to it by the above
bijection, so that for all <span class="math inline">\(H \in
\mathfrak{h}_\mathbb{R}\)</span>, <span
class="math display">\[e^\lambda(e(H)) = e(\lambda(H)).\]</span> This
definition applies in particular to each <span
class="math inline">\(\alpha \in R \subseteq
\mathfrak{h}_\mathbb{Z}^*\)</span>.</p>
</div>
<h2 id="sec:org00a6b97">§33.3. Topologies on character groups<span
id="sec:tops-on-char-gps" label="sec:tops-on-char-gps"></span></h2>
<p>Let’s talk briefly about topology. Let <span
class="math inline">\(G\)</span> be a topological group. Let <span
class="math inline">\(\mathfrak{X}(G)\)</span> denote the set of
continuous homomorphisms <span class="math inline">\(\chi : G
\rightarrow \mathbb{C}^{(1)}\)</span>. (The notation is consistent with
that used above when <span class="math inline">\(G\)</span> is a torus.)
We equip <span class="math inline">\(\mathfrak{X}(G)\)</span> with the
“compact-open” topology. This means that a subbasis for the open sets in
<span class="math inline">\(\mathfrak{X}(G)\)</span> is given by cosets
of sets of the form <span class="math inline">\(V(C,U) := \{\chi \in
\mathfrak{X}(G) : \chi(C) \subseteq U\}\)</span>, where <span
class="math inline">\(C \subseteq T\)</span> is compact and <span
class="math inline">\(U \subseteq \mathbb{C}^{(1)}\)</span> is open.
Equivalently, a net <span class="math inline">\(\chi^{(\alpha)} \in
\mathfrak{X}(G)\)</span> converges to some <span
class="math inline">\(\chi \in \mathfrak{X}(G)\)</span> precisely when
it converges uniformly on compact sets in the ordinary sense. We may
define on <span class="math inline">\(\mathfrak{X}(G)\)</span> the
binary operation <span class="math inline">\(\cdot\)</span> given by
<span class="math inline">\((\chi_1 \cdot \chi_2)(g) := \chi_1(g)
\chi_2(g)\)</span>.</p>
<div class="exercise">
<p><strong>Exercise 37</strong>. Show that <span
class="math inline">\(\mathfrak{X}(G)\)</span> is a topological group
with respect to this operation.</p>
</div>
<div id="lem:cpct-group-dual-is-discrete" class="lemma">
<p><strong>Lemma 270</strong>. Suppose that <span
class="math inline">\(G\)</span> is compact. Then <span
class="math inline">\(\mathfrak{X}(G)\)</span> is discrete.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Take <span class="math inline">\(C := G\)</span> and
let <span class="math inline">\(U \subseteq \mathbb{C}^{(1)}\)</span> be
an interval of length <span class="math inline">\(1/10\)</span> with
center <span class="math inline">\(1 \in \mathbb{C}^{(1)}\)</span>. Let
<span class="math inline">\(\chi_0 \in \mathfrak{X}(G)\)</span> denote
the trivial character <span class="math inline">\(\chi_0(g) :=
1\)</span>. We claim that <span class="math inline">\(V(C,U) =
\{\chi_0\}\)</span>. Clearly <span class="math inline">\(\chi_0 \in
V(C,U)\)</span>. Conversely, let <span class="math inline">\(\chi \in
\mathfrak{X}(G) - \{\chi_0\}\)</span> be a nontrivial character, so that
there exists <span class="math inline">\(g \in G\)</span> for which
<span class="math inline">\(\chi(g) \neq 1\)</span>. Since <span
class="math inline">\(\chi(g) \in \mathbb{C}^{(1)} - \{1\}\)</span>, we
can find some power of it, say <span class="math inline">\(\chi(g)^n =
\chi(g^n)\)</span>, which has negative real part. But then <span
class="math inline">\(\chi(g^n) \notin U\)</span>, hence <span
class="math inline">\(\chi \notin V(C,U)\)</span>. We now use that a
topological group is discrete if and only if the set consisting of its
identity element is open (if this wasn’t an exercise before, it could be
now). ◻</p>
</span></div>
<p>The lemma applies notably to the case that <span
class="math inline">\(G\)</span> is a compact torus <span
class="math inline">\(T = (\mathbb{R}/\mathbb{Z})^k\)</span>. We saw
above that <span class="math inline">\(\mathfrak{X}(T) \cong
\mathbb{Z}^k\)</span> as groups. Lemma <a
href="#lem:cpct-group-dual-is-discrete" data-reference-type="ref"
data-reference="lem:cpct-group-dual-is-discrete">270</a> tells us
moreover that <span class="math inline">\(\mathfrak{X}(T)\)</span> and
<span class="math inline">\(\mathbb{Z}^k\)</span> are isomorphic as
topological groups, each equipped with the discrete topology.</p>
<h2 id="sec:org1044d7f">§33.4. Maximal tori give rise to Cartan
subalgebras</h2>
<div class="theorem">
<p><strong>Theorem 271</strong>. <em>Let <span
class="math inline">\(T\)</span> be a maximal torus in the compact
connected Lie group <span class="math inline">\(K\)</span>. Let <span
class="math inline">\(\mathfrak{t} \leq \mathfrak{k}\)</span> denote
their Lie algebras and <span class="math display">\[\mathfrak{h} :=
\mathfrak{t} \otimes \mathbb{C} \leq \mathfrak{g} := \mathfrak{k}
\otimes \mathbb{C}\]</span> the complexifications. Then <span
class="math inline">\(\mathfrak{h}\)</span> is a Cartan subalgebra of
<span class="math inline">\(\mathfrak{g}\)</span>. The roots are purely
imaginary on <span class="math inline">\(\mathfrak{t}\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> According to our definition, we must check that <span
class="math inline">\(\mathfrak{h}\)</span> is abelian, <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span>-diagonalizable, and
self-centralizing.</p>
<ol>
<li><p>Since <span class="math inline">\(T\)</span> is abelian, so is
<span class="math inline">\(\mathfrak{t}\)</span>, hence <span
class="math inline">\(\mathfrak{h}\)</span> is abelian.</p></li>
<li><p>Consider the adjoint action <span
class="math inline">\(\mathop{\mathrm{Ad}}: K \rightarrow
\mathop{\mathrm{End}}(\mathfrak{k})\)</span>. Restrict it to obtain
<span class="math inline">\(\mathop{\mathrm{Ad}}: T \rightarrow
\mathop{\mathrm{End}}(\mathfrak{k})\)</span>. Extend it complex-linearly
to obtain <span class="math inline">\(\mathop{\mathrm{Ad}}: T
\rightarrow \mathop{\mathrm{End}}(\mathfrak{g})\)</span>. Since <span
class="math inline">\(T\)</span> is compact, this complex linear
representation of it is completely reducible. By the previous lemma, it
decomposes as a direct sum of one-dimensional invariant subspaces.
Differentiating this fact, we see that <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{t})\)</span> and
hence (by linearity) <span
class="math inline">\(\mathop{\mathrm{ad}}(\mathfrak{h})\)</span> is
diagonalizable.</p>
<p>The functionals <span class="math inline">\(\lambda \in
\mathfrak{h}^*\)</span> for <span
class="math inline">\(\mathfrak{h}\)</span> acting on <span
class="math inline">\(\mathfrak{g}\)</span> by the adjoint map
correspond to the characters <span class="math inline">\(\chi\)</span>
of <span class="math inline">\(T\)</span> occurring in the decomposition
described above. It follows from our earlier discussion that each such
<span class="math inline">\(\lambda\)</span> is real-valued on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(V_0 := \{X \in \mathfrak{g} :
\mathop{\mathrm{Ad}}(t) X = X \text{ for all } t \in T\}\)</span> be the
subspace on which <span
class="math inline">\(\mathop{\mathrm{Ad}}(T)\)</span> acts trivially.
By the usual differentiation/exponentiation trick, we have <span
class="math display">\[V_0 = \{X \in \mathfrak{g} : [X,\mathfrak{t}] =
0\}\]</span> and <span class="math display">\[V_0 = \{X \in \mathfrak{g}
: [X,\mathfrak{h}] = 0\}\]</span> . From the first of these last two
equations and linear algebra, we have <span class="math display">\[V_0 =
\{X \in \mathfrak{k} : [X,\mathfrak{t}] = 0\} \otimes
\mathbb{C}.\]</span> By Corollary <a
href="#cor:self-centralizing-algebra-of-maximal-torus"
data-reference-type="ref"
data-reference="cor:self-centralizing-algebra-of-maximal-torus">263</a>,
we see that <span class="math inline">\(V_0 = \mathfrak{h}\)</span>.
This gives the required self-centralizing property of <span
class="math inline">\(\mathfrak{h}\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<p>In general Lie groups, nontrivial tori (let alone maximal ones) need
not exist. But in compact Lie groups, things are better:</p>
<div class="lemma">
<p><strong>Lemma 272</strong>. Let <span
class="math inline">\(K\)</span> be a compact connected Lie group. For
any torus <span class="math inline">\(S\)</span> in <span
class="math inline">\(K\)</span>, there is a maximal torus <span
class="math inline">\(T\)</span> in <span
class="math inline">\(K\)</span> that contains <span
class="math inline">\(S\)</span>. (Note that the trivial torus <span
class="math inline">\(S = \{1\}\)</span> always exists.)</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If <span class="math inline">\(S\)</span> is not
maximal, then it is contained in some strictly larger torus <span
class="math inline">\(S&#39;\)</span>, which then (by consideration of
LIe algebras) has strictly larger dimension. Iterating the procedure
<span class="math inline">\(S \mapsto S&#39;\)</span> finitely many
times, we wind up with a maximal torus. (We can’t iterate forever,
because <span class="math inline">\(\mathfrak{k}\)</span> is
finite-dimensional. ◻</p>
</span></div>
<h2 id="sec:org822bc0f">§33.5. Some notation involving roots<span
id="sec:notationinvolvingroots-for-amxl-tori-section"
label="sec:notationinvolvingroots-for-amxl-tori-section"></span></h2>
<p>So now we have the full theory of roots at our disposal. Let’s set up
some notation. Let <span class="math inline">\(K\)</span> be compact
connected, and let <span class="math inline">\(T \leq K\)</span> be a
maximal torus. Let <span
class="math inline">\(\mathfrak{h},\mathfrak{g}\)</span> be as above. We
can then decompose <span id="eq:root-space-decmop-for-compact-LIe-group-amxiaml-trous" class="math display">\[\label{eq:root-space-decmop-for-compact-LIe-group-amxiaml-trous}\tag{142}
  \mathfrak{g} = \mathfrak{h} \oplus (\oplus_{\alpha \in R}
\mathfrak{g}^\alpha)\]</span> where <span
class="math inline">\(R\)</span> is a finite subset of <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^* - \{0\}\)</span>. In
fact, the discussion above implies that <span class="math inline">\(R
\subseteq \mathfrak{h}_\mathbb{Z}^* - \{0\}\)</span>. For each <span
class="math inline">\(H \in \mathfrak{h}_\mathbb{R}\)</span> and <span
class="math inline">\(X \in \mathfrak{g}^\alpha\)</span>, we have <span
class="math display">\[= \alpha(H) X,\]</span> For <span
class="math inline">\(\lambda \in \mathfrak{h}_\mathbb{Z}^*\)</span>,
let <span class="math inline">\(e^\lambda \in \mathfrak{X}(T)\)</span>
be as in Definitnio <a href="#defn:char-associated-to-functional"
data-reference-type="ref"
data-reference="defn:char-associated-to-functional">269</a>. This
applies in particular to <span class="math inline">\(\alpha \in R
\subseteq \mathfrak{h}_\mathbb{Z}^*\)</span>, and the above identity
translates to: for <span class="math inline">\(t \in T\)</span> and
<span class="math inline">\(X \in \mathfrak{g}^\alpha\)</span>, <span
class="math display">\[\mathop{\mathrm{Ad}}(t) X = e^\alpha (t)
X.\]</span> Note also that if <span class="math inline">\(t =
e(H)\)</span> with <span class="math inline">\(H \in
\mathfrak{h}_\mathbb{R}\)</span>, then <span
class="math inline">\(e^\alpha (t) = e(\alpha(H))\)</span>, hence <span id="eq:how-ad-e-H-acts-on-X" class="math display">\[\label{eq:how-ad-e-H-acts-on-X}\tag{143}
  \mathop{\mathrm{Ad}}(e(H)) X = e(\alpha(H)) X.\]</span></p>
<h2 id="sec:orgc0705cb">§33.6. The automorphism group of a compact torus<span
id="sec:aut-gp-compact-torus"
label="sec:aut-gp-compact-torus"></span></h2>
<p>Let <span class="math inline">\(T\)</span> be a compact torus. Fix an
identification <span class="math inline">\(T =
(\mathbb{R}/\mathbb{Z})^k\)</span> for some <span
class="math inline">\(k \in \mathbb{Z}_{\geq 0}\)</span>. Then <span
class="math inline">\(T\)</span> is a compact Lie group. We may speak of
its automorphism group <span
class="math inline">\(\mathop{\mathrm{Aut}}(T)\)</span>. By definition,
this consists of continuous homomorphisms <span
class="math inline">\(\sigma : T \rightarrow T\)</span> that admit
continuous inverse homomorphisms. We may identify <span
class="math inline">\(\mathfrak{t} := \mathop{\mathrm{Lie}}(T)\)</span>
with <span class="math inline">\(\mathbb{R}^k\)</span>. Since <span
class="math inline">\(T\)</span> is connected, any such <span
class="math inline">\(\sigma\)</span> is determined by its differential
<span class="math inline">\(d \sigma : \mathbb{R}^k \rightarrow
\mathbb{R}^k\)</span>, which is a linear map, call it <span
class="math inline">\(A\)</span>. Since the exponential map <span
class="math inline">\(\mathfrak{t} \rightarrow T\)</span> is given with
respect to our identifications by the natural projection <span
class="math inline">\(\mathbb{R}^k \rightarrow \mathbb{R}^k /
\mathbb{Z}^k\)</span>, we see that <span
class="math inline">\(\sigma\)</span> is the map induced by a linear map
<span class="math inline">\(A : \mathbb{R}^k \rightarrow
\mathbb{R}^k\)</span>. For <span class="math inline">\(\sigma\)</span>
to be well-defined, we must have <span
class="math inline">\(A(\mathbb{Z}^k) \subseteq \mathbb{Z}^k\)</span>.
For <span class="math inline">\(\sigma\)</span> to be an isomorphism,
its inverse <span class="math inline">\(\sigma^{-1}\)</span> should
exist and be well-defined, and so we should have <span
class="math inline">\(A(\mathbb{Z}^k) = \mathbb{Z}^k\)</span>. But <span
class="math inline">\(\{A \in {\mathop{\mathrm{GL}}}_k(\mathbb{R}) : A
\mathbb{Z}^k = \mathbb{Z}^k\} =
{\mathop{\mathrm{GL}}}_k(\mathbb{Z})\)</span>. We may thereby identify
<span class="math display">\[\mathop{\mathrm{Aut}}(T) \cong
{\mathop{\mathrm{GL}}}_k(\mathbb{Z}).\]</span> We define the topology on
<span class="math inline">\(\mathop{\mathrm{Aut}}(T)\)</span> in this
case to be the discrete topology.</p>
<p>There’s another “transposed” way to make the above identification.
Given an automorphism <span class="math inline">\(\sigma\)</span> of
<span class="math inline">\(T\)</span>, we can attach the induced
automorphism <span class="math inline">\(\sigma^t\)</span> of <span
class="math inline">\(\mathfrak{X}(T)\)</span>, which sends a character
<span class="math inline">\(\chi\)</span> of <span
class="math inline">\(T\)</span> to the new character <span
class="math inline">\(\sigma^t \chi \in \mathfrak{X}(T)\)</span> given
by <span class="math inline">\(\sigma^t \chi(t) := \chi(\sigma
t)\)</span>. The map <span
class="math display">\[\mathop{\mathrm{Aut}}(T) \ni \sigma \mapsto
\sigma^{-t} := (\sigma^t)^{-1} = (\sigma^{-1})^t \in
\mathop{\mathrm{Aut}}(\mathfrak{X}(T))\]</span> is an isomorphism. Since
<span class="math inline">\(\mathfrak{X}(T) \cong \mathbb{Z}^k\)</span>,
we have <span
class="math inline">\(\mathop{\mathrm{Aut}}(\mathfrak{X}(T)) =
{\mathop{\mathrm{GL}}}_k(\mathbb{Z})\)</span>.</p>
<h2 id="sec:orga53673f">§33.7. Generators<span id="sec:gens-tori"
label="sec:gens-tori"></span></h2>
<p>Recall that an abstract group <span class="math inline">\(G\)</span>
is said to be <em>cyclic</em> if it admits a <em>generator</em>, i.e.,
an element <span class="math inline">\(g \in G\)</span> for which <span
class="math inline">\(G = \{g^n : n \in \mathbb{Z} \}\)</span>. There
aren’t so many cyclic groups; they are all isomorphic either to <span
class="math inline">\(\mathbb{Z}\)</span> or <span
class="math inline">\(\mathbb{Z}/n\)</span> for some <span
class="math inline">\(n \in \mathbb{Z}_{\geq 1}\)</span>.</p>
<p>Given a topological group <span class="math inline">\(G\)</span>, one
says that <span class="math inline">\(G\)</span> is <em>topologically
cyclic</em> if it admits a <em>topological generator</em>, i.e., an
element <span class="math inline">\(g \in G\)</span> for which <span
class="math inline">\(G = \overline{\{g^n : n \in \mathbb{Z}
\}}\)</span> where <span class="math inline">\(\overline{.}\)</span>
denotes closure. For example, any abstract cyclic group (equipped with
the discrete topology or any other topology, for that matter) is
topologically cyclic, and any generator in the group-theoretic sense is
a topological generator, but there are more interesting examples of
topologically cyclic groups than just those that are cyclic in the
ordinary sense. (For example: the profinite integers <span
class="math inline">\(\hat{\mathbb{Z} }\)</span>, the <span
class="math inline">\(p\)</span>-adic integers <span
class="math inline">\(\mathbb{Z}_p\)</span>, etc.)</p>
<p>For our purposes, it will be useful to know that compact tori are
topologically cyclic:</p>
<div class="lemma">
<p><strong>Lemma 273</strong>. Let <span class="math inline">\(T \cong
\mathbb{R}^k/\mathbb{Z}^k\)</span> be a compact torus. Then the set of
topological generators of <span class="math inline">\(T\)</span> is
dense; in particular, it is nonempty.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We presented the simple pigeonholing argument in
lecture. Fix a countable basis <span
class="math inline">\(B_1,B_2,\dotsc\)</span> for <span
class="math inline">\(T\)</span>. Take any open subset <span
class="math inline">\(U\)</span> of <span
class="math inline">\(T\)</span>. We want to show that we can find <span
class="math inline">\(g \in U\)</span> so that for each <span
class="math inline">\(i \in \mathbb{Z}_{\geq 1}\)</span> there exists an
<span class="math inline">\(n \in \mathbb{Z}\)</span> so that <span
class="math inline">\(g^n \in B_i\)</span>. (Then we’re done.)</p>
<p>We now aim to construct such a <span
class="math inline">\(g\)</span>. For convenience of notation, let us
realize <span class="math inline">\(T\)</span> as the additive group
<span class="math inline">\(\mathbb{R}^k/\mathbb{Z}^k\)</span>. We aim
to find for each <span class="math inline">\(i \in \mathbb{Z}_{\geq
1}\)</span></p>
<ul>
<li><p>a nonempty open set <span class="math inline">\(U_i\)</span>,
and</p></li>
<li><p>an integer <span class="math inline">\(N_i\)</span></p></li>
</ul>
<p>so that <span class="math inline">\(U \supseteq U_1 \supseteq U_2
\supseteq U_3 \supseteq \dotsb\)</span> and so that the set <span
class="math inline">\(N_i U_i := \{n_i c_i : n_i \in N_i, c_i \in
U_i\}\)</span> is contained in <span
class="math inline">\(B_i^0\)</span>, where <span
class="math inline">\(B_i^0\)</span> denotes an open subset of <span
class="math inline">\(B_i\)</span> for which <span
class="math inline">\(\overline{B_i^0} \subseteq B_i\)</span>. To do
this, set <span class="math inline">\(U_0 := U\)</span>. For each <span
class="math inline">\(i=1,2,3, \dotsc\)</span>, choose <span
class="math inline">\(N_i\)</span> large enough that <span
class="math inline">\(N_i U_{i-1} = T\)</span>. This is possible because
<span class="math inline">\(U_{i-1}\)</span> is open. Then set <span
class="math inline">\(U_i := \{u \in U_{i-1} : N_i u \in
B_i^0\}\)</span>.</p>
<p>The set <span class="math inline">\(\cap_i \overline{U_i}\)</span> is
nonempty by the finite intersection property. Any element of it is
easily seen to be a generator. ◻</p>
</span></div>
<p>Since we are primarily interested in topological groups here (or
indeed, in Lie groups), we henceforth abuse terminology slightly by
saying <em>generator</em> when we really mean “topological
generator.”</p>
<p>Generators are nice. For example, suppose <span
class="math inline">\(g \in K\)</span> satisfies <span
class="math inline">\(g t g^{-1} = t\)</span> for some generator <span
class="math inline">\(t\)</span> of <span
class="math inline">\(T\)</span>. Then also <span
class="math inline">\(g t^n g^{-1} = t^n\)</span> for all <span
class="math inline">\(n \in \mathbb{Z}\)</span>. Since the set of all
<span class="math inline">\(x \in K\)</span> for which <span
class="math inline">\(g x g^{-1} = x\)</span> is closed, we deduce that
<span class="math inline">\(g x g^{-1} = x\)</span> holds for all <span
class="math inline">\(x \in T\)</span>, i.e., that <span
class="math inline">\(g\)</span> centralizes <span
class="math inline">\(T\)</span>. We shall use arguments along these
lines repeatedly.</p>
<h2 id="sec:org8429097">§33.8. A maximal torus is the connected component of
its normalizer</h2>
<p>Let <span class="math inline">\(T\)</span> be a torus in a compact
connected Lie group <span class="math inline">\(K\)</span>. Let <span
class="math inline">\(N(T) := \{g \in K : g T g^{-1} = T\}\)</span>
denote its normalizer. The condition defining <span
class="math inline">\(N(T)\)</span> is closed, so <span
class="math inline">\(N(T)\)</span> is a closed subgroup of <span
class="math inline">\(K\)</span>, hence is a Lie subgroup of <span
class="math inline">\(K\)</span>. (One can also show this more directly
along the lines of §<a href="#sec:detect-lie-stabilizers"
data-reference-type="ref"
data-reference="sec:detect-lie-stabilizers">25.3</a>.)
We can thus speak of the connected component <span
class="math inline">\(N(T)_0\)</span>. In general, <span
class="math inline">\(N(T)_0\)</span> can be quite large. For example,
if <span class="math inline">\(T = \{1\}\)</span> is the trivial torus,
then <span class="math inline">\(N(T) = N(T)_0 = 0\)</span>.
However:</p>
<div class="lemma">
<p><strong>Lemma 274</strong>. Suppose <span
class="math inline">\(T\)</span> is maximal. Then <span
class="math inline">\(N(T)_0 = T\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Consider the map <span class="math inline">\(f :
N(T)_0 \rightarrow \mathop{\mathrm{Aut}}(T)\)</span> given by <span
class="math inline">\(f(n) := [t \mapsto n t n^{-1}]\)</span>. The
domain <span class="math inline">\(N(T)_0\)</span> is connected, and the
target <span class="math inline">\(\mathop{\mathrm{Aut}}(T)\)</span> is
discrete. Assuming for now that <span class="math inline">\(f\)</span>
is continuous, it follows that its image must consist of a point, and so
<span class="math inline">\(N(T)_0\)</span> actually centralizes <span
class="math inline">\(T\)</span>. Suppose that <span
class="math inline">\(N(T)_0\)</span> strictly contains <span
class="math inline">\(T\)</span>. Since they are both connected Lie
groups, this implies that we can find <span class="math inline">\(X \in
\mathfrak{k}, X \notin \mathfrak{t}\)</span> that commutes with all of
<span class="math inline">\(\mathfrak{t}\)</span>. But this contradicts
Corollary <a href="#cor:self-centralizing-algebra-of-maximal-torus"
data-reference-type="ref"
data-reference="cor:self-centralizing-algebra-of-maximal-torus">263</a>.</p>
<p>It remains to verify that <span class="math inline">\(f\)</span> is
continuous. Let <span class="math inline">\(\chi_1, \dotsc,
\chi_k\)</span> be a <span
class="math inline">\(\mathbb{Z}\)</span>-basis for the character group
<span class="math inline">\(\mathfrak{X}(T) \cong \mathbb{Z}^k\)</span>.
As in the discussion at the end of §<a href="#sec:aut-gp-compact-torus"
data-reference-type="ref"
data-reference="sec:aut-gp-compact-torus">33.6</a>,
we can think of <span class="math inline">\(f(n)^{-t} \in
\mathop{\mathrm{Aut}}(\mathfrak{X}(T))\)</span>. Suppose that <span
class="math inline">\((n_i)_{i \in \mathbb{Z}_{\geq 1}}\)</span> is a
sequence of elements in <span class="math inline">\(N(T)\)</span>
tending to some limit <span class="math inline">\(n \in N(T)\)</span>.
Then we have to check that <span class="math inline">\(f(n_i)^{-t}
\rightarrow f(n)^{-t} \in \mathfrak{X}(T)\)</span> with respect to the
discrete topology. This means that we have to show that for <span
class="math inline">\(i\)</span> large enough, one has <span
class="math inline">\(f(n_i)^{-t} = f(n)^{-t}\)</span>. Equivalently, we
have to show for each <span class="math inline">\(j \in
\{1..k\}\)</span>, one has <span class="math inline">\(f(n_i)^{-t}
\chi_j = f(n)^{-t} \chi_j\)</span> for <span
class="math inline">\(i\)</span> large enough. Since the character group
<span class="math inline">\(\mathfrak{X}(T)\)</span> is discrete (see
§<a href="#sec:tops-on-char-gps" data-reference-type="ref"
data-reference="sec:tops-on-char-gps">33.3</a>), it
suffices to show that <span class="math inline">\(f(n_i)^{-t}
\chi_j\)</span> converges to <span class="math inline">\(f(n)^{-t}
\chi_j\)</span> as functions, uniformly on compact sets. This follows
immediately from the continuity of the conjugation action of <span
class="math inline">\(N(T)\)</span> on <span
class="math inline">\(T\)</span> and the compactness of <span
class="math inline">\(T\)</span>.</p>
<p>(There are probably simpler or slicker ways to write this proof; I
hope in any event that it’s clear.) ◻</p>
</span></div>
<div class="corollary">
<p><strong>Corollary 275</strong>. <em>Let <span
class="math inline">\(T\)</span> be a maximal torus. Then the quotient
<span class="math inline">\(N(T) / T\)</span> is finite.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Indeed, that quotient identifies with the set <span
class="math inline">\(N(T) / N(T)_0\)</span> of connected components of
<span class="math inline">\(N(T)\)</span>. Since <span
class="math inline">\(K\)</span> is compact and <span
class="math inline">\(N(T)\)</span> is closed, we see also that <span
class="math inline">\(N(T)\)</span> is compact, hence has only finitely
many connected components. ◻</p>
</span></div>
<h2 id="sec:orgb02c776">§33.9. Conjugacy of maximal tori</h2>
<p>Let <span class="math inline">\(K\)</span> be a compact connected Lie
group <span class="math inline">\(K\)</span>. Note that if <span
class="math inline">\(T\)</span> is a maximal torus in <span
class="math inline">\(K\)</span>, then so is its conjugate <span
class="math inline">\(g T g^{-1}\)</span> for any <span
class="math inline">\(g \in K\)</span>. Here’s the big theorem on
maximal tori in compact Lie groups:</p>
<div id="thm:maximal-tori-conjugates-exhaust-K" class="theorem">
<p><strong>Theorem 276</strong>. <em>Let <span
class="math inline">\(T\)</span> be a maximal torus in a compact
connected Lie group <span class="math inline">\(K\)</span>. Then <span
class="math inline">\(K = \cup_{g \in K} g T g^{-1}\)</span>.</em></p>
</div>
<p>The (standard) proof we’ll record uses the Lefschetz fixed point
theorem. That theorem (or one variant of it) says that for a compact
manifold <span class="math inline">\(M\)</span>, one can attach to each
continuous map <span class="math inline">\(f : M \rightarrow M\)</span>
an integer <span class="math inline">\(\Lambda(f)\)</span> with the
following properties:</p>
<ol>
<li><p><span class="math inline">\(\Lambda(f)\)</span> only depends upon
the homotopy class of <span class="math inline">\(f\)</span>.</p></li>
<li><p>If <span class="math inline">\(f\)</span> has <em>isolated simple
fixed points</em>, that is to say, if the set <span
class="math inline">\(\mathop{\mathrm{Fix}}(f) := \{x \in M : f(x) =
x\}\)</span> is finite and if for each <span class="math inline">\(x \in
\mathop{\mathrm{Fix}}(f)\)</span>, the linear map <span
class="math inline">\(T_x f : T_x M \rightarrow T_{f(x)} M = T_x
M\)</span> satisfies <span class="math inline">\(\det(1 - T_x f) \neq
0\)</span>, then <span class="math display">\[\Lambda(f) = \sum_{x \in
\mathop{\mathrm{Fix}}(f)} \varepsilon_x(f),\]</span> where <span
class="math inline">\(\varepsilon_x(f) \in \{\pm 1\}\)</span> denotes
the sign of the nonzero real number <span class="math inline">\(\det(1 -
T_x f) \in \mathbb{R}^\times\)</span>.</p></li>
</ol>
<p>In particular, if <span
class="math inline">\(\mathop{\mathrm{Fix}}(f) = \emptyset\)</span>,
then <span class="math inline">\(\Lambda(f) = 0\)</span>. This is a
theorem from algebraic topology that we won’t prove. We record the
definition anyway: <span class="math display">\[\Lambda(f) = \sum_{i \in
\mathbb{Z}_{\geq 0}} (-1)^i \mathop{\mathrm{trace}}(f^* |
H^i(M,\mathbb{Q}))\]</span> where the RHS involves singular cohomology
groups with rational coefficients. For the identity map <span
class="math inline">\(1 : M \rightarrow M\)</span>, one writes <span
class="math inline">\(\chi(M) := \Lambda(1)\)</span>. The quantity <span
class="math display">\[\chi(M) = \sum_{i \in \mathbb{Z}_{\geq 0}} (-1)^i
\mathop{\mathrm{trace}}(f^* | H^i(M,\mathbb{Q}))\]</span> is called the
<em>Euler characteristic</em> of <span
class="math inline">\(M\)</span>.</p>
<p>Anyway, back to our goal. We want to show that for each <span
class="math inline">\(x \in K\)</span>, there exists <span
class="math inline">\(g \in K\)</span> so that <span
class="math inline">\(x \in g T g^{-1}\)</span>, or equivalently, so
that <span class="math inline">\(x g \in g T\)</span>, or equivalently,
so that <span class="math inline">\(x g T = g T\)</span>. In other
words, we want to show that the map <span class="math display">\[f_x :
K/T \rightarrow K/T\]</span> <span class="math display">\[f_x(g T) := x
g T\]</span> has a fixed point. The manifold <span
class="math inline">\(K/T\)</span> is compact (since <span
class="math inline">\(K\)</span> is), so we can apply the Lefschetz
theorem. Assuming for the sake of contradiction that <span
class="math inline">\(f_x\)</span> had no fixed point, we’d deduce from
the Lefschetz that <span class="math inline">\(\Lambda(f_x) =
0\)</span>. Let’s note that since <span class="math inline">\(K\)</span>
is a connected manifold, it is path-connected. For any <span
class="math inline">\(x,y \in K\)</span>, we can find a path connected
them; that path induces a homotopy between the maps <span
class="math inline">\(f_x\)</span> and <span
class="math inline">\(f_y\)</span>, and in particular between them and
the identity map <span class="math inline">\(f_1\)</span>, for which
<span class="math inline">\(\Lambda(f_1) = \chi(M)\)</span>. So we’re
done if we can show that <span class="math inline">\(\chi(M) \neq
0\)</span>. We’ll actually show more precisely that <span
class="math display">\[\chi(M) = \# N(T)/T.\]</span> As noted above, we
can compute <span class="math inline">\(\chi(M)\)</span> as <span
class="math inline">\(\Lambda(f_x)\)</span> for <em>any</em> <span
class="math inline">\(x \in K\)</span>. It is convenient to take for
<span class="math inline">\(x\)</span> a generator (see §<a
href="#sec:gens-tori" data-reference-type="ref"
data-reference="sec:gens-tori">33.7</a>) of the torus <span
class="math inline">\(T\)</span>. What, then, are the fixed points of
<span class="math inline">\(f_x\)</span>? Well, <span
class="math inline">\(g T \in \mathop{\mathrm{Fix}}(f_x)\)</span> if and
only if <span class="math inline">\(x g T = g T\)</span>, i.e., <span
class="math inline">\(g^{-1} x g \in T\)</span>; but since <span
class="math inline">\(x\)</span> generates <span
class="math inline">\(T\)</span>, it follows then that <span
class="math inline">\(g^{-1} T g \subseteq T\)</span>. One can then see
in many ways that <span class="math inline">\(g^{-1} T g = T\)</span>.
(For example, they are both maximal tori.) Hence <span
class="math inline">\(g \in N(T)\)</span>. Thus <span
class="math inline">\(\mathop{\mathrm{Fix}}(f_x) = N(T) /
T\)</span>.</p>
<p>Henceforth abbreviate <span class="math inline">\(f := f_x\)</span>.
For each <span class="math inline">\(g \in N(T) / T\)</span>, we have a
commutative diagram as drawn in class which shows that <span
class="math inline">\(\det(1 - T_{g T} f | T_{g T}(G/T))\)</span> is
independent of <span class="math inline">\(g\)</span>, so we henceforth
focus on the case that <span class="math inline">\(g T = e T\)</span> is
the identity coset.</p>
<p>We can then identify <span class="math display">\[T_{e T}(G/T) =
\mathfrak{k} / \mathfrak{t}\]</span> and hence <span
class="math display">\[T_{e T}(G/T)_{\mathbb{C}} = \mathfrak{g} /
\mathfrak{h} \cong \oplus_{\alpha \in R} \mathfrak{g}^\alpha.\]</span>
with the usual notation. Let’s write <span class="math inline">\(x =
e(H)\)</span> for some <span class="math inline">\(H \in
\mathfrak{h}_\mathbb{R}\)</span>. Our assumption that <span
class="math inline">\(x\)</span> is a generator entails in particular
that <span class="math inline">\(e(\alpha(H)) \neq 1\)</span> for all
<span class="math inline">\(\alpha \in R\)</span>, as otherwise <span
class="math inline">\(x\)</span> would belong to the codimension <span
class="math inline">\(1\)</span> submanifold of <span
class="math inline">\(T\)</span> consisting of elements <span
class="math inline">\(e(H)\)</span> for which <span
class="math inline">\(e(\alpha(H)) = 1\)</span>. By linear algebra, we
can compute determinants after complexifying. We can also write <span
class="math display">\[T_x f : T_{e T}(G/T)_{\mathbb{C}} \rightarrow
T_{e T}(G/T) _{\mathbb{C}}\]</span> as <span
class="math display">\[\mathop{\mathrm{Ad}}(x) :
\mathfrak{g}/\mathfrak{h} \rightarrow \mathfrak{g}/\mathfrak{h}\]</span>
because, since <span class="math inline">\(x \in T\)</span>, one has
<span class="math display">\[x g T = x g x^{-1} T.\]</span> Thus <span
class="math display">\[\det(1 - T_{e T} f | T_{e T}(G/T)) =
\prod_{\alpha \in R} \det(1 - \mathop{\mathrm{Ad}}(x) |
\mathfrak{g}^\alpha).\]</span> On the other hand <span
class="math display">\[\det(1 - \mathop{\mathrm{Ad}}(x) |
\mathfrak{g}^\alpha) = 1 - e(\alpha(H)).\]</span> We can split the
product into a product over pairs <span class="math inline">\(\pm \alpha
\in R / \{\pm 1\}\)</span> taken up to sign, giving <span
class="math display">\[\det(1 - T_{e T} f | T_{e T}(G/T)) = \prod_{\pm
\alpha \in R} (1 - e(\alpha(H))) (1 - e(-\alpha(H))).\]</span> For each
<span class="math inline">\(\alpha \in R\)</span>, write <span
class="math inline">\(\theta := 2 \pi i \alpha(H)\)</span>. Then <span
class="math display">\[0 \neq (1 - e(\alpha(H))) (1 - e(-\alpha(H))) =
(1 - e^{i \theta}) (1 - e^{-i \theta}) = 2 - 2 \cos(\theta) \geq
0.\]</span> We conclude that <span class="math display">\[\det(1 - T_{e
T} f | T_{e T}(G/T)) &gt; 0\]</span> hence that (as explained more
carefully in class via a commutative diagram) <span
class="math display">\[\det(1 - T_{g T} f | T_{e T}(G/T)) &gt; 0 \text{
for each } g \in N(T)/T\]</span> hence that <span
class="math inline">\(f\)</span> has isolated fixed points <span
class="math inline">\(g T\)</span> with signs <span
class="math inline">\(\varepsilon_{g T}(f) = 1\)</span>. Therefore <span
class="math display">\[\Lambda(f) = \# N(T)/T,\]</span> as required.</p>
<h2 id="sec:org3dd568d">§33.10. Basic consequences of the conjugacy
theorem.</h2>
<p>Let <span class="math inline">\(K\)</span> be a connected compact Lie
group, and let all other notation be as usual. For now, we indicate some
consequecnes relevant for answering the questions raised last time.</p>
<div id="cor:center-is-intersection-of-maxiaml-tori" class="corollary">
<p><strong>Corollary 277</strong>. <em>The center <span
class="math inline">\(Z\)</span> of <span
class="math inline">\(K\)</span> is the intersection <span
class="math inline">\(\cap T\)</span> of all (maximal) tori.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(z \in Z\)</span>, and
let <span class="math inline">\(T\)</span> be a maximal torus. By the
theorem, we may write <span class="math inline">\(z = g t
g^{-1}\)</span> for some <span class="math inline">\(t \in T\)</span>.
But then <span class="math inline">\(t = g^{-1} z g = z\)</span>,
because <span class="math inline">\(z\)</span> is in the center. Hence
<span class="math inline">\(z\)</span> belongs to <span
class="math inline">\(T\)</span>.</p>
<p>Conversely, suppose <span class="math inline">\(z \in K\)</span>
belongs to <span class="math inline">\(\cap T\)</span>. Let <span
class="math inline">\(x \in K\)</span>; we must show that <span
class="math inline">\(x\)</span> and <span
class="math inline">\(z\)</span> commute. To that end, we apply Theorem
<a href="#thm:maximal-tori-conjugates-exhaust-K"
data-reference-type="ref"
data-reference="thm:maximal-tori-conjugates-exhaust-K">276</a> to find a
maximal torus <span class="math inline">\(T\)</span> that contains <span
class="math inline">\(x\)</span>. Then <span
class="math inline">\(T\)</span> contains <span
class="math inline">\(z\)</span> and <span
class="math inline">\(x\)</span>; since <span
class="math inline">\(T\)</span> is commutative, the elements <span
class="math inline">\(x\)</span> and <span
class="math inline">\(z\)</span> commute, as required. ◻</p>
</span></div>
<div class="theorem">
<p><strong>Theorem 278</strong>. <em>Let <span
class="math inline">\(T\)</span> be a maximal torus in the compact
connecteed Lie group <span class="math inline">\(K\)</span>. Let <span
class="math inline">\(\mathfrak{h}_\mathbb{R} := i \mathfrak{t}\)</span>
and <span class="math inline">\(e : \mathfrak{h}_\mathbb{R}/h_\mathbb{Z}
\xrightarrow{\cong }T\)</span> be as usual. Let <span
class="math inline">\(R\)</span> denote the set of roots for <span
class="math inline">\(\mathfrak{h} := \mathfrak{t} \otimes
\mathbb{C}\)</span> acting on <span class="math inline">\(\mathfrak{g}
:= \mathfrak{k} \otimes \mathbb{C}\)</span> by the adjiont
representation. Let <span class="math inline">\(Z\)</span> denote the
center of <span class="math inline">\(K\)</span>. Then <span
class="math inline">\(e\)</span> induces an isomorphism <span
class="math display">\[(\mathbb{Z} R)^* /\mathfrak{h}_\mathbb{Z} \cong
Z.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By Corollary <a
href="#cor:center-is-intersection-of-maxiaml-tori"
data-reference-type="ref"
data-reference="cor:center-is-intersection-of-maxiaml-tori">277</a>,
<span class="math inline">\(Z\)</span> is contained in <span
class="math inline">\(T\)</span>, hence the image of <span
class="math inline">\(e\)</span> contains <span
class="math inline">\(Z\)</span>. To complete the proof, all that
remains to be showed is the following: for <span class="math inline">\(H
\in \mathfrak{h}_\mathbb{R}\)</span>, we have <span
class="math inline">\(e(H) \in Z\)</span> if and only if <span
class="math inline">\(H \in (\mathbb{Z} R)^\wedge\)</span>. This
equivalence is demonstrated by noting that each of the following
assertions is evidently equivalent to the next:</p>
<ol>
<li><p><span class="math inline">\(e(H) \in Z\)</span>.</p></li>
<li><p><span class="math inline">\(e(H) \in
\ker(\mathop{\mathrm{Ad}})\)</span> (using here that <span
class="math inline">\(K\)</span> is connected)</p></li>
<li><p><span class="math inline">\(e(\alpha(H)) = 1\)</span> for all
<span class="math inline">\(\alpha \in R\)</span> (use <a
href="#eq:root-space-decmop-for-compact-LIe-group-amxiaml-trous"
data-reference-type="eqref"
data-reference="eq:root-space-decmop-for-compact-LIe-group-amxiaml-trous">\((142)\)</a>
and <a href="#eq:how-ad-e-H-acts-on-X" data-reference-type="eqref"
data-reference="eq:how-ad-e-H-acts-on-X">\((143)\)</a>,
and note that <span
class="math inline">\(\mathop{\mathrm{Ad}}(e(H))\)</span> acts trivially
on <span class="math inline">\(\mathfrak{h}\)</span> because <span
class="math inline">\(\mathfrak{t}\)</span> is abelian)</p></li>
<li><p><span class="math inline">\(\alpha(H) \in \mathbb{Z}\)</span> for
all <span class="math inline">\(\alpha \in R\)</span> (because <span
class="math inline">\(\mathbb{Z} = \{x \in \mathbb{R} : e^{2 \pi i x} =
1\}\)</span>)</p></li>
<li><p><span class="math inline">\(H \in (\mathbb{Z} R)^*\)</span> (by
definition of the latter).</p></li>
</ol>
<p> ◻</p>
</span></div>
<div class="lemma">
<p><strong>Lemma 279</strong>. Let <span class="math inline">\(T_1,
T_2\)</span> be maximal tori in <span class="math inline">\(K\)</span>.
Then <span class="math inline">\(T_1,T_2\)</span> are conjugate.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Choose a generator <span
class="math inline">\(t_1\)</span> for <span
class="math inline">\(T_1\)</span>. By the cnojugacy theorem, we may
find <span class="math inline">\(g \in G\)</span> so that <span
class="math inline">\(g t_1 g^{-1} \in T_2\)</span>. Since <span
class="math inline">\(t_1\)</span> is a generator, it follows that <span
class="math inline">\(g T_1 g^{-1} \subseteq T_2\)</span>. Since <span
class="math inline">\(T_1,T_2\)</span> are both maximal, we conclude
that <span class="math inline">\(g T_1 g^{-1} = T_2\)</span>, as
required. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 280</strong>. Given an element <span
class="math inline">\(u \in K\)</span>, the <em>centralizer</em> <span
class="math inline">\(Z(u) := Z_K(u)\)</span> is defined to be <span
class="math inline">\(Z(u) := \{g \in K : g u g^{-1} = u\}\)</span>.</p>
<p>Similarly, for any subgroup <span class="math inline">\(U \leq
K\)</span>, the <em>centralizer</em> <span class="math inline">\(Z(U) :=
Z_K(U)\)</span> is defined to be <span class="math inline">\(Z(U) :=
\cap_{u \in U} Z(u) = \{g \in K : g u g^{-1} = u \text{ for all } u \in
U\}\)</span>.</p>
</div>
<div class="lemma">
<p><strong>Lemma 281</strong>. Let <span
class="math inline">\(T\)</span> be a maximal torus. Then <span
class="math inline">\(Z(T) = T\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This is a tricky argument, so I’ve spelled the proof
out a bit more verbosely. (This one is worth studying and rewriting on
your own, I think.)</p>
<p>Since <span class="math inline">\(T\)</span> is abelian, we have
<span class="math inline">\(T \subseteq Z(T)\)</span>. Conversely, let
<span class="math inline">\(g \in Z(T)\)</span>. Let <span
class="math inline">\(H\)</span> be the closure of the subgroup of <span
class="math inline">\(K\)</span> generated by <span
class="math inline">\(T\)</span> and <span
class="math inline">\(g\)</span>. Since <span
class="math inline">\(g\)</span> commutes with <span
class="math inline">\(T\)</span> and <span
class="math inline">\(T\)</span> is abelian, we know that <span
class="math inline">\(H\)</span> is abelian.</p>
<p>If we were lucky enough that <span class="math inline">\(H\)</span>
happened to be connected, then we’d be done: <span
class="math inline">\(H\)</span> would then be connected, compact, and
abelian, hence a torus, but since <span class="math inline">\(T\)</span>
is a maximal torus, the only possiblity is <span class="math inline">\(H
= T\)</span>, and thus <span class="math inline">\(g \in T\)</span>.</p>
<p>Unfortunately, there is no obvious reason for <span
class="math inline">\(H\)</span> to be connected. We are led to consider
its connected component <span class="math inline">\(H_0\)</span>. Since
<span class="math inline">\(T\)</span> is connected, we know that <span
class="math inline">\(H\)</span> contains <span
class="math inline">\(T\)</span>. Since <span
class="math inline">\(H_0\)</span> is connected, abelian and compact
(being closed inside <span class="math inline">\(K\)</span>), it is a
torus; since <span class="math inline">\(T\)</span> is maximal, we must
have <span class="math inline">\(H_0 = T\)</span>.</p>
<p>If we were lucky enough that <span class="math inline">\(g\)</span>
happened to belong to <span class="math inline">\(H_0\)</span>, then
again, we’d be done. But there is no obvious reason for that be the
case. (Think about it.) Fortunately, as we now explain, <span
class="math inline">\(H/H_0\)</span> is not too complicated, so we can
make the argument work anyway.</p>
<p>Let’s see. Since <span class="math inline">\(H_0 \subseteq H\)</span>
is open, the quotient <span class="math inline">\(H/H_0\)</span> is
discrete; it is also compact, hence finite. Moreover, by construction of
<span class="math inline">\(H\)</span>, that quotient is generated by
the image <span class="math inline">\(\overline{g} \in H/H_0\)</span> of
<span class="math inline">\(g\)</span>. Let <span
class="math inline">\(m \in \mathbb{Z}_{\geq 1}\)</span> be the smallest
natural number for which <span class="math inline">\(\overline{g}^m =
1\)</span>, or equivalently, for which <span class="math inline">\(g^m
\in H_0 = T\)</span>. Let <span class="math inline">\(t \in T\)</span>
be a generator of the torus. The torus is a divisible group, so we can
find <span class="math inline">\(s \in T\)</span> for which <span
class="math inline">\(s^m = t g^{-m}\)</span>.</p>
<p>Set <span class="math inline">\(u := s g\)</span>. We claim that
<span class="math inline">\(u\)</span> is a generator of <span
class="math inline">\(H\)</span>. To see that, we must check that the
powers of <span class="math inline">\(u\)</span> are dense. We have
<span class="math inline">\(u^m = t\)</span>, and <span
class="math inline">\(t\)</span> is a generator of <span
class="math inline">\(T\)</span>, so the closure of the set of powers of
<span class="math inline">\(u\)</span> contains <span
class="math inline">\(T\)</span>. The full group <span
class="math inline">\(H\)</span> is the union over <span
class="math inline">\(j \in \mathbb{Z}/m\)</span> of the cosets <span
class="math inline">\(g^j H_0 = g^j T\)</span>. The set of powers <span
class="math inline">\(u^{m n + j} = u^j t^n \in g^j T\)</span> (<span
class="math inline">\(n \in \mathbb{Z}\)</span>) are dense in that
coset. Hence <span class="math inline">\(u\)</span> generates <span
class="math inline">\(H\)</span>.</p>
<p>Now we use the big theorem on conjugacy of maximal tori to deduce
that <span class="math inline">\(u\)</span> is contained in
<em>some</em> maximal torus <span class="math inline">\(S\)</span> of
<span class="math inline">\(G\)</span> (e.g., a conjugate of <span
class="math inline">\(T\)</span>). Since <span
class="math inline">\(u\)</span> generates <span
class="math inline">\(H\)</span>, we must also have <span
class="math inline">\(H \subseteq S\)</span>. So now we have the
following containments: <span class="math display">\[T \subseteq H
\subseteq S.\]</span> Since <span class="math inline">\(T\)</span> is a
<em>maximal</em> torus, the only possiblity is that <span
class="math inline">\(T = S\)</span>, hence that <span
class="math inline">\(H = T\)</span>, hence that <span
class="math inline">\(g \in T\)</span>.</p>
<p>Since <span class="math inline">\(g \in Z(T)\)</span> was arbitrary,
we conclude finally that <span class="math inline">\(Z(T) = T\)</span>,
as required. ◻</p>
</span></div>
<h1 id="sec:orgf4996f8">§34. Regular and singular elements</h1>
<h2 id="sec:orgedf2662">§34.1. Definitions and basic properties</h2>
<p>Recall that every element of <span class="math inline">\(K\)</span>
is contained in <em>some</em> maximal torus.</p>
<div class="definition">
<p><strong>Definition 282</strong>. We say that an element <span
class="math inline">\(g \in K\)</span> is <em>regular</em> if it belongs
to exactly one maximal torus; if otherwise it belongs to at least two
maximal tori, then we call it <em>singular</em>.</p>
</div>
<p>Introduce the superscript <span
class="math inline">\(\mathop{\mathrm{reg}}\)</span>, as in <span
class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span> or <span
class="math inline">\(T^{\mathop{\mathrm{reg}}}\)</span> (for a maximal
torus <span class="math inline">\(T\)</span>), to denote “subset of
regular elements.”</p>
<p>Being regular is a property of conjugacy classes: if <span
class="math inline">\(x \in K\)</span> is regular, then so is <span
class="math inline">\(g x g^{-1}\)</span> for any <span
class="math inline">\(g \in K\)</span>, and vice-versa. Since every
element is conjugate to some element of any given maximal torus <span
class="math inline">\(T\)</span>, we can understand the regular elements
pretty well if we understand which elements of <span
class="math inline">\(T\)</span> are regular.</p>
<p>To that end, let <span class="math inline">\(R\)</span> denote the
set of roots of <span class="math inline">\(T\)</span>. For each <span
class="math inline">\(\alpha \in R\)</span>, set <span
class="math display">\[T_\alpha := \ker(e^\alpha) \leq T\]</span> where
<span class="math inline">\(e^\alpha : T \rightarrow
\mathbb{C}^{(1)}\)</span> is the character <span class="math inline">\(T
\ni e(H) \mapsto e(\alpha(H))\)</span> (here <span
class="math inline">\(H \in \mathfrak{h}_\mathbb{R}\)</span>). We refer
to §<a href="#sec:notationinvolvingroots-for-amxl-tori-section"
data-reference-type="ref"
data-reference="sec:notationinvolvingroots-for-amxl-tori-section">33.5</a>
for any unexplained notation.</p>
<p>More verbosely, since <span class="math inline">\(\alpha(H) \in
\mathbb{Z}\)</span> iff <span class="math inline">\(e(\alpha(H)) =
1\)</span>, one has <span class="math display">\[T_\alpha = \left\{ e(H)
: H \in \mathfrak{h}_\mathbb{R}, \alpha(H) \in \mathbb{Z}
\right\}.\]</span> <span class="math inline">\(T_\alpha\)</span> need
not be connected, but its connected component <span
class="math inline">\((T_\alpha)_0\)</span> is easily seen to be
codimension one subtorus of <span class="math inline">\(T\)</span> with
Lie algebra <span class="math inline">\(\mathfrak{t}_\alpha =
\ker(\alpha : \mathfrak{t} \rightarrow i \mathbb{R})\)</span>.</p>
<div class="proposition">
<p><strong>Proposition 283</strong>. <em>An element of <span
class="math inline">\(T\)</span> is regular if and only if it doesn’t
belong to any the <span class="math inline">\(T_\alpha\)</span>, i.e.,
<span class="math display">\[T^{\mathop{\mathrm{reg}}} = T -
\cup_{\alpha \in R} T_\alpha.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> For <span class="math inline">\(t \in T\)</span>, let
<span class="math inline">\(Z(t) := \{g \in K : g t g^{-1} =
t\}\)</span> denote its centralizer. It is a Lie subgroup of <span
class="math inline">\(K\)</span> with Lie algebra <span
class="math inline">\(\mathfrak{z}(t) = \{X \in \mathfrak{k} :
\mathop{\mathrm{Ad}}(t)X = X\}\)</span> whose complexification is in
turn <span class="math display">\[V := \mathfrak{z}(t)_\mathbb{C} = \{Z
\in \mathfrak{g} : \mathop{\mathrm{Ad}}(t)Z = Z\},\]</span> where <span
class="math inline">\(\mathfrak{g} := \mathfrak{k}_\mathbb{C}\)</span>
as usual. It is clear that <span class="math inline">\(Z(t) \supseteq
T\)</span>, hence that <span class="math inline">\(\mathfrak{z}(t)
\supseteq \mathfrak{t}\)</span>, hence that <span
class="math inline">\(V \supseteq \mathfrak{h} :=
\mathfrak{t}_\mathbb{C}\)</span>. Consider the root space decomposition
<span class="math inline">\(\mathfrak{g} = \mathfrak{h} \oplus
(\oplus_{\alpha \in R} \mathfrak{g}^\alpha)\)</span>. If <span
class="math inline">\(Z \in \mathfrak{g}\)</span> has the form <span
class="math inline">\(Z = Z_0 + \sum Z_\alpha\)</span> with <span
class="math inline">\(Z_0 \in \mathfrak{h}\)</span> and <span
class="math inline">\(Z_\alpha \in \mathfrak{g}^\alpha\)</span>, then
<span class="math display">\[\mathop{\mathrm{Ad}}(t) Z_0 = Z_0, \quad
\mathop{\mathrm{Ad}}(t) Z_\alpha = e^\alpha(t) Z_\alpha,\]</span> hence
<span class="math display">\[\mathop{\mathrm{Ad}}(t) Z = Z \iff
e^\alpha(t) = 1 \text{ whenever } Z_\alpha \neq 0.\]</span> We deduce
that the following are equivalent:</p>
<ol>
<li><p><span class="math inline">\(V\)</span> properly contains <span
class="math inline">\(\mathfrak{h}\)</span>.</p></li>
<li><p>There exists <span class="math inline">\(\alpha \in R\)</span> so
that <span class="math inline">\(e^\alpha(t) = 1\)</span>.</p></li>
<li><p><span class="math inline">\(t \in \cup_{\alpha \in R}
T_\alpha\)</span>.</p></li>
</ol>
<p>We now prove the required equivalence. Suppose first that <span
class="math inline">\(t\)</span> is not regular. Then it is contained in
some maximal torus <span class="math inline">\(T&#39;\)</span> other
than <span class="math inline">\(T\)</span>, hence <span
class="math inline">\(Z(t) \supseteq T&#39;\)</span>, and thus <span
class="math inline">\(\mathfrak{z}(t) \supseteq \mathfrak{t} &#39; :=
\mathop{\mathrm{Lie}}(T&#39;)\)</span>; consequently <span
class="math inline">\(\mathfrak{z}(t)\)</span> properly contains <span
class="math inline">\(\mathfrak{t}\)</span> and so <span
class="math inline">\(V\)</span> properly contains <span
class="math inline">\(\mathfrak{h}\)</span>; by the above, this is
equivalent to <span class="math inline">\(t\)</span> belonging to <span
class="math inline">\(\cup_{\alpha \in R} T_\alpha\)</span>.</p>
<p>Conversely, suppose <span class="math inline">\(t\)</span> is
regular. We claim then that <span class="math inline">\(Z(t)_0 =
T\)</span>. Clearly <span class="math inline">\(T \subseteq
Z(t)_0\)</span>. Conversely, let <span class="math inline">\(g \in
Z(t)_0\)</span>. By the main theorem on maximal tori applied to <span
class="math inline">\(Z(t)_0\)</span>, we can find a maximal torus <span
class="math inline">\(S\)</span> of <span
class="math inline">\(Z(t)_0\)</span> containing <span
class="math inline">\(g\)</span>. Since <span
class="math inline">\(t\)</span> belongs to the center of <span
class="math inline">\(Z(t)_0\)</span>, we know also that <span
class="math inline">\(S\)</span> contains <span
class="math inline">\(t\)</span>. Let <span
class="math inline">\(S&#39;\)</span> be a maximal torus of <span
class="math inline">\(G\)</span> that contains <span
class="math inline">\(S\)</span>. Then <span
class="math inline">\(S&#39;\)</span> contains <span
class="math inline">\(t\)</span>; since <span
class="math inline">\(t\)</span> is regular, this implies that <span
class="math inline">\(S&#39; = T\)</span>. Consequently <span
class="math inline">\(g \in S \subseteq S&#39; = T\)</span>. Since <span
class="math inline">\(g\)</span> was arbitrary, the claim that <span
class="math inline">\(Z(t)_0 = T\)</span> is proven. Consequently <span
class="math inline">\(V = \mathfrak{h}\)</span> and thus <span
class="math inline">\(t \notin \cup_{\alpha \in R} T_\alpha\)</span>, as
required. ◻</p>
</span></div>
<h2 id="sec:org776dd5b">§34.2. Singular elements have codimension at least
three</h2>
<p>We know that <span class="math inline">\(K = \cup_{g \in K} g T
g^{-1}\)</span>. In other words, the well-defined map <span
class="math display">\[f : K / T \times T \rightarrow K\]</span> <span
class="math display">\[f(g,t) := g t g^{-1}\]</span> is surjective. By
the discussion above, the subset <span
class="math inline">\(K^{\mathop{\mathrm{sing}}}\)</span> of singular
elements is the union over <span class="math inline">\(\alpha \in
R\)</span> of the images of the well-defined maps <span
class="math display">\[f_\alpha : K / Z(T_\alpha) \times T_\alpha
\rightarrow K.\]</span> Set <span class="math inline">\(n :=
\dim(K)\)</span> and <span class="math inline">\(k := \dim(T)\)</span>.
Clearly <span class="math inline">\(\dim(T_\alpha) = k - 1\)</span>. On
the other hand, as discussed more leisurely in class, <span
class="math inline">\(Z(T_\alpha)_\mathbb{C}\)</span> contains <span
class="math inline">\(\mathfrak{h} \oplus \mathfrak{g}^\alpha \oplus
\mathfrak{g}^{-\alpha}\)</span>. Thus <span
class="math inline">\(\dim(Z(T_\alpha)) \geq k+ 2\)</span>, and so <span
class="math display">\[\mathop{\mathrm{image}}(f_\alpha) \leq (n -
(k+2)) + (k-1) \leq n - 3.\]</span> Therefore the subset of singular
elements in <span class="math inline">\(K\)</span> has codimension <span
class="math inline">\(\leq 3\)</span>.</p>
<p>It is a general fact that given a manifold <span
class="math inline">\(M\)</span> with submanifold <span
class="math inline">\(M_0\)</span> for which <span
class="math inline">\(M - M_0\)</span> has codimension <span
class="math inline">\(\geq 3\)</span>, the natural map <span
class="math inline">\(\pi_1(M_0) \rightarrow \pi_1(M)\)</span> is an
isomorphism.</p>
<p>A simpler example: if <span class="math inline">\(M - M_0\)</span>
has codimension <span class="math inline">\(\geq 2\)</span>, then the
connected components of <span class="math inline">\(M\)</span> and <span
class="math inline">\(M_0\)</span> are in natural bijection (i.e., <span
class="math inline">\(\pi_0(M_0) \rightarrow \pi_1(M)\)</span> is a
bijection).</p>
<h2 id="sec:org8a0ef0a">§34.3. The key covering morphism<span
id="sec:key-cov-morph" label="sec:key-cov-morph"></span></h2>
<p>We have a well-defined surjective map <span class="math display">\[f
: K/T \times T^{\mathop{\mathrm{reg}}} \rightarrow
K^{\mathop{\mathrm{reg}}}.\]</span> The following was explained in
lecture, and is not so difficult:</p>
<div class="lemma">
<p><strong>Lemma 284</strong>. This map is a covering map, i.e., a
locally trivial fiber bundle with discrete fibers. The fibers have
cardinality <span class="math inline">\(|N/T|\)</span>, where <span
class="math inline">\(N := N(T) := \{g \in K : g T g^{-1} =
T\}\)</span>.</p>
</div>
<h2 id="sec:org8dfce1f">§34.4. The affine Weyl group and the components of the
set of regular elements<span id="sec:affine-weyl-gp"
label="sec:affine-weyl-gp"></span></h2>
<p>Let <span
class="math display">\[\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}
:= \{H \in \mathfrak{h}_\mathbb{R} : \alpha(H) \notin \mathbb{Z} \text{
for all } \alpha \in R\}.\]</span> Equivalently, <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>
is the preimage under <span class="math inline">\(e :
\mathfrak{h}_\mathbb{R} \rightarrow T\)</span> of <span
class="math inline">\(T^{\mathop{\mathrm{reg}}}\)</span>.</p>
<p>The open subset <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>
of <span class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span> is a
union of complements of hyperplane. Each connected component <span
class="math inline">\(P\)</span> of <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>
is convex, and admits a definition of the shape <span
class="math display">\[P = \{H \in \mathfrak{h}_\mathbb{R} : n_\alpha
&lt; \alpha(H) &lt; n_\alpha + 1 \text{ for all } \alpha \in R
\}\]</span> for some system of integral parameters <span
class="math inline">\(n_\alpha \in \mathbb{Z}\)</span> attached to the
roots <span class="math inline">\(\alpha \in R\)</span>. It is worth
trying to draw some pictures of <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{reg}}}\)</span>
in all the rank <span class="math inline">\(2\)</span> classical Lie
algebras (as attempted in lecture for <span
class="math inline">\(B_2\)</span>).</p>
<p>The group <span class="math inline">\((\mathbb{Z} R)^*\)</span> acts
on <span class="math inline">\(\{H \in \mathfrak{h}_\mathbb{R} :
\alpha(H) \in \mathbb{Z}\}\)</span> by translation: for <span
class="math inline">\(Z \in (\mathbb{Z} R)^*\)</span>, one has <span
class="math inline">\(\alpha(Z) \in \mathbb{Z}\)</span>, hence <span
class="math inline">\(\alpha(H+Z) \in \mathbb{Z}\)</span> precisely when
<span class="math inline">\(\alpha(H) \in \mathbb{Z}\)</span>.
Consequently <span class="math inline">\((\mathbb{Z} R)^*\)</span> acts
also on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>,
by translation.</p>
<p>Recall that the Weyl group <span class="math inline">\(W\)</span> is
generated by the root reflections <span class="math inline">\(s_\alpha :
\mathfrak{h}_\mathbb{R}^* \rightarrow \mathfrak{h}_\mathbb{R}^*\)</span>
defined for roots <span class="math inline">\(\alpha \in R\)</span> by
<span class="math inline">\(s_\alpha \lambda := \lambda -
\lambda(H_\alpha) \alpha\)</span>. Recall also that <span
class="math inline">\(s_\alpha(R) = R\)</span>. For each <span
class="math inline">\(s \in W\)</span>, we may define the transpose
element <span class="math inline">\({}^t s\)</span>, which acts now on
the space <span class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span>
dual to the domain <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^*\)</span> of <span
class="math inline">\(s\)</span>; the action of <span
class="math inline">\({}^t s\)</span> is characterized by requiring that
for <span class="math inline">\(H \in \mathfrak{h}_\mathbb{R}\)</span>,
one has for each <span class="math inline">\(\lambda \in
\mathfrak{h}_\mathbb{R}^*\)</span> that <span
class="math inline">\(\lambda({}^t s H) = (s \lambda)(H)\)</span>. This
relation might be more pleasantly written <span
class="math display">\[\langle \lambda, {}^t s H \rangle = \langle s
\lambda, H \rangle.\]</span></p>
<div class="exercise">
<p><strong>Exercise 38</strong>. Show that for <span
class="math inline">\(\alpha \in R\)</span> and <span
class="math inline">\(H \in \mathfrak{h}_\mathbb{R}\)</span>, one has
<span class="math display">\[{}^t s_\alpha H = H - \alpha(H)
H_\alpha.\]</span></p>
</div>
<p>From now on we might abuse notation slightly by writing simply <span
class="math inline">\(s_\alpha := {}^t s_\alpha\)</span> and identifying
<span class="math inline">\(W\)</span> with the subgroup <span
class="math inline">\(\{s := {}^t s : s \in W\}\)</span> of <span
class="math inline">\(\mathop{\mathrm{GL}}(\mathfrak{h}_\mathbb{R})\)</span>.
In this way, we regard <span class="math inline">\(W\)</span> as acting
on <span class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span>.</p>
<p>This action of <span class="math inline">\(W\)</span> preserves <span
class="math inline">\(\mathbb{Z} R^\wedge\)</span>. Indeed, for each
<span class="math inline">\(s \in W\)</span>, one has <span
class="math inline">\(s(R^\wedge) = R^\wedge\)</span>, so the generators
get permuted.</p>
<p>For this reason, we can form the semidirect product <span
class="math inline">\(\mathbb{Z} R^\wedge \rtimes W\)</span>. It is the
group consisting of all pairs <span
class="math inline">\((H,s)\)</span>, where <span
class="math inline">\(s \in W, Z \in \mathbb{Z} R^\wedge\)</span>. The
multiplication law is <span class="math display">\[(Z_1,s_1) (Z_2,s_2) =
(Z_1 + s_1 Z_2, s_1 s_2).\]</span> This group acts naturally on <span
class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span> by the formula
<span class="math display">\[(Z,s) \cdot H := Z + s H.\]</span></p>
<p>For each <span class="math inline">\(\alpha \in R\)</span> and <span
class="math inline">\(n \in \mathbb{Z}\)</span>, consider the linear map
<span class="math inline">\(s_{\alpha n} : \mathfrak{h}_\mathbb{R}
\rightarrow \mathfrak{h}_\mathbb{R}\)</span> given by reflection in the
hyperplane <span class="math inline">\(\{H : \alpha(H) = n\}\)</span>;
explicitly, <span class="math display">\[s_{\alpha n}(H) = H -
(\alpha(H) - n) H_\alpha.\]</span> Clearly <span
class="math inline">\(s_{\alpha 0} = s_\alpha \in W\)</span>. On the
other hand, it is easy to check (either by straightforward algebra or by
drawing a picture) that <span class="math display">\[s_{\alpha 1} \circ
s_{\alpha 0}(H) = H + H_\alpha\]</span> and more generally for <span
class="math inline">\(n \in \mathbb{Z}\)</span> that <span
class="math display">\[s_{\alpha,n+1 } \circ s_{\alpha, n}(H) = H +
H_\alpha.\]</span> From these and the identities <span
class="math inline">\(s_{\alpha,n}^2 = 1\)</span>, we see that the
following subgroups of <span
class="math inline">\(\mathop{\mathrm{GL}}(\mathfrak{h}_\mathbb{R})\)</span>
coincide:</p>
<ol>
<li><p>The image of <span class="math inline">\(\mathbb{Z} R^\wedge
\rtimes W\)</span>.</p></li>
<li><p>The group generated by the <span
class="math inline">\(s_{\alpha,n}\)</span>, for <span
class="math inline">\(\alpha \in R\)</span> and <span
class="math inline">\(n \in \mathbb{Z}\)</span>.</p></li>
</ol>
<p>Either group is called the <em>affine Weyl group</em>. I’ll denote
that group <span class="math inline">\(W_a\)</span>.</p>
<p>By the above discussion, <span class="math inline">\(W_a\)</span>
acts on the hyperplanes <span class="math inline">\(\{H : \alpha(H) =
n\}\)</span> and hence on their complement <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 285</strong>. <span class="math inline">\(W_a\)</span>
acts transitively on the set of connected components of <span
class="math inline">\(\mathfrak{h}_\mathbb{R}^{\mathop{\mathrm{sreg}}}\)</span>.</p>
</div>
<div class="lemma">
<p><strong>Lemma 286</strong>. Given two such connected components <span
class="math inline">\(P_0, P_1\)</span>, take some basepoints <span
class="math inline">\(H_i \in P_i\)</span> and draw a path <span
class="math inline">\(H_t\)</span> from <span
class="math inline">\(H_0\)</span> to <span
class="math inline">\(H_1\)</span> that crosses at most one of the
hyperplanes <span class="math inline">\(\{H : \alpha(H) = n\}\)</span>
at a time. One obtains in this way a sequence of pairs <span
class="math inline">\((\alpha_1,n_1),\dotsc,(\alpha_k,n_k)\)</span> so
that as <span class="math inline">\(t\)</span> goes from <span
class="math inline">\(0\)</span> to <span
class="math inline">\(1\)</span>, the point <span
class="math inline">\(H_t\)</span> crosses the planes <span
class="math inline">\(\{H : \alpha_i(H) = n_i\}\)</span> in order from
<span class="math inline">\(i=1\)</span> to <span
class="math inline">\(i=k\)</span>. Then the composition <span
class="math inline">\(s_{\alpha_k,n_k} \circ \dotsb \circ
s_{\alpha_1,n_1}\)</span> maps <span class="math inline">\(P_0\)</span>
to <span class="math inline">\(P_1\)</span>.</p>
</div>
<h1 id="sec:org25cd375">§35. The distinguished <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>’s<span
id="sec:distinguished-su2" label="sec:distinguished-su2"></span></h1>
<p>Let notation be as in previous sections: <span
class="math inline">\(K\)</span> is a compact connected Lie group, <span
class="math inline">\(T\)</span> is a maximal torus in <span
class="math inline">\(K\)</span>, plus all the other usual notation.</p>
<p>Let <span class="math inline">\(\mathfrak{k} :=
\mathop{\mathrm{Lie}}(K)\)</span> and <span
class="math inline">\(\mathfrak{g} := \mathfrak{k}_\mathbb{C} :=
\mathfrak{k} \otimes _{\mathbb{R}} \mathbb{C}\)</span>, as usual. Let
<span class="math inline">\(\theta : \mathfrak{g} \rightarrow
\mathfrak{g}\)</span> denote the involution given by complex conjugation
on the second factor of <span class="math inline">\(\mathfrak{k}
\otimes_{\mathbb{R}} \mathbb{C}\)</span>, so that when we identify <span
class="math inline">\(\mathfrak{k}\)</span> with a real Lie subalgebra
of <span class="math inline">\(\mathfrak{g}\)</span>, we have <span
class="math inline">\(\mathfrak{k} = \{X \in \mathfrak{g} : \theta(X) =
X\}\)</span>. (In typical examples such as <span
class="math inline">\(\mathfrak{k} = \mathfrak{u}(n), \mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})\)</span>, the
operator <span class="math inline">\(\theta\)</span> is given by <span
class="math inline">\(X \mapsto -{}^t \overline{X}\)</span>.) Then <span
class="math inline">\(\theta(H) = - H\)</span> for all <span
class="math inline">\(H \in \mathfrak{h}_\mathbb{R} = i
\mathfrak{t}\)</span>, <span class="math inline">\(\mathfrak{t} :=
\mathop{\mathrm{Lie}}(T)\)</span>.</p>
<p>Let <span class="math inline">\(\alpha\)</span> belong to the set
<span class="math inline">\(R\)</span> of roots for <span
class="math inline">\(T\)</span>. Recall that <span
class="math inline">\(\mathfrak{g}\)</span> contains the subalgebra
<span class="math inline">\(\mathfrak{s}_\alpha = \mathbb{C} H_\alpha
\oplus \mathbb{C} X_\alpha \oplus \mathbb{C} Y_\alpha\)</span>, which is
isomorphism in the evident way to <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>.
The subalgebra <span class="math inline">\(\mathfrak{k}^{(\alpha)} :=
\{X \in \mathfrak{s}_\alpha : \theta(X) = X\}\)</span> is a real Lie
subalgebra of <span class="math inline">\(\mathfrak{s}_\alpha\)</span>.
We can easily work out a basis for it. Since <span
class="math inline">\(H_\alpha \in \mathfrak{h}_\mathbb{R}\)</span>, one
has <span class="math inline">\(\theta(H_\alpha) = - H_\alpha\)</span>.
One has <span class="math inline">\(\theta (\mathfrak{g}^\alpha)
\subseteq \mathfrak{g}^{-\alpha}\)</span> and <span
class="math inline">\(\theta (\mathfrak{g}^{-\alpha}) \subseteq
\mathfrak{g}^{\alpha}\)</span>, and <span class="math inline">\(\theta^2
= 1\)</span>. It follows that the trace of <span
class="math inline">\(\theta\)</span> acting on <span
class="math inline">\(\mathfrak{s}_\alpha = 0\)</span>, so it has the
same number of <span class="math inline">\(+1\)</span> and <span
class="math inline">\(-1\)</span> eigenvalues, hence <span
class="math inline">\(\dim_{\mathbb{R}}(\mathfrak{k}^{(\alpha)}) =
3\)</span>. If we let <span class="math inline">\(x,y\)</span> be any
<span class="math inline">\(\mathbb{R}\)</span>-basis of the <span
class="math inline">\(1\)</span>-dimensional <span
class="math inline">\(\mathbb{C}\)</span>-vector space <span
class="math inline">\(\mathfrak{g}^\alpha\)</span>, then it follows
easily that <span class="math inline">\(\{i H_\alpha, x + \theta(x), y +
\theta(y)\}\)</span> given an <span
class="math inline">\(\mathbb{R}\)</span>-basis of <span
class="math inline">\(\mathfrak{k}^{(\alpha)}\)</span>. Using the
existence of a positive-definite <span
class="math inline">\(K\)</span>-invariant inner product on <span
class="math inline">\(\mathfrak{k}\)</span>, we can show that <span
class="math inline">\(\mathfrak{k}^{(\alpha)} \cong
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span>. (TODO: explain
more.) Since <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> is
simply-connected, we get from this a morphism <span
class="math display">\[F_\alpha : \mathop{\mathrm{SU}}(2) \rightarrow
K\]</span> so that <span class="math inline">\((d
F_\alpha)_\mathbb{C}\)</span> is the natural map <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
\rightarrow \mathfrak{s}_\alpha\)</span>. (Compare with homework <a
href="#hw:Falphaz" data-reference-type="ref"
data-reference="hw:Falphaz">17</a>.) The image of <span
class="math inline">\(F_\alpha\)</span> is contained in <span
class="math inline">\(Z(T_\alpha)^0\)</span>. We get an element <span
class="math display">\[w_\alpha := F_\alpha (
\begin{pmatrix}
    0 &amp; 1 \\
    -1 &amp; 0
  \end{pmatrix}
  )\]</span> for which <span
class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha)\)</span> gives the
root reflection <span class="math inline">\(s_\alpha\)</span>.</p>
<p>We (mostly) explained in lecture how we can use this to identify
<span class="math inline">\(N/T\)</span> with the Weyl group <span
class="math inline">\(W\)</span> (as defined using root reflections).
One of the key steps was to show that if an element <span
class="math inline">\(w\)</span> of <span
class="math inline">\(N/T\)</span> stabilizes a Weyl chamber <span
class="math inline">\(C\)</span>, then it is the identity (i.e., <span
class="math inline">\(w \in T\)</span>). For this we reduced by an
averaging trick to the case that <span class="math inline">\(w\)</span>
actually fixes some element <span class="math inline">\(H \in
C\)</span>. (TODO: explain more.)</p>
<h1 id="sec:org1822737">§36. Proofs regarding the basic homomorphism
describnig fundamental groups of compact Lie groups</h1>
<h2 id="sec:org1514b4c">§36.1. Definition</h2>
<p>Let notation be as usual. Recall that we initially define <span
class="math display">\[f : \mathfrak{h}_\mathbb{Z} \rightarrow
\pi_1(K)\]</span> by taking for <span
class="math inline">\(f(H)\)</span> the homotopy class <span
class="math inline">\([\gamma]\)</span> of the path <span
class="math inline">\(\gamma : [0,1]\rightarrow K\)</span> given by
<span class="math display">\[\gamma(t) := e(t H) := \exp(2 \pi i t
H).\]</span></p>
<h2 id="sec:orgddabaf2">§36.2. The basic homomorphism: checking that it’s a
homomorphism</h2>
<p>Given <span class="math inline">\(H_1, H_2 \in
\mathfrak{h}_\mathbb{Z}\)</span>, we obtain paths <span
class="math inline">\(\gamma_1, \gamma_2 : [0,1] \rightarrow K\)</span>
as above. Their composition in the fundamental group is the path (with
domain <span class="math inline">\([0,1]\)</span>) <span
class="math display">\[t \mapsto
  \begin{cases}
    \gamma_1(2 t) &amp; t \leq 1/2 \\
    \gamma_2(2 t - 1) &amp;  t \geq 1/2
  \end{cases}\]</span> which we can rewrite as <span
class="math display">\[t \mapsto \left(
    \begin{cases}
      \gamma_1(2 t) &amp; t \leq 1/2 \\
      1 &amp;  t \geq 1/2
    \end{cases}
  \right) \cdot \left(
    \begin{cases}
      1 &amp; t \leq 1/2 \\
      \gamma_2(2 t - 1) &amp;  t \geq 1/2
    \end{cases}
  \right).\]</span> Introduce a deformation parameter <span
class="math inline">\(s \in [0,1]\)</span>. Choose a continuous
monotonically decreasing function <span class="math inline">\(c : [0,1]
\rightarrow [1,2]\)</span> for which <span class="math inline">\(c_0 =
2\)</span> and <span class="math inline">\(c_1 = 1\)</span>. The above
path is then homotopic to <span class="math display">\[t \mapsto \left(
    \begin{cases}
      \gamma_1(c_s t) &amp; c_s t \leq 1 \\
      1 &amp;  c_s t \geq 1
    \end{cases}
  \right) \cdot \left(
    \begin{cases}
      1 &amp; 1 + c_s (t  - 1) \leq 0 \\
      \gamma_2(1 + c_s (t - 1)) &amp;  1 + c_s(t-1) \geq 0.
    \end{cases}
  \right).\]</span> At deformation parameter <span
class="math inline">\(s=1\)</span>, the above path is given by <span
class="math display">\[t \mapsto \gamma_1(t) \gamma_2(t) = e(t (H_1 +
H_2)).\]</span> Therefore <span class="math inline">\(f :
\mathfrak{h}_\mathbb{Z} \rightarrow \pi_1(K)\)</span> is a
homomorphism.</p>
<div class="exercise">
<p><strong>Exercise 39</strong>. Use an argument similar to that above
to show that the fundamental group of any topological group is
abelian.</p>
</div>
<h2 id="sec:org9527204">§36.3. Checking that some stuff is in its kernel</h2>
<p>We now show that for <span class="math inline">\(H \in \mathbb{Z}
R^\wedge\)</span> one has <span class="math inline">\(f(H) = 0\)</span>.
Since <span class="math inline">\(f\)</span> is a homomorphism and <span
class="math inline">\(R^\wedge\)</span> gives a basis for <span
class="math inline">\(\mathbb{Z} R^\wedge\)</span>, our task reduces to
verifying for each <span class="math inline">\(\alpha \in R\)</span>
that the path <span id="eq:path-to-be-shown-is-nullhomotopic" class="math display">\[\label{eq:path-to-be-shown-is-nullhomotopic}\tag{145}
[0,1] \ni t
  \mapsto e(t H_\alpha) \in K\]</span> is null-homotopic.</p>
<p>To that end, observe first that <span
class="math inline">\(e(\tfrac{1}{2} H_\alpha) \in T_\alpha\)</span>;
indeed, since <span class="math inline">\(\alpha(H_\alpha) = 2\)</span>,
<span class="math display">\[e^\alpha(\tfrac{1}{2} H_\alpha) =
e(\alpha(\tfrac{1}{2} H_\alpha)) = e(1) = 1.\]</span> Recall from §<a
href="#sec:distinguished-su2" data-reference-type="ref"
data-reference="sec:distinguished-su2">35</a> that
there exists <span class="math inline">\(w_\alpha \in
Z(T_\alpha)^0\)</span> for which <span
class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha) H_\alpha = -
H_\alpha\)</span>. For <span class="math inline">\(s \in [0,1]\)</span>,
let <span class="math inline">\(c_s \in Z(T_\alpha)^0\)</span> be such
that <span class="math inline">\(c_0 = 1\)</span> (the identity element)
and <span class="math inline">\(c_1 = w_\alpha\)</span>. We then have
<span class="math display">\[c_s e(\tfrac{1}{2} H_\alpha) c_s^{-1} =
e(\tfrac{1}{2} H_\alpha) \text{ for all } s.\]</span> For this reason,
the path <a href="#eq:path-to-be-shown-is-nullhomotopic"
data-reference-type="eqref"
data-reference="eq:path-to-be-shown-is-nullhomotopic">\((145)\)</a>
may be continuously deformed to <span class="math display">\[t \mapsto
  \begin{cases}
    e(t H_\alpha) &amp;  t \leq 1/2 \\
    c_s e(t H_\alpha) c_s^{-1} &amp; t \geq 1/2.
  \end{cases}\]</span> After we deform to <span class="math inline">\(s
= 1\)</span>, we get <span class="math display">\[w_\alpha e(t H_\alpha)
w_\alpha^{-1} = e( t \mathop{\mathrm{Ad}}(w_\alpha)H_\alpha) = e(-t
H_\alpha) = e((1-t) H_\alpha),\]</span> so we deduce that the path <a
href="#eq:path-to-be-shown-is-nullhomotopic" data-reference-type="eqref"
data-reference="eq:path-to-be-shown-is-nullhomotopic">\((145)\)</a>
is homotopic to <span id="eq:boomerang-path" class="math display">\[\label{eq:boomerang-path}\tag{146}
  t \mapsto
  \begin{cases}
    e(t H_\alpha) &amp;  t \leq 1/2 \\
    e((1-t) H_\alpha)  &amp; t \geq 1/2.
  \end{cases}\]</span> Now introduce another deformation parameter <span
class="math inline">\(r\)</span>, starting at <span
class="math inline">\(r=1/2\)</span> and deforming to <span
class="math inline">\(r=0\)</span>. The path <a
href="#eq:boomerang-path" data-reference-type="eqref"
data-reference="eq:boomerang-path">\((146)\)</a> is then
homotopic to <span id="eq:boomerang-path-2" class="math display">\[\label{eq:boomerang-path-2}\tag{147}
  t \mapsto
  \begin{cases}
    e(t H_\alpha) &amp;  t \leq r \\
    e((2r-t) H_\alpha)  &amp; r \leq t \leq 2 r \\
    1 &amp; 2 r \leq t.
  \end{cases}\]</span> When <span class="math inline">\(r = 0\)</span>,
we get the trivial path <span class="math inline">\(t \mapsto
1\)</span>. Thus the path <a
href="#eq:path-to-be-shown-is-nullhomotopic" data-reference-type="eqref"
data-reference="eq:path-to-be-shown-is-nullhomotopic">\((145)\)</a>
is nullhomotopic.</p>
<h2 id="sec:orgea26b3f">§36.4. The basic homomorphism: checking that it’s
surjective</h2>
<p>We now argue that <span class="math inline">\(f\)</span> is
surjective. Recall that <span class="math inline">\(\pi^1(K) =
\pi^1(K^{\mathop{\mathrm{reg}}})\)</span>. Let <span
class="math inline">\(H_0\)</span> be a small element of <span
class="math inline">\(\mathfrak{h}_{\mathbb{R}}^{\mathop{\mathrm{sreg}}}\)</span>,
so that <span class="math inline">\(e(H_0)\)</span> is a small element
of <span class="math inline">\(T^{\mathop{\mathrm{reg}}}\)</span>. Any
element of <span class="math inline">\(\pi_1(K)\)</span> can be deformed
a bit to start and end at <span class="math inline">\(e(H_0)\)</span>,
and then deformed a bit more so that it lies entirely in <span
class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span>. Using the
covering morphism of §<a href="#sec:key-cov-morph"
data-reference-type="ref"
data-reference="sec:key-cov-morph">34.3</a>, we can then
uniquely lift our path to <span class="math inline">\(K/T \times
T^{\mathop{\mathrm{reg}}}\)</span>; this means concretely that we may
express our path uniquely in the form <span class="math display">\[\ni t
\mapsto c_t \exp(H_t) c_t^{-1},\]</span> where <span
class="math inline">\(c_t \in K/T\)</span> satisfies <span
class="math inline">\(c_0 = e T\)</span>, where <span
class="math inline">\(H_t\)</span> belongs to the same connected
component <span class="math inline">\(P\)</span> of <span
class="math inline">\(\mathfrak{h}_{\mathbb{R}}^{\mathop{\mathrm{sreg}}}\)</span>
as <span class="math inline">\(H_0\)</span> and satisfies <span
class="math inline">\(H_t|_{t=0} = H_0\)</span>, and finally <span id="eq:final-condition-c1-H11-H00" class="math display">\[\label{eq:final-condition-c1-H11-H00}\tag{148}
  c_1 \exp(H_1) c_1^{-1} = \exp(H_0).\]</span> This last condition says
in particular that <span class="math inline">\(s := c_1\)</span>
satisfies <span class="math inline">\(s t s^{-1} \in
T^{\mathop{\mathrm{reg}}}\)</span> for some <span
class="math inline">\(t := e(H_1) \in
T^{\mathop{\mathrm{reg}}}\)</span>; since <span
class="math inline">\(t\)</span> is regular, it belongs to exactly one
maximal torus, and so since <span class="math inline">\(t \in T\)</span>
and <span class="math inline">\(t \in s^{-1} T s\)</span> we deduce that
<span class="math inline">\(T = s^{-1} T s\)</span>, i.e., that <span
class="math inline">\(s\)</span> belongs to the normalizer <span
class="math inline">\(N := N_K(T) := \{g \in K : g T g^{-1} =
T\}\)</span> of <span class="math inline">\(T\)</span>. We may also
rewrite the condition <a href="#eq:final-condition-c1-H11-H00"
data-reference-type="eqref"
data-reference="eq:final-condition-c1-H11-H00">\((148)\)</a>
in the form <span id="eq:integrality-condition-on-s-H11-H00" class="math display">\[\label{eq:integrality-condition-on-s-H11-H00}\tag{149}
  s \cdot H_1 + H_0 \in \mathfrak{h}_\mathbb{Z} := \ker(e :
\mathfrak{h}_\mathbb{R} \rightarrow T),\]</span> where we abbreviate
<span class="math inline">\(s \cdot H_1 := \mathop{\mathrm{Ad}}(s)
H_1\)</span>.</p>
<p>We now want to deform our path so that it is obviously in the image
of <span class="math inline">\(f\)</span>. To that end, let us first
translate it by <span class="math inline">\(e(-H_0)\)</span> so that its
basepoint is at the origin again. We are then left to stare at the path
<span class="math display">\[t \mapsto e(-H_0) c_t e(H_t)
c_t^{-1}.\]</span> Since <span class="math inline">\(P\)</span> is
convex and <span class="math inline">\(H_0,H_1 \in P\)</span>, there is
no harm in assuming that <span class="math inline">\(H_t\)</span> is the
straight line path from <span class="math inline">\(H_0\)</span> to
<span class="math inline">\(H_1\)</span>, given by <span
class="math inline">\(H_t = H_0 + t(H_1 - H_0)\)</span>. Using <a
href="#eq:integrality-condition-on-s-H11-H00"
data-reference-type="eqref"
data-reference="eq:integrality-condition-on-s-H11-H00">\((149)\)</a>
and the fact that <span class="math inline">\(s\)</span> and <span
class="math inline">\(s^{-1}\)</span> preserve <span
class="math inline">\(\mathfrak{h}_\mathbb{Z}\)</span>, we may write
<span class="math display">\[H_1 = s^{-1} \cdot H_0 + Z\]</span> for
some <span class="math inline">\(Z \in \mathfrak{h}_\mathbb{Z}\)</span>.
We are thus looking at the path <span class="math display">\[t \mapsto
e(-H_0) c_t e(H_0 + t (s^{-1} \cdot H_0 + Z - H_0) ) c_t^{-1}.\]</span>
In the above path, we may continuously deform <span
class="math inline">\(H_0\)</span> to <span
class="math inline">\(0\)</span>. This gives a family of loops based at
the origin. When we reach <span class="math inline">\(H_0 = 0\)</span>,
we end up with the path <span id="eq:penult-path-before-showing-in-image-of-f" class="math display">\[\label{eq:penult-path-before-showing-in-image-of-f}\tag{150}
  t \mapsto
  c_t e(t  Z ) c_t^{-1}.\]</span> Since <span class="math inline">\(Z
\in \mathfrak{h}_\mathbb{Z}\)</span>, we have <span
class="math inline">\(e(0 Z) = e(1 Z) = 1\)</span>. So we can now deform
every element of <span class="math inline">\(c_t\)</span> to the
identity element and get a homotopic path. In other words, we can
replace the above path by <span class="math inline">\(t \mapsto
c_{\varepsilon t} e(t Z) c_{\varepsilon t}^{-1}\)</span> for <span
class="math inline">\(0 \leq \varepsilon\leq 1\)</span>; we start with
<span class="math inline">\(\varepsilon= 1\)</span>, giving <a
href="#eq:penult-path-before-showing-in-image-of-f"
data-reference-type="eqref"
data-reference="eq:penult-path-before-showing-in-image-of-f">\((150)\)</a>,
and then deform to <span class="math inline">\(\varepsilon= 0\)</span>,
giving the path <span class="math display">\[t \mapsto e(t Z),\]</span>
which is obviously in the image of <span
class="math inline">\(f\)</span>.</p>
<h2 id="sec:org8c8e428">§36.5. The basic homomorphism: pinning down the
kernel</h2>
<p>We’ve seen that we have a well-defined surjective map <span
class="math display">\[f : \mathfrak{h}_\mathbb{Z} / \mathbb{Z} R^\wedge
\rightarrow \pi_1(K).\]</span> We want to show that it’s actually
injective. Let’s observe first also that for any <span
class="math inline">\(Z \in \mathfrak{h}_\mathbb{Z}\)</span> and <span
class="math inline">\(s \in W = N/T\)</span>, we have <span
class="math display">\[f(s Z) = f(Z).\]</span> Indeed, <span
class="math inline">\(s Z - Z\)</span> belongs to <span
class="math inline">\(\mathbb{Z} R^\wedge\)</span> (check this on the
generators <span class="math inline">\(s = s_\alpha\)</span> of <span
class="math inline">\(W\)</span>, using that <span
class="math inline">\(H_\alpha \in R^\wedge\)</span>), and <span
class="math inline">\(f\)</span> is a homomorphism. So this tells us
that <span class="math inline">\(f(Z)\)</span> doesn’t change if we
replace <span class="math inline">\(Z\)</span> with anything in the same
orbit under the affine Weyl group <span class="math inline">\(W_a :=
\mathbb{Z} R^\wedge \rtimes W\)</span> (see §<a
href="#sec:affine-weyl-gp" data-reference-type="ref"
data-reference="sec:affine-weyl-gp">34.4</a>). Fix some
<span class="math inline">\(H_0 \in
\mathfrak{h}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span> and let <span
class="math inline">\(P\)</span> denote its connected component. Since
<span class="math inline">\(W_a\)</span> acts transitively on the
connected components and since the union of their closures is all of
<span class="math inline">\(\mathfrak{h}_\mathbb{R}\)</span>, any <span
class="math inline">\(Z \in \mathfrak{h}_\mathbb{Z}\)</span> is in the
<span class="math inline">\(W_a\)</span>-orbit of some element of the
closure of <span class="math inline">\(P - H_0\)</span>; since <span
class="math inline">\(Z \in \mathfrak{h}_\mathbb{Z}\)</span>, it can’t
lie on the boundary of <span class="math inline">\(P - H_0\)</span>
(check this; it’s easy), and so must lie in <span
class="math inline">\(P - H_0\)</span> itself.</p>
<p>What we want to show now is that the above map is an isomorphism.
This means we should show that if <span class="math inline">\(Z \in
\mathfrak{h}_\mathbb{Z}\)</span> has the property that the path <span
class="math inline">\(t \mapsto e(t Z)\)</span> is nullhomotopic, then
<span class="math inline">\(Z\)</span> belongs to <span
class="math inline">\(\mathbb{Z} R^\wedge\)</span>. By the above
discussion, we may assume that <span class="math inline">\(Z \in P -
H_0\)</span>. Since <span class="math inline">\(P\)</span> is convex,
there is then no loss in shifting basepoints a bit to suppose that we
are considering the path in <span
class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span> given by <span
class="math display">\[\gamma(t) := e(H_0 + t Z).\]</span> Under the
covering map <span class="math inline">\(K/T \times
T^{\mathop{\mathrm{reg}}} \rightarrow
K^{\mathop{\mathrm{reg}}}\)</span>, the above path lifts uniquely to
<span class="math display">\[\tilde{\gamma}(t) \mapsto (e T, H_0 + t
Z).\]</span> The endpoint <span class="math inline">\(\tilde{\gamma}(1)
= t Z\)</span> of this lifting is moreover invariant under
base-and-end-point-preserving homotopies of <span
class="math inline">\(\gamma\)</span>. So if <span
class="math inline">\(\gamma\)</span> is nullhomotopic, then we must
have <span class="math inline">\(Z = 0\)</span>. The proof is now
complete.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The notation is inspired by that used in algebraic
geometry for rational maps.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>What we call <em>submanifold</em> might normally be more
verbosely called <em>smooth submanifold</em>.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>If the definition of products such as <span
class="math inline">\(\Phi&#39;(0) \Phi(t)\)</span> is unclear, one
should either consult §<a href="#sec:translate-tangent-spaces-gp-elts"
data-reference-type="ref"
data-reference="sec:translate-tangent-spaces-gp-elts">11.6</a>
or (better) assume that <span class="math inline">\(G\)</span> is a
linear Lie and interpret such products as as being given by matrix
multiplication.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><span class="math inline">\(\mathbf{k} =
\mathbb{R}\)</span>, “ball” means “interval”, of course<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>What I’ve recorded here is not the standard definition
of “Cartan subalgebra,” but is equivalent to a specialization of that
definition, and is convenient for our immediate purposes; we may return
to the more general notion later.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Defined via the scalar product <span
class="math inline">\(\langle x,y \rangle := \sum_{j=1}^n (x_j y_{n+j} +
x_{n+j} y_j) + x_{2 n+1} y_{2n+1}\)</span><a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>A morphism is a map that preserves all relevant
structure. An isomorphism is a morphism with a two-sided inverse
morphism.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>We have only proved this for those that satisfy the
Cartan subalgebra theorem.<a href="#fnref8" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<script>
document.querySelectorAll(".toggle-proof").forEach(function(toggle) {
  toggle.addEventListener("click", function(e) {
    e.preventDefault();
    const content = this.nextElementSibling;
    const em = this.querySelector('em');
    if (window.getComputedStyle(content).display === "none") {
      content.style.display = "inline";
      em.textContent = em.dataset.defaultText;
    } else {
      content.style.display = "none";
      em.textContent = em.dataset.foldedText;
    }
  });
});
</script>
<script>
document.querySelector("#toggle-all-proofs").addEventListener("click", function(e) {
  e.preventDefault();
  const proofs = document.querySelectorAll(".proof-content");
  proofs.forEach(function(proof) {
    const proofToggle = proof.previousElementSibling;
    if (window.getComputedStyle(proof).display === "none") {
      proof.style.display = "inline";
      proofToggle.innerHTML = `<em>${proofToggle.dataset.defaultText}</em>`;
    } else {
      proof.style.display = "none";
      proofToggle.innerHTML = `<em>${proofToggle.dataset.foldedText}</em>`;
    }
  });
});
</script>

<script src="https://giscus.app/client.js"
        data-repo="Ultronozm/math"
        data-repo-id="R_kgDOJlhjqQ"
        data-category="Announcements"
        data-category-id="DIC_kwDOJlhjqc4CWo21"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</body>
</html>
