<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Paul D. Nelson" />
  <title>Representations of Lie groups</title>
  <link rel="stylesheet" href="tex.css">
  <style>
      .my-links-container {
        position: absolute;
        top: 0;
        right: 0;
        padding-right: 20px;
        padding-top: 10px;
      }
      .my-link {
        margin-left: 10px;
      }
      .my-links-container-2 { /* new CSS class for the second row */
        position: absolute;
        top: 40px; /* adjust this value based on the height of your links */
        right: 0;
        padding-right: 20px;
      }
      .my-link-2 {
        margin-left: 10px;
      }

    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    div.abstract {
      margin: 2em 2em 2em 2em;
      text-align: left;
      font-size: 85%;
    }
    div.abstract-title {
      font-weight: bold;
      text-align: center;
      padding: 0;
      margin-bottom: 0.5em;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
    <div class="my-links-container">
2024-03-12 19:15:14
      <a href="20240311T165141--spring-2019-lie-group-representations__course.tex" class="my-link">tex</a>
      <a href="20240311T165141--spring-2019-lie-group-representations__course.pdf" class="my-link">pdf</a>
      <a href="https://github.com/ultronozm/math/commits/main/20240311T165141--spring-2019-lie-group-representations__course.tex" class="my-link">history</a>
      <a href="." class="my-link">home</a>
    </div>
<header id="title-block-header">
<h1 class="title">Representations of Lie groups</h1>
<p class="author">Paul D. Nelson</p>
<div class="abstract">
<div class="abstract-title">Abstract</div>
<p>Notes for a semester course on the representation theory of Lie
groups, focusing on compact groups and complex reductive groups, taught
at ETH Zürich in Spring 2019.</p>
</div>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#acknowledgments"
id="toc-acknowledgments">Acknowledgments</a></li>
<li><a href="#prerequisites" id="toc-prerequisites">Prerequisites</a>
<ul>
<li><a href="#conventions" id="toc-conventions">Conventions</a></li>
<li><a href="#topological-groups"
id="toc-topological-groups">Topological groups</a></li>
<li><a href="#lie-theory" id="toc-lie-theory">Lie theory</a></li>
<li><a href="#haar-measure" id="toc-haar-measure">Haar measure</a></li>
<li><a href="#sec:spectr-theory-comp"
id="toc-sec:spectr-theory-comp">Spectral theory for compact self-adjoint
operators</a></li>
<li><a href="#sec:linear-algebra" id="toc-sec:linear-algebra">Linear
algebra</a></li>
</ul></li>
<li><a href="#introduction" id="toc-introduction">Introduction</a>
<ul>
<li><a href="#representations"
id="toc-representations">Representations</a></li>
<li><a href="#unitarity" id="toc-unitarity">Unitarity</a></li>
<li><a
href="#morphisms-equivariant-maps-intertwiners-isomorphisms-equivalences-and-so-on"
id="toc-morphisms-equivariant-maps-intertwiners-isomorphisms-equivalences-and-so-on">Morphisms,
equivariant maps, intertwiners, isomorphisms, equivalences, and so
on</a></li>
<li><a href="#reduction-and-decomposition"
id="toc-reduction-and-decomposition">Reduction and
decomposition</a></li>
<li><a href="#characters" id="toc-characters">Characters</a></li>
<li><a href="#sec:conn-comp-abel" id="toc-sec:conn-comp-abel">The
connected compact abelian case</a></li>
</ul></li>
<li><a href="#sec:char-theory-comp"
id="toc-sec:char-theory-comp">Character theory of compact unitary
groups</a>
<ul>
<li><a href="#recap" id="toc-recap">Recap</a></li>
<li><a href="#conjugacy-classes-in-mathopmathrmun"
id="toc-conjugacy-classes-in-mathopmathrmun">Conjugacy classes in <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></a></li>
<li><a href="#sec:weight-decmop-U-n"
id="toc-sec:weight-decmop-U-n">Weight space decompositions of
representations of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></a></li>
<li><a href="#sec:weyl-integr-form" id="toc-sec:weyl-integr-form">The
Weyl integral formula for <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></a></li>
<li><a href="#primer-on-symmetric-polynomials"
id="toc-primer-on-symmetric-polynomials">Primer on symmetric
polynomials</a></li>
<li><a href="#weyl-character-and-dimension-formulas-for-mathopmathrmun"
id="toc-weyl-character-and-dimension-formulas-for-mathopmathrmun">Weyl
character and dimension formulas for <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></a></li>
<li><a href="#sec:some-groups-closely"
id="toc-sec:some-groups-closely">Some groups closely related to <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></a></li>
<li><a href="#sec:case-su2" id="toc-sec:case-su2">The case of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></a></li>
<li><a href="#branching-problems" id="toc-branching-problems">Branching
problems</a></li>
<li><a href="#gelfandtsetlin-bases"
id="toc-gelfandtsetlin-bases">Gelfand–Tsetlin bases</a></li>
</ul></li>
<li><a
href="#matrix-coefficients-for-compact-groups-and-the-peterweyl-theorem"
id="toc-matrix-coefficients-for-compact-groups-and-the-peterweyl-theorem">Matrix
coefficients for compact groups and the Peter–Weyl theorem</a>
<ul>
<li><a href="#spaces-of-matrix-coefficients"
id="toc-spaces-of-matrix-coefficients">Spaces of matrix
coefficients</a></li>
<li><a href="#uniqueness-of-invariant-inner-products"
id="toc-uniqueness-of-invariant-inner-products">Uniqueness of invariant
inner products</a></li>
<li><a
href="#matrix-entries-as-a-basis-for-the-space-of-matrix-coefficients"
id="toc-matrix-entries-as-a-basis-for-the-space-of-matrix-coefficients">Matrix
entries as a basis for the space of matrix coefficients</a></li>
<li><a href="#special-functions-as-matrix-coefficients"
id="toc-special-functions-as-matrix-coefficients">Special functions as
matrix coefficients</a></li>
<li><a href="#some-actions-of-g-times-g"
id="toc-some-actions-of-g-times-g">Some actions of <span
class="math inline">\(G \times G\)</span></a></li>
<li><a href="#burnsides-lemma" id="toc-burnsides-lemma">Burnside’s
lemma</a></li>
<li><a href="#sec:schur-orthogonality"
id="toc-sec:schur-orthogonality">Schur orthogonality</a></li>
<li><a href="#the-coefficient-ring-of-a-compact-group"
id="toc-the-coefficient-ring-of-a-compact-group">The coefficient ring of
a compact group</a></li>
<li><a href="#sec:peter-weyl-theorem"
id="toc-sec:peter-weyl-theorem">Peter–Weyl theorem: statement and proof
sketch</a></li>
</ul></li>
<li><a href="#sec:integral-operators"
id="toc-sec:integral-operators">Integral operators</a>
<ul>
<li><a href="#integrating-functions-taking-values-in-hilbert-spaces"
id="toc-integrating-functions-taking-values-in-hilbert-spaces">Integrating
functions taking values in Hilbert spaces</a></li>
<li><a
href="#definition-of-integral-operators-attached-to-representations"
id="toc-definition-of-integral-operators-attached-to-representations">Definition
of integral operators attached to representations</a></li>
<li><a href="#basic-properties" id="toc-basic-properties">Basic
properties</a></li>
<li><a href="#sec:appr-vect-their"
id="toc-sec:appr-vect-their">Approximating vectors by their images under
integral operators</a>
<ul>
<li><a href="#sec:autom-cont-finite"
id="toc-sec:autom-cont-finite">Automatic continuity for
finite-dimensional subrepresentations of <span
class="math inline">\(L^2(G)\)</span></a></li>
</ul></li>
<li><a href="#some-functional-analytic-considerations"
id="toc-some-functional-analytic-considerations">Some
functional-analytic considerations</a></li>
<li><a href="#proof-of-the-l2-density-part-of-the-peterweyl-theorem"
id="toc-proof-of-the-l2-density-part-of-the-peterweyl-theorem">Proof of
the <span class="math inline">\(L^2\)</span>-density part of the
Peter–Weyl theorem</a></li>
<li><a
href="#proof-of-the-uniform-density-part-of-the-peterweyl-theorem"
id="toc-proof-of-the-uniform-density-part-of-the-peterweyl-theorem">Proof
of the uniform density part of the Peter–Weyl theorem</a></li>
<li><a href="#sec:finite-dimens-irred"
id="toc-sec:finite-dimens-irred">Finite-dimensionality of
irreducibles</a></li>
<li><a href="#sec:four-analys-comp"
id="toc-sec:four-analys-comp">Fourier analysis on a compact group <span
class="math inline">\(G\)</span></a></li>
<li><a href="#sec:isotyp-decomp" id="toc-sec:isotyp-decomp">Isotypic
decomposition</a></li>
<li><a href="#decompositions-of-compact-type-representations"
id="toc-decompositions-of-compact-type-representations">Decompositions
of compact-type representations</a></li>
</ul></li>
<li><a href="#algebraicity-of-compact-lie-groups"
id="toc-algebraicity-of-compact-lie-groups">Algebraicity of compact Lie
groups</a>
<ul>
<li><a href="#preliminaries-on-algebraic-groups"
id="toc-preliminaries-on-algebraic-groups">Preliminaries on algebraic
groups</a></li>
<li><a href="#complexification-of-a-compact-lie-group"
id="toc-complexification-of-a-compact-lie-group">Complexification of a
compact Lie group</a></li>
<li><a href="#a-glimpse-of-tannakian-duality"
id="toc-a-glimpse-of-tannakian-duality">A glimpse of Tannakian
duality</a></li>
<li><a href="#sec:cartan-decomposition"
id="toc-sec:cartan-decomposition">Cartan decomposition</a></li>
<li><a href="#algebraic-representations"
id="toc-algebraic-representations">Algebraic representations</a></li>
<li><a href="#reductive-groups" id="toc-reductive-groups">Reductive
groups</a></li>
<li><a href="#unitary-trick" id="toc-unitary-trick">Unitary
trick</a></li>
</ul></li>
<li><a href="#structure-of-compact-lie-groups"
id="toc-structure-of-compact-lie-groups">Structure of compact Lie
groups</a>
<ul>
<li><a href="#sec:notat-relat-torus"
id="toc-sec:notat-relat-torus">Notation related to a torus</a></li>
<li><a href="#sec:maxim-tori:-defin"
id="toc-sec:maxim-tori:-defin">Maximal tori: definition and
existence</a></li>
<li><a href="#roots-and-root-space-decomposition"
id="toc-roots-and-root-space-decomposition">Roots and root space
decomposition</a></li>
<li><a href="#generators" id="toc-generators">Generators</a></li>
<li><a
href="#definition-and-finitude-of-the-weyl-group-of-a-maximal-torus"
id="toc-definition-and-finitude-of-the-weyl-group-of-a-maximal-torus">Definition
and finitude of the Weyl group of a maximal torus</a></li>
<li><a href="#sec:weyl-integr-form-general"
id="toc-sec:weyl-integr-form-general">Weyl integral formula</a></li>
<li><a href="#consequences-of-the-conjugacy-theorem"
id="toc-consequences-of-the-conjugacy-theorem">Consequences of the
conjugacy theorem</a></li>
<li><a href="#sec:basics-weyl-chambers"
id="toc-sec:basics-weyl-chambers">Basics on Weyl chambers</a></li>
<li><a href="#notation-and-preliminaries-concerning-mathopmathrmsu2"
id="toc-notation-and-preliminaries-concerning-mathopmathrmsu2">Notation
and preliminaries concerning <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></a></li>
<li><a href="#sec:from-roots-dist" id="toc-sec:from-roots-dist">From
roots to distinguished <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>’s</a></li>
<li><a href="#classification-of-rank-one-groups"
id="toc-classification-of-rank-one-groups">Classification of rank one
groups</a></li>
<li><a href="#sec:some-invariant-inner"
id="toc-sec:some-invariant-inner">Some invariant inner products</a></li>
<li><a href="#sec:proofs-conc-pass" id="toc-sec:proofs-conc-pass">Proofs
concerning the passage from roots to <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>’s</a></li>
<li><a href="#construction-of-root-reflections"
id="toc-construction-of-root-reflections">Construction of root
reflections</a></li>
<li><a href="#using-root-reflections-to-elucidate-the-weyl-group"
id="toc-using-root-reflections-to-elucidate-the-weyl-group">Using root
reflections to elucidate the Weyl group</a></li>
<li><a href="#basics-on-dominance-positivity-and-simple-roots"
id="toc-basics-on-dominance-positivity-and-simple-roots">Basics on
dominance, positivity and simple roots</a></li>
<li><a href="#cartan-matrices" id="toc-cartan-matrices">Cartan
matrices</a></li>
<li><a href="#strings-of-roots" id="toc-strings-of-roots">Strings of
roots</a></li>
<li><a href="#sec:gener-lie-algebra"
id="toc-sec:gener-lie-algebra">Generating the Lie algebra using simple
root vectors</a></li>
<li><a href="#proof-of-theorem-thmcartan-matrix-determines-k"
id="toc-proof-of-theorem-thmcartan-matrix-determines-k">Proof of Theorem
141</a></li>
<li><a href="#dynkin-diagrams" id="toc-dynkin-diagrams">Dynkin
diagrams</a></li>
<li><a href="#sec:root-data" id="toc-sec:root-data">Root data</a></li>
</ul></li>
<li><a href="#sec:repr-comp-lie"
id="toc-sec:repr-comp-lie">Representations of compact Lie groups</a>
<ul>
<li><a href="#setup-and-preliminaries"
id="toc-setup-and-preliminaries">Setup and preliminaries</a></li>
<li><a href="#classification-of-irreducibles"
id="toc-classification-of-irreducibles">Classification of
irreducibles</a></li>
<li><a href="#sec:borel-weil"
id="toc-sec:borel-weil">Borel–Weil</a></li>
</ul></li>
<li><a href="#plancherel-formula-for-complex-reductive-groups"
id="toc-plancherel-formula-for-complex-reductive-groups">Plancherel
formula for complex reductive groups</a>
<ul>
<li><a href="#sec:iwas-decomp" id="toc-sec:iwas-decomp">Iwasawa
decomposition</a></li>
<li><a href="#sec:integr-b-backsl"
id="toc-sec:integr-b-backsl">Integration on <span
class="math inline">\(B \backslash G\)</span></a></li>
<li><a href="#principal-series-representations"
id="toc-principal-series-representations">Principal series
representations</a></li>
<li><a href="#characters-of-principal-series-representations"
id="toc-characters-of-principal-series-representations">Characters of
principal series representations</a></li>
<li><a href="#some-basics-concerning-conjugacy-classes-in-g"
id="toc-some-basics-concerning-conjugacy-classes-in-g">Some basics
concerning conjugacy classes in <span
class="math inline">\(G\)</span></a></li>
<li><a href="#a-change-of-variables" id="toc-a-change-of-variables">A
change of variables</a></li>
<li><a href="#passage-to-the-lie-algebra"
id="toc-passage-to-the-lie-algebra">Passage to the Lie algebra</a></li>
<li><a href="#main-result" id="toc-main-result">Main result</a></li>
</ul></li>
</ul>
</nav>
<p>In mathematics and related fields, one often encounters vector spaces
<span class="math inline">\(V\)</span>, such as</p>
<ul>
<li><p>the vector space <span class="math inline">\(V =
L^2(X,\mu)\)</span> consisting of functions <span
class="math inline">\(f : X \rightarrow \mathbb{C}\)</span> on some nice
topological space <span class="math inline">\(X\)</span> that are
square-integrable with respect to some measure <span
class="math inline">\(\mu\)</span>, or</p></li>
<li><p>the space of solutions <span class="math inline">\(\phi\)</span>
to some linear differential equation <span class="math inline">\(D \phi
= 0\)</span>,</p></li>
</ul>
<p>and so on. The inputs to the construction of <span
class="math inline">\(V\)</span> are sometimes invariant by some
symmetry group <span class="math inline">\(G\)</span>. In the first
example, <span class="math inline">\(G\)</span> might have a
measure-preserving action on <span
class="math inline">\((X,\mu)\)</span>. In the second, <span
class="math inline">\(G\)</span> might commute with the operator <span
class="math inline">\(D\)</span> (for instance, many of the basic
equations of mathematical physics are invariant by something like the
rotation group <span
class="math inline">\(\mathop{\mathrm{SO}}(3)\)</span>). In either case
we obtain a linear action of <span class="math inline">\(G\)</span> on
<span class="math inline">\(V\)</span>, i.e., a homomorphism <span
class="math inline">\(G \rightarrow \mathop{\mathrm{GL}}(V)\)</span>.
The case that <span class="math inline">\(G\)</span> is a Lie group is
simultaneously one of the most interesting cases (because of the many
examples) and accessible (because, e.g., connected Lie groups are in
many respects simpler than finite groups, thanks to powerful tools from
calculus and linear algebra). In this course, we still develop the basic
theory of such actions. We emphasize the general theory of compact
groups, their relation with complex reductive groups, the structure
theory and representations of compact Lie groups, and conclude with a
bit about representations of complex reductive groups.</p>
<h2 class="unnumbered" id="acknowledgments">Acknowledgments</h2>
<p>We thank Subhajit Jana, Constantin Kogler, Kaj B<span>ä</span>uerle
and many other participants of the course for corrections and
comments.</p>
<h1 id="prerequisites">Prerequisites</h1>
<p>We recall here some of the basics from linear algebra, topology,
differential geometry, Lie theory, and functional analysis that will be
used throughout the course.</p>
<p>We won’t assume any prior knowledge of representation theory.</p>
<h2 id="conventions">Conventions</h2>
<p>In this course, <span class="math display">\[\text{``topological
space&#39;&#39;} := \text{``separable Hausdorff topological
space.&#39;&#39;}\]</span> The examples we consider will moreover be
locally compact, but we will mention this hypothesis explicitly when it
is used. Similarly <span class="math display">\[\text{``vector
space&#39;&#39;} := \text{``complex vector space&#39;&#39;}\]</span>
unless we specify otherwise.</p>
<h2 id="topological-groups">Topological groups</h2>
<div class="definition">
<p><strong>Definition 1</strong>. A <em>topological group</em> is a
group <span class="math inline">\(G\)</span> equipped with a topology
such that the maps <span class="math display">\[G \times G \rightarrow
G\]</span> <span class="math display">\[(x,y) \mapsto x y\]</span> and
<span class="math display">\[G \rightarrow G\]</span> <span
class="math display">\[x \mapsto x^{-1}\]</span> are continuous.
Similarly, a <em>topological vector space</em> is a vector space
equipped with a topology such that the maps <span
class="math display">\[V \times V \rightarrow V\]</span> <span
class="math display">\[(x,y) \mapsto x + y\]</span> and <span
class="math display">\[\mathbb{C} \times V \rightarrow V\]</span> <span
class="math display">\[(\lambda,x) \mapsto \lambda x\]</span> are
continuous. We write in that case <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> for the group of
continuous linear maps <span class="math inline">\(\phi : V \rightarrow
V\)</span> that admit a continuous two-sided inverse.</p>
</div>
<p>For instance, any finite group (always equipped with the discrete
topology) is a topological group, as is any Lie group; any
finite-dimensional vector space is naturally a topological vector space,
as is any Hilbert space or Banach space.</p>
<h2 id="lie-theory">Lie theory</h2>
<p>We’ll assume a large number of facts from basic Lie theory. For
instance, a Lie group <span class="math inline">\(G\)</span> has a Lie
algebra <span class="math inline">\(\mathfrak{g}\)</span>. A continuous
homomorphism <span class="math inline">\(G_1 \rightarrow G_2\)</span>
between two Lie groups is automatically smooth, or even analytic, and
differentiates to a Lie algebra homomorphism <span
class="math inline">\(\mathfrak{g}_1 \rightarrow
\mathfrak{g}_2\)</span>. For a finite-dimensional vector space <span
class="math inline">\(V\)</span>, the group <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> is a Lie group
with Lie algebra <span
class="math inline">\(\mathop{\mathrm{End}}(V)\)</span>.</p>
<h2 id="haar-measure">Haar measure</h2>
<p>We abbreviate “locally compact topological group” to “locally compact
group,” and similarly for “compact group.”</p>
<div class="definition">
<p><strong>Definition 2</strong>. Let <span
class="math inline">\(G\)</span> be a locally compact group. Recall that
a <em>Radon measure</em> <span class="math inline">\(d g\)</span> on
<span class="math inline">\(G\)</span> is a functional <span
class="math display">\[C_c(G) \rightarrow \mathbb{C}\]</span> <span
class="math display">\[f \mapsto \int_G f \, d g = \int_{g \in G} f(g)
\, d g\]</span> such that <span class="math inline">\(f \geq 0 \implies
\int_G f \, d g \geq 0\)</span>.<a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a> For each such <span
class="math inline">\(f\)</span> and each <span class="math inline">\(h
\in G\)</span>, we denote by <span class="math inline">\(\lambda_h
f\)</span> and <span class="math inline">\(\rho_h f\)</span> the left
and right translates of <span class="math inline">\(G\)</span>,
normalized so that <span class="math inline">\(\lambda_{h_1 h_2} =
\lambda_{h_1} \lambda_{h_2}\)</span> and <span
class="math inline">\(\rho_{h_1 h_2} = \rho_{h_1} \rho_{h_2}\)</span>:
<span class="math display">\[\lambda_h f(g) := f(h^{-1} g), \quad \rho_h
f(g) := f(g h^{-1}).\]</span> Recall that <span class="math inline">\(d
g\)</span> is a <em>left Haar measure</em> if <span
class="math inline">\(\int_G f \, d g = \int_G \lambda_{h} f \, d
g\)</span> for all <span class="math inline">\(h \in G\)</span>. The
notion of a <em>right Haar measure</em> is defined analogously using
<span class="math inline">\(\rho_h\)</span>. We say that <span
class="math inline">\(d g\)</span> is a <em>Haar measure</em> if it is
both a left Haar measure and a right Haar measure.</p>
</div>
<div class="theorem">
<p><strong>Theorem 3</strong>. <em>Let <span
class="math inline">\(G\)</span> be a locally compact group. Then left
Haar measures exist, and any two are positive multiples of one another.
Similarly for right Haar measures.</em></p>
<p><em>Suppose moreover that <span class="math inline">\(G\)</span> is
compact. Then Haar measures exist, and assign finite volume to <span
class="math inline">\(G\)</span>.</em></p>
</div>
<p>In particular, there is a unique Haar measure <span
class="math inline">\(d g\)</span> on <span
class="math inline">\(G\)</span> such that <span
class="math inline">\(\mathop{\mathrm{vol}}(G,d g) = 1\)</span>; we call
it the <em>probability Haar measure on <span
class="math inline">\(G\)</span></em>. We will often denote integration
with respect to the probability Haar simply by <span
class="math inline">\(\int_G f := \int_G f \, d g\)</span>, omitting the
<span class="math inline">\(d g\)</span> when it is clear by
context.</p>
<p>For example, if <span class="math inline">\(G\)</span> is finite,
then the probability Haar <span class="math inline">\(d g\)</span> is
given by the normalized counting measure: <span
class="math display">\[\int_G f \, d g = \frac{1}{|G|} \sum_{g \in G}
f(g).\]</span></p>
<h2 id="sec:spectr-theory-comp">§1.5. Spectral theory for compact self-adjoint
operators</h2>
<p>Let <span class="math inline">\(V = (V, \langle , \rangle)\)</span>
be a Hilbert space and <span class="math inline">\(T : V \rightarrow
V\)</span> a bounded operator. Recall that <span
class="math inline">\(T\)</span> is</p>
<ul>
<li><p><em>self-adjoint</em> if <span class="math inline">\(\langle T
v_1, v_2 \rangle = \langle v_1, T v_2 \rangle\)</span> for all <span
class="math inline">\(v_1, v_2 \in V\)</span>, and</p></li>
<li><p><em>compact</em> if it maps the unit ball to a precompact set, or
equivalently, if each bounded sequence <span
class="math inline">\(v_n\)</span> in <span
class="math inline">\(V\)</span> has a subsequence <span
class="math inline">\(v_{n_k}\)</span> such that the sequence <span
class="math inline">\(T v_{n_k}\)</span> converges.</p></li>
</ul>
<p>A basic example is when <span class="math inline">\(T\)</span> is
diagonalized by an orthonormal basis <span
class="math inline">\(e_1,e_2,\dotsc\)</span> of <span
class="math inline">\(V\)</span>, thus <span class="math inline">\(T e_j
= \lambda_j e_j\)</span> for some <span class="math inline">\(\lambda_j
\in \mathbb{C}\)</span>; then <span class="math inline">\(T\)</span> is
compact precisely when <span class="math inline">\(\lambda_j \rightarrow
0\)</span> as <span class="math inline">\(j \rightarrow
\infty\)</span>.</p>
<div id="thm:spectral-theorem-compact" class="theorem">
<p><strong>Theorem 4</strong>. <em>Let <span
class="math inline">\(T\)</span> be compact and self-adjoint. Then every
eigenvalue <span class="math inline">\(\lambda\)</span> of <span
class="math inline">\(T\)</span> is real. For each such <span
class="math inline">\(\lambda\)</span>, let <span
class="math inline">\(V_\lambda \subseteq V\)</span> denote the <span
class="math inline">\(\lambda\)</span>-eigenspace. Then <span
class="math inline">\(V\)</span> is the Hilbert direct sum <span
class="math inline">\(\hat{\oplus}_{\lambda} V_\lambda\)</span>, i.e.,
the closure of the algebraic direct sum <span
class="math inline">\(\oplus_{\lambda} V_\lambda\)</span>. Moreover, for
each <span class="math inline">\(\varepsilon&gt; 0\)</span>, the space
<span class="math inline">\(\oplus_{\lambda : |\lambda| \geq
\varepsilon} V_\lambda\)</span> is finite-dimensional. In particular, if
<span class="math inline">\(V\)</span> is nonzero, then <span
class="math inline">\(T\)</span> has an eigenvector.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof sketch." data-folded-text="Proof sketch. (...)">Proof sketch.</em></a>
<span class="proof-content"> Let’s note first that the
finite-dimensionality of the spaces <span
class="math inline">\(\oplus_{\lambda : |\lambda| \geq \varepsilon}
V_\lambda\)</span> is automatic: if any such space were
infinite-dimensional, then we could find an infinite sequence of unit
vectors <span class="math inline">\(v_n\)</span> for which <span
class="math inline">\(\|T v_n\| \geq \varepsilon\)</span>, contrary to
the assumed compactness of <span class="math inline">\(T\)</span>.</p>
<p>Turning to the main point of the proof, let <span
class="math inline">\(W\)</span> denote the orthogonal complement of
<span class="math inline">\(\oplus_{\lambda} V_\lambda\)</span>. We know
that <span class="math inline">\(T\)</span> acts on <span
class="math inline">\(W\)</span> and has no eigenvectors in <span
class="math inline">\(W\)</span>, while our task is to show that <span
class="math inline">\(W = \{0\}\)</span>. The main point is thus to show
that any compact self-adjoint operator on a nonzero Hilbert space admits
an eigenvector. See for instance §9.2 of my “Lie Groups” notes on the
course homepage. ◻</p>
</span></div>
<p>Recall also from linear algebra the following consequence of (e.g.)
the Jordan normal form:</p>
<div class="lemma">
<p><strong>Lemma 5</strong>. Any linear operator on a nonzero
finite-dimensional (complex) vector space has an eigenvector.</p>
</div>
<h2 id="sec:linear-algebra">§1.6. Linear algebra</h2>
<p>Let <span class="math inline">\(V, V_1, V_2\)</span> be
finite-dimensional vector spaces. We can then construct some additional
vector spaces:</p>
<ol>
<li><p>The dual space <span class="math inline">\(V^* =
\mathop{\mathrm{Hom}}(V,\mathbb{C})\)</span> consisting of linear
functionals <span class="math inline">\(\ell : V \rightarrow
\mathbb{C}\)</span>. For <span class="math inline">\(\ell \in
V^*\)</span> and <span class="math inline">\(v \in V\)</span>, we
sometimes write <span class="math inline">\(\langle \ell, v \rangle =
\ell(v)\)</span> for the natural pairing.</p></li>
<li><p>The conjugate space <span
class="math inline">\(\overline{V}\)</span>. By definition, this is a
set equipped with a bijection <span class="math inline">\(V \rightarrow
\overline{V}\)</span>, denoted <span class="math inline">\(v \mapsto
\overline{v}\)</span>. We define the vector space structure on <span
class="math inline">\(\overline{V}\)</span> by requiring that <span
class="math inline">\(v \mapsto \overline{v}\)</span> commute with
addition (i.e., <span class="math inline">\(\overline{v_1} +
\overline{v_2} = \overline{v_1 + v_2}\)</span>) and intertwine scalar
multiplication with conjugation, thus for <span
class="math inline">\(\lambda \in \mathbb{C}\)</span>, <span
class="math display">\[\lambda \overline{v} :=
\overline{(\overline{\lambda} v )}.\]</span></p></li>
<li><p>The space <span
class="math inline">\(\mathop{\mathrm{Hom}}(V_1,V_2)\)</span> of linear
maps <span class="math inline">\(T : V_1 \rightarrow
V_2\)</span>.</p></li>
<li><p>The space <span class="math inline">\(\mathop{\mathrm{End}}(V) :=
\mathop{\mathrm{Hom}}(V,V)\)</span> of linear operators <span
class="math inline">\(T : V \rightarrow V\)</span>.</p></li>
<li><p>The direct sum <span class="math inline">\(V_1 \oplus
V_2\)</span>, for which linear maps <span class="math inline">\(f : V_1
\oplus V_2 \rightarrow V\)</span> are in natural bijection with pairs
<span class="math inline">\((f_1,f_2)\)</span> of linear maps <span
class="math inline">\(f_i : V_i \rightarrow V\)</span>.</p></li>
<li><p>The tensor product <span class="math inline">\(V_1 \otimes
V_2\)</span>, for which linear maps <span class="math inline">\(f : V_1
\otimes V_2 \rightarrow V\)</span> are in natural bijection with
bilinear maps <span class="math inline">\(f : V_1 \times V_2 \rightarrow
V\)</span>.</p></li>
</ol>
<p>We have an isomorphism <span class="math display">\[V_1^* \otimes V_2
\rightarrow \mathop{\mathrm{Hom}}(V_1,V_2)\]</span> given by <span
class="math display">\[\ell_1 \otimes v_2 \mapsto [w_1 \mapsto
\ell_1(w_1) v_2]\]</span> The inverse map is described by taking
coefficients of <span class="math inline">\(T\)</span> with respect to
bases. In more detail, fix bases <span
class="math inline">\(e_1,\dotsc,e_m\)</span> of <span
class="math inline">\(V_1\)</span> and <span
class="math inline">\(f_1,\dotsc,f_n\)</span> of <span
class="math inline">\(V_2\)</span> together with dual bases <span
class="math inline">\(e_1^*, \dotsc, e_m^*\)</span> of <span
class="math inline">\(V_1^*\)</span> and <span
class="math inline">\(f_1^*, \dotsc, f_n^*\)</span> of <span
class="math inline">\(V_2^*\)</span>, so that <span
class="math inline">\(\langle e_i^*, e_j \rangle = \langle f_i^*, f_j
\rangle = \delta_{i j}\)</span>. Then for any <span
class="math inline">\(T \in \mathop{\mathrm{Hom}}(V_1,V_2)\)</span> and
<span class="math inline">\(v \in V_1\)</span>, we have <span
class="math display">\[v = \sum_i \langle e_i^*, v \rangle e_i\]</span>
and <span class="math display">\[T e_j = \sum_i \underbrace{ \langle
f_i^*, T e_j \rangle }_{=: a_{ij} } f_i,\]</span> so that <span
class="math display">\[T v = \sum_{i,j} a_{i j} \langle e_j^*, v \rangle
f_i,\]</span> and thus <span
class="math display">\[\mathop{\mathrm{Hom}}(V_1,V_2) \ni T
\leftrightarrow \sum_{i,j} a_{i j} e_j^* \otimes f_i \in V_1^* \otimes
V_2.\]</span></p>
<p>In particular, we may identify <span
class="math display">\[\mathop{\mathrm{End}}(V) \cong V^* \otimes
V.\]</span> Under this identification, <span
class="math display">\[\mathop{\mathrm{trace}}: \mathop{\mathrm{End}}(V)
\rightarrow \mathbb{C}\]</span> corresponds to the linear map <span
class="math display">\[V^* \otimes V \rightarrow \mathbb{C}\]</span>
<span class="math display">\[\ell \otimes v \mapsto \langle \ell, v
\rangle.\]</span></p>
<h1 id="introduction">Introduction</h1>
<h2 id="representations">Representations</h2>
<div class="definition">
<p><strong>Definition 6</strong>. Let <span
class="math inline">\(G\)</span> be a topological group and <span
class="math inline">\(V\)</span> a topological vector space. A
<em>representation</em> <span class="math inline">\(\pi\)</span> of
<span class="math inline">\(G\)</span> on <span
class="math inline">\(V\)</span> is a group homomorphism <span
class="math display">\[\pi : G \rightarrow
\mathop{\mathrm{GL}}(V)\]</span> for which the map <span
class="math display">\[G \times V \rightarrow V\]</span> <span
class="math display">\[(g,v) \mapsto \pi(g) v =: g v\]</span> is
continuous.</p>
</div>
<p>Rather than saying “<span class="math inline">\((\pi,V)\)</span> is a
representation of <span class="math inline">\(G\)</span>,” we might
simply say “let <span class="math inline">\(V\)</span> be a
representation of <span class="math inline">\(G\)</span>” or “let <span
class="math inline">\(G\)</span> act linearly on <span
class="math inline">\(V\)</span>,” with the action map <span
class="math inline">\(\pi = \pi_V\)</span> defined implicitly and its
continuity conditions imposed by default; we will then often denote the
action by juxtaposition, <span class="math inline">\(g v := \pi_V(g)
v\)</span>, as above. Other times we’ll say “let <span
class="math inline">\(\pi\)</span> be a representation of <span
class="math inline">\(G\)</span>,” with the underlying vector space
<span class="math inline">\(V = V_\pi\)</span> defined implicitly.
Eventually we’ll often write simply <span
class="math inline">\(\pi\)</span> both for the action and the
underlying vector space, but we’ll avoid doing that for now.</p>
<div class="remark">
<p><strong>Remark 7</strong>. Suppose that <span
class="math inline">\(G\)</span> is a Lie group and <span
class="math inline">\(V\)</span> is finite-dimensional, so that <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> is a Lie group
with Lie algebra <span
class="math inline">\(\mathop{\mathrm{End}}(V)\)</span>. Then a theorem
from “Lie groups” implies that <span class="math inline">\(\pi\)</span>
is automatically smooth, hence differentiates to a Lie algebra
homomorphism <span class="math inline">\(\mathfrak{g} :=
\mathop{\mathrm{Lie}}(G) \rightarrow
\mathop{\mathrm{End}}(V)\)</span>.</p>
</div>
<div class="example">
<p><strong>Example 8</strong>.  </p>
<ol>
<li><p>Let <span class="math inline">\(X\)</span> be a locally compact
space equipped with a Radon measure <span
class="math inline">\(\mu\)</span>. Suppose that <span
class="math inline">\(G\)</span> acts on <span
class="math inline">\(X\)</span>, preserving <span
class="math inline">\(\mu\)</span> (i.e., there is a continuous map
<span class="math inline">\(G \times X \rightarrow X\)</span>,
satisfying the axioms for a group action, such that for each <span
class="math inline">\(g \in G\)</span>, the induced map <span
class="math inline">\(g : X \rightarrow X\)</span> satisfies <span
class="math inline">\(g_* \mu = \mu\)</span>). Then <span
class="math inline">\(G\)</span> acts linearly on <span
class="math inline">\(L^2(X,\mu)\)</span>, i.e., we have a
representation <span class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(L^2(X,\mu))\)</span>. These representations provide
some of the most important examples.</p>
<p>In more detail, if we are given a left action denoted “<span
class="math inline">\(g x\)</span>,” then for <span
class="math inline">\(g \in G\)</span> and <span class="math inline">\(f
\in L^2(X,\mu)\)</span>, we set <span id="eq:action-on-functions-induced-by-left-translation" class="math display">\[\label{eq:action-on-functions-induced-by-left-translation}\tag{1}
      (\pi(g) f)(x) := f(g^{-1} x),\]</span> while if we are instead
given a right action denoted “<span class="math inline">\(x g\)</span>,”
then we should take <span id="eq:action-on-functions-induced-by-right-translation" class="math display">\[\label{eq:action-on-functions-induced-by-right-translation}\tag{2}
      (\pi(g) f)(x) := f(x g).\]</span> As an exercise, check in either
case that <span class="math inline">\(\pi(g_1) \pi(g_2) = \pi(g_1
g_2)\)</span> for all <span class="math inline">\(g_1, g_2 \in
G\)</span>.</p>
<p>Check for instance for <span class="math inline">\(G =
\mathbb{R}\)</span> acting on <span class="math inline">\(X =
\mathbb{R}\)</span> by translation, and with <span
class="math inline">\(\mu\)</span> Lebesgue measure, that the action map
<span class="math display">\[\mathbb{R} \times L^2(\mathbb{R})
\rightarrow L^2(\mathbb{R})\]</span> is continuous; on the other hand,
for any nonzero <span class="math inline">\(x \in \mathbb{R}\)</span>
there exists <span class="math inline">\(f \in L^2(\mathbb{R})\)</span>
with <span class="math inline">\(\|f\| = 1\)</span> so that <span
class="math inline">\(\|\pi(x) f - f \| \geq 1\)</span> (e.g., take for
<span class="math inline">\(f\)</span> a bump function supported in
<span class="math inline">\([-|x|/10, |x|/10]\)</span>), so that the map
from <span class="math inline">\(\mathbb{R}\)</span> to the space <span
class="math inline">\(\mathop{\mathrm{GL}}(L^2(\mathbb{R}))\)</span>
equipped with the operator norm is not continuous. These observations
motivate the definition of “representation” given above.</p>
<p>Suppose for instance that <span class="math inline">\(G\)</span> is a
compact group, equipped with its probability Haar measure <span
class="math inline">\(d g\)</span>. Then the action of <span
class="math inline">\(G\)</span> on itself by right multiplication
preserves <span class="math inline">\(d g\)</span>. The above discussion
specialized to <span class="math inline">\((X,\mu) = (G, d g)\)</span>
gives a representation <span class="math display">\[\rho : G \rightarrow
\mathop{\mathrm{GL}}(L^2(G,d g))\]</span> given by right translation as
in <a href="#eq:action-on-functions-induced-by-right-translation"
data-reference-type="eqref"
data-reference="eq:action-on-functions-induced-by-right-translation">\((2)\)</a>.
This representation is called the <em>right regular representation</em>.
We may similarly define the <em>left regular representation</em> <span
class="math display">\[\lambda : G \rightarrow
\mathop{\mathrm{GL}}(L^2(G, d g))\]</span> using left translation as in
<a href="#eq:action-on-functions-induced-by-left-translation"
data-reference-type="eqref"
data-reference="eq:action-on-functions-induced-by-left-translation">\((1)\)</a>.
Note that if <span class="math inline">\(G\)</span> is finite, then
<span class="math inline">\(L^2(G, d g)\)</span> is just the space <span
class="math inline">\(\mathbb{C}^G\)</span> of functions <span
class="math inline">\(f : G \rightarrow \mathbb{C}\)</span>. Note also
that we didn’t really require compactness: on any locally compact group,
we can define the right (resp. left) regular representation using any
right (resp. left) Haar measure.</p></li>
<li><p>The <em>trivial representation</em> of a group <span
class="math inline">\(G\)</span> on the one-dimensional vector space
<span class="math inline">\(\mathbb{C}\)</span> is the map <span
class="math inline">\(G \rightarrow \mathop{\mathrm{GL}}(\mathbb{C}) =
{\mathop{\mathrm{GL}}}_1(\mathbb{C})\)</span> given by <span
class="math inline">\(g \mapsto 1\)</span>.</p></li>
<li><p>The <em>zero representation</em> of <span
class="math inline">\(G\)</span> on the zero-dimensional vector space
<span class="math inline">\(\{0\}\)</span>. This representation is
unimportant, and will practically never be considered in this course; we
mention it for now just to disambiguate it from the (very important)
trivial representation.</p></li>
<li><p>Most of the classical groups <span
class="math inline">\(G\)</span> that one encounters in Lie theory
(e.g., <span class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{R}),
{\mathop{\mathrm{GL}}}_n(\mathbb{C}), \operatorname{O}(n),
\mathop{\mathrm{U}}(n)\)</span> and <span
class="math inline">\(\mathop{\mathrm{Sp}}(n)\)</span> for <span
class="math inline">\(n\)</span> even) come with a “standard
representation” <span class="math inline">\(G \rightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C}) =
\mathop{\mathrm{GL}}(\mathbb{C}^n)\)</span>.</p></li>
<li><p>For a finite-dimensional vector space <span
class="math inline">\(V\)</span>, the group <span
class="math inline">\(\mathop{\mathrm{GL}}(V)\)</span> is a Lie group.
Its finite-dimensional representations <span class="math display">\[\rho
: \mathop{\mathrm{GL}}(V) \rightarrow \mathop{\mathrm{GL}}(W)\]</span>
play a special role in the theory: given any representation <span
class="math display">\[\pi : G \rightarrow
\mathop{\mathrm{GL}}(V),\]</span> we may compose it with <span
class="math inline">\(\rho\)</span> to get a new representation <span
class="math display">\[\rho \circ \pi : G \rightarrow
\mathop{\mathrm{GL}}(W).\]</span></p>
<p>For example, we may take for <span
class="math inline">\(\rho\)</span> the determinant representation <span
class="math inline">\(\det : \mathop{\mathrm{GL}}(V) \rightarrow
{\mathop{\mathrm{GL}}}_1(\mathbb{C}) = \mathbb{C}^\times\)</span>, and
form the determinant <span class="math inline">\(\det \circ \pi : G
\rightarrow \mathbb{C}^\times\)</span> of a representation <span
class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span>.</p></li>
<li><p>A Lie group <span class="math inline">\(G\)</span> defined over
the reals has a Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>, which is a real vector
space; its complexification <span
class="math inline">\(\mathfrak{g}_{\mathbb{C}} := \mathfrak{g}
\otimes_{\mathbb{R}} \mathbb{C}\)</span> is a complex vector space, and
the adjoint representation <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
{\mathop{\mathrm{GL}}}_{\mathbb{R}}(\mathfrak{g})\)</span> defines in
particular a (complex) representation <span
class="math display">\[\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g}_{\mathbb{C}}).\]</span> (If we start
with a Lie group <span class="math inline">\(G\)</span> over the complex
numbers, like <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, then
we get a representation <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g})\)</span> in the sense of this course
without having to complexify.)</p></li>
<li><p>The symmetric group <span class="math inline">\(S(n)\)</span>
comes with a <em>standard representation</em> <span
class="math display">\[\pi : S(n) \rightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\]</span> on <span
class="math inline">\(\mathbb{C}^n\)</span>, given by permuting the
standard basis elements <span
class="math inline">\(e_1,\dotsc,e_n\)</span>: for <span
class="math inline">\(g \in S(n)\)</span>, we define <span
class="math inline">\(\pi(g) e_j := e_{g(j)}\)</span>. This is just the
representation of elements of the symmetric group by permutation
matrices; for <span class="math inline">\(n=2\)</span> we get <span
class="math inline">\(\begin{pmatrix}
      1 &amp;  \\
        &amp; 1
    \end{pmatrix}
,
\begin{pmatrix}
      &amp; 1 \\
      1 &amp;
    \end{pmatrix}\)</span>, for <span class="math inline">\(n =
3\)</span> we get <span class="math inline">\(\begin{pmatrix}
      1 &amp;  &amp;  \\
        &amp; 1 &amp;  \\
        &amp; &amp; 1
    \end{pmatrix}\)</span>, <span class="math inline">\(\begin{pmatrix}
      &amp; 1 &amp;  \\
      1 &amp;  &amp;  \\
      &amp; &amp; 1
    \end{pmatrix}\)</span>, and so on. We can compose <span
class="math inline">\(\pi\)</span> with the determinant map <span
class="math inline">\(\det : {\mathop{\mathrm{GL}}}_n(\mathbb{C})
\rightarrow \mathbb{C}^\times\)</span> to get the <em>sign
representation</em> <span class="math display">\[\mathop{\mathrm{sgn}}:=
\det \circ \pi : S(n) \rightarrow \{\pm 1\} \subseteq
\mathbb{C}^\times.\]</span> Equivalently, <span
class="math inline">\(\mathop{\mathrm{sgn}}(g) = (-1)^k\)</span> if
<span class="math inline">\(g = \tau_1 \dotsb \tau_k\)</span>, with each
<span class="math inline">\(\tau_j\)</span> a transposition. We will
sometimes use the notation <span class="math display">\[(-1)^g :=
\mathop{\mathrm{sgn}}(g)\]</span> for <span class="math inline">\(g \in
S(n)\)</span>.</p></li>
<li><p>Most of the standard operations from linear algebra (e.g., those
recalled in §<a href="#sec:linear-algebra" data-reference-type="ref"
data-reference="sec:linear-algebra">1.6</a>) induce corresponding
operations on representations. For instance, given finite-dimensional
representations <span
class="math inline">\((\pi,V),(\pi_1,V_1),(\pi_2,V_2)\)</span> of <span
class="math inline">\(G\)</span>, we may form:</p>
<ul>
<li><p>the <em>dual</em> (or <em>contragredient</em>)
<em>representation</em> <span class="math inline">\((\pi^*,
V^*)\)</span> on the dual space <span class="math inline">\(V^*\)</span>
by setting <span class="math display">\[(\pi^*(g) \ell)(v) :=
\ell(\pi(g)^{-1} v),\]</span> so that <span
class="math display">\[\langle \pi^*(g) \ell, \pi(g) v \rangle = \langle
\ell, v \rangle,\]</span></p></li>
<li><p>the <em>conjugate representation</em> <span
class="math inline">\((\overline{\pi}, \overline{V})\)</span> by <span
class="math display">\[\overline{\pi }(g) \overline{v} :=
\overline{\pi(g) v},\]</span></p></li>
<li><p>the direct sum <span class="math inline">\((\pi_1 \oplus \pi_2,
V_1 \oplus V_2)\)</span> by <span class="math display">\[g (v_1, v_2) :=
(g v_1, g v_2),\]</span></p></li>
<li><p>the tensor product <span class="math inline">\((\pi_1 \otimes
\pi_2, V_1 \otimes V_2)\)</span> by <span class="math display">\[g (v_1
\otimes v_2) := g v_1 \otimes g v_2,\]</span> and</p></li>
<li><p>the representation <span
class="math inline">\((\mathop{\mathrm{Hom}}(\pi_1,\pi_2),
\mathop{\mathrm{Hom}}(V_1,V_2))\)</span> by, for <span
class="math inline">\(g \in G\)</span> and <span class="math inline">\(f
\in \mathop{\mathrm{Hom}}(V_1,V_2)\)</span>, <span
class="math display">\[g f := [V_1 \ni v_1 \mapsto \pi_2(g)
f(\pi_1(g)^{-1} v_1) \in V_2 ].\]</span></p></li>
</ul></li>
</ol>
</div>
<h2 id="unitarity">Unitarity</h2>
<div class="definition">
<p><strong>Definition 9</strong>. Let <span class="math inline">\(\pi :
G \rightarrow \mathop{\mathrm{GL}}(V)\)</span> be a representation as
above. Suppose that <span class="math inline">\(V\)</span> is equipped
with an inner product <span class="math inline">\(\langle ,
\rangle\)</span> (e.g., if <span class="math inline">\(V\)</span> is a
Hilbert space). We say then that <span
class="math inline">\(\pi\)</span> is <em>unitary</em> (with respect to
<span class="math inline">\(\langle , \rangle\)</span>) if <span
class="math display">\[\langle g v_1, g v_2 \rangle = \langle v_1, v_2
\rangle\]</span> for all <span class="math inline">\(g \in G\)</span>
and <span class="math inline">\(v_1, v_2 \in V\)</span>; we might
equivalently say that the inner product <span
class="math inline">\(\langle , \rangle\)</span> is <em>invariant</em>
for the action of <span class="math inline">\(G\)</span>. We say in
general that <span class="math inline">\(\pi\)</span> is
<em>unitarizable</em> if there exists an invariant inner product, i.e.,
an inner product <span class="math inline">\(\langle , \rangle\)</span>
on <span class="math inline">\(V\)</span> with respect to which <span
class="math inline">\(\pi\)</span> is unitary.</p>
</div>
<p>We can already prove a basic theorem:</p>
<div id="thm:compact-unitarizability" class="theorem">
<p><strong>Theorem 10</strong>. <em>Let <span
class="math inline">\(G\)</span> be a compact group. Let <span
class="math inline">\(V\)</span> be a finite-dimensional representation,
or a Hilbert space representation. Then <span
class="math inline">\(V\)</span> is unitarizable.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> In the finite-dimensional case, let <span
class="math inline">\(\langle , \rangle_0\)</span> be any inner product
on <span class="math inline">\(V\)</span>; in the Hilbert case, let it
denote the “given” inner product; in either case, note that it defines a
continuous map <span class="math inline">\(V \times V \rightarrow
V\)</span>. The idea is to average this inner product using the Haar
measure to get an invariant inner product. Turning to details, recall
that the action map <span class="math inline">\(G \times V \rightarrow
V\)</span> is assumed continuous. For <span class="math inline">\(v_1,
v_2\)</span>, the function <span class="math inline">\(G \ni g \mapsto
\langle g v_1, g v_2 \rangle_0\)</span> is then a continuous function on
a compact set, hence is bounded, and in particular integrable with
respect to the probabilty Haar <span class="math inline">\(d g\)</span>.
We set <span class="math display">\[\langle v_1, v_2 \rangle := \int_{g
\in G} \langle g v_1, g v_2 \rangle_0 \, d g.\]</span> It’s easy to see
that <span class="math inline">\(\langle , \rangle\)</span> defines an
inner product; for instance, if <span class="math inline">\(v \neq
0\)</span>, then <span class="math inline">\(\langle v,v \rangle_0 &gt;
0\)</span>, hence (by continuity) <span class="math inline">\(\langle g
v, g v \rangle_0 &gt; 0\)</span> for all <span
class="math inline">\(g\)</span> in some neighborhood of the identity
element, hence (by regularity of Radon measures) <span
class="math inline">\(\langle v, v \rangle &gt; 0\)</span>. Using the
right-invariance of <span class="math inline">\(d g\)</span>, we verify
for <span class="math inline">\(h \in G\)</span> that <span
class="math display">\[\langle h v_1, h v_2 \rangle = \int_{g \in G}
\langle g h v_1, g h v_2 \rangle_0 \, d g = \int_{g \in G} \langle g
v_1, g v_2 \rangle_0 \, d g = \langle v_1, v_2 \rangle.\]</span> Thus
the representation <span class="math inline">\(V\)</span> is unitary
with respect to the inner product <span class="math inline">\(\langle ,
\rangle\)</span>. ◻</p>
</span></div>
<h2
id="morphisms-equivariant-maps-intertwiners-isomorphisms-equivalences-and-so-on">Morphisms,
equivariant maps, intertwiners, isomorphisms, equivalences, and so
on</h2>
<div class="definition">
<p><strong>Definition 11</strong>. Let <span
class="math inline">\((\pi_1, V_1)\)</span> and <span
class="math inline">\((\pi_2, V_2)\)</span> be representations of <span
class="math inline">\(G\)</span>. By a <em>morphism</em> of
representations <span class="math inline">\(\phi : V_1 \rightarrow
V_2\)</span> we will mean a continuous linear map that is compatible
with the given representations in the sense that <span
class="math inline">\(\pi_2(g) \phi(v_1) = \phi(\pi_1(g) v_1)\)</span>
for all <span class="math inline">\(v_1 \in V_1\)</span> and <span
class="math inline">\(g \in G\)</span>. The following phrases will be
used interchangeably with “morphism”:</p>
<ul>
<li><p><span class="math inline">\(G\)</span>-equivariant map, or simply
equivariant map.</p></li>
<li><p>intertwining operator.</p></li>
</ul>
<p>We denote by <span
class="math display">\[{\mathop{\mathrm{Hom}}}_G(V_1,V_2)\]</span> the set
of such <span class="math inline">\(\phi\)</span>. This set is a vector
space.</p>
<p>This definition endows the set of representations of a given group
<span class="math inline">\(G\)</span> with the structure of a
category.</p>
<p>An <em>isomorphism</em> (or sometimes “equivalence”, etc.) of
representations is a morphism that admits a two-sided inverse morphism;
in the case of finite-dimensional representations, an isomorphism is the
same thing as a bijective morphism.</p>
</div>
<div class="example">
<p><strong>Example 12</strong>.  </p>
<ol>
<li><p>For finite-dimensional representations <span
class="math inline">\(V_1, V_2\)</span> of <span
class="math inline">\(G\)</span>, the isomorphism of vector spaces <span
class="math inline">\(V_1^* \otimes V_1 \cong
\mathop{\mathrm{Hom}}(V_1,V_2)\)</span> (as recalled in §<a
href="#sec:linear-algebra" data-reference-type="ref"
data-reference="sec:linear-algebra">1.6</a>) defines an isomorphism of
representations.</p></li>
<li><p>Let <span class="math inline">\(G = \mathbb{Z}/n
\mathbb{Z}\)</span>; thus <span class="math inline">\(G\)</span> is the
finite cyclic group of order <span class="math inline">\(n\)</span>.
Take for <span class="math inline">\((\pi_1,V_1)\)</span> the right
regular representation on <span class="math inline">\(V_1 =
\mathbb{C}^G\)</span>, thus <span class="math display">\[\pi_1(g) f(x) =
f(x + g).\]</span> Take <span class="math inline">\(V_2 =
\mathbb{C}^n\)</span>, with <span class="math inline">\(\pi_2\)</span>
the representation assigning to each <span class="math inline">\(g \in
G\)</span> the diagonal matrix <span
class="math inline">\(\pi_2(g)\)</span> with entries <span
class="math inline">\(1, e(g/n), e(2 g/n), e(3 g/n), \dotsc, e((n-1)
g/n)\)</span>, where <span class="math inline">\(e(x) := e^{2 \pi i
x}\)</span>. Then <span class="math inline">\((\pi_1,V_1)\)</span> and
<span class="math inline">\((\pi_2,V_2)\)</span> are equivalent
representations; an isomorphism is given by the finite Fourier transform
<span class="math display">\[\phi : V_1 \rightarrow V_2\]</span> <span
class="math display">\[\phi(f) := (\hat{f}(0), \hat{f}(1), \dotsc,
\hat{f}(n-1)),\]</span> <span class="math display">\[\hat{f}(x) :=
\sum_{y \in \mathbb{Z}/n} f(y) e(-x y/n).\]</span></p></li>
</ol>
</div>
<p><a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<p>We pause to introduce, for any representation <span
class="math inline">\((\pi,V)\)</span>, the notation <span
class="math display">\[V^G :=  \{v \in V : \pi(g) v = v \text{ for all }
g \in G\}\]</span> for the <em><span
class="math inline">\(G\)</span>-fixed subspace</em> of <span
class="math inline">\(V\)</span>. Recall that we have defined for any
representations <span class="math inline">\(V_1, V_2\)</span> a
representation <span
class="math inline">\(\mathop{\mathrm{Hom}}(V_1,V_2)\)</span>; it thus
makes sense to speak of the fixed subspace of the latter representation,
and we verify readily from the definitions that <span
class="math display">\[\mathop{\mathrm{Hom}}(V_1,V_2)^G =
{\mathop{\mathrm{Hom}}}_G(V_1, V_2).\]</span></p>
<p>We defined earlier the dual of any finite-dimensional representation.
More generally, for any representation for which the underlying vector
space is given the structure of a Hilbert space, we define the dual
representation using the <em>continuous</em> dual, which is then itself
a Hilbert space.</p>
<div id="lem:unitary-implies-conjugate-self-dual" class="lemma">
<p><strong>Lemma 13</strong>. Let <span
class="math inline">\((\pi,V)\)</span> be a representation of <span
class="math inline">\(G\)</span> such that</p>
<ul>
<li><p><span class="math inline">\(V\)</span> is a Hilbert space <span
class="math inline">\((V, \langle , \rangle)\)</span>, and</p></li>
<li><p><span class="math inline">\(\pi\)</span> is unitary.</p></li>
</ul>
<p>Then <span class="math inline">\(\pi\)</span> is isomorphic to its
conjugate dual, and the conjugate and dual of <span
class="math inline">\(\pi\)</span> are isomorphic to each other: <span
class="math display">\[\pi \cong \overline{\pi }^*, \quad \overline{\pi
} \cong \pi^*.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since <span class="math inline">\(V\)</span> is a
Hilbert space, we have (by what is sometimes called the “Riesz
representation theorem”) an isomorphism of vector spaces <span
class="math display">\[V \rightarrow \overline{V}^*\]</span> <span
class="math display">\[v \mapsto \langle v, \cdot \rangle.\]</span>
Since <span class="math inline">\(\pi\)</span> is unitary, this
isomorphism is equivariant. This establishes the first isomorphism; the
second is obtained similarly. ◻</p>
</span></div>
<h2 id="reduction-and-decomposition">Reduction and decomposition</h2>
<div class="definition">
<p><strong>Definition 14</strong>. Let <span
class="math inline">\((\pi,V)\)</span> be a representation of <span
class="math inline">\(G\)</span>. A <em>closed invariant subspace</em>
<span class="math inline">\(W \subseteq V\)</span> is a closed subspace
such that <span class="math inline">\(\pi(g) W \subseteq W\)</span> for
all <span class="math inline">\(g \in G\)</span>. We note that:</p>
<ul>
<li><p>A subspace <span class="math inline">\(W \subseteq V\)</span> is
closed if and only if the quotient space <span
class="math inline">\(V/W\)</span>, equipped with the quotient topology,
is Hausdorff. If <span class="math inline">\(V\)</span> is
finite-dimensional, then every subspace <span
class="math inline">\(W\)</span> is closed. We will practically never
discuss non-closed subspaces in this course.</p></li>
<li><p>The condition <span class="math inline">\(\pi(g) W \subseteq
W\)</span>, applied both to <span class="math inline">\(g\)</span> and
<span class="math inline">\(g^{-1}\)</span>, implies that in fact <span
class="math inline">\(\pi(g) W = W\)</span>.</p></li>
</ul>
<p>To each closed invariant subspace <span class="math inline">\(W
\subseteq V\)</span> we may associate a <em>subrepresentation</em> <span
class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(W)\)</span> and a <em>quotient representation</em>
<span class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(V/W)\)</span>. We will often use
“subrepresentation” as a synonym for “closed invariant subspace.”</p>
</div>
<p>For instance, if <span class="math inline">\(\dim(W) = 2\)</span> and
<span class="math inline">\(\dim(V) = 5\)</span>, then we can extend a
basis <span class="math inline">\(e_1,e_2\)</span> for <span
class="math inline">\(W\)</span> to a basis <span
class="math inline">\(e_1,\dotsc,e_5\)</span> for <span
class="math inline">\(V\)</span>, and the matrix entries of our
representation expressed in terms of this basis look like <span
class="math display">\[\pi(g) =
  \begin{pmatrix}
    \ast &amp; \ast &amp; \ast &amp; \ast &amp; \ast \\
    \ast &amp; \ast &amp; \ast &amp; \ast &amp; \ast \\
    0 &amp; 0 &amp; \ast &amp; \ast &amp; \ast \\
    0 &amp; 0 &amp; \ast &amp; \ast &amp; \ast \\
    0 &amp; 0 &amp; \ast &amp; \ast &amp; \ast
  \end{pmatrix}
.\]</span> The upper-left <span class="math inline">\(2 \times
2\)</span> block corresponds to the subrepresentation on <span
class="math inline">\(W\)</span>, the lower-right <span
class="math inline">\(3 \times 3\)</span> block to the quotient
representation on <span class="math inline">\(V/W\)</span>.</p>
<div class="example">
<p><strong>Example 15</strong>. </p>
<ol>
<li><p>For any representation <span
class="math inline">\((\pi,V)\)</span> of <span
class="math inline">\(G\)</span>, the fixed subspace <span
class="math inline">\(V^G \subseteq V\)</span> is a closed invariant
subspace.</p></li>
<li><p>If <span class="math inline">\(G\)</span> acts in a
measure-preserving fashion on some measured space <span
class="math inline">\((X,\mu)\)</span> of finite volume, then the
representation <span class="math inline">\(V = L^2(X,\mu)\)</span>
contains the closed invariant subspace <span
class="math inline">\(\mathbb{C}\)</span> consisting of constant
functions.</p></li>
</ol>
</div>
<div class="definition">
<p><strong>Definition 16</strong>. Let <span
class="math inline">\((\pi,V)\)</span> be a nonzero representation (thus
<span class="math inline">\(V\)</span> is not the zero-dimensional space
<span class="math inline">\(\{0\}\)</span>; it might be the
one-dimensional trivial representation).</p>
<p>We say that <span class="math inline">\(V\)</span> is
<em>reducible</em> if there exists a closed invariant subspace <span
class="math inline">\(W \subseteq V\)</span> with <span
class="math inline">\(W \neq \{0\}, V\)</span>. We say otherwise that
<span class="math inline">\(V\)</span> is <em>irreducible</em>; this
means that <span class="math inline">\(\{0\}\)</span> and <span
class="math inline">\(V\)</span> are the only closed invariant
subspaces.</p>
</div>
<div class="example">
<p><strong>Example 17</strong>. “Most” <span
class="math inline">\(V\)</span> considered previously are reducible. If
<span class="math inline">\(\dim(V) = 1\)</span>, then <span
class="math inline">\(V\)</span> is irreducible.</p>
</div>
<p>The irreducible representations are a bit like the prime numbers,
with closed invariant subspaces playing the role of divisors and the
zero space <span class="math inline">\(\{0\}\)</span> a bit like the
unit element <span class="math inline">\(1\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 18</strong> (Schur’s lemma). <em>Let <span
class="math inline">\((\pi_1, V_1)\)</span> and <span
class="math inline">\((\pi_2, V_2)\)</span> be irreducible
finite-dimensional representations of some group <span
class="math inline">\(G\)</span>. Then <span class="math display">\[\dim
{\mathop{\mathrm{Hom}}}_G (V_1, V_2) =
    \begin{cases}
      1 &amp; \text{ if } V_1 \cong V_2, \\
      0 &amp; \text{ otherwise},
    \end{cases}\]</span> where “<span class="math inline">\(V_1 \cong
V_2\)</span>” means “isomorphic as representations of <span
class="math inline">\(G\)</span>.” If moreover <span
class="math inline">\(V = V_1 = V_2\)</span>, then <span
class="math inline">\({\mathop{\mathrm{End}}}_G(V) :=
{\mathop{\mathrm{Hom}}}_G(V,V)\)</span> is the space <span
class="math inline">\(\mathbb{C} \mathop{\mathrm{id}}\)</span> of scalar
multiples of the identity <span
class="math inline">\(\mathop{\mathrm{id}}: V \rightarrow
V\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(\phi\)</span> be a
nonzero element of <span
class="math inline">\({\mathop{\mathrm{Hom}}}_G(V_1,V_2)\)</span>. Then
<span class="math inline">\(\mathop{\mathrm{image}}(\phi) \subseteq
V_2\)</span> and <span class="math inline">\(\ker(\phi) \subseteq
V_1\)</span> are invariant subspaces. Since <span
class="math inline">\(\phi \neq 0\)</span>, we must have <span
class="math inline">\(\mathop{\mathrm{image}}(\phi) \neq 0\)</span> and
<span class="math inline">\(\ker(\phi) \neq V_1\)</span>. Thus by the
irreducibility of <span class="math inline">\(V_1, V_2\)</span>, we have
<span class="math inline">\(\mathop{\mathrm{image}}(\phi) = V_1\)</span>
and <span class="math inline">\(\ker(\phi) = 0\)</span>. Thus <span
class="math inline">\(\phi\)</span> is an isomorphism. In particular, if
<span class="math inline">\(V_1, V_2\)</span> are non-isomorphic, then
<span class="math inline">\({\mathop{\mathrm{Hom}}}_G(V_1,V_2) =
\{0\}\)</span>. If <span class="math inline">\(V_1\)</span> and <span
class="math inline">\(V_2\)</span> are isomorphic, then the spaces <span
class="math inline">\({\mathop{\mathrm{Hom}}}_G (V_1, V_2) \cong
{\mathop{\mathrm{Hom}}}_G(V_1,V_1)\)</span> are isomorphic via composition
with an isomorphism <span class="math inline">\(V_1 \rightarrow
V_2\)</span>, so in particular <span class="math inline">\(\dim
{\mathop{\mathrm{Hom}}}_G (V_1, V_2) = \dim
{\mathop{\mathrm{Hom}}}_G(V_1,V_1)\)</span>; we thereby reduce to
establishing the final assertion concerning <span
class="math inline">\(\phi \in {\mathop{\mathrm{End}}}_G(V)\)</span>.
(<span><strong>Note: this last step was treated incorrectly in
lecture!</strong></span>) Since <span class="math inline">\(V\)</span>
is a nonzero finite-dimensional vector spaces over the complex numbers,
the operator <span class="math inline">\(\phi\)</span> has an eigenvalue
<span class="math inline">\(\lambda\)</span>. Let <span
class="math inline">\(V_\lambda\)</span> denote the corresponding
eigenspace. For any <span class="math inline">\(g \in G\)</span> and
<span class="math inline">\(v \in V_\lambda\)</span>, we have <span
class="math display">\[\phi(\pi(g) v)
    =
    \pi(g) \phi(v)
    = \pi(g) \lambda v
    = \lambda \pi(g) v,\]</span> thus <span class="math inline">\(\pi(g)
v \in V^\lambda\)</span>, i.e., <span
class="math inline">\(V^\lambda\)</span> is a nonzero invariant
subspace; since <span class="math inline">\(V\)</span> is irreducible,
it follows that <span class="math inline">\(V^\lambda = V\)</span>, and
so <span class="math inline">\(\phi = \lambda \cdot
\mathop{\mathrm{id}}\)</span>, as required. ◻</p>
</span></div>
<div class="remark">
<p><strong>Remark 19</strong>. Inserted to keep numbering consistent
with the numbering that I messed up in lecture; maybe I’ll think of
something clever to put here later.</p>
</div>
<div class="remark">
<p><strong>Remark 20</strong>. Same.</p>
</div>
<div id="cor:schur-ab" class="corollary">
<p><strong>Corollary 21</strong>. <em>Suppose that <span
class="math inline">\(G\)</span> is abelian and <span
class="math inline">\((\pi,V)\)</span> is finite-dimensional and
irreducible. Then <span class="math inline">\(\dim(V) =
1\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(h \in G\)</span>.
Then for all <span class="math inline">\(g \in G\)</span>, <span
class="math inline">\(\pi(h) \pi(g) = \pi(h g) = \pi(g h) = \pi(g)
\pi(h)\)</span>. Thus <span class="math inline">\(\pi(h) \in
{\mathop{\mathrm{End}}}_G(V) = \mathbb{C} \mathop{\mathrm{id}}\)</span>,
and so <span class="math inline">\(\pi(h)\)</span> stabilizes every line
in <span class="math inline">\(V\)</span>. Thus any line in <span
class="math inline">\(V\)</span> is a nonzero invariant subspace; by
irreducibility, any such line is equal to <span
class="math inline">\(V\)</span>, and so <span
class="math inline">\(\dim(V) = 1\)</span>. ◻</p>
</span></div>
<p>As a matter of notation, we now define for a compact group <span
class="math inline">\(G\)</span> the set <span
class="math display">\[\mathop{\mathrm{Irr}}(G) := \{\text{isomorphism
classes of finite-dimensional irreducible representations $\pi =
(\pi,V_\pi)$ of $G$}\}.\]</span></p>
<div id="thm:complete-reducibility-compact-group" class="theorem">
<p><strong>Theorem 22</strong>. <em>Let <span
class="math inline">\(G\)</span> be compact and <span
class="math inline">\((\pi,V)\)</span> finite-dimensional. Then there
exists for each <span class="math inline">\(\sigma = (\sigma,W_\sigma)
\in \mathop{\mathrm{Irr}}(G)\)</span> a nonnegative integer <span
class="math inline">\(n(\sigma)\)</span> so that we have an isomorphism
of representations <span class="math display">\[V \cong \oplus_{\sigma
\in \mathop{\mathrm{Irr}}(G)} W_\sigma^{\oplus n(\sigma)}.\]</span>
(Here <span class="math inline">\(W^{\oplus n} := W \oplus \dotsb \oplus
W\)</span>, with <span class="math inline">\(n\)</span> copies.) The
<span class="math inline">\(n(\sigma)\)</span> are determined uniquely
by <span class="math inline">\(V\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since <span class="math inline">\(G\)</span> is
compact, we may equip <span class="math inline">\(V\)</span> with an
invariant inner product <span class="math inline">\(\langle ,
\rangle\)</span>. We may assume also that <span
class="math inline">\(V\)</span> is nonzero, since the conclusion of the
theorem holds in that case. Then there exist nonzero invariant subspaces
<span class="math inline">\(U_1\)</span> of <span
class="math inline">\(V\)</span>, such as <span
class="math inline">\(V\)</span> itself. Choose a <em>minimal</em> such
subspace <span class="math inline">\(U_1\)</span>. Then the orthogonal
complement <span class="math inline">\(U_1^\perp\)</span> is an
invariant subspace, since for <span class="math inline">\(v \in
U_1^\perp\)</span> and <span class="math inline">\(g \in G\)</span>, we
have for each <span class="math inline">\(u \in U_1\)</span> that
likewise <span class="math inline">\(g^{-1} \in U_1\)</span>, and so
<span class="math display">\[\langle g v, u \rangle = \langle v, g^{-1}
u \rangle = 0.\]</span> By choosing (if possible) another minimal
nonzero invariant subspace <span class="math inline">\(U_2 \leq
U_1^\perp\)</span> and inducting on dimension (note that <span
class="math inline">\(\dim(U_1^\perp) &lt; \dim(V) &lt;
\infty\)</span>), we see that we may write <span
class="math inline">\(V\)</span> as the (orthogonal) direct sum <span
class="math display">\[V = U_1 \oplus U_2 \oplus \dotsb \oplus
U_n,\]</span> where each <span class="math inline">\(U_j\)</span> is an
irreducible invariant subspace. We now group the <span
class="math inline">\(U_j\)</span> according to their isomorphism class,
giving a partition of <span class="math inline">\(\{1, \dotsc,
n\}\)</span> by <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span>; this gives the
required decomposition.</p>
<p>The uniqueness of the <span class="math inline">\(n(\sigma)\)</span>
may be deduced as in the proof of the Jordan–H<span>ö</span>lder
theorem; we will give an alternative proof later. ◻</p>
</span></div>
<p>This last result suggests two problems for a given <span
class="math inline">\(G\)</span>:</p>
<ul>
<li><p>Determine the set <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span>
explicitly.</p></li>
<li><p>Explicitly decompose “interesting” <span
class="math inline">\(V\)</span> in the above sense.</p></li>
</ul>
<h2 id="characters">Characters</h2>
<p>Throughout this section we take <span
class="math inline">\(G\)</span> compact and <span
class="math inline">\((\pi,V)\)</span> finite-dimensional.</p>
<div class="definition">
<p><strong>Definition 23</strong>. The <em>character</em> of <span
class="math inline">\(\pi\)</span> is the function <span
class="math display">\[\chi_\pi : G \rightarrow \mathbb{C}\]</span>
<span class="math display">\[g \mapsto
\mathop{\mathrm{trace}}(\pi(g)).\]</span> We sometimes write <span
class="math inline">\(\chi_V\)</span> for <span
class="math inline">\(\chi_\pi\)</span>.</p>
<p>A <em>class function</em> <span class="math inline">\(f : G
\rightarrow \mathbb{C}\)</span> is a function that is constant on
conjugacy classes, thus <span class="math inline">\(f(g^{-1} x g) =
f(x)\)</span> for all <span class="math inline">\(x,g \in G\)</span>.
Note that characters are class functions (because trace is
conjugation-invariant).</p>
</div>
<p>The idea is that, given a linear operator on a finite-dimensional
vector space, the only way to linearly assign to that operator a scalar
without choosing a basis is to take the trace (or a multiple thereof).
We’re looking to study isomorphism classes of representations, which
suggests looking at their characters. Here are some basic
properties:</p>
<div id="lem:characters-basic" class="lemma">
<p><strong>Lemma 24</strong>. Let <span class="math inline">\(\pi,
\pi_1, \pi_2\)</span> be finite-dimensional representations of the
compact group <span class="math inline">\(G\)</span>, as above.</p>
<ol>
<li><p><span class="math inline">\(\chi_{\pi}\)</span> depends only upon
the isomorphism class of <span
class="math inline">\(\pi\)</span>.</p></li>
<li><p><span class="math inline">\(\chi_{\overline{\pi }} =
\overline{\chi_\pi}\)</span></p></li>
<li><p><span class="math inline">\(\chi_{\pi_1 \oplus \pi_2}=
\chi_{\pi_1} + \chi_{\pi_2}\)</span></p></li>
<li><p><span class="math inline">\(\chi_{\pi_1 \otimes \pi_2}=
\chi_{\pi_1} \chi_{\pi_2}\)</span></p></li>
<li><p><span class="math inline">\(\chi_{\pi^*} = \chi_{\overline{\pi }}
= \overline{\chi_\pi }\)</span></p></li>
<li><p><span
class="math inline">\(\chi_{\mathop{\mathrm{Hom}}(\pi_1,\pi_2)} =
\overline{\chi_{\pi_1}} \chi_{\pi_2}\)</span></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The only “tricky” part is that since <span
class="math inline">\(G\)</span> is compact, <span
class="math inline">\(\pi\)</span> is unitarizable, and so (by Lemma <a
href="#lem:unitary-implies-conjugate-self-dual"
data-reference-type="ref"
data-reference="lem:unitary-implies-conjugate-self-dual">13</a>) <span
class="math inline">\(\overline{\pi } \cong \pi^*\)</span>, thus <span
class="math inline">\(\chi_{\pi^*} = \chi_{\overline{\pi }}\)</span>. We
also use that <span
class="math inline">\(\mathop{\mathrm{Hom}}(\pi_1,\pi_2) \cong \pi_1^*
\otimes \pi_2\)</span>. ◻</p>
</span></div>
<p>The key to unlocking the power of characters in the case of compact
groups is the following identity between the dimension of the fixed
subspace and the average value of the character:</p>
<div class="lemma">
<p><strong>Lemma 25</strong>. Define a linear map <span
class="math display">\[p : V \rightarrow V\]</span> <span
class="math display">\[v \mapsto \int_{g \in G} \pi(g) v \, d
g.\]</span> (Here <span class="math inline">\(d g\)</span> denotes as
usual the probability Haar, and we are integrating a function <span
class="math inline">\(g \mapsto \pi(g) v\)</span> valued in the
finite-dimensional vector space <span class="math inline">\(V\)</span>;
this can be defined by choosing a basis and integrating each coordinate,
for instance.) Then <span class="math display">\[\dim(V^G) =
\mathop{\mathrm{trace}}(p)
    = \int_{g \in G} \chi_\pi(g) \, d g.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We check readily that <span
class="math inline">\(p(V) \subseteq V^G\)</span> and that <span
class="math inline">\(p\)</span> restricts to the identity on <span
class="math inline">\(V^G\)</span>, so that <span
class="math inline">\(p\)</span> is a projection onto <span
class="math inline">\(V^G\)</span>; its trace is thus the dimension of
that subspace, giving the first identity.</p>
<p>The second identity follows from the linearity of the trace map. (In
more detail, let’s fix a basis <span
class="math inline">\(e_1,\dotsc,e_n\)</span> for <span
class="math inline">\(V\)</span> and dual basis <span
class="math inline">\(e_1^*,\dotsc,e_n^*\)</span> and write <span
class="math inline">\(\pi_{ij}(g) := \langle e_j^*, \pi(g) e_i
\rangle\)</span> for the coefficients of <span
class="math inline">\(\pi(g)\)</span> with respect to that basis. Let
<span class="math inline">\(p_{ij} := \langle e_j^*, p e_i
\rangle\)</span> denote the coefficients of <span
class="math inline">\(p\)</span>. By definition, <span
class="math inline">\(p_{i j} = \langle e_j^*, \int_{g \in G} \pi(g) e_i
\, d g \rangle\)</span>. The coefficients of a vector-valued integral
are obtained by integrating the coefficients, i.e., <span
class="math inline">\(\langle e_j^*, \int_{g \in G} \pi(g) e_i \, d g
\rangle = \int_{g \in G} \langle e_j^*, \pi(g) e_i \rangle \, d
g\)</span>, thus <span class="math inline">\(p_{i j} = \int_{g \in G}
\pi_{i j}(g) \, d g\)</span>. Summing over <span class="math inline">\(i
= j\)</span> gives <span
class="math inline">\(\mathop{\mathrm{trace}}(p) = \sum_i p_{i i} =
\sum_{i} \int_{g \in G} \pi_{i i}(g) \, d g =\int_{g \in G} \sum_{i}
\pi_{i i}(g) \, d g = \int_{G} \chi_\pi\)</span>, as required. ◻</p>
</span></div>
<div id="thm:basic-orthogonality-characters" class="theorem">
<p><strong>Theorem 26</strong>. <em></em></p>
<ol>
<li><p><em>Let <span class="math inline">\(\pi, \pi &#39; \in
\mathop{\mathrm{Irr}}(G)\)</span>. Then <span id="eq:characters-orthonormal" class="math display">\[\label{eq:characters-orthonormal}\tag{4}
      \langle \chi_\pi, \chi_{\pi &#39;} \rangle_{L^2(G)}
      =
\begin{cases}
        1 &amp; \text{ if $\pi \cong \pi &#39;$}, \\
        0 &amp; \text{ otherwise.}
      \end{cases}\]</span> Thus <span class="math inline">\(\{\chi_\pi :
\pi \in \mathop{\mathrm{Irr}}(G)\}\)</span> is an orthonormal subset of
<span class="math display">\[L^2(G)^{\mathop{\mathrm{class}}} :=
\{\text{class functions in $L^2(G)$}\}.\]</span></em></p></li>
<li><p><em>Let <span class="math inline">\((\pi,V)\)</span> be any
finite-dimensional representation, with decomposition <span
class="math display">\[V = \oplus_{\sigma \in \mathop{\mathrm{Irr}}(G)}
W_\sigma ^{\oplus n(\sigma)}\]</span> as before. Then <span
class="math display">\[n(\sigma) = \langle \chi_\pi,
\chi_\sigma  \rangle.\]</span> In particular, <span
class="math inline">\(\chi_\pi\)</span> determines <span
class="math inline">\(\pi\)</span> up to isomorphism.</em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol>
<li><p>By definition, <span class="math inline">\(\langle \chi_{\pi},
\chi_{\pi &#39;} \rangle = \int_G \chi_\pi \overline{\chi_{\pi
&#39;}}\)</span>. We have seen that <span class="math inline">\(\chi_\pi
\overline{\chi_{\pi &#39;}} = \chi_{\mathop{\mathrm{Hom}}(\pi &#39;,
\pi)}\)</span>, and that the average value of the latter is the
dimension of <span class="math inline">\(\mathop{\mathrm{Hom}}(\pi
&#39;, \pi)^G = {\mathop{\mathrm{Hom}}}_G(\pi &#39;, \pi)\)</span>; the
required conclusion now follows from Schur’s lemma.</p></li>
<li><p>We have <span class="math inline">\(\chi_\pi = \sum_\sigma
n(\sigma) \chi_\sigma\)</span>, so the conclusion follows from <a
href="#eq:characters-orthonormal" data-reference-type="eqref"
data-reference="eq:characters-orthonormal">\((4)\)</a>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<div id="thm:peter-weyl-for-chars" class="theorem">
<p><strong>Theorem 27</strong> (Part of the Peter–Weyl theorem).
<em>Recall that <span class="math inline">\(G\)</span> is compact. The
orthonormal subset <span class="math inline">\(\{\chi_\pi : \pi \in
\mathop{\mathrm{Irr}}(G)\}\)</span> of <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span> is in
fact an orthonormal basis, i.e., has dense span.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We postpone this proof until a bit later in the
course; it is not so difficult, but we prefer to compute some actual
characters first. ◻</p>
</span></div>
<div class="corollary">
<p><strong>Corollary 28</strong>. <em>If <span
class="math inline">\(G\)</span> is finite, then <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span> is a finite set
whose cardinality is the number of conjugacy classes <span
class="math inline">\(C\)</span> of <span
class="math inline">\(G\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> In that case <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span> has a
basis given by the characteristic functions <span
class="math inline">\(1_C\)</span> of each such <span
class="math inline">\(C\)</span>. ◻</p>
</span></div>
<h2 id="sec:conn-comp-abel">§2.6. The connected compact abelian case</h2>
<p>Let’s illustrate the content of Peter–Weyl by explicating it
completely in the case of a connected compact abelian Lie group. In such
a group, conjugation is trivial, so “class function” just means
“function;” also, we have seen that any irreducible finite-dimensional
representation is one-dimensional, hence may be identified with a group
homomorphism <span class="math inline">\(\pi : G \rightarrow
{\mathop{\mathrm{GL}}}_1(\mathbb{C}) = \mathbb{C}^\times\)</span>, which
is thus the “same” as its character, i.e., <span
class="math inline">\(\pi(g)\)</span> and <span
class="math inline">\(\chi_\pi(g)\)</span> are the same complex scalar
for all <span class="math inline">\(g \in G\)</span>. Recall that <span
class="math display">\[\mathop{\mathrm{U}}(1) := \{z \in
\mathbb{C}^\times : |z| = 1\} \cong \mathbb{R}/\mathbb{Z},\]</span>
<span class="math display">\[e(\theta) := e^{2 \pi i \theta} \mapsfrom
\theta.\]</span></p>
<div id="lem:reps-of-tori" class="lemma">
<p><strong>Lemma 29</strong>. Let <span class="math inline">\(G\)</span>
be a compact connected abelian Lie group of dimension <span
class="math inline">\(n \geq 0\)</span>. Then <span
class="math display">\[G \cong \mathop{\mathrm{U}}(1)^n \cong
(\mathbb{R}/\mathbb{Z})^n \cong \mathbb{R}^n/\mathbb{Z}^n.\]</span> One
has a bijection <span class="math display">\[\mathop{\mathrm{Irr}}(G)
\leftrightarrow \mathbb{Z}^n\]</span> given by associating to each <span
class="math inline">\(\lambda = (\lambda_1,\dotsc,\lambda_n) \in
\mathbb{Z}^n\)</span> the one-dimensional representation <span id="eq:defn-char-of-U1-to-the-n" class="math display">\[\label{eq:defn-char-of-U1-to-the-n}\tag{5}
    \mathop{\mathrm{U}}(1)^n
    \ni z = (z_1,\dotsc,z_n)
    \mapsto z^{\lambda} :=
    z_1^{\lambda_1} \dotsb z_n^{\lambda_n}
    \in \mathop{\mathrm{U}}(1) \subseteq
{\mathop{\mathrm{GL}}}_1(\mathbb{C}).\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We verify first that <span class="math inline">\(G
\cong \mathop{\mathrm{U}}(1)^n\)</span>:</p>
<ol>
<li><p>Set <span class="math inline">\(\mathfrak{g} =
\mathop{\mathrm{Lie}}(G)\)</span>. Since <span
class="math inline">\(G\)</span> is abelian, <span
class="math inline">\(\exp : \mathfrak{g} \rightarrow G\)</span> is a
homomorphism.</p></li>
<li><p>Since <span class="math inline">\(G\)</span> is connected and
<span class="math inline">\(\exp\)</span> is a homomorphism whose image
contains a neighborhood of the identity element of <span
class="math inline">\(G\)</span>, it follows that <span
class="math inline">\(\exp\)</span> is surjective.</p></li>
<li><p>The kernel <span class="math inline">\(\Lambda \subseteq
\mathfrak{g}\)</span> of <span class="math inline">\(\exp\)</span> is a
subgroup. Using that the exponential map is a local diffeomorphism near
the origin, we see that <span class="math inline">\(\Lambda\)</span> is
discrete. (Indeed, if there were a sequence <span
class="math inline">\(v_n \in \Lambda\)</span> that converged to some
element of <span class="math inline">\(\Lambda\)</span>, then the
sequence of differences <span class="math inline">\(v_{n+1} -
v_n\)</span> would converge to <span
class="math inline">\(0\)</span>.)</p></li>
<li><p>By general theory on quotients of Lie groups (see e.g. Theorem
157 in my Fall 2016 notes), we have <span class="math inline">\(G \cong
\mathfrak{g}/\Lambda\)</span>. In particular, <span
class="math inline">\(\Lambda\)</span> is cocompact.</p></li>
<li><p>It’s not hard to see that for every discrete cocompact subgroup
<span class="math inline">\(\Lambda\)</span> of an <span
class="math inline">\(n\)</span>-dimensional Euclidean space <span
class="math inline">\(\mathfrak{g}\)</span> there exists an isomorphism
<span class="math inline">\(\mathfrak{g} \cong \mathbb{R}^n\)</span>
under which <span class="math inline">\(\Lambda\)</span> identifies with
<span class="math inline">\(\mathbb{Z}^n\)</span>. (Indeed, induct on
<span class="math inline">\(n\)</span>. We may assume that <span
class="math inline">\(n \geq 1\)</span>. Fix an arbitrary Euclidean norm
on <span class="math inline">\(\mathfrak{g}\)</span>. Since <span
class="math inline">\(\Lambda\)</span> is discrete, we can find a
nonzero element <span class="math inline">\(e_1 \in V\)</span> of
minimal norm. We might suppose having normalized our norm so that the
norm of <span class="math inline">\(e_1\)</span> is exactly <span
class="math inline">\(1\)</span>. In any event, the minimality of this
norm implies that <span class="math inline">\(\mathbb{R} e_1 \cap
\Lambda = \mathbb{Z} e_1\)</span>. Let <span
class="math inline">\(W\)</span> be a subspace of <span
class="math inline">\(\mathfrak{g}\)</span> complementary to <span
class="math inline">\(\mathbb{R} e_1\)</span> (e.g., the orthogonal
complement), and let <span class="math inline">\(p : V \rightarrow
W\)</span> be the projection with kernel <span
class="math inline">\(\mathbb{R} e_1\)</span>. We then have a short
exact sequence of <span
class="math inline">\(\mathbb{Z}\)</span>-modules <span
class="math display">\[0 \rightarrow \mathbb{Z} e_1 \rightarrow \Lambda
\rightarrow p(\Lambda) \rightarrow 0.\]</span> We claim that <span
class="math inline">\(p(\Lambda) \subseteq W\)</span> is a discrete
subgroup; it follows then inductively that <span
class="math inline">\(p(\Lambda)\)</span> is a finite free <span
class="math inline">\(\mathbb{Z}\)</span>-module of rank at most <span
class="math inline">\(\dim(W) = n-1\)</span>, hence that <span
class="math inline">\(\Lambda\)</span> is a free <span
class="math inline">\(\mathbb{Z}\)</span>-module of rank at most <span
class="math inline">\(n\)</span>; the assumed compactness of <span
class="math inline">\(\mathfrak{g}/\Lambda\)</span> then forces the rank
to equal <span class="math inline">\(n\)</span>, and so <span
class="math inline">\(\Lambda \cong \mathbb{Z}^n\)</span> with respect
to some coordinates.</p>
<p>To verify the claim, it suffices to bound from below the norms of
nonzero elements of <span class="math inline">\(p(\Lambda)\)</span>
(this implies that such elements can’t accumulate at the origin, hence
neither can their differences, giving the required discreteness). So let
<span class="math inline">\(v \in \Lambda\)</span> with <span
class="math inline">\(p(v) \neq 0\)</span>, i.e., <span
class="math display">\[v \notin \mathbb{R} e_1.\]</span> The difference
<span class="math inline">\(v - p(v)\)</span> then lies in <span
class="math inline">\(\mathbb{R} e_1\)</span>. We can find an integral
multiple <span class="math inline">\(m e_1\)</span> of <span
class="math inline">\(e_1\)</span> that “best approximates” this
difference in the sense that <span class="math display">\[v - p(v) - m
e_1 \in [-1/2,1/2] e_1.\]</span> We have <span class="math inline">\(v
\neq m e_1\)</span>, so <span class="math inline">\(v - m e_1\)</span>,
being a nonzero element of <span class="math inline">\(\Lambda\)</span>,
has norm bounded from below by <span class="math inline">\(1\)</span>
(the minimal norm of any such element). But elements of <span
class="math inline">\([-1/2,1/2] e_1\)</span> have norm at most <span
class="math inline">\(1/2\)</span>. The triangle inequality thus forces
<span class="math inline">\(p(v)\)</span> to have norm at least <span
class="math inline">\(1/2\)</span>.)</p></li>
</ol>
<p>Having proved that <span class="math inline">\(G \cong
\mathop{\mathrm{U}}(1)^n\)</span>, we turn to classifying its
irreducible finite-dimensional representations <span
class="math inline">\(\pi\)</span>. By Corollary <a href="#cor:schur-ab"
data-reference-type="ref" data-reference="cor:schur-ab">21</a>, any such
<span class="math inline">\(\pi\)</span> is one-dimensional, and so may
be regarded as a homomorphism <span class="math display">\[\pi : G
\rightarrow {\mathop{\mathrm{GL}}}_1(\mathbb{C}) =
\mathbb{C}^\times.\]</span> Compose this with the isomorphism <span
class="math display">\[\mathbb{R}^n/\mathbb{Z}^n \ni \theta =
(\theta_1,\dotsc,\theta_n) \mapsto
    e(\theta)  := (e(\theta_1),\dotsc,e(\theta_n)) \in G\]</span> to get
a morphism of Lie groups <span class="math display">\[\tau :
\mathbb{R}^n/\mathbb{Z}^n
    \ni \theta \mapsto \pi(e(\theta)) \in \mathbb{C}^\times.\]</span>
Differentiate this to obtain a morphism of Lie algebras <span
class="math display">\[\mathbb{R}^n \ni \theta \mapsto d \tau(\theta)
\in \mathop{\mathrm{Lie}}(\mathbb{C}^\times) = \mathbb{C}.\]</span> Any
such morphism is of the form <span class="math display">\[d \tau(\theta)
= \lambda_1 \theta_1 + \dotsb + \lambda_n \theta_n \text{ for some
$\lambda = (\lambda_1,\dotsc,\lambda_n) \in \mathbb{C}^n$.}\]</span> By
the compatibility between Lie group morphisms, Lie algebra morphisms and
the exponential map, we have <span class="math display">\[\tau(\theta) =
e(\lambda_1 \theta_1 + \dotsb + \lambda_n \theta_n).\]</span> Since
<span class="math inline">\(\tau(\mathbb{Z}^n) = \{1\}\)</span>, we have
in particular <span class="math display">\[e(\lambda_1) = \dotsb =
e(\lambda_n) = 1,\]</span> and so <span
class="math inline">\(\lambda_1,\dotsc,\lambda_n \in
\mathbb{Z}\)</span>, as required.</p>
<p>We note finally that all of the one-dimensional representations of
<span class="math inline">\(G = \mathop{\mathrm{U}}(1)^n\)</span> that
we have defined are inequivalent; for instance, we verify readily that
they (and hence, what amounts to the same, their characters) are
orthogonal to one another in <span
class="math inline">\(L^2(G)\)</span>, thanks to repeated application of
the basic identity: for <span class="math inline">\(\ell \in
\mathbb{Z}\)</span>, <span class="math display">\[\int_{\theta \in
[0,1]}
    e(\ell \theta)
    \, d \theta
    =
    \begin{cases}
      1 &amp; \text{ if } \ell = 0, \\
      0 &amp; \text{ otherwise.}
    \end{cases}\]</span> ◻</p>
</span></div>
<p>The content of Peter–Weyl in the setting of the compact connected
abelian Lie groups <span
class="math inline">\(\mathop{\mathrm{U}}(1)^n\)</span> is thus that, as
<span class="math inline">\(\lambda\)</span> varies over <span
class="math inline">\(\mathbb{Z}^n\)</span>, the “trigonometric
polynomials” <span class="math inline">\(\mathop{\mathrm{U}}(1)^n \ni z
\mapsto z^{\lambda}\)</span> have dense span in <span
class="math inline">\(L^2(\mathop{\mathrm{U}}(1)^n)\)</span>. This may
be a familiar fact from abelian Fourier analysis. It can be established
using (e.g.) the Stone–Weierstrass theorem, or a bit of functional
analysis. The proof of the general case of the Peter–Weyl theorem, to be
given a bit later, will involve similar arguments.<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<h1 id="sec:char-theory-comp">§3. Character theory of compact unitary
groups</h1>
<h2 id="recap">Recap</h2>
<p>Before beginning, let’s pause to attach some vocabulary to results
from last time.</p>
<div class="definition">
<p><strong>Definition 30</strong>. A <em>torus</em> <span
class="math inline">\(T\)</span> is a compact connected abelian Lie
group.</p>
</div>
<p>We saw last time that any <span
class="math inline">\(n\)</span>-dimensional torus <span
class="math inline">\(T\)</span> is isomorphic to <span
class="math inline">\(\mathop{\mathrm{U}}(1)^n\)</span>, and that its
irreducible representations are indexed by <span
class="math inline">\(\lambda \in \mathbb{Z}^n\)</span> and given by
<span class="math display">\[e^\lambda : \mathop{\mathrm{U}}(n)
\rightarrow \mathop{\mathrm{U}}(1)\]</span> <span
class="math display">\[t = (t_1,\dotsc,t_n) \mapsto t^\lambda :=
(t_1^{\lambda_1},\dotsc,t_n^{\lambda_n}).\]</span></p>
<h2 id="conjugacy-classes-in-mathopmathrmun">Conjugacy classes in <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></h2>
<div class="definition">
<p><strong>Definition 31</strong>. The compact unitary group <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> is defined by
<span class="math display">\[\mathop{\mathrm{U}}(n) := \{g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{C}) : \langle g v, g w
    \rangle
    = \langle v, w \rangle \text{ for all } v,w
    \in \mathbb{C}^n\},\]</span> where <span
class="math inline">\(\langle v, w \rangle := \sum_{j=1}^n v_j
\overline{w_j}\)</span> denotes the standard inner product. We can also
describe it as the group of matrices <span class="math inline">\(g =
(g_{i j})\)</span> whose rows (or columns) form an orthonormal basis,
i.e., <span class="math display">\[\mathop{\mathrm{U}}(n) = \{g : \sum_k
g_{i k} \overline{g_{j k}} = \delta_{i j} \} = \{g : \sum_k g_{k i}
\overline{g_{k j}} = \delta_{i j} \}.\]</span></p>
</div>
<p>From the second description we see in particular that each <span
class="math inline">\(|g_{i j}| \leq 1\)</span>, hence that <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> is compact.</p>
<p>Henceforth set <span class="math display">\[G :=
\mathop{\mathrm{U}}(n).\]</span> We’re interested in studying
(finite-dimensional) representations <span
class="math inline">\(\pi\)</span> of <span
class="math inline">\(G\)</span>. As we saw last time, we can do this by
studying their characters <span class="math inline">\(\chi_\pi\)</span>.
Characters are class functions, so we might get started by recalling
what the conjugacy classes in <span class="math inline">\(G\)</span>
look like.</p>
<p>Let <span class="math inline">\(T \leq G\)</span> denote the subgroup
of diagonal elements. Then <span class="math display">\[T \cong
\mathop{\mathrm{U}}(1)^n\]</span> <span
class="math display">\[\begin{pmatrix}
    t_1 &amp;  &amp;  \\
        &amp; \ddots  &amp;  \\
        &amp; &amp; t_n
  \end{pmatrix}
  \leftrightarrow (t_1,\dotsc,t_n).\]</span> Let <span
class="math inline">\(W \leq G\)</span> denote the subgroup of
permutation matrices, i.e., the image of the permutation representation
of the symmetric group discussed previously. Then <span
class="math inline">\(W\)</span> acts on <span
class="math inline">\(T\)</span> by conjugation, permuting coordinates:
<span class="math display">\[w \cdot t := w t w^{-1} = (t_{w^{-1}(1)},
t_{w^{-1}(2)},\dotsc , t_{w^{-1}(n)}).\]</span> Here in writing <span
class="math inline">\(w^{-1}(j)\)</span> we regard <span
class="math inline">\(w\)</span> as a permutation of <span
class="math inline">\(\{1,\dotsc,n\}\)</span>. We have <span
class="math inline">\(|W| = n!\)</span>.</p>
<div id="lem:describe-conjugacy-classes-Un" class="lemma">
<p><strong>Lemma 32</strong>. Every conjugacy class in <span
class="math inline">\(G\)</span> intersects <span
class="math inline">\(T\)</span>, and two elements of <span
class="math inline">\(T\)</span> are conjugate in <span
class="math inline">\(G\)</span> precisely when they have the same <span
class="math inline">\(W\)</span>-orbit.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> This is presumably known from a linear algebra course
as the “spectral theorem for unitary operators,” but perhaps it won’t
hurt to recall the proof:</p>
<p>Let <span class="math inline">\(g \in G\)</span>. We can then find an
orthonormal basis <span class="math inline">\(v_1,\dotsc,v_n\)</span>
for <span class="math inline">\(\mathbb{C}^n\)</span> consisting of
eigenvectors for <span class="math inline">\(g\)</span>. (Take for <span
class="math inline">\(v_1\)</span> any eigenvector, normalize it to have
norm <span class="math inline">\(1\)</span>, observe that the unitarity
of <span class="math inline">\(g\)</span> implies that <span
class="math inline">\(g\)</span> stabilizes the orthogonal complement
<span class="math inline">\(v_1^\perp\)</span>, take for <span
class="math inline">\(v_2\)</span> any norm one eigenvector of <span
class="math inline">\(g\)</span> in <span
class="math inline">\(v_1^\perp\)</span>, and so on. Alternatively, let
<span class="math inline">\(\Gamma\)</span> denote the closure of the
group generated by <span class="math inline">\(g\)</span>; then <span
class="math inline">\(\Gamma\)</span> is a compact abelian group to
which Theorem <a href="#thm:complete-reducibility-compact-group"
data-reference-type="ref"
data-reference="thm:complete-reducibility-compact-group">22</a> applies.
The “two proofs” are basically the same, of course.) Let <span
class="math inline">\(h \in G\)</span> have rows <span
class="math inline">\(v_1,\dotsc,v_n\)</span>. Let <span
class="math inline">\(e_1,\dotsc,e_n\)</span> denote the standard
orthonormal basis of <span class="math inline">\(\mathbb{C}^n\)</span>.
Then <span class="math inline">\(h e_j = v_j\)</span>, so <span
class="math inline">\(t := h^{-1} g h\)</span> is a diagonal element of
<span class="math inline">\(G\)</span>, i.e., <span
class="math inline">\(t \in T\)</span>. This shows that every conjugacy
class in <span class="math inline">\(G\)</span> intersects <span
class="math inline">\(T\)</span>. If two elements of <span
class="math inline">\(T\)</span> lie in the same <span
class="math inline">\(W\)</span>-orbit, then they are obviously
conjugate in <span class="math inline">\(G\)</span>, because <span
class="math inline">\(W \leq G\)</span>. Conversely, if two elements of
<span class="math inline">\(T\)</span> are conjugate in <span
class="math inline">\(G\)</span>, then they have the same multiset of
eigenvalues, so we can find a permutation <span class="math inline">\(w
\in W\)</span> sending one to the other. ◻</p>
</span></div>
<div id="cor:class-fns-via-T" class="corollary">
<p><strong>Corollary 33</strong>. <em>Restriction defines a bijection
<span class="math display">\[\{\text{class functions on } G\}
\leftrightarrow \{\text{$W$-invariant functions on }
T\}.\]</span></em></p>
</div>
<h2 id="sec:weight-decmop-U-n">§3.3. Weight space decompositions of
representations of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></h2>
<p>In particular, let <span class="math inline">\((\pi,V)\)</span> be
any finite-dimensional representation of <span
class="math inline">\(G\)</span>. Then its character <span
class="math inline">\(\chi_\pi : G \rightarrow \mathbb{C}\)</span> is a
class function, hence determined by its restriction <span
class="math inline">\(\chi_\pi|_{T}\)</span> to <span
class="math inline">\(T\)</span>, which is <span
class="math inline">\(W\)</span>-invariant. The restriction <span
class="math inline">\(\chi_{\pi}|_{T}\)</span> may be regarded as the
character of the restriction <span class="math inline">\(\pi|_T : T
\rightarrow \mathop{\mathrm{GL}}(V)\)</span> of the representation <span
class="math inline">\(\pi\)</span>. By our general discussion of
representations of tori (Lemma <a href="#lem:reps-of-tori"
data-reference-type="ref" data-reference="lem:reps-of-tori">29</a>) and
of compact groups (Theorem <a
href="#thm:complete-reducibility-compact-group"
data-reference-type="ref"
data-reference="thm:complete-reducibility-compact-group">22</a>), we may
decompose <span class="math inline">\(\pi|_T\)</span> as a direct sum of
irreducible representations <span class="math inline">\(e^\lambda : t
\mapsto t^\lambda\)</span> of <span class="math inline">\(T\)</span>,
each occurring with some multiplicities <span
class="math inline">\(m_\pi(\lambda) \in \mathbb{Z}_{\geq 0}\)</span>
(denoted “<span class="math inline">\(n(\sigma)\)</span>” in the cited
theorem). Of course <span class="math inline">\(\dim(\pi) = \sum
_{\lambda} m_\pi (\lambda)\)</span>, so only finitely many of the <span
class="math inline">\(m_\pi(\lambda)\)</span> are nonzero. Thus for
<span class="math inline">\(t \in T\)</span>, <span
class="math display">\[\chi_\pi(t)
  =
  \sum_{\lambda}
  m_\pi(\lambda) t^\lambda.\]</span> Setting <span
class="math display">\[V^{\lambda} := \{v \in V : \pi(t) v = t^\lambda v
\text{ for all } t \in T\},\]</span> we have <span
class="math display">\[\dim V^{\lambda} = m_\pi(\lambda)\]</span> and
<span class="math display">\[V = \oplus_{\lambda} V^{\lambda}.\]</span>
If <span class="math inline">\(m_\pi(\lambda) &gt; 0\)</span>
(equivalently, <span class="math inline">\(V^{\lambda} \neq 0\)</span>),
we say that <span class="math inline">\(\lambda\)</span> is a
<em>weight</em> of <span class="math inline">\(\pi\)</span> and refer to
<span class="math inline">\(m_\pi(\lambda)\)</span> as the
<em>multiplicity</em> of <span class="math inline">\(\lambda\)</span> in
<span class="math inline">\(\pi\)</span>, to <span
class="math inline">\(V^{\lambda}\)</span> as the corresponding
<em>weight space</em>, and to nonzero elements of <span
class="math inline">\(V^{\lambda}\)</span> as <em>weight
vectors</em>.</p>
<p>Some examples will presumably clarify matters. In what follows we
identify characters with functions on <span
class="math inline">\(T\)</span> as above. We also write, e.g., <span
class="math inline">\(t_j\)</span> as shorthand for the map <span
class="math inline">\(T \ni t \mapsto t_j\)</span>.</p>
<div class="example">
<p><strong>Example 34</strong>. </p>
<ol>
<li><p>The trivial representation <span
class="math inline">\(\pi\)</span> has character <span
class="math inline">\(1\)</span>, so the only weight is <span
class="math inline">\(\lambda = 0\)</span>, with multiplicity <span
class="math inline">\(1\)</span>.</p></li>
<li><p>The standard representation <span
class="math inline">\(\mathbb{C}^n\)</span> has a basis of weight
vectors <span class="math inline">\(e_1,\dotsc,e_n\)</span> (the
standard basis) with corresponding weights <span
class="math inline">\(t_1,\dotsc,t_n\)</span> and each of multiplicity
<span class="math inline">\(1\)</span>, so the character is <span
class="math inline">\(t_1 + \dotsb + t_n\)</span>.</p></li>
<li><p>The dual <span class="math inline">\((\mathbb{C}^n)^*\)</span> of
the standard representation, with basis of weight vectors <span
class="math inline">\(e_1^*,\dotsc,e_n^*\)</span> (the dual of the
standard basis, i.e., <span class="math inline">\(\langle e_i^*, e_j
\rangle = \delta_{i j}\)</span>) with corresponding weights <span
class="math inline">\(t_1^{-1},\dotsc,t_n^{-1}\)</span> each of
multiplicity <span class="math inline">\(1\)</span>, hence character
given by <span class="math inline">\(t_1^{-1} + \dotsb +
t_n^{-1}\)</span>.</p></li>
<li><p>The complexified adjoint representation <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
{\mathop{\mathrm{GL}}}_{\mathbb{R}}(\mathfrak{g}) \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g}_{\mathbb{C}})\)</span>. Here <span
class="math inline">\(\mathfrak{g}_{\mathbb{C}} \cong
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
because <span
class="math inline">\({\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})
\cong \mathfrak{g} \oplus i \mathfrak{g}\)</span> via the map <span
class="math inline">\(x \mapsto (\tfrac{1}{2} (x - \overline{x}^t),
\tfrac{1}{2} (x + \overline{x}^t))\)</span>. We can thus identify <span
class="math inline">\(\mathfrak{g}_{\mathbb{C}}\)</span> with the space
of <span class="math inline">\(n \times n\)</span> complex matrices,
which has a standard basis <span class="math inline">\(E_{i j}\)</span>.
The action is described in this optic by <span
class="math inline">\(\mathop{\mathrm{Ad}}(g) x = g x g^{-1}\)</span>.
We have <span class="math inline">\(\mathop{\mathrm{Ad}}(t) E_{i j} =
(t_i/t_j) E_{i j}\)</span>, so the character is given by <span
class="math inline">\(\sum_{i,j} t_i/t_j\)</span>, which we may rewrite
as <span class="math inline">\(n + \sum_{i \neq j} t_i/t_j\)</span>.
Thus the trivial character of <span class="math inline">\(T\)</span> is
a weight with multiplicity <span class="math inline">\(n\)</span>. The
nontrivial weights are indexed by <span class="math inline">\(i \neq
j\)</span>, occur with multiplicity one, and are given by <span
class="math inline">\(\varepsilon_i - \varepsilon_j : t \mapsto
t_i/t_j\)</span>. (These, the nontrivial weights for the adjoint action,
are in general called <em>roots</em>.)</p>
<p>We note incidentally that the representation <span
class="math inline">\(\mathop{\mathrm{Ad}}: G \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g}_{\mathbb{C}})\)</span> is isomorphic
to <span
class="math inline">\(\mathop{\mathrm{End}}(\mathbb{C}^n)\)</span>,
i.e., to the tensor product <span class="math inline">\(\mathbb{C}^n
\otimes (\mathbb{C}^n)^*\)</span> of the standard representation and its
dual; this isomorphism is reflected in the character identity <span
class="math inline">\(\sum_{i,j} t_i/t_j = (\sum_i t_i) (\sum_j
t_j^{-1})\)</span>.</p></li>
<li><p>The <span class="math inline">\(k\)</span>th symmetric power
<span
class="math inline">\({\mathop{\mathrm{Sym}}}^k(\mathbb{C}^n)\)</span> of
the standard representation has a basis of weight vectors <span
class="math inline">\(e_{i_1} \dotsb e_{i_k}\)</span> indexed by <span
class="math inline">\(i_1 \leq \dotsb \leq i_k\)</span>, with
corresponding weights <span class="math inline">\(t_{i_1} \dotsb
t_{i_k}\)</span>, each occurring with multiplicity one; the character is
<span id="eq:wts-sym-k" class="math display">\[\label{eq:wts-sym-k}\tag{7}
      \sum_{i_1 \leq \dotsb \leq i_k} t_{i_1} \dotsb
t_{i_k}.\]</span></p></li>
<li><p>The <span class="math inline">\(k\)</span>th exterior power <span
class="math inline">\(\Lambda^k(\mathbb{C}^n)\)</span> of the standard
representation has a basis of weight vectors <span
class="math inline">\(e_{i_1} \wedge \dotsb \wedge e_{i_k}\)</span>
indexed by <span class="math inline">\(i_1 &lt; \dotsb &lt;
i_k\)</span>, with corresponding weights <span
class="math inline">\(t_{i_1} \dotsb t_{i_k}\)</span>, each occurring
with multiplicity one; the character is <span
class="math display">\[\sum_{i_1 &lt; \dotsb &lt; i_k} t_{i_1} \dotsb
t_{i_k},\]</span> which is often called the <em><span
class="math inline">\(k\)</span>th elementary symmetric
function</em>.</p></li>
<li><p>The <span class="math inline">\(k\)</span>th tensor power <span
class="math inline">\((\mathbb{C}^n)^{\otimes k}\)</span> of the
standard representation has basis of weight vectors <span
class="math inline">\(e_{i_1} \otimes \dotsb \otimes e_{i k}\)</span>
indexed by any <span class="math inline">\(i_1,\dotsc,i_k\)</span>, with
corresponding weights <span class="math inline">\(t_{i_1} \dotsb
t_{i_k}\)</span>. The character is <span
class="math display">\[\sum_{i_1,\dotsc,i_k} t_{i_1} \dotsb t_{i_k} =
(t_1 + \dotsb + t_n)^k,\]</span> i.e., the <span
class="math inline">\(k\)</span>th power of the character of the
standard representation, as we could have predicted from Lemma <a
href="#lem:characters-basic" data-reference-type="ref"
data-reference="lem:characters-basic">24</a>. Note that nontrivial
multiplicities <span class="math inline">\(m_\pi(\lambda)\)</span> occur
in general, and are given by multinomial coefficients.</p></li>
</ol>
</div>
<p>Note that in all of these examples, we indeed obtained a <span
class="math inline">\(W\)</span>-invariant Laurent polynomial <span
class="math inline">\(\sum_{\lambda} m_\pi(\lambda)
t^\lambda\)</span>.</p>
<h2 id="sec:weyl-integr-form">§3.4. The Weyl integral formula for <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></h2>
<p>Enough examples for now. Our goal is to use the orthogonality
relations for characters of irreducible representations to derive
formulas for them. Since we’ve seen that the characters assume a
particularly simple form when we restrict them to <span
class="math inline">\(T\)</span>, we might try first to understand how
the integral over <span class="math inline">\(G\)</span> of a class
function may be expressed in terms of the restriction of that function
to <span class="math inline">\(T\)</span>.</p>
<div id="thm:weyl-int" class="theorem">
<p><strong>Theorem 35</strong> (Weyl integral formula). <em>For a
continuous class function <span class="math inline">\(f : G \rightarrow
\mathbb{C}\)</span>, we have <span class="math display">\[\int_G f =
\frac{1}{|W|} \int_T |\Delta|^2 f,\]</span> where <span
class="math display">\[\Delta(t) := \prod_{i &lt; j} (t_i -
t_j).\]</span> Here both integrals are taken with respect to probability
Haar measures. More generally, for any continuous <span
class="math inline">\(f : G \rightarrow \mathbb{C}\)</span>, we have
<span class="math display">\[\int_G f = \frac{1}{|W|} \int_{g \in G}
\int_{t \in T} |\Delta(t)|^2 f(g t g^{-1}) \, d t \, d
g.\]</span></em></p>
</div>
<p>This should be thought of as a bit like the formula for integrating
in polar coordinates in <span
class="math inline">\(\mathbb{R}^3\)</span>. We give the proof below.
For further reading, see</p>
<ul>
<li><p>Weyl’s original treatment (see section V.17 of “Group theory and
quantum mechanics” in the course references),</p></li>
<li><p>the treatment given in sections I.5 and IV.1 of BTD (the course
reference with those author initials)</p></li>
<li><p>section VIII.5 of Knapp’s “Lie groups beyond and
introduction,”</p></li>
<li><p>section 6.4 of Rossmann’s book,</p></li>
<li><p>and others from the reference list.</p></li>
</ul>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We first review some basics concerning integration on
manifolds. Let <span class="math inline">\(M\)</span> be a connected
<span class="math inline">\(N\)</span>-manifold, and let <span
class="math inline">\(\omega\)</span> be a nowhere vanishing
differential <span class="math inline">\(N\)</span>-form on <span
class="math inline">\(M\)</span>. Then <span
class="math inline">\(\omega\)</span> defines an orientation and a
volume measure <span class="math inline">\(C_c(M) \ni f \mapsto \int_M f
\, d \omega\)</span>: for any function <span
class="math inline">\(f\)</span> supported in an oriented coordinate
chart <span class="math inline">\((x_1,\dotsc,x_N)\)</span>, we set
<span class="math display">\[\int_M f \, d \omega :=
    \int_{x_1,\dotsc,x_N}
    f(x_1,\dotsc,x_N)
    \omega(x_1 \wedge \dotsb \wedge x_N)
    \, d x_1 \dotsb d x_N,\]</span> and then extend this definition to
general <span class="math inline">\(f\)</span> via a suitable partition
of unity. If <span class="math inline">\((M,\omega)\)</span> and <span
class="math inline">\((M&#39;,\omega &#39;)\)</span> are two such pairs
and <span class="math inline">\(\phi : M \rightarrow M&#39;\)</span> is
a differentiable map, that we may express the pullback <span
class="math inline">\(\phi^* \omega &#39;\)</span> as <span
class="math inline">\(\det(\phi) \omega\)</span> for some function <span
class="math inline">\(\det(\phi) : M \rightarrow \mathbb{R}\)</span>
(the <em>determinant</em> of <span class="math inline">\(\phi\)</span>
with respect to <span class="math inline">\(\omega\)</span> and <span
class="math inline">\(\omega &#39;\)</span>). If <span
class="math inline">\(\phi\)</span> is a diffeomorphism, then we have
the change of variables formulas: for <span class="math inline">\(f \in
C_c(M&#39;)\)</span>, <span id="eq:change-of-vars" class="math display">\[\label{eq:change-of-vars}\tag{8}
    \int_{M&#39;}
    f \, d \omega &#39; = \int_M (f \circ \phi) \cdot |\det(\phi)| \, d
\omega.\]</span> Also, determinant is multiplicative with respect to
composition in the obvious sense.</p>
<p>We next recall how to integrate on a compact Lie group using
differential forms. Let <span class="math inline">\(\omega\)</span> be a
nonzero element of <span
class="math inline">\(\Lambda^N(\mathfrak{g})^*\)</span>. Then, via the
correspondence between <span class="math inline">\(\mathfrak{g}\)</span>
and left-invariant vector fields on <span
class="math inline">\(G\)</span>, we may identify <span
class="math inline">\(\omega\)</span> with a left-invariant <span
class="math inline">\(N\)</span>-form <span
class="math inline">\(\tilde{\omega}\)</span> on <span
class="math inline">\(G\)</span>. For each <span class="math inline">\(g
\in G\)</span>, the right translation map <span
class="math inline">\(R_g : G \rightarrow G\)</span> has some
determinant <span class="math inline">\(\det(R_g)\)</span> (defined with
respect to <span class="math inline">\(\tilde{\omega}\)</span> both on
source and target). We check readily that <span class="math inline">\(g
\mapsto \det(R_g)\)</span> defines a continuous homomorphism <span
class="math inline">\(G \rightarrow \mathbb{R}^\times_+\)</span>, but
since <span class="math inline">\(G\)</span> is compact, any such map is
trivial. Thus <span class="math inline">\(\tilde{\omega}\)</span> is
both left and right invariant, and so the corresponding volume measure
is a Haar measure. We assume <span class="math inline">\(\omega\)</span>
normalized so that <span class="math inline">\(\int_G \, d
\tilde{\omega} = 1\)</span>; then <span class="math inline">\(f \mapsto
\int_G f \, d \tilde{\omega}\)</span> is the probability Haar on <span
class="math inline">\(G\)</span>. The two-sided invariance means that
for any <span class="math inline">\(g_1, g_2 \in G\)</span>, the local
chart <span class="math inline">\(g_1 e^x g_2 \mapsto x \in
\mathfrak{g}\)</span> at <span class="math inline">\(g_1 g_2\)</span>
has determinant one at <span class="math inline">\(g_1 g_2\)</span>.</p>
<p>We may similarly realize the probability Haar on <span
class="math inline">\(T\)</span> as <span class="math inline">\(f
\mapsto \int_T f d \, \tilde{\alpha}\)</span>, where <span
class="math inline">\(\tilde{\alpha}\)</span> corresponds to some
nonzero element <span class="math inline">\(\alpha \in
\Lambda^n(\mathfrak{t})^*\)</span>.</p>
<p>Equip <span class="math inline">\(\mathfrak{g}\)</span> with any
<span class="math inline">\(\mathop{\mathrm{Ad}}(T)\)</span>-invariant
scalar product (e.g., by averaging), and let <span
class="math inline">\(\mathfrak{g}/\mathfrak{t}\)</span> denote the
orthogonal complement to <span
class="math inline">\(\mathfrak{t}\)</span>. Then <span
class="math inline">\(\mathfrak{g} = \mathfrak{t} \oplus
\mathfrak{g}/\mathfrak{t}\)</span>. The complexification <span
class="math inline">\((\mathfrak{g}/\mathfrak{t})_{\mathbb{C}}\)</span>
of <span class="math inline">\(\mathfrak{g}/\mathfrak{t}\)</span> is
then an <span
class="math inline">\(\mathop{\mathrm{Ad}}(T)\)</span>-invariant
complement to <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> in <span
class="math inline">\(\mathfrak{g}_{\mathbb{C}}\)</span>; by our
discussion of the adjoint representation above, we see that <span
class="math display">\[(\mathfrak{g}/\mathfrak{t})_{\mathbb{C}}
    = \oplus_{i \neq j} \mathbb{C} E_{i j},\]</span> i.e., it is the
space of matrices whose diagonal entries vanish.</p>
<p>There is a unique <span class="math inline">\(\beta \in
\Lambda^{N-n}(\mathfrak{g}/\mathfrak{t})^*\)</span> so that <span
class="math inline">\(\omega = \alpha \wedge \beta\)</span>. For <span
class="math inline">\(t \in T\)</span>, the operator <span
class="math inline">\(\mathop{\mathrm{Ad}}(t)^*\)</span> sends <span
class="math inline">\(\beta\)</span> to <span
class="math inline">\(\det(\mathop{\mathrm{Ad}}(t)|_{\mathfrak{g}/\mathfrak{t}})
\beta\)</span>, but (either by explicit calculation, or using the
compactness of <span class="math inline">\(T\)</span>) the determinant
in question is trivial, so <span class="math inline">\(\beta\)</span> is
<span
class="math inline">\(\mathop{\mathrm{Ad}}(T)^*\)</span>-invariant. It
thus corresponds to a <span class="math inline">\(G\)</span>-invariant
<span class="math inline">\((N-n)\)</span>-form <span
class="math inline">\(\tilde{\beta}\)</span> on the <span
class="math inline">\((N-n)\)</span>-dimensional manifold <span
class="math inline">\(G/T\)</span>, whose corresponding volume form is
invariant under left translation by <span
class="math inline">\(G\)</span>. Fubini’s theorem applied in local
coordinates implies that for any <span class="math inline">\(f \in
C_c(G)\)</span>, <span class="math display">\[\int_G f \, d
\tilde{\omega}
    =
    \int_{g \in G/T}
    (\int_{t \in T}
    f(g t) \, d \tilde{\alpha}(t))
    \, d \tilde{\beta}(g).\]</span> (Alternatively, note that the RHS
defines a Haar probability measure on <span
class="math inline">\(G\)</span>, hence equals the LHS by uniqueness of
Haar measures.) Applying this relation with <span
class="math inline">\(f = 1\)</span> gives in particular that <span
class="math inline">\(\int_{G/T} \, d \tilde{\beta} = 1\)</span>, hence
that the integral of a function <span class="math inline">\(G/T
\rightarrow \mathbb{R}\)</span> with respect to <span
class="math inline">\(d \tilde{\beta}\)</span> is the same as the
integral of its pullback to <span class="math inline">\(G\)</span> with
respect to the probability Haar. We can now restate the desired integral
formula as <span id="eq:weyl-integral-via-diff-forms" class="math display">\[\label{eq:weyl-integral-via-diff-forms}\tag{9}
    \frac{1}{|W|}
    \int_{g \in G/T}
    (\int_{t \in T}
    |\Delta(t)|^2
    f(g t g^{-1}) \, d \tilde{\alpha}(t))
    \, d \tilde{\beta}(g)
    =
    \int_{G}  f \, d \tilde{\omega}.\]</span> The basic idea of the
proof is that the map <span class="math display">\[\phi : G/T \times T
\rightarrow G\]</span> <span class="math display">\[(g T,t) \mapsto g t
g^{-1}\]</span> is generically <span
class="math inline">\(|W|\)</span>-to-<span
class="math inline">\(1\)</span> and has determinant <span
class="math inline">\(|\Delta|^2(t)\)</span>.</p>
<p>Turning to rigorous details, let’s compute <span
class="math inline">\(\det(\phi)\)</span> with respect to the
differential forms <span class="math inline">\(\tilde{\beta} \times
\tilde{\alpha}\)</span> on <span class="math inline">\(G/T \times
T\)</span> and <span class="math inline">\(\tilde{\omega}\)</span> on
<span class="math inline">\(G\)</span>. The scalar <span
class="math inline">\(\det(\phi)(g T, t)\)</span> is the same as the
determinant at the origin of the composition <span
class="math display">\[\mathfrak{g}/\mathfrak{t} \oplus \mathfrak{t} %
  \mathrel{%
    \mathpalette{\da@xarrow{}{(x,y) \mapsto (g \exp(x) T, \exp(y)
t)}{}\mathchar&quot;0\hexnumber@\symAMSa 4B {\,}{}}{}%
  }%
G/T \times T \xrightarrow{\phi } G %
  \mathrel{%
    \mathpalette{\da@xarrow{}{g \exp(x&#39;+y) t g^{-1} \mapsto
(x&#39;,y)}{}\mathchar&quot;0\hexnumber@\symAMSa 4B {\,}{}}{}%
  }%
\mathfrak{g}/\mathfrak{t} \oplus \mathfrak{t},\]</span> since in this
composition the outermost two arrows have determinant one at the
relevant argument by construction. (A dashed arrow denotes a partial
map, defined on a suitable open.) But since <span
class="math display">\[(g e^x) (e^y t) (g e^x)^{-1} \simeq g \exp(x -
\mathop{\mathrm{Ad}}(t) x + y) t g^{-1},\]</span> where <span
class="math inline">\(\simeq\)</span> means ignoring terms that depend
quadratically or higher upon <span class="math inline">\(x\)</span> and
<span class="math inline">\(y\)</span>, we see that the above
composition has the same determinant at the origin as the linear map
<span class="math display">\[(x,y) \mapsto (x - \mathop{\mathrm{Ad}}(t)
x, y).\]</span> We may compute the determinant of the operator <span
class="math inline">\(x \mapsto x - \mathop{\mathrm{Ad}}(t) x\)</span>
on <span class="math inline">\(\mathfrak{g}/\mathfrak{t}\)</span> after
complexifying and using the explicit basis of weight vectors <span
class="math inline">\(E_{i j}\)</span>. We obtain in this way that <span id="eq:compute-det-phi" class="math display">\[\label{eq:compute-det-phi}\tag{10}
    \det(\phi)(g T, t)
    =
    \prod_{i \neq j}
    (1 - t_i/t_j)
    = |\Delta|^2(t).\]</span></p>
<p>We observe next that the function <span
class="math inline">\(|\Delta|^2 : T \rightarrow
\mathbb{R}_{&gt;0}\)</span> extends to a conjugacy-invariant function on
<span class="math inline">\(G\)</span> sending <span
class="math inline">\(g \in G\)</span> to the product of the squared
magnitudes of the differences between its distinct eigenvalues, with
<span class="math inline">\(|\Delta|^2(g) = 0\)</span> precisely when
<span class="math inline">\(g\)</span> has a repeated eigenvalue. Let
<span class="math inline">\(G_{\mathop{\mathrm{sing}}}\)</span> denote
the <em>singular subset</em> consisting of <span class="math inline">\(g
\in G\)</span> having a repeated eigenvalue; it is the zero locus of
<span class="math inline">\(|\Delta|^2\)</span>, hence a compact subset
of <span class="math inline">\(G\)</span>. The function <span
class="math inline">\(|\Delta|^2\)</span> is real-analytic (e.g.,
because it is a polynomial in the coefficients of the characteristic
polynomial) and not identically zero on <span
class="math inline">\(G\)</span>, so its zero locus <span
class="math inline">\(G_{\mathop{\mathrm{sing}}}\)</span> has measure
zero; moreover, the volume of <span class="math inline">\(\{g \in G :
|\Delta|^2 &lt; \varepsilon\}\)</span> tends to zero as <span
class="math inline">\(\varepsilon\rightarrow 0\)</span>. By an
approximation argument, we can thus reduce to establishing <a
href="#eq:weyl-integral-via-diff-forms" data-reference-type="eqref"
data-reference="eq:weyl-integral-via-diff-forms">\((9)\)</a>
in the special case that <span class="math inline">\(f\)</span> is
supported on <span class="math inline">\(\{g \in G : |\Delta|^2 \geq
\varepsilon\}\)</span> for some <span
class="math inline">\(\varepsilon&gt; 0\)</span>. In particular, we may
assume that <span class="math inline">\(f\)</span> is supported on a
compact subset of the <em>regular subset</em> <span
class="math inline">\(G_{\mathop{\mathrm{reg}}} := G -
G_{\mathop{\mathrm{sing}}}\)</span> consisting of <span
class="math inline">\(g \in G\)</span> having distinct eigenvalues.</p>
<p>Set <span class="math inline">\(T_{\mathop{\mathrm{reg}}} :=
G_{\mathop{\mathrm{reg}}} \cap T\)</span>. We observe that it consists
of those <span class="math inline">\(t \in T\)</span> having trivial
<span class="math inline">\(W\)</span>-stabilizer. (This turns out to be
a special feature of <span class="math inline">\(G =
\mathop{\mathrm{U}}(n)\)</span>; what’s essential is that the subset of
<span class="math inline">\(t \in T_{\mathop{\mathrm{reg}}}\)</span>
with trivial <span class="math inline">\(W\)</span>-stabilizer has full
measure.) We observe that for <span class="math inline">\(t \in
T_{\mathop{\mathrm{reg}}}\)</span>, its <span
class="math inline">\(G\)</span>-centralizer is <span
class="math inline">\(T\)</span> (indeed, any centralizing element must
stabilize its eigenspaces, which are the one-dimensional spaces <span
class="math inline">\(\mathbb{C} e_j\)</span>). From this and the fact
(Lemma <a href="#lem:describe-conjugacy-classes-Un"
data-reference-type="ref"
data-reference="lem:describe-conjugacy-classes-Un">32</a>) that the
conjugates of <span class="math inline">\(x\)</span> in <span
class="math inline">\(T\)</span> lie in a single <span
class="math inline">\(W\)</span>-orbit, we deduce that <span
class="math inline">\(w \cdot (g T, t) := (g w^{-1} T, w t
w^{-1})\)</span> defines a simply-transitive action of <span
class="math inline">\(W\)</span> on the fiber <span
class="math inline">\(\{(g T, t) : g t g^{-1} = x\}\)</span> above <span
class="math inline">\(x \in G_{\mathop{\mathrm{reg}}}\)</span>. In
particular, the fibers all have cardinality <span
class="math inline">\(|W|\)</span>. On the other hand, we see from <a
href="#eq:compute-det-phi" data-reference-type="eqref"
data-reference="eq:compute-det-phi">\((10)\)</a> that the
induced map <span class="math display">\[\phi : G/T \times
T_{\mathop{\mathrm{reg}}} \rightarrow G_{\mathop{\mathrm{reg}}}\]</span>
has everywhere nonvanishing differential. By the inverse function
theorem, it follows that <span class="math inline">\(\phi\)</span>
defines <span class="math inline">\(|W|\)</span>-fold covering map. By a
partition of unity, we may assume that <span
class="math inline">\(f\)</span> is supported in a small connected
neighborhood <span class="math inline">\(U \subseteq
G_{\mathop{\mathrm{reg}}}\)</span> of some <span class="math inline">\(x
\in G_{\mathop{\mathrm{reg}}}\)</span> over which <span
class="math inline">\(\phi^{-1}(U) \rightarrow U\)</span> is the trivial
<span class="math inline">\(|W|\)</span>-fold cover. We conclude by
applying <a href="#eq:change-of-vars" data-reference-type="eqref"
data-reference="eq:change-of-vars">\((8)\)</a> and <a
href="#eq:compute-det-phi" data-reference-type="eqref"
data-reference="eq:compute-det-phi">\((10)\)</a> on each
connected component of <span
class="math inline">\(\phi^{-1}(U)\)</span>. ◻</p>
</span></div>
<p><a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></p>
<h2 id="primer-on-symmetric-polynomials">Primer on symmetric
polynomials</h2>
<p>We have encountered already several elements of the ring of Laurent
polynomials in the variable <span
class="math inline">\(t_1,\dotsc,t_n\)</span>. For their further study,
it will be convenient to denote that ring by some letter: <span
class="math display">\[L := \mathbb{Z}[t_1^{\pm
1},\dotsc,t_n^{\pm}]\]</span> As a <span
class="math inline">\(\mathbb{Z}\)</span>-module, <span
class="math inline">\(L\)</span> has the basis consisting of the
monomials <span class="math inline">\(e^\lambda : t \mapsto t^{\lambda}
= t_1^{\lambda_1} \dotsb t_n^{\lambda_n}\)</span> considered previously,
thus <span class="math display">\[L = \oplus_{\lambda \in \mathbb{Z}^n}
\mathbb{Z} e^\lambda.\]</span> As above, we refer to the <span
class="math inline">\(\lambda\)</span> as <em>weights</em>.</p>
<p>The symmetric group <span class="math inline">\(W \cong S(n)\)</span>
acts on <span class="math inline">\(L\)</span> by <span
class="math inline">\(w \cdot f(t_1,\dotsc,t_n) := f(t_{w(1)}, \dotsc,
t_{w(n)})\)</span>.</p>
<div class="definition">
<p><strong>Definition 36</strong>. We say that <span
class="math inline">\(f \in L\)</span> is <em>symmetric</em> if <span
class="math inline">\(w \cdot f = f\)</span> for all <span
class="math inline">\(w \in W\)</span>, and <em>alternating</em> if
<span class="math inline">\(w \cdot f = (-1)^w f\)</span> for all <span
class="math inline">\(w \in W\)</span>. We denote by <span
class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span> and <span
class="math inline">\(L^{\mathop{\mathrm{alt}}}\)</span> the respective
spaces of symmetric and alternating Laurent polynomials.</p>
</div>
<p>We have seen that for any finite-dimensional representation <span
class="math inline">\(\pi\)</span> of <span class="math inline">\(G =
\mathop{\mathrm{U}}(n)\)</span>, the restriction <span
class="math inline">\(\chi_\pi|_{T}\)</span> to <span
class="math inline">\(T\)</span> of its character <span
class="math inline">\(\chi_\pi\)</span> is a symmetric polynomial. To be
pedantic, <span class="math inline">\(\chi_\pi|_{T}\)</span> is the
function <span class="math inline">\(\mathop{\mathrm{U}}(1)^n
\rightarrow \mathbb{C}\)</span> associated to a unique symmetric
polynomial; we will identify polynomials with their associated functions
freely in what follows. We will also abbreviate the restriction <span
class="math inline">\(\chi_\pi|_{T}\)</span> simply by <span
class="math inline">\(\chi_\pi\)</span>, keeping in mind that the
character is determined by its restriction in view of Corollary <a
href="#cor:class-fns-via-T" data-reference-type="ref"
data-reference="cor:class-fns-via-T">33</a>. Subject to these
identifications, <span class="math inline">\(\chi_\pi \in
L^{\mathop{\mathrm{sym}}}\)</span>.</p>
<p>On the other hand, the discriminant polynomial <span
class="math inline">\(\Delta(t) = \prod_{i &lt; j} (t_i - t_j)\)</span>
that appeared in the Weyl character formula is alternating. One can make
this more visible by using the Vandermonde determinant formula <span
class="math inline">\(\Delta(t) = \det(t_i^{n-j})_{i,j=1..n}\)</span>.
We can see that <span class="math inline">\(\Delta \in
L^{\mathop{\mathrm{alt}}}\)</span> by recalling that the determinant
changes sign when we swap a pair of its rows or columns.</p>
<p>The <em>monomial symmetric polynomials</em> are defined for <span
class="math inline">\(\lambda \in \mathbb{Z}^n\)</span> by <span
class="math display">\[M_{\lambda} := \sum_{\mu \in W \cdot \lambda}
e^\mu.\]</span> They obviously belong to <span
class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span>. Note that we
sum over the <span class="math inline">\(W\)</span>-orbit of <span
class="math inline">\(\lambda\)</span> without multiplicity. Note also
that <span class="math inline">\(M_\lambda(t)\)</span> is symmetric not
only with respect to the argument <span
class="math inline">\(t\)</span>, but also with respect to the index
<span class="math inline">\(\lambda\)</span>, i.e., <span
class="math inline">\(M_{w \cdot \lambda} = M_\lambda\)</span>. For
example, if <span class="math inline">\(n = 2\)</span>, then <span
class="math inline">\(M_{(7,6)}(t) = t_1^7 t_2^6 + t_1^6 t_2^7 =
M_{(6,7)}(t)\)</span>, while <span class="math inline">\(M_{(7,7)}(t) =
t_1^7 t_2^7\)</span>. We get a basis for <span
class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span> from the <span
class="math inline">\(M_\lambda\)</span>’s by considering one <span
class="math inline">\(\lambda\)</span> from each <span
class="math inline">\(W\)</span>-orbit on <span
class="math inline">\(\mathbb{Z}^n\)</span>. It will be convenient to
choose an explicit set of representatives:</p>
<div class="definition">
<p><strong>Definition 37</strong>. We say that <span
class="math inline">\(\lambda \in \mathbb{Z}^n\)</span> is
<em>dominant</em> if <span class="math inline">\(\lambda_1 \geq \dotsb
\geq \lambda_n\)</span>, and <em>strictly dominant</em> if <span
class="math inline">\(\lambda_1 &gt; \dotsb &gt; \lambda_n\)</span>.</p>
</div>
<p>Thus the dominant <span class="math inline">\(\lambda\)</span> give a
set of representatives for the <span
class="math inline">\(W\)</span>-orbits on <span
class="math inline">\(\mathbb{Z}^n\)</span>, and so the <span
class="math inline">\(M_\lambda\)</span> for dominant <span
class="math inline">\(\lambda\)</span> give a basis for <span
class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span>.</p>
<p>The <em>elementary symmetric polynomials</em> are defined for <span
class="math inline">\(k=1,\dotsc,n\)</span> by <span
class="math display">\[\sigma_k(t) := \sum_{1 \leq i_1 &lt; \dotsb &lt;
i_k \leq n} t_{i_1} \dotsb t_{i_k}.\]</span> For example, <span
class="math inline">\(\sigma_1 = t_1 + \dotsb + t_n\)</span>, <span
class="math inline">\(\sigma_2 = t_1 t_2 + t_1 t_3 + + \dotsb + t_{n-1}
t_n\)</span>, while <span class="math inline">\(\sigma_n = t_1 \dotsb
t_n\)</span>. We might recall from §<a href="#sec:weight-decmop-U-n"
data-reference-type="ref" data-reference="sec:weight-decmop-U-n">3.3</a>
that <span class="math inline">\(\sigma_k\)</span> is the character of
the <span class="math inline">\(k\)</span>th exterior power <span
class="math inline">\(\Lambda^n(\mathbb{C}^n)\)</span> of the standard
representation <span class="math inline">\(\mathbb{C}^n\)</span>. The
<span class="math inline">\(\sigma_k\)</span> together with the inverse
of <span class="math inline">\(\sigma_n\)</span> are well-known to
generate <span class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span>;
for completeness we state this below and sketch the proof.</p>
<div id="lem:symmetric-functino-theory" class="lemma">
<p><strong>Lemma 38</strong>. We have <span
class="math display">\[L^{\mathop{\mathrm{sym}}} = \oplus
_{\lambda:\text{dominant}} \mathbb{Z} M_\lambda =
\mathbb{Z}[\sigma_1,\sigma_2,\dotsc,\sigma_{n-1},\sigma_n,1/\sigma_n].\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The first identity was noted earlier. For the second
identity, the containment “<span
class="math inline">\(\supseteq\)</span>” is clear; we must verify the
reverse containment “<span class="math inline">\(\subseteq\)</span>”,
i.e., that <span class="math inline">\(M_\lambda\)</span> belongs to the
RHS for all dominant <span class="math inline">\(\lambda\)</span>.
Replacing <span class="math inline">\(M_\lambda\)</span> with <span
class="math inline">\(M_\lambda/\sigma_n^{\lambda_n}\)</span> has the
effect of replacing <span class="math inline">\(\lambda\)</span> with
<span class="math inline">\((\lambda_1 - \lambda_n, \lambda_2 -
\lambda_n, \dotsc, \lambda_{n-1} - \lambda_n, 0)\)</span>. We may reduce
in this way to the case that <span class="math inline">\(\lambda_n =
0\)</span>. Having performed this reduction, we now induct on <span
class="math inline">\(\lambda\)</span> with respect to lexicographical
ordering (i.e., ordering first by <span
class="math inline">\(\lambda_1\)</span>, then using <span
class="math inline">\(\lambda_2\)</span> to break the tie if necessary,
and so on). For the base case <span class="math inline">\(\lambda =
(0,\dotsc,0)\)</span> we have <span class="math inline">\(M_\lambda = 1
\in \mathbb{Z}\)</span>. In general, we observe that <span
class="math display">\[\begin{align}
    M_\lambda(t)
    &amp;= t_1^{\lambda_1} \dotsb t_n^{\lambda_n}
      = t_1^{\lambda_1 - \lambda_2}
      (t_1 t_2)^{\lambda_2 - \lambda_3}
      \dotsb (t_1 \dotsb t_{n-1})^{\lambda_{n-1} - \lambda_n} \\
    &amp;= \sigma_1^{\lambda_1 - \lambda_2}
      \sigma_2^{\lambda_2 - \lambda_3} \dotsb
      \sigma_{n-1}^{\lambda_{n-1} - \lambda_n}
      (t)
      + \dotsb,
  
\end{align}\]</span> where <span class="math inline">\(\dotsb\)</span>
denotes an integral linear combination of <span
class="math inline">\(M_{\mu}\)</span> taken over dominant <span
class="math inline">\(\mu\)</span> lexicographically lower than <span
class="math inline">\(\lambda\)</span>. By our inductive hypothesis,
<span class="math inline">\(M_{\mu}/\sigma_n^{\mu_n}\)</span> belongs to
<span
class="math inline">\(\mathbb{Z}[\sigma_1,\dotsc,\sigma_{n-1}]\)</span>
for each such <span class="math inline">\(\mu\)</span>, hence also <span
class="math inline">\(M_{\lambda} \in
\mathbb{Z}[\sigma_1,\dotsc,\sigma_{n-1}]\)</span>, as required. ◻</p>
</span></div>
<p>The <em>monomial alternating polynomials</em> are defined by <span
class="math display">\[A_{\lambda} := \sum_{w \in W} (-1)^w e^{w \cdot
\lambda}.\]</span> They obviously define elements of <span
class="math inline">\(L^{\mathop{\mathrm{alt}}}\)</span>. The
discriminant <span class="math inline">\(\Delta\)</span> arises in this
way. Indeed, we may expand the determinental formula for <span
class="math inline">\(\Delta(t)\)</span> noted earlier as <span
class="math inline">\(\sum_{w \in W} (-1)^w \prod_j
t_{w(j)}^{n-j}\)</span> or as <span class="math inline">\(\sum_{w \in W}
(-1)^w \prod_i t_{i}^{n-w(i)}\)</span>. Introducing the notation <span
class="math display">\[\rho := (n-1,n-2,\dotsc,2,1,0) \in
\mathbb{Z}^n,\]</span> so that <span class="math inline">\(t^\rho =
t_1^{n-1} t_2^{n-2} \dotsb t_{n-2}^2 t_{n-1}\)</span>, we obtain <span
class="math inline">\(\Delta(t) = \sum_{w \in W} (-1)^w t^{w \cdot
\rho}\)</span>, that is to say, <span class="math display">\[\Delta =
A_{\rho}.\]</span></p>
<p>As in the case of monomial symmetric polynomials, the <span
class="math inline">\(A_\lambda\)</span> are alternating not just with
respect to their argument but also their index: <span
class="math inline">\(A_{w \cdot \lambda} = (-1)^w A_\lambda\)</span>.
In particular, if <span class="math inline">\(\lambda_i =
\lambda_j\)</span> for some <span class="math inline">\(i \neq
j\)</span>, then <span class="math inline">\(A_{\lambda} = 0\)</span>.
For instance, if <span class="math inline">\(n = 2\)</span>, then <span
class="math inline">\(M_{(7,6)}(t) = t_1^7 t_2^6 - t_1^6 t_2^7 = -
M_{(6,7)}(t)\)</span>, while <span class="math inline">\(M_{(7,7)}(t) =
t_1^7 t_2^7 - t_1^7 t_2^7 = 0\)</span>. (To established the required
vanishing in general, take for <span class="math inline">\(w\)</span>
the transposition swapping <span class="math inline">\(i\)</span> and
<span class="math inline">\(j\)</span>, so that <span
class="math inline">\(w \cdot \lambda = \lambda\)</span>; then <span
class="math inline">\(A_\lambda = (-1)^w A_{w \cdot \lambda} = -
A_\lambda\)</span>, i.e., <span class="math inline">\(2 A_\lambda =
0\)</span>, and so <span class="math inline">\(A_\lambda = 0\)</span>.
Alternatively, consider cosets in <span class="math inline">\(W\)</span>
of the two-element group generated by <span
class="math inline">\(w\)</span>, and note that the sum in the
definition of <span class="math inline">\(A_{\lambda}\)</span> vanishes
over each such coset.) If <span class="math inline">\(\lambda\)</span>
has distinct components, then <span class="math inline">\(A_\lambda \neq
0\)</span>; indeed, its lexicographically highest term is <span
class="math inline">\(e^{\lambda}\)</span>.</p>
<p>As <span class="math inline">\(\lambda\)</span> runs over the <span
class="math inline">\(W\)</span>-orbits of <span
class="math inline">\(\lambda \in \mathbb{Z}^n\)</span> having distinct
components, the <span class="math inline">\(A_\lambda\)</span> furnish a
basis for <span
class="math inline">\(L^{\mathop{\mathrm{alt}}}\)</span>. The strictly
dominant <span class="math inline">\(\lambda\)</span> give a system of
representatives for such orbits. An equivalent system is given by the
<span class="math inline">\(\lambda + \rho\)</span> for dominant <span
class="math inline">\(\lambda\)</span>, noting that the map <span
class="math inline">\(\lambda \mapsto \lambda + \rho\)</span> induces a
bijection between dominant and strictly dominant weights. Thus <span
class="math display">\[L^{\mathop{\mathrm{alt}}}
  = \oplus_{\lambda:\text{strictly dominant}}
  \mathbb{Z} A_\lambda
  = \oplus_{\lambda:\text{dominant}}
  \mathbb{Z} A_{\lambda + \rho}.\]</span></p>
<div class="lemma">
<p><strong>Lemma 39</strong>. Multiplication by <span
class="math inline">\(\Delta\)</span> induces an isomorphism of <span
class="math inline">\(\mathbb{Z}\)</span>-modules <span
class="math display">\[L^{\mathop{\mathrm{sym}}} \xrightarrow{f \mapsto
\Delta f} L^{\mathop{\mathrm{alt}}}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The indicated map is clearly defined (because <span
class="math inline">\(w \cdot (\Delta f) = (w \cdot \Delta) (w \cdot f)
= (-1)^w \Delta f\)</span>) and injective, so the content here is that
any alternating Laurent polynomial <span
class="math inline">\(h\)</span> may be divided by <span
class="math inline">\(\Delta\)</span> inside the ring of Laurent
polynomials. After clearing denominators by multiplying <span
class="math inline">\(h\)</span> by a sufficiently large power of <span
class="math inline">\(t_1 \dotsb t_n\)</span>, it suffices to show that
any alternating polynomial <span class="math inline">\(h\)</span> is
divisible by <span class="math inline">\(\Delta\)</span> in the ring
<span class="math inline">\(\mathbb{Z}[t_1,\dotsc,t_n]\)</span> of
ordinary polynomials. For this we induct on <span
class="math inline">\(n\)</span>. The case <span class="math inline">\(n
\geq 1\)</span> is tautological, because then <span
class="math inline">\(\Delta = 1\)</span>, so suppose <span
class="math inline">\(n \geq 2\)</span>. We note (since <span
class="math inline">\(2\)</span> is not a zerodivisor in <span
class="math inline">\(\mathbb{Z}\)</span>) that the alternating
condition on <span class="math inline">\(h\)</span> implies that it
vanishes under any substitution <span class="math inline">\(t_i :=
t_j\)</span> (<span class="math inline">\(i \neq j\)</span>). (Indeed,
from some perspectives it would be better to take this property as the
<em>definition</em> of alternating.) On the other hand, by division with
remainder in the variable <span class="math inline">\(t_n\)</span>, we
may write <span class="math inline">\(h = (t_n - t_1) q + r\)</span>
where <span class="math inline">\(q \in
\mathbb{Z}[t_1,\dotsc,t_n]\)</span> and <span class="math inline">\(r
\in \mathbb{Z}[t_1,\dotsc,t_{n-1}]\)</span>, but then substituting <span
class="math inline">\(t_n := t_1\)</span> shows that <span
class="math inline">\(r = 0\)</span>, and so <span
class="math inline">\(h = (t_n - t_1) q\)</span>. Since <span
class="math inline">\(h\)</span> vanishes under the substitution <span
class="math inline">\(t_n := t_2\)</span> and our polynomial rings are
integral domains, we see that <span class="math inline">\(q\)</span>
vanishes under the substitution <span class="math inline">\(t_n :=
t_2\)</span>. We may thus iterate the above division with remainder
argument to see that <span class="math inline">\(h = (t_n - t_1) (t_n -
t_2) \dotsb (t_n - t_{n-1}) q&#39;\)</span> for some <span
class="math inline">\(q&#39; \in \mathbb{Z}[t_1,\dotsc,t_n]\)</span>. We
may expand <span class="math inline">\(q &#39;\)</span> in powers of
<span class="math inline">\(t_n\)</span> as <span
class="math inline">\(\sum a_j t_n^j\)</span>, with coefficients <span
class="math inline">\(a_j \in \mathbb{Z}[t_1,\dotsc,t_{n-1}]\)</span>.
We may likewise expand <span class="math inline">\(h\)</span> in powers
of <span class="math inline">\(t_n\)</span>; each coefficient in this
expansion is then an alternating polynomial in the variables <span
class="math inline">\(t_1,\dotsc,t_{n-1}\)</span>, so the same holds for
the <span class="math inline">\(a_j\)</span>. By our inductive
hypothesis, <span class="math inline">\(a_j\)</span> is divisible by
<span class="math inline">\(\prod_{i &lt; j \leq n-1} (t_i -
t_j)\)</span>. It follows as required that <span
class="math inline">\(f\)</span> is divisible by <span
class="math inline">\(\Delta\)</span>. ◻</p>
</span></div>
<p>In particular, the division in the following definition makes
sense:</p>
<div class="definition">
<p><strong>Definition 40</strong>. The <em>Schur polynomial</em>
attached to a dominant <span class="math inline">\(\lambda \in
\mathbb{Z}^n\)</span> is <span class="math display">\[s_\lambda :=
\frac{A_{\lambda + \rho}}{A_\rho } \in
L^{\mathop{\mathrm{sym}}}.\]</span></p>
</div>
<p>If <span class="math inline">\(t\)</span> is <em>regular</em> in the
sense that <span class="math inline">\(t_i \neq t_j\)</span> for <span
class="math inline">\(i \neq j\)</span>, then <span id="eq:evaluation-Schur-rational" class="math display">\[\label{eq:evaluation-Schur-rational}\tag{11}
  s_\lambda(t)
  =  
  \frac{\det(t_i^{\lambda_j + n - j})}{\prod_{i &lt; j} (t_i -
    t_j)}.\]</span> Otherwise, <span
class="math inline">\(s_\lambda(t)\)</span> must be understood by
continuity, or by first simplifying the above rational function to a
polynomial. For instance, when <span class="math inline">\(n =
2\)</span>, we have for <span class="math inline">\(\lambda _1 \geq
\lambda_2\)</span> that <span class="math display">\[\begin{align}
  s_{(\lambda_1,\lambda_2)}(t)
  &amp;=
    \frac
    {    \det    
\begin{pmatrix}
      t_1^{\lambda_1+1} &amp;
                                                          t_1^{\lambda_2}
\\      t_2^{\lambda_1+1} &amp;
                                                                                                      t_2^{\lambda_2}    
\end{pmatrix}
    }
    {
    t_1 - t_2
    }
    =
    \frac{t_1^{\lambda_1 +1} t_2^{\lambda_2}
    - t_1^{\lambda_2} t_2^{\lambda_1 + 1}
    }{
    t_1 - t_2
    }
  \\
  &amp;=
    t_1^{\lambda_1} t_2^{\lambda_2}
    +
    t_1^{\lambda_1 - 1} t_2^{\lambda_2 + 1}
    + \dotsb
    +
    t_1^{\lambda_2} t_2^{\lambda_1}.
\end{align}\]</span></p>
<p>Since the <span class="math inline">\(A_{\lambda+\rho}\)</span> give
a basis for <span
class="math inline">\(L^{\mathop{\mathrm{alt}}}\)</span>, we deduce:</p>
<div class="lemma">
<p><strong>Lemma 41</strong>. The <span
class="math inline">\(s_\lambda\)</span> give a basis for <span
class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span>: <span
class="math display">\[L^{\mathop{\mathrm{sym}}} = \oplus
_{\lambda:\text{dominant}} \mathbb{Z} s_\lambda.\]</span></p>
</div>
<p>We’ll need later the computation of the values of the Schur
polynomials at the identity element <span class="math inline">\(t = 1 =
(1,\dotsc,1) \in \mathop{\mathrm{U}}(1)^n\)</span>:</p>
<div id="lem:schur-evalu-at-1-U-n" class="lemma">
<p><strong>Lemma 42</strong>. Let <span class="math inline">\(\lambda
\in \mathbb{Z}^n\)</span> be dominant. Temporarily abbreviate <span
class="math inline">\(\lambda &#39; := \lambda + \rho\)</span>, i.e.,
<span class="math inline">\(\lambda_j&#39; := \lambda_j + n -
j\)</span>. Then <span class="math display">\[s_\lambda(1) = \prod_{i
&lt; j} \frac{\lambda_i&#39; - \lambda_j&#39;}{j - i}.\]</span> In
particular, <span class="math inline">\(s_\lambda(1) &gt;
0\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> A direct attempt via <a
href="#eq:evaluation-Schur-rational" data-reference-type="eqref"
data-reference="eq:evaluation-Schur-rational">\((11)\)</a>
gives “<span class="math inline">\(0/0\)</span>,” so we need to take a
limit along some sequence of regular elements <span
class="math inline">\(t\)</span> tending to <span
class="math inline">\(1\)</span>. A clever choice is given by <span
class="math inline">\(t_j := z^{n-j}\)</span>, where <span
class="math inline">\(z \in \mathop{\mathrm{U}}(1)\)</span> traverses a
sequence tending to <span class="math inline">\(1\)</span>. The
numerator then simplifies to another Vandermonde determinant: <span
class="math display">\[\det(t_i^{\lambda_j + n-j}) = \det(z^{(n-i)
\lambda_j&#39;}) = \prod_{i &lt; j} (z^{\lambda_i&#39;} -
z^{\lambda_j&#39;}).\]</span> Using that <span class="math inline">\(z^a
- z^b \sim \log(z) (a - b)\)</span>, we arrive at the required
formula. ◻</p>
</span></div>
<p>We record some inner product formulas:</p>
<div id="lem:inner-products-symmetric-functions" class="lemma">
<p><strong>Lemma 43</strong>. Let <span class="math inline">\(\langle ,
\rangle\)</span> denote the inner product in <span
class="math inline">\(L^2(T)\)</span> taken with respect to the
probability Haar, so that <span class="math inline">\(\langle e^\lambda,
e^\mu \rangle = \delta_{\lambda \mu}\)</span>. For strictly dominant
<span class="math inline">\(\lambda, \mu\)</span>, we have <span
class="math display">\[\langle \Delta s_\lambda, \Delta s_\mu \rangle =
\langle A_{\lambda+\rho}, A_{\mu+\rho} \rangle = |W| \delta_{\lambda
\mu}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Immediate. ◻</p>
</span></div>
<h2 id="weyl-character-and-dimension-formulas-for-mathopmathrmun">Weyl
character and dimension formulas for <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></h2>
<div id="thm:weyl-char-Un" class="theorem">
<p><strong>Theorem 44</strong>. <em>Let <span
class="math inline">\((\pi,V)\)</span> belong to the set <span
class="math inline">\(\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\)</span>
of (isomorphism classes of) irreducible finite-dimensional
representations of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>.</em></p>
<ol>
<li><p><em>There exists a unique dominant weight <span
class="math inline">\(\lambda \in \mathbb{Z}^n\)</span> so that (the
restriction to the torus of) the character <span
class="math inline">\(\chi_\pi\)</span> is equal to the Schur polynomial
<span class="math inline">\(s_\lambda\)</span>. We write in this case
<span class="math inline">\((\pi,V) = (\pi_\lambda ,V_\lambda)\)</span>.
The weight space <span class="math inline">\(V^{\lambda}\)</span> is
one-dimensional, while <span class="math inline">\(V^{\mu} =
\{0\}\)</span> for any lexicographically larger weight <span
class="math inline">\(\mu\)</span>.</em></p></li>
<li><p><em>Every dominant weight <span
class="math inline">\(\lambda\)</span> arises in this way, giving a
bijection <span
class="math display">\[\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))
\leftrightarrow \{\text{dominant } \lambda \in
\mathbb{Z}^n\}.\]</span></em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We first prove part (i). Recall the notation <span
class="math inline">\(G := \mathop{\mathrm{U}}(n) \geq T \cong
\mathop{\mathrm{U}}(1)^n\)</span>. Write <span
class="math inline">\(\chi_\pi = \sum_{\mu} m_\pi(\mu) e^\mu\)</span> as
before. Let <span class="math inline">\(\lambda\)</span> be the
lexicographically highest weight for which <span
class="math inline">\(m_\pi(\lambda) \neq 0\)</span>. Since <span
class="math inline">\(\chi_\pi\)</span> is <span
class="math inline">\(W\)</span>-invariant, we know that <span
class="math inline">\(\lambda\)</span> is dominant, as otherwise it
would be lexicographically smaller than something in its <span
class="math inline">\(W\)</span>-orbit. In any event, <span
class="math display">\[\chi_\pi = m_\pi(\lambda) e^\lambda +
\dotsb,\]</span> where <span class="math inline">\(\dotsb\)</span>
denotes the contribution from lexicographically smaller weights. Since
also <span class="math inline">\(\Delta = e^\rho + \dotsb\)</span>, it
follows that <span class="math display">\[\Delta \chi_\pi =
m_\pi(\lambda) e^{\lambda + \rho} + \dotsb.\]</span> Since the Laurent
polynomial <span class="math inline">\(\Delta \chi_\pi\)</span> is
alternating, we may group its terms into monomial alternating functions,
giving <span id="eq:expand-delta-chi-pi" class="math display">\[\label{eq:expand-delta-chi-pi}\tag{14}
    \Delta \chi_\pi = m_\pi(\lambda) A_{\lambda + \rho} +
\dotsb,\]</span> where <span class="math inline">\(\dotsb\)</span>
denotes a linear combination of <span class="math inline">\(A_{\mu +
\rho}\)</span> taken over dominant <span
class="math inline">\(\mu\)</span> lexicographically lower than <span
class="math inline">\(\lambda\)</span>. We combine this expansion with
the orthogonality relations for characters (Theorem <a
href="#thm:basic-orthogonality-characters" data-reference-type="ref"
data-reference="thm:basic-orthogonality-characters">26</a>), the Weyl
integral formula (Theorem <a href="#thm:weyl-int"
data-reference-type="ref" data-reference="thm:weyl-int">35</a>), and the
inner product formulas for monomial alternating functions (Lemma <a
href="#lem:inner-products-symmetric-functions" data-reference-type="ref"
data-reference="lem:inner-products-symmetric-functions">43</a>) to see
that <span class="math display">\[1
    = \langle \chi_\pi, \chi_\pi \rangle_G
    =
    \frac{1}{|W|}
    \langle     \Delta \chi_\pi
    ,    \Delta \chi_\pi
    \rangle_T
    \geq
    \frac{1}{|W|}
    \langle     m_\pi(\lambda) A_{\lambda + \rho},     m_\pi(\lambda)
A_{\lambda + \rho} \rangle_T
    =
    |m_\pi(\lambda)|^2.\]</span> <span class="math display">\[% 1
    % = \|\chi_\pi \|_G^2
    % =
    % \frac{1}{|W|}
    % \|\Delta \chi_\pi \|_T^2
    % \geq
    % \frac{1}{|W|}
    % \|m_\pi(\lambda) A_{\lambda + \rho}\|^2
    % \geq
    % |\mu_\pi(\lambda)|^2.
    %\]</span> But since <span
class="math inline">\(m_\pi(\lambda)\)</span> is a positive integer, it
follows that <span class="math inline">\(m_\pi(\lambda) = 1\)</span> and
also that equality holds in each step. In particular, the remainder
terms “<span class="math inline">\(\dotsb\)</span>” in <a
href="#eq:expand-delta-chi-pi" data-reference-type="eqref"
data-reference="eq:expand-delta-chi-pi">\((14)\)</a>
must vanish identically, i.e., <span class="math inline">\(\Delta
\chi_\pi = A_{\lambda+\rho}\)</span>, giving the required formula <span
class="math inline">\(\chi_\pi = s_\lambda\)</span>. The uniqueness of
<span class="math inline">\(\lambda\)</span> is clear from the
orthogonality relations for the Schur polynomials.</p>
<p>We give two proofs that every dominant weight <span
class="math inline">\(\lambda\)</span> arises in this way:</p>
<ol>
<li><p>Assume for the sake of contradiction that <span
class="math inline">\(\lambda\)</span> does not arise, i.e., that <span
class="math inline">\(\chi_\pi \neq s_\lambda\)</span> for all <span
class="math inline">\(\pi \in \mathop{\mathrm{Irr}}(G)\)</span>. We may
uniquely extend the <span class="math inline">\(W\)</span>-invariant
function <span class="math inline">\(s_\lambda\)</span> on <span
class="math inline">\(T\)</span> to a class function on <span
class="math inline">\(G\)</span>. For each <span
class="math inline">\(\pi \in \mathop{\mathrm{Irr}}(G)\)</span>, we may
write <span class="math inline">\(\chi_\pi = s_{\lambda &#39;}\)</span>
for some dominant <span class="math inline">\(\lambda &#39; \neq
\lambda\)</span>. By the orthogonality relations for the Schur
polynomials, it follows then that <span
class="math inline">\(s_\lambda\)</span> is orthogonal to <span
class="math inline">\(\chi_\pi\)</span> in <span
class="math inline">\(L^2(G)\)</span>. But this contradicts the
Peter–Weyl theorem (Theorem <a href="#thm:peter-weyl-for-chars"
data-reference-type="ref"
data-reference="thm:peter-weyl-for-chars">27</a>).</p></li>
<li><p>Let <span class="math inline">\(W\)</span> denote the following
representation of <span class="math inline">\(G\)</span>, whose
definition may be motivated by the proof of Lemma <a
href="#lem:symmetric-functino-theory" data-reference-type="ref"
data-reference="lem:symmetric-functino-theory">38</a>: <span
class="math display">\[W := \Lambda(\mathbb{C}^n)^{\otimes \lambda_1 -
\lambda_2} \otimes \Lambda^2(\mathbb{C}^n) ^{\otimes \lambda_2 -
\lambda_3} \otimes \dotsb \otimes \Lambda^{n-1}(\mathbb{C}^n)^{\otimes
\lambda_{n-1}-\lambda_n} \otimes
\Lambda^n(\mathbb{C}^n)^{\lambda_n}.\]</span> (Note that <span
class="math inline">\(\Lambda^n(\mathbb{C}^n)\)</span> is the
one-dimensional determinant representation, so it makes sense to raise
it to any integral power <span class="math inline">\(\lambda_n\)</span>,
giving the one-dimensional representation <span
class="math inline">\(\mathop{\mathrm{U}}(n) \ni g \mapsto
\det(g)^{\lambda_n} \in \mathop{\mathrm{U}}(1)\)</span> denoted above by
<span
class="math inline">\(\Lambda^n(\mathbb{C}^n)^{\lambda_n}\)</span>.)
Thus, as before, <span class="math display">\[\chi_W =
\sigma_1^{\lambda_1 - \lambda_2} \sigma_2^{\lambda_2 - \lambda_3} \dotsb
\sigma_{n-1}^{\lambda_{n-1} - \lambda_n} \sigma_n^{\lambda_n} =
e^\lambda + \dotsb,\]</span> where <span
class="math inline">\(\dotsb\)</span> denotes the contribution of
lexicographically smaller weights. On the other hand, we may decompose
<span class="math inline">\(W\)</span> into irreducible subspaces
(Theorem <a href="#thm:basic-orthogonality-characters"
data-reference-type="ref"
data-reference="thm:basic-orthogonality-characters">26</a>), taking into
account the recently-established description of <span
class="math inline">\(\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\)</span>:
<span class="math display">\[W = \oplus_{\text{dominant }\mu}
V_\mu^{\oplus n(\mu)}.\]</span> (By convention, here we sum only over
those <span class="math inline">\(\mu\)</span> which we as yet know to
arise from <span
class="math inline">\(\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\)</span>.)
At the level of characters, this decomposition reads <span
class="math inline">\(\chi_W = \sum_{\mu} n(\mu) \chi_\mu\)</span>.
Multiplying through by <span class="math inline">\(\Delta = e^\rho +
\dotsb\)</span> and taking into account the formula <span
class="math inline">\(\Delta \chi_\mu = A_{\mu + \rho} = e^{\mu+\rho} +
\dotsb\)</span>, we obtain <span class="math display">\[e^{\lambda +
\rho} + \dotsb = n(\lambda) e^{\lambda+\rho} + \dotsb.\]</span> Thus
<span class="math inline">\(n(\lambda) = 1\)</span>, that is to say,
<span class="math inline">\(V_\lambda\)</span> occurs (exactly once) as
a subrepresentation of <span class="math inline">\(W\)</span>. In
particular, the representation <span
class="math inline">\(V_\lambda\)</span> exists in the first place, as
required.</p>
<p>(A third proof, closely related to the second: if <span
class="math inline">\(s_\lambda\)</span> is orthogonal to the character
of every irreducible representation, then it is orthogonal in particular
to any of the ring <span class="math inline">\(\mathbb{Z}[\sigma_1,
\dotsc, \sigma_{n-1}, \sigma_n, 1/\sigma_n]\)</span> generated by the
characters of the exterior powers of the standard representation and the
inverse of the determinant, but we have seen that this ring is equal to
<span class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span>
.)</p></li>
</ol>
<p> ◻</p>
</span></div>
<p>We note incidentally that the second proof given above of the
surjectivity of the map <span
class="math inline">\(\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))
\rightarrow \{\text{dominant } \lambda \in \mathbb{Z}^n\}\)</span> gives
an independent proof of the Peter–Weyl theorem in this case. We note
also that, with notation as in that proof, we may realize <span
class="math inline">\(V_\lambda\)</span> inside <span
class="math inline">\(W\)</span> explicitly, as follows. The proof shows
that the weight space <span class="math inline">\(W[\lambda]\)</span> is
one-dimensional, hence coincides with the one-dimensional weight space
<span class="math inline">\(V_\lambda[\lambda]\)</span>. Consequently,
<span class="math inline">\(V_\lambda\)</span> is the representation
generated by (i.e., spanned by the <span
class="math inline">\(G\)</span>-orbit of) any nonzero element of <span
class="math inline">\(W[\lambda]\)</span>, such as <span
class="math inline">\(e_1^{\otimes \lambda_1 - \lambda_2} \otimes (e_1
\wedge e_2)^{\otimes \lambda_2 - \lambda_3} \otimes \dotsb\)</span>.</p>
<p>This result gives a satisfying description of the character theory of
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. It has some
immediate applications:</p>
<ol>
<li><p>A formula for the multiplicity in <span
class="math inline">\(m_{\pi_\lambda}(\mu)\)</span> of the weight <span
class="math inline">\(\mu\)</span> in the representation <span
class="math inline">\(\pi_\lambda\)</span>, as the coefficient of <span
class="math inline">\(e^\mu\)</span> in <span
class="math inline">\(s_\lambda = A_{\lambda + \rho}/\Delta\)</span>.
One way to “evaluate” this further is to write <span
class="math inline">\(\Delta(t) = t^\rho \prod_{i &lt; j} (1 -
t_j/t_i)\)</span> and expand <span class="math inline">\((1 -
t_j/t_i)^{-1}\)</span> as a geometric series (look up the <em>Kostant
partition formula</em>).</p></li>
<li><p>A formula for the coefficients of the decomposition of a tensor
product of irreducible representations of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>: writing <span
class="math display">\[V_{\lambda &#39;}
    \otimes V_{\lambda &#39;}
    \cong \oplus_{\lambda}
    n(\lambda) V_{\lambda},\]</span> we have <span
class="math inline">\(\chi_{\lambda &#39;} \chi_{\lambda &#39;&#39;} =
\sum_{\lambda} n(\lambda) \chi_\lambda\)</span>, hence <span
class="math display">\[\sum_{\lambda} n(\lambda) A_{\lambda+\rho} =
\Delta \chi_{\lambda &#39;} \chi_{\lambda &#39;&#39;} = \frac{A_{\lambda
&#39; + \rho} A_{\lambda &#39;&#39; + \rho}}{\Delta }.\]</span> We may
then determine <span class="math inline">\(n(\lambda)\)</span> as the
coefficient of <span class="math inline">\(e^{\lambda+\rho}\)</span> on
both sides. (Look up the <em>Steinberg multiplicity
formula</em>.)</p></li>
<li><p>A proof of the irreducibility of several of the representations
considered in §<a href="#sec:weight-decmop-U-n"
data-reference-type="ref"
data-reference="sec:weight-decmop-U-n">3.3</a>, such as <span
class="math inline">\({\mathop{\mathrm{Sym}}}^k(\mathbb{C}^n)\)</span> or
<span class="math inline">\(\Lambda^k(\mathbb{C}^n)\)</span>. (A direct
“algebraic” proof of their irreducibility is not very difficult, so the
present argument should be regarded as an alternative “analytic” proof.)
For example, consider <span class="math inline">\(V =
{\mathop{\mathrm{Sym}}}^k(\mathbb{C}^n)\)</span>. By “stars and bars,” we
have (TODO: fix binomial coefficients) On the other hand, <span
class="math inline">\(\lambda = (k,0,\dotsc,0)\)</span> is the
lexicographically highest weight of <span
class="math inline">\(V\)</span>. Thus <span
class="math inline">\(\lambda\)</span> is lexicographically highest
among the dominant weights <span class="math inline">\(\mu\)</span>
contributing to the decomposition <span class="math inline">\(\chi_V =
\sum_{\mu} n(\mu) \chi_\mu\)</span>, and so <span
class="math inline">\(V_\lambda\)</span> must occur as an irreducible
subrepresentation of <span class="math inline">\(V\)</span>. In
particular, <span class="math inline">\(\dim(V_\lambda) \leq
\dim(V)\)</span>. On the other hand, a short calculation with the
dimension formula gives readily the “numerical coincidence” <span
class="math inline">\(\dim(V_\lambda) = \dim(V)\)</span> (see the
homework), from which we deduce that <span class="math inline">\(V \cong
V_\lambda\)</span>; in particular, <span
class="math inline">\(V\)</span> is irreducible. A similar argument
applies to the exterior powers.</p></li>
</ol>
<p><a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<h2 id="sec:some-groups-closely">§3.7. Some groups closely related to <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span></h2>
<p>Set <span class="math display">\[\mathop{\mathrm{SU}}(n) := \{g \in
\mathop{\mathrm{U}}(n) : \det(g) = 1 \}.\]</span> Let <span
class="math display">\[Z := \{
\begin{pmatrix}
    z &amp;  &amp;  \\
      &amp; \dotsb  &amp;  \\
      &amp;  &amp; z
  \end{pmatrix}
\in \mathop{\mathrm{U}}(n) : z \in \mathop{\mathrm{U}}(1)\} \cong
\mathop{\mathrm{U}}(1)\]</span> denote the center of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>, and let <span
class="math display">\[\PU(n) := \mathop{\mathrm{U}}(n)/Z\]</span>
denote the corresponding quotient. Observe that</p>
<ul>
<li><p>given a representation of <span
class="math inline">\(\PU(n)\)</span>, we obtain a representation of
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> by pullback,
i.e., by composing with the projection <span
class="math inline">\(\mathop{\mathrm{U}}(n) \twoheadrightarrow
\PU(n)\)</span>, and</p></li>
<li><p>given a representation of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>, we obtain a
representation of <span
class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span> by restriction,
i.e., by composing with the inclusion <span
class="math inline">\(\mathop{\mathrm{SU}}(n) \rightarrow
\mathop{\mathrm{U}}(n)\)</span>.</p></li>
</ul>
<div id="thm:SU-PU" class="theorem">
<p><strong>Theorem 45</strong>. <em>The operations of pullback and
restriction just described preserve irreducibility, inducing an
injective map <span class="math display">\[\mathop{\mathrm{Irr}}(\PU(n))
\hookrightarrow \mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\]</span>
and a surjective map <span
class="math display">\[\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))
\twoheadrightarrow
\mathop{\mathrm{Irr}}(\mathop{\mathrm{SU}}(n)).\]</span> The latter maps
and the bijection <span
class="math inline">\(\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))
\leftrightarrow \{\text{dominant elements of }\mathbb{Z}^n\}\)</span> as
in the Weyl character formula are compatible with bijections <span
class="math display">\[\mathop{\mathrm{Irr}}(\mathop{\mathrm{SU}}(n))
    \leftrightarrow \{\text{dominant elements of }\mathbb{Z}^n /
\mathbb{Z} e_0 \}, \quad e_0 := (1,\dotsc,1)\]</span> and <span
class="math display">\[\mathop{\mathrm{Irr}}(\PU(n)) \leftrightarrow
\{\text{dominant elements of }\mathbb{Z}^n_0 := \{\lambda \in
\mathbb{Z}^n : \sum_j \lambda_j = 0\} \}.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We leave most of this to the homework; here we just
record a few remarks that hopefully make the description of what happens
under restriction to <span
class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span> seem plausible.
Observe that if <span class="math inline">\(\lambda,\mu\)</span> are
dominant elements of <span class="math inline">\(\mathbb{Z}^n\)</span>
differing by a multiple of <span class="math inline">\(e_0\)</span>, say
<span class="math inline">\(\lambda = \mu + \ell e_0\)</span>, then the
corresponding irreducible representations <span
class="math inline">\(\pi_\lambda, \pi_\mu\)</span> of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> satisfy <span
class="math display">\[\pi_{\lambda} \cong \pi_{\mu} \otimes
{\det}^{\ell}.\]</span> Indeed, we may check this by comparing the
characters of these representations, and we have <span
class="math display">\[\chi_\lambda(t)
    = \frac{\det(t_i^{\lambda_j + n - j})}{\Delta(t)}
    =
    \underbrace{(t_1 \dotsb t_n)^{\ell}}_{\det(t)^{\ell}}
    \frac{\det(t_i^{\mu_j + n - j})}{\Delta(t)}.\]</span> It follows
that <span class="math inline">\(\pi_\lambda\)</span> and <span
class="math inline">\(\pi_\mu\)</span> have isomorphic restrictions to
<span class="math inline">\(\mathop{\mathrm{SU}}(n-1)\)</span>. ◻</p>
</span></div>
<h2 id="sec:case-su2">§3.8. The case of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></h2>
<div class="theorem">
<p><strong>Theorem 46</strong>. <em>We have bijections <span
class="math display">\[\mathop{\mathrm{Irr}}(\mathop{\mathrm{SU}}(2))
    \leftrightarrow
    \mathbb{Z}_{\geq 0}
    \leftrightarrow
    \{\text{dominant }
    \lambda = (\lambda_1,\lambda_2) \in
    \mathbb{Z}^2/\mathbb{Z}(1,1)\}\]</span> <span
class="math display">\[\pi_\lambda \leftrightarrow \lambda
\leftrightarrow (\text{the class of }(\lambda,0))\]</span> such that the
character <span class="math inline">\(\chi_\lambda\)</span> of <span
class="math inline">\(\pi_\lambda\)</span> is given by <span id="eq:char-formula-SU2" class="math display">\[\label{eq:char-formula-SU2}\tag{16}
    \chi_\lambda
\begin{pmatrix}
      t &amp;  \\
        &amp; t^{-1}
    \end{pmatrix}
    =
    \frac{\det
\begin{pmatrix}
      t^{\lambda+1} &amp; 1 \\
      t^{-\lambda-1} &amp; 1
    \end{pmatrix}
}{ t - t^{-1}} = t^{\lambda} + t^{\lambda-2} + t^{\lambda-4} + \dotsb +
t^{-\lambda}.\]</span> We have <span
class="math inline">\(\dim(\pi_\lambda) = \lambda + 1\)</span>. We have
<span class="math display">\[\pi_\lambda
  \cong {\mathop{\mathrm{Sym}}}^\lambda(\mathbb{C}^2)
  \cong
  {\mathop{\mathrm{Sym}}}^\lambda ((\mathbb{C}^2)^*),\]</span> where <span
class="math inline">\(\mathbb{C}^2\)</span> denotes as usual the
standard representation of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>. If we let <span
class="math inline">\(x,y \in (\mathbb{C}^2)^*\)</span> denote the
standard basis elements of the dual given in coordinates <span
class="math inline">\(z = (z_1,z_2)\)</span> by <span
class="math inline">\(x : z \mapsto z_1, y : z \mapsto z_2\)</span>,
then <span class="math inline">\(\pi_\lambda \cong
{\mathop{\mathrm{Sym}}}^\lambda((\mathbb{C}^2)^*)\)</span> identifies with
the space <span
class="math inline">\(\mathbb{C}[x,y]^{(\lambda)}\)</span> of
homogeneous polynomials <span class="math inline">\(f\)</span> of degree
<span class="math inline">\(\lambda\)</span> in the variables <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>, with the action of <span
class="math inline">\(g =
\begin{pmatrix}
  a &amp; b \\
  c &amp; d
\end{pmatrix}
\in \mathop{\mathrm{SU}}(2)\)</span> given by <span
class="math inline">\(g \cdot f(x,y) = f((x,y) g) = f(x a + y c, x b + y
d)\)</span>; a basis of weight vectors for <span class="math inline">\(T
= \left\{
\begin{pmatrix}
  t &amp;  \\
    &amp; t^{-1}
\end{pmatrix}
\right\} \leq \mathop{\mathrm{SU}}(2)\)</span> is given by <span
class="math display">\[x^{\lambda},
  x^{\lambda-1} y,
  x^{\lambda-2} y^2,
  \dotsc,
  y^{\lambda},\]</span> with corresopnding weights <span
class="math display">\[\begin{pmatrix}
    t &amp;  \\
      &amp; t^{-1}
  \end{pmatrix}
  \mapsto
  t^{\lambda}, t^{\lambda-2},
  t^{\lambda-4},
  \dotsc,
  t^{-\lambda}.\]</span> Finally, we have the Clebsch–Gordan rule: for
<span class="math inline">\(\lambda, \mu \in \mathbb{Z}_{\geq
0}\)</span>, <span id="eq:clebsch-gordan" class="math display">\[\label{eq:clebsch-gordan}\tag{19}
  \pi_{\lambda}
  \otimes \pi_{\mu}
  \cong \pi_{\lambda+\mu}
  \oplus
  \pi_{\lambda+\mu-2}
  \oplus
  \pi_{\lambda+\mu-4}
  \oplus
  \dotsb
  \oplus
  \pi_{|\lambda-\mu|}.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Almost every assertion follows immediately from
Theorem <a href="#thm:SU-PU" data-reference-type="ref"
data-reference="thm:SU-PU">45</a> and the description <a
href="#eq:wts-sym-k" data-reference-type="eqref"
data-reference="eq:wts-sym-k">\((7)\)</a> of the weights of
symmetric powers of the standard representation, together with the
analogous description of those of its dual. To verify the existence of
the isomorphism <a href="#eq:clebsch-gordan" data-reference-type="eqref"
data-reference="eq:clebsch-gordan">\((19)\)</a>, we just need
to check that <span class="math inline">\(\chi_\lambda \chi_\mu =
\chi_{\lambda+\mu} + \dotsb + \chi_{|\lambda-\mu|}\)</span>, which is
easy to derive from <a href="#eq:char-formula-SU2"
data-reference-type="eqref"
data-reference="eq:char-formula-SU2">\((16)\)</a>. ◻</p>
</span></div>
<h2 id="branching-problems">Branching problems</h2>
<p>Given compact groups <span class="math inline">\(H \leq G\)</span>
and a representation <span class="math inline">\((\pi,V)\)</span> of
<span class="math inline">\(G\)</span>, we may form the restricted
representation <span class="math inline">\(\pi|_{H} : H \rightarrow
\mathop{\mathrm{GL}}(V|_{H})\)</span> of <span
class="math inline">\(H\)</span>; here <span
class="math inline">\(V|_{H}\)</span> is just <span
class="math inline">\(V\)</span>, but regarded as a representation of
<span class="math inline">\(H\)</span>. The branching problem is to
describe this restriction in terms of <span
class="math inline">\(\pi\)</span>.</p>
<p>We assume henceforth that <span class="math inline">\(\pi\)</span> is
irreducible. Its restriction is then “typically” not irreducible, but
may in any event be decomposed as <span class="math display">\[V|_{H}
  \cong \oplus_{\sigma \in \mathop{\mathrm{Irr}}(H)}
  W_\sigma ^{\oplus n_\pi(\sigma)}\]</span> for some nonnegative
integers <span class="math inline">\(n_\pi(\sigma)\)</span>, called
“branching coefficients.” The problem is to describe these.</p>
<p>We start with some examples that are either basic or have already
been discussed implicitly.</p>
<ol>
<li><p>If <span class="math inline">\(H = G\)</span>, then <span
class="math inline">\(n_\pi(\sigma)\)</span> is <span
class="math inline">\(1\)</span> if <span class="math inline">\(\sigma
\cong \pi\)</span> and <span class="math inline">\(0\)</span>
otherwise.</p></li>
<li><p>If <span class="math inline">\(H = \{1\}\)</span> is the trivial
subgroup, then <span
class="math inline">\(\mathop{\mathrm{Irr}}(H)\)</span> is a singleton
consisting of the trivial representation <span
class="math inline">\(\sigma_{\text{trivial}}\)</span>, and we have
<span class="math inline">\(n_\pi(\sigma_{\text{trivial}}) =
\dim(\pi)\)</span>.</p></li>
<li><p>If <span class="math inline">\(G =
\mathop{\mathrm{U}}(n)\)</span> and <span class="math inline">\(H \cong
\mathop{\mathrm{U}}(1)^n\)</span> is the diagonal subgroup, then <span
class="math inline">\(\sigma\)</span> is the one-dimensional
representation <span class="math inline">\(\sigma = \sigma_\mu :=
e^{\mu} : t \mapsto t^{\mu} = t_1^{\mu_1} \dotsb t_n^{\mu_n}\)</span>
attached to some weight <span class="math inline">\(\mu \in
\mathbb{Z}^n\)</span>. The branching coefficient <span
class="math inline">\(n_\pi(\sigma)\)</span> is just the weight
multiplicity <span class="math inline">\(m_\pi(\mu)\)</span> considered
in §<a href="#sec:weight-decmop-U-n" data-reference-type="ref"
data-reference="sec:weight-decmop-U-n">3.3</a> and onwards. These
integers are typically <span class="math inline">\(&gt; 1\)</span> when
<span class="math inline">\(n \geq 3\)</span> (cf. homework).</p></li>
<li><p>If <span class="math inline">\(G =
\mathop{\mathrm{U}}(n)\)</span> and <span class="math inline">\(H =
\mathop{\mathrm{SU}}(n)\)</span>, then Theorem <a href="#thm:SU-PU"
data-reference-type="ref" data-reference="thm:SU-PU">45</a> implies that
for each <span class="math inline">\(\pi\)</span> there is exactly one
<span class="math inline">\(\sigma\)</span> (namely, the restriction of
<span class="math inline">\(\pi\)</span>) for which <span
class="math inline">\(n_{\pi}(\sigma)\)</span> is nonzero, and for that
<span class="math inline">\(\sigma\)</span>, we have <span
class="math inline">\(n_{\pi}(\sigma) = 1\)</span>.</p></li>
</ol>
<p>The overall theme here is that the larger the subgroup <span
class="math inline">\(H\)</span>, the more likely the representations of
<span class="math inline">\(G\)</span> are to have irreducible
restriction to <span class="math inline">\(H\)</span>, or at least to
have “mild” branching coefficients. This theme is supported further by
the example <span class="math display">\[H := \mathop{\mathrm{U}}(n-1)
  \hookrightarrow G := \mathop{\mathrm{U}}(n)\]</span> <span
class="math display">\[h \mapsto
\begin{pmatrix}
    h &amp; 0 \\
    0 &amp; 1
  \end{pmatrix}
,\]</span> which we now address. As a matter of notation, for dominant
elements <span class="math inline">\(\lambda \in \mathbb{Z}^n\)</span>
and <span class="math inline">\(\mu \in \mathbb{Z}^{n-1}\)</span>, let
us write <span class="math inline">\(\pi_\lambda \in
\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\)</span> and <span
class="math inline">\(\sigma_{\mu} \in
\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n-1))\)</span> for the
corresponding irreducibles, and <span
class="math inline">\(n_\lambda(\mu) :=
n_{\pi_\lambda}(\sigma_\mu)\)</span> for the branching coefficient. We
say that <span class="math inline">\(\mu\)</span> <em>interlaces</em>
<span class="math inline">\(\lambda\)</span>, denoted <span
class="math inline">\(\mu \prec \lambda\)</span>, if <span
class="math display">\[\lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2
  \geq \dotsb \geq \mu_{n-1} \geq \lambda_n.\]</span></p>
<div class="theorem">
<p><strong>Theorem 47</strong>. <em>We have <span
class="math inline">\(n_\lambda(\mu) = 0\)</span> unless <span
class="math inline">\(\mu \prec \lambda\)</span>, in which case <span
class="math inline">\(n_\lambda(\mu) = 1\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We must verify that <span id="eq:restrict-Un-Unmi1-reps" class="math display">\[\label{eq:restrict-Un-Unmi1-reps}\tag{20}
    \pi_{\lambda}|_{\mathop{\mathrm{U}}(n-1)}
    \cong
    \oplus_{\mu \prec \lambda}
    \sigma_{\mu}.\]</span> It suffices to check that the representations
of <span class="math inline">\(\mathop{\mathrm{U}}(n-1)\)</span>
appearing on both sides have the same character. It suffices to compare
their characters on the representatives <span class="math inline">\(t =
\mathop{\mathrm{diag}}(t_1,\dotsc,t_{n-1},1)\)</span> for the conjugacy
classes in <span class="math inline">\(\mathop{\mathrm{U}}(n-1) \leq
\mathop{\mathrm{U}}(n)\)</span>. We’ll undertake this comparison in
detail when <span class="math inline">\(n = 3\)</span>; the general case
is similar, but with many occurrences of <span
class="math inline">\((\dotsb)\)</span>. By the character formula, our
task is to show that <span class="math display">\[\frac{1}{(t_1 - t_2)
(t_1 - 1) (t_2 - 1)}
    \det
    \begin{pmatrix}
      t_1^{\lambda_1 + 2} &amp; t_1^{\lambda_2 + 1} &amp;
                                                  t_1^{\lambda_3} \\
      t_2^{\lambda_1 + 2} &amp; t_2^{\lambda_2 + 1} &amp;
                                                  t_2^{\lambda_3} \\
      1 &amp; 1 &amp; 1      
    \end{pmatrix}
    =
    \frac{1}{t_1 - t_2}
    \sum_{\mu \prec \lambda}
    \det
    \begin{pmatrix}
      t_1^{\mu_1 + 1} &amp; t_1^{\mu_2} \\
      t_2^{\mu_1 + 1} &amp; t_2^{\mu_2}
    \end{pmatrix}
    .\]</span> We simplify the <span class="math inline">\(3 \times
3\)</span> determinant using elementary column operations, replacing its
columns <span class="math inline">\(a,b,c\)</span> with <span
class="math inline">\(a-b, b-c, c\)</span>. That determinant then
simplifies to <span class="math display">\[% \det \begin{pmatrix}
t_1^{\lambda_1 + 2} &amp; t_1^{\lambda_2 + 1} &amp;
    %   t_1^{\lambda_3} \\
  %   t_2^{\lambda_1 + 2} &amp; t_2^{\lambda_2 + 1} &amp;
    %   t_2^{\lambda_3} \\
    %   1 &amp; 1 &amp; 1
    % \end{pmatrix}
    % =
    \det
\begin{pmatrix}
      t_1^{\lambda_1 + 2} - t_1^{\lambda_2 + 1}
      &amp; t_1^{\lambda_2 + 1} - t_1^{\lambda_3} &amp;
      t_1^{\lambda_3} \\
      t_2^{\lambda_1 + 2} -
      t_2^{\lambda_2 + 1} &amp;
      t_2^{\lambda_2 + 1} - t_2^{\lambda_3}  &amp;
      t_2^{\lambda_3} \\
      0 &amp; 0 &amp; 1      
    \end{pmatrix}
    =
    \det
\begin{pmatrix}
      t_1^{\lambda_1 + 2} - t_1^{\lambda_2 + 1}
      &amp; t_1^{\lambda_2 + 1} - t_1^{\lambda_3} \\
      t_2^{\lambda_1 + 2} -
      t_2^{\lambda_2 + 1} &amp; t_2^{\lambda_2
        + 1} - t_2^{\lambda_3}      \\
    \end{pmatrix}
.\]</span> Using that the determinant is linear in the rows, and
expanding out the definition of “<span class="math inline">\(\mu \prec
\lambda\)</span>,” our task reduces to checking that <span
class="math display">\[\det
    \begin{pmatrix}
      \frac{t_1^{\lambda_1 + 2} - t_1^{\lambda_2 + 1}}{t_1 - 1}
      &amp; \frac{t_1^{\lambda_2 + 1} - t_1^{\lambda_3}}{t_1-1} \\
      \frac{t_2^{\lambda_1 + 2} -
      t_2^{\lambda_2 + 1}}{t_2-1} &amp;
                                    \frac{t_2^{\lambda_2
                                    + 1} -
t_2^{\lambda_3}}{t_2-1}      \\
    \end{pmatrix}
    =
    \sum_{\lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3}
    \det
    \begin{pmatrix}
      t_1^{\mu_1 + 1} &amp; t_1^{\mu_2} \\
      t_2^{\mu_1 + 1} &amp; t_2^{\mu_2}
    \end{pmatrix}
    .\]</span> This identity follows from the linearity of the
determinant with respect to columns and geometric series identities such
as <span class="math inline">\(\frac{t_1^{\lambda_1 + 2} -
t_1^{\lambda_2 + 1}}{t_1 - 1} = \sum_{\lambda_1 \geq \mu_1 \geq
\lambda_2} t^{\mu_1 + 1}\)</span>. ◻</p>
</span></div>
<p>Groups <span class="math inline">\((G,H)\)</span> with the property
that every branching coefficient <span
class="math inline">\(n_\pi(\sigma)\)</span> belongs to <span
class="math inline">\(\{0,1\}\)</span> are called <em>strong Gelfand
pairs</em>; we may discuss them in more detail later.</p>
<h2 id="gelfandtsetlin-bases">Gelfand–Tsetlin bases</h2>
<p>We now describe briefly how to deduce from the formulas for the
branching coefficients for <span
class="math inline">\(\mathop{\mathrm{U}}(n-1) \leq
\mathop{\mathrm{U}}(n)\)</span> a canonical decomposition of any
irreducible representation of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. Let <span
class="math inline">\(\mu \in \mathbb{Z}^n\)</span> be dominant, and
<span class="math inline">\((\pi_\mu,V_\mu) \in
\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\)</span> the corresponding
representation. The decomposition <a href="#eq:restrict-Un-Unmi1-reps"
data-reference-type="eqref"
data-reference="eq:restrict-Un-Unmi1-reps">\((20)\)</a>
implies that for each dominant <span class="math inline">\(\nu \in
\mathbb{Z}^{n-1}\)</span> that interlaces <span
class="math inline">\(\mu\)</span>, there is a unique <span
class="math inline">\(\mathop{\mathrm{U}}(n-1)\)</span>-subrepresentation
<span class="math inline">\(V _{
\begin{pmatrix}
    \mu   \\
    \nu
  \end{pmatrix}
}\)</span> of <span class="math inline">\(V_{\mu}\)</span> of parameter
<span class="math inline">\(\nu\)</span>, and moreover <span id="eq:first-dcemop" class="math display">\[\label{eq:first-dcemop}\tag{21}
  V_\mu = \oplus_{\nu \prec \mu} V _{
\begin{pmatrix}
      \mu   \\
      \nu
    \end{pmatrix}
}.\]</span> The idea is now to iterate this decomposition using the
chain of subgroups <span class="math inline">\(\mathop{\mathrm{U}}(n-2),
\mathop{\mathrm{U}}(n-3), \dotsc\)</span>, all the way down to <span
class="math inline">\(\mathop{\mathrm{U}}(1)\)</span>, whose irreducible
representations are all one-dimensional. In preparation for this
iteration, we set <span class="math inline">\(\lambda^{(n)} :=
\mu\)</span> and denote by <span
class="math inline">\(\lambda^{(j)}\)</span> a dominant element of <span
class="math inline">\(\mathbb{Z}^{j}\)</span>. With this notation, <a
href="#eq:first-dcemop" data-reference-type="eqref"
data-reference="eq:first-dcemop">\((21)\)</a> now reads <span
class="math display">\[V_\mu |_{\mathop{\mathrm{U}}(n-1)}
  =
  \oplus_{\lambda^{(n-1)} \prec \lambda^{(n)} = \mu }
  V _{
    \begin{pmatrix}
      \lambda^{(n)}  \\
      \lambda^{(n-1)}
    \end{pmatrix}
  }.\]</span> We now apply the same reasoning to the restriction to
<span class="math inline">\(\mathop{\mathrm{U}}(n-2)\)</span> of each
representation <span class="math inline">\(V _{
\begin{pmatrix}
    \lambda^{(n)}  \\
    \lambda^{(n-1)}
  \end{pmatrix}
}\)</span> of <span
class="math inline">\(\mathop{\mathrm{U}}(n-1)\)</span> arising above,
giving <span class="math display">\[V_\mu |_{\mathop{\mathrm{U}}(n-2)}
  =
  \oplus_{\lambda^{(n-2)} \prec \lambda^{(n-1)} \prec \lambda^{(n)} =
\mu }
  V _{
    \begin{pmatrix}
      \lambda^{(n)}  \\
      \lambda^{(n-1)} \\
      \lambda^{(n-2)}
    \end{pmatrix}
  }.\]</span> Proceeding, we eventually obtain a canonical decomposition
of <span class="math inline">\(V_\mu\)</span> into one-dimensional
subspaces: <span class="math display">\[V_\mu
  =
  \oplus_{\lambda^{(1)} \prec
    \lambda^{(2)} \prec \dotsb \prec \lambda^{(n)} = \mu }
  V _{
    \begin{pmatrix}
      \lambda^{(n)}  \\
      \dotsb \\
      \lambda^{(1)}
    \end{pmatrix}
  }.\]</span> Let’s formalize things a bit:</p>
<div class="definition">
<p><strong>Definition 48</strong>. A <em>Gelfand–Tsetlin pattern of
order <span class="math inline">\(n \geq 1\)</span></em> is a column
vector <span class="math inline">\(\lambda =
\begin{pmatrix}
    \lambda^{(n)}  \\
    \dotsb   \\
    \lambda^{(1)}
  \end{pmatrix}\)</span>, with <span class="math inline">\(\lambda^{(j)}
\in \mathbb{Z}^j\)</span>, so that <span
class="math inline">\(\lambda^{(1)} \prec \dotsb \prec
\lambda^{(n)}\)</span>. For instance, if <span class="math inline">\(n =
3\)</span>, then we can visualize <span
class="math inline">\(\mathrm{GT}(n)\)</span> as the space of all
triangular arrays <span class="math display">\[\lambda =
    \begin{pmatrix}
      \lambda^{(3)}_1 &amp;  &amp; \lambda^{(3)}_2 &amp; &amp;
\lambda^{(3)}_3 \\
                      &amp; \lambda^{(2)}_1 &amp;  &amp; \lambda^{(2)}_2
&amp;  \\
                      &amp;  &amp; \lambda^{(1)}_1 &amp;  &amp;  \\
    \end{pmatrix}\]</span> satisfying the interlacing conditions <span
class="math display">\[\lambda^{(3)}_1 \leq \lambda^{(2)}_1 \leq
\lambda^{(3)}_2
    \leq \lambda^{(2)}_2
    \leq \lambda^{(3)}_3\]</span> and <span
class="math display">\[\lambda^{(2)}_1 \leq \lambda^{(1)}_1 \leq
\lambda^{(2)}_2.\]</span> We denote by <span
class="math inline">\(\mathrm{GT}(n)\)</span> the set of all
Gelfand–Tsetlin patterns <span class="math inline">\(\lambda\)</span> of
order <span class="math inline">\(n\)</span>, and by <span
class="math display">\[\mathrm{GT}(n)_{\mu} := \{\lambda \in
\mathrm{GT}(n) : \lambda^{(n)}
    = \mu \}\]</span> the subset of Gelfand–Tsetlin patterns having “top
row” equal to <span class="math inline">\(\mu\)</span>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 49</strong>. <em>For each dominant <span
class="math inline">\(\mu \in \mathbb{Z}^n\)</span> there is a unique
decomposition <span class="math display">\[V_\mu = \oplus_{\lambda \in
\mathrm{GT}(n)_\mu} V_\lambda\]</span> of <span
class="math inline">\(V_\mu \in
\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(n))\)</span> into
one-dimensional subspaces <span
class="math inline">\(V_\lambda\)</span>, indexed by <span
class="math inline">\(\lambda \in \mathrm{GT}(n)_\mu\)</span>, with the
property that for each <span class="math inline">\(j \in
\{1..n\}\)</span> and <span class="math inline">\(\nu \in
\mathbb{Z}^{(j)}\)</span>, the subspace <span
class="math display">\[\oplus_{\lambda \in \mathrm{GT}(n)_\mu :
\lambda^{(j)} = \nu} V_\lambda\]</span> of <span
class="math inline">\(V_\mu\)</span> is <span
class="math inline">\(\mathop{\mathrm{U}}(j)\)</span>-invariant and
isomorphic as a representation of <span
class="math inline">\(\mathop{\mathrm{U}}(j)\)</span> to a direct sum of
isomorphic copies of <span class="math inline">\(V_\nu \in
\mathop{\mathrm{Irr}}(\mathop{\mathrm{U}}(j))\)</span>; it is then the
maximal subspace with this property.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> More-or-less immediate from the above discussion; ask
me if anything seems unclear. ◻</p>
</span></div>
<p>This decomposition can be refined further by choosing basis elements
for the one-dimensional spaces <span
class="math inline">\(V_\lambda\)</span> and describing the
representation explicitly in terms of that basis, but we will not pursue
such refinements here.</p>
<h1
id="matrix-coefficients-for-compact-groups-and-the-peterweyl-theorem">Matrix
coefficients for compact groups and the Peter–Weyl theorem</h1>
<h2 id="spaces-of-matrix-coefficients">Spaces of matrix
coefficients</h2>
<p>Let <span class="math inline">\(G\)</span> be a compact group and
<span class="math inline">\((\pi,V)\)</span> a finite-dimensional
representation. So far, our main tool for saying anything interesting
about <span class="math inline">\(\pi\)</span> has been via its
character <span class="math inline">\(\chi_\pi : G \rightarrow
\mathbb{C}\)</span>, defined as the composition <span
class="math display">\[G \xrightarrow{\pi } \mathop{\mathrm{GL}}(V)
\hookrightarrow \mathop{\mathrm{End}}(V)
  \xrightarrow{\mathop{\mathrm{trace}}} \mathbb{C}.\]</span> To say
more, we replace the trace map by a general linear functional <span
class="math inline">\(\alpha \in \mathop{\mathrm{End}}(V)^*\)</span>. We
denote by <span class="math inline">\(\pi_\alpha : G \rightarrow
\mathbb{C}\)</span> the resulting composition <span
class="math display">\[G \xrightarrow{\pi } \mathop{\mathrm{GL}}(V)
  \hookrightarrow \mathop{\mathrm{End}}(V)
  \xrightarrow{\alpha } \mathbb{C}.\]</span></p>
<div class="definition">
<p><strong>Definition 50</strong>. A <em>matrix coefficient</em> of
<span class="math inline">\(\pi = (\pi,V)\)</span> is a function <span
class="math inline">\(G \rightarrow \mathbb{C}\)</span> of the form
<span class="math inline">\(\pi_\alpha\)</span> for some <span
class="math inline">\(\alpha \in \mathop{\mathrm{End}}(V)\)</span>. We
denote by <span class="math display">\[\mathcal{A}(\pi) := \{\pi_\alpha
: \alpha \in \mathop{\mathrm{End}}(V)^*\}\]</span> the space of matrix
coefficients of <span class="math inline">\(\pi\)</span>.</p>
</div>
<p>For example, if <span class="math inline">\(\alpha\)</span> is the
trace map, then <span class="math inline">\(\pi_\alpha =
\chi_\pi\)</span>, so the character <span class="math inline">\(\chi_\pi
\in \mathcal{A}(\pi)\)</span> is a matrix coefficient.<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<h2 id="uniqueness-of-invariant-inner-products">Uniqueness of invariant
inner products</h2>
<p>It will be convenient in discussing matrix coefficients to suppose
that our representations are unitary, so that we can work simply with
orthonormal bases for a given representation rather than bases and dual
bases for a representation and its dual. In making this assumption it’s
convenient to know the following:</p>
<div class="lemma">
<p><strong>Lemma 51</strong>. For <span class="math inline">\((\pi,V)
\in \mathop{\mathrm{Irr}}(G)\)</span>, any two invariant inner products
<span class="math inline">\(\langle , \rangle_1\)</span> and <span
class="math inline">\(\langle , \rangle_2\)</span> on <span
class="math inline">\(V\)</span> differ by a positive scalar: there
exists <span class="math inline">\(C &gt; 0\)</span> so that <span
class="math inline">\(\langle u,v \rangle_1 = C \langle u,v
\rangle_2\)</span> for all <span class="math inline">\(u,v \in
\pi\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We may identify inner products <span
class="math inline">\(\langle , \rangle\)</span> with certain linear
maps <span class="math display">\[V \rightarrow \overline{V}^*\]</span>
<span class="math display">\[v \mapsto \langle v, \cdot
\rangle.\]</span> The inner product is invariant if and only if the
linear map is equivariant, i.e., defines an element of the space <span
class="math inline">\({\mathop{\mathrm{Hom}}}_G(\pi, \overline{\pi
}^*)\)</span>. But Schur’s lemma implies that the latter space is
one-dimensional. Hence any two invariant inner products differ by a
scalar. Positive-definiteness forces the scalar to be positive. ◻</p>
</span></div>
<h2
id="matrix-entries-as-a-basis-for-the-space-of-matrix-coefficients">Matrix
entries as a basis for the space of matrix coefficients</h2>
<p>We suppose henceforth that <span class="math inline">\(\pi\)</span>
is unitary, and fix an orthonormal basis <span
class="math inline">\(\{e_i\}_{i=1}^{\dim(\pi)}\)</span> for <span
class="math inline">\(V\)</span>. Each <span class="math inline">\(T \in
\mathop{\mathrm{End}}(V)\)</span> then defines a matrix with entries
<span class="math inline">\(T_{i j} = \langle T e_j, e_i
\rangle\)</span>. Write <span class="math inline">\(\varepsilon_{i j}
\in \mathop{\mathrm{End}}(V)^*\)</span> for the map <span
class="math inline">\(\mathop{\mathrm{End}}(V) \rightarrow
\mathbb{C}\)</span> assigning to an operator <span
class="math inline">\(T\)</span> the matrix entry <span
class="math inline">\(T_{i j}\)</span>. Then the <span
class="math inline">\(\varepsilon_{i j}\)</span> give a basis for <span
class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span>, and so the
functions <span class="math inline">\(\pi_{i j} := \pi_{\varepsilon_{i
j}}\)</span> span the space <span
class="math inline">\(\mathcal{A}(\pi)\)</span> of matrix coefficients
of <span class="math inline">\(\pi\)</span>. (They need not in general
be linearly independent: consider for instance a direct sum of copies of
the trivial representation, for which <span class="math inline">\(\pi_{i
i}(g) = 1\)</span> for all <span class="math inline">\(i\)</span> and
<span class="math inline">\(g\)</span>.) The numbers <span
class="math inline">\(\pi_{i j}(g)\)</span> are the matrix entries of
<span class="math inline">\(\pi(g)\)</span>. We may write the map <span
class="math inline">\(\mathop{\mathrm{trace}}: \mathop{\mathrm{End}}(V)
\rightarrow \mathbb{C}\)</span> as the sum of diagonal matrix entries
<span class="math inline">\(\sum_i \varepsilon_{i i}\)</span>, so that
<span class="math inline">\(\chi_\pi = \sum_i \pi_{i i}\)</span>.</p>
<h2 id="special-functions-as-matrix-coefficients">Special functions as
matrix coefficients</h2>
<p>“Most” interesting special functions in mathematics and mathematical
physics (Bessel, Whittaker, Legendre, Laguerre, <span
class="math inline">\(\dotsc\)</span>) arise as matrix coefficients of
representations, and may be profitably studied from this perspective.
For instance, <span class="math inline">\(G = \mathbb{R}/2 \pi
\mathbb{Z}\)</span> has a representation <span
class="math inline">\(\pi\)</span> on <span class="math inline">\(V =
\mathbb{C}^2\)</span> given by the rotations <span
class="math display">\[\pi(\theta) =
\begin{pmatrix}
    \cos \theta  &amp;  \sin \theta  \\
    - \sin \theta &amp; \cos \theta
  \end{pmatrix}
  =
\begin{pmatrix}
    \pi_{11}(\theta) &amp; \pi_{1 2}(\theta) \\
    \pi_{21}(\theta) &amp; \pi_{22}(\theta)
  \end{pmatrix}
,\]</span> whose matrix coefficients are thus the trigonometric
functions. Their addition law is obtained by writing the homomorphism
property <span class="math inline">\(\pi(\theta_1 + \theta_2) =
\pi(\theta_1) \pi(\theta_2)\)</span> as <span
class="math inline">\(\pi_{i j}(\theta_1 + \theta_2) = \sum_k \pi_{i
k}(\theta_1) \pi_{k j}(\theta_2)\)</span>, i.e., <span
class="math display">\[\begin{pmatrix}
    \cos (\theta_1 + \theta_2)  &amp;  \sin (\theta_1 + \theta_2)  \\
    - \sin (\theta_1 + \theta_2) &amp; \cos (\theta_1 + \theta_2)
  \end{pmatrix}
  =
  \begin{pmatrix}
    \cos \theta_1  &amp;  \sin \theta_1  \\
    - \sin \theta_1 &amp; \cos \theta_1
  \end{pmatrix}
  \begin{pmatrix}
    \cos \theta_2  &amp;  \sin \theta_2  \\
    - \sin \theta_2 &amp; \cos \theta_2
  \end{pmatrix}
  ,\]</span> giving a convenient way to remember the formulas <span
class="math inline">\(\cos (\theta_1 + \theta_2) = \cos(\theta_1)
\cos(\theta_2) - \sin(\theta_1) \sin(\theta_2)\)</span> and <span
class="math inline">\(\sin (\theta_1 + \theta_2) = \cos(\theta_1)
\sin(\theta_2) + \sin(\theta_1) \cos(\theta_2)\)</span>. See the book by
Vilenkin for many more examples like this.</p>
<h2 id="some-actions-of-g-times-g">Some actions of <span
class="math inline">\(G \times G\)</span></h2>
<p>Anyway, the association <span class="math inline">\(\alpha \mapsto
\pi_\alpha\)</span> defines a map <span id="eq:map-End-V-star-to-A-pi" class="math display">\[\label{eq:map-End-V-star-to-A-pi}\tag{24}
  \mathop{\mathrm{End}}(V)^* \rightarrow \mathcal{A}(\pi).\]</span> The
spaces involved in this map are naturally representations of the product
group <span class="math inline">\(G \times G\)</span>: For <span
class="math inline">\((g_1,g_2) \in G \times G\)</span> and <span
class="math inline">\(\alpha \in \mathop{\mathrm{End}}(V)^*\)</span>, we
denote by <span class="math inline">\((g_1,g_2) \cdot \alpha\)</span>
the functional <span class="math display">\[\mathop{\mathrm{End}}(V)
\rightarrow \mathbb{C}\]</span> <span class="math display">\[T \mapsto
\alpha(\pi(g_1)^{-1} T \pi(g_2))\]</span> Another way to arrive at the
same definition is via the external tensor product <span
class="math inline">\(V_1 \boxtimes V_2\)</span> of representations
<span class="math inline">\(V_1\)</span> of <span
class="math inline">\(G_1\)</span> and <span
class="math inline">\(V_2\)</span> of <span
class="math inline">\(G_2\)</span> as in the homework. This is the
representation on the tensor product space given by <span
class="math inline">\((g_1,g_2) \cdot (v_1 \otimes v_2) = g_1 v_1
\otimes g_2 v_2\)</span>. We have equivariant identifications <span id="eq:identify-End-V-star" class="math display">\[\label{eq:identify-End-V-star}\tag{25}
  \mathop{\mathrm{End}}(V)^*
  \cong
  (V^* \boxtimes V)^*
  \cong
  V^* \boxtimes V.\]</span> For any function <span
class="math inline">\(f : G \rightarrow \mathbb{C}\)</span>, we write
<span class="math inline">\((g_1,g_2) \cdot f\)</span> for the function
<span class="math display">\[G \rightarrow \mathbb{C}\]</span> <span
class="math display">\[x \mapsto f(g_1^{-1} x g_2).\]</span> This
definition applies to <span class="math inline">\(f \in
\mathcal{A}(\pi)\)</span>, and the space <span
class="math inline">\(\mathcal{A}(\pi)\)</span> is <span
class="math inline">\(G \times G\)</span>-invariant. The map <a
href="#eq:map-End-V-star-to-A-pi" data-reference-type="eqref"
data-reference="eq:map-End-V-star-to-A-pi">\((24)\)</a>
is equivariant for these actions of <span class="math inline">\(G \times
G\)</span>.</p>
<p>We denote by <span class="math inline">\(\Delta G\)</span> the
diagonal subgroup <span class="math inline">\(\{(g,g) : g \in
G\}\)</span> of <span class="math inline">\(G \times G\)</span>. Then
the fixed subspace <span class="math inline">\(L^2(G)^{\Delta
G}\)</span> is the space of class functions <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span>.</p>
<h2 id="burnsides-lemma">Burnside’s lemma</h2>
<p>The spaces of matrix coefficients are particularly well-behaved in
the case of an irreducible representation:</p>
<div id="lem:schur-for-inner-products" class="lemma">
<p><strong>Lemma 52</strong>. Let <span class="math inline">\((\pi,V)
\in \mathop{\mathrm{Irr}}(G)\)</span>. Then</p>
<ol type="i">
<li><p><span class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span>
and <span class="math inline">\(\mathcal{A}(\pi)\)</span> define
irreducible representations of <span class="math inline">\(G \times
G\)</span>, and the map <span
class="math inline">\(\mathop{\mathrm{End}}(V)^* \rightarrow
\mathcal{A}(\pi)\)</span> is an isomorphism.</p></li>
<li><p>The <span class="math inline">\(\Delta G\)</span>-fixed subspace
<span class="math inline">\((\mathop{\mathrm{End}}(V)^*)^{\Delta
G}\)</span> is the one-dimensional space <span
class="math inline">\(\mathbb{C} \mathop{\mathrm{trace}}\)</span> of
multiples of <span class="math inline">\(\mathop{\mathrm{trace}}:
\mathop{\mathrm{End}}(V) \rightarrow \mathbb{C}\)</span>, whereas <span
class="math inline">\(\mathcal{A}(\pi)^{\Delta G}\)</span> is the
one-dimensional space <span class="math inline">\(\mathbb{C}
\chi_\pi\)</span> of multiples of the character of <span
class="math inline">\(\pi\)</span>.</p></li>
<li><p>(Burnside’s lemma) The matrix entries <span
class="math inline">\(\pi_{i j}\)</span> define linearly independent
functions on <span class="math inline">\(G\)</span>. The set <span
class="math inline">\(\{\pi(g) : g \in G\}\)</span> spans <span
class="math inline">\(\mathop{\mathrm{End}}(V)\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>From the homework, we know that if <span
class="math inline">\(V_1\)</span> and <span
class="math inline">\(V_2\)</span> are irreducible representations of
the (compact) groups <span class="math inline">\(G_1\)</span> and <span
class="math inline">\(G_2\)</span>, then <span class="math inline">\(V_1
\boxtimes V_2\)</span> is an irreducible representation of <span
class="math inline">\(G_1 \times G_2\)</span>. From this and <a
href="#eq:identify-End-V-star" data-reference-type="eqref"
data-reference="eq:identify-End-V-star">\((25)\)</a> we
deduce that <span
class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span> is <span
class="math inline">\(G \times G\)</span>-irreducible. The map <span
class="math inline">\(\mathop{\mathrm{End}}(V)^* \rightarrow
\mathcal{A}(\pi)\)</span> is equivariant, surjective (by definition) and
nonzero (since its image contains <span
class="math inline">\(\chi_\pi\)</span>), hence its kernel <span
class="math inline">\(W\)</span> is a proper invariant subspace of <span
class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span>, but since
<span class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span> is
irreducible, we must have <span class="math inline">\(W =
\{0\}\)</span>. Therefore the map in question is an isomorphism; in
particular, <span class="math inline">\(\mathcal{A}(\pi)\)</span> is
irreducible.</p></li>
<li><p>It’s clear that <span
class="math inline">\(\mathop{\mathrm{trace}}\)</span> and <span
class="math inline">\(\chi_\pi\)</span> define nonzero elements of <span
class="math inline">\(\mathop{\mathrm{End}}(V^*)^{\Delta G}\)</span> and
<span class="math inline">\(\mathcal{A}(\pi)^{\Delta G}\)</span>, so we
just need to check that the latter two spaces are at most
one-dimensional. Part (i) implies that they are isomorphic, so we may
conclude via the identification <span
class="math inline">\(\mathop{\mathrm{End}}(V)^* \cong
\mathop{\mathrm{End}}(V^*)\)</span> and Schur’s lemma in the form <span
class="math inline">\(\dim {\mathop{\mathrm{End}}}_G(V^*) \leq
1\)</span>.</p></li>
<li><p>The <span class="math inline">\(\pi_{i j}\)</span> are the images
of the basis elements <span class="math inline">\(\varepsilon_{i
j}\)</span> under the isomorphism <span
class="math inline">\(\mathop{\mathrm{End}}(V)^* \rightarrow
\mathcal{A}(\pi)\)</span>, so they are linearly independent. For the
second assertion, let <span class="math inline">\(W \leq
\mathop{\mathrm{End}}(V)\)</span> denote the span of <span
class="math inline">\(\{\pi(g) : g \in G\}\)</span>. If <span
class="math inline">\(W \neq \mathop{\mathrm{End}}(V)\)</span>, then we
can find a nonzero <span class="math inline">\(\alpha \in
\mathop{\mathrm{End}}(V)^*\)</span> vanishing on <span
class="math inline">\(W\)</span>. Then <span
class="math inline">\(\pi_\alpha(g) = \alpha(\pi(g)) \in \alpha(W) =
\{0\}\)</span> for all <span class="math inline">\(g \in G\)</span>, so
<span class="math inline">\(\pi_\alpha = 0\)</span>, contrary to
(i).</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="sec:schur-orthogonality">§4.7. Schur orthogonality</h2>
<div class="definition">
<p><strong>Definition 53</strong>. The space <span
class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span> comes with a
natural <span class="math inline">\(G \times G\)</span>-invariant inner
product (“dual of the Hilbert–Schmidt inner product”) given explicitly
in coordinates by requiring that the <span
class="math inline">\(\varepsilon_{i j}\)</span> be an orthonormal
basis, i.e., <span class="math display">\[\langle
    \sum a_{i j} \varepsilon_{i j},
    \sum b_{i j} \varepsilon_{i j}
    \rangle
    = \sum a_{i j} \overline{b_{i j}}\]</span> and more invariantly as
the composition <span class="math display">\[\mathop{\mathrm{End}}(V)^*
\otimes \overline{\mathop{\mathrm{End}}(V)^*}
    \cong V \otimes V^* \otimes \overline{V} \otimes
    \overline{V}^*
    \rightarrow \mathbb{C}\]</span> where the second arrow sends <span
class="math inline">\(v_1 \otimes v_2 \otimes \overline{v_3} \otimes
\overline{v_4}\)</span> to <span class="math inline">\(\langle v_1, v_3
\rangle_V \langle v_2, v_4 \rangle_{V^*}\)</span>, where <span
class="math inline">\(V^*\)</span> is equipped with the inner product
obtained from that on <span class="math inline">\(V\)</span> via the
duality isomorphism <span class="math inline">\(V \ni \mapsto \langle v,
\cdot \rangle \in \overline{V}^*\)</span> induced by the given inner
product on <span class="math inline">\(V\)</span>.</p>
</div>
<p>Another inner product on <span
class="math inline">\(\mathop{\mathrm{End}}(V)^*\)</span> is obtained
from that on <span class="math inline">\(L^2(G)\)</span> by taking
matrix coefficients. It’s natural to ask how the two inner products
compare:</p>
<div class="theorem">
<p><strong>Theorem 54</strong> (Schur orthogonality relations). <em>Let
<span class="math inline">\((\pi,V), (\pi &#39;,V&#39;) \in
\mathop{\mathrm{Irr}}(G)\)</span>, with <span
class="math inline">\(G\)</span> compact as usual. Then for <span
class="math inline">\(\alpha \in \mathop{\mathrm{End}}(V)^*\)</span> and
<span class="math inline">\(\beta \in
\mathop{\mathrm{End}}(V&#39;)^*\)</span>, <span
class="math display">\[\langle
    \pi_{\alpha}, \pi_{\beta }&#39;
    \rangle
    =
    \begin{cases}
      0 &amp;  \text{ if } \pi \not\cong \pi &#39;, \\
      \frac{1}{\dim(\pi)} \langle \alpha, \beta  \rangle
        &amp; \text{ if } (\pi,V) = (\pi &#39;, V&#39;),
    \end{cases}\]</span> where the inner product on the left is in <span
class="math inline">\(L^2(G)\)</span> with respect to the probability
Haar, while <span class="math inline">\(\langle \alpha, \beta
\rangle\)</span> denotes the dual Hilbert–Schmidt inner product defined
above. Explicitly, <span class="math display">\[\langle \pi_{i j},
\pi_{k \ell}&#39; \rangle
    = \frac{1}{\dim(\pi)}
    \delta_{\pi, \pi&#39;}
    \delta_{i, k} \delta_{j, \ell}.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The proof is basically as in Lemma <a
href="#lem:schur-for-inner-products" data-reference-type="ref"
data-reference="lem:schur-for-inner-products">52</a>. If <span
class="math inline">\(\pi\)</span> is not <span
class="math inline">\(G\)</span>-isomorphic to <span
class="math inline">\(\pi &#39;\)</span>, then <span
class="math inline">\(\mathop{\mathrm{End}}(\pi)^*\)</span> is likewise
not <span class="math inline">\(G \times G\)</span>-isomorphic to <span
class="math inline">\(\mathop{\mathrm{End}}(\pi &#39;)^*\)</span> (as
may be checked for instance by verifying that their characters are
orthogonal, as on the homework), but the map <span
class="math display">\[\mathop{\mathrm{End}}(V)^* \rightarrow
\overline{\mathop{\mathrm{End}}(V&#39;)^*}^* \cong
\mathop{\mathrm{End}}(V&#39;)^*\]</span> <span
class="math display">\[\alpha \mapsto [\beta \mapsto \langle \pi_\alpha,
\pi_\beta \rangle]\]</span> is <span class="math inline">\(G \times
G\)</span>-equivariant, so Schur’s lemma implies that it vanishes
identically. In the case <span class="math inline">\((\pi, V) = (\pi
&#39;, V&#39;)\)</span>, we use Lemma <a
href="#lem:schur-for-inner-products" data-reference-type="ref"
data-reference="lem:schur-for-inner-products">52</a> (a basic
consequence of Schur’s lemma) to write <span
class="math display">\[\langle \pi_\alpha, \pi _\beta \rangle = C
\langle \alpha, \beta \rangle\]</span> for some <span
class="math inline">\(C &gt; 0\)</span>, which may depend upon <span
class="math inline">\(\pi\)</span>, but not upon <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>. To compute <span
class="math inline">\(C\)</span>, we take <span
class="math display">\[\alpha = \beta =
\mathop{\mathrm{trace}},\]</span> so that <span
class="math display">\[\pi_\alpha = \pi_\beta = \chi_\pi,\]</span> and
note that <span class="math display">\[\langle \mathop{\mathrm{trace}},
\mathop{\mathrm{trace}}\rangle = \langle \sum \varepsilon_{i i}, \sum
\varepsilon_{i i} \rangle = \dim(\pi)\]</span> and recall that <span
class="math inline">\(\langle \chi_\pi, \chi_\pi \rangle =
1\)</span>. ◻</p>
</span></div>
<h2 id="the-coefficient-ring-of-a-compact-group">The coefficient ring of
a compact group</h2>
<p>Having now studied in detail the matrix coefficients of irreducibles,
we piece them together as follows.</p>
<div class="definition">
<p><strong>Definition 55</strong>. Let <span
class="math inline">\(G\)</span> be, as usual, a compact group. The
<em>coefficient ring</em> of <span class="math inline">\(G\)</span> is
defined to be the set <span class="math display">\[\mathcal{A}(G) :=
\cup _{(\pi,V) \text{ finite-dimensional}} \mathcal{A}(\pi) \subseteq
L^2(G).\]</span></p>
</div>
<p>The terminology is justified by:</p>
<div id="thm:coeff-ring-characterizations" class="theorem">
<p><strong>Theorem 56</strong>. <em></em></p>
<ol type="i">
<li><p><em><span class="math inline">\(\mathcal{A}(G)\)</span> is a
<span class="math inline">\(\mathbb{C}\)</span>-algebra, closed under
complex conjugation, and <span class="math inline">\(G \times
G\)</span>-invariant.</em></p></li>
<li><p><em><span class="math inline">\(\mathcal{A}(G)\)</span> is the
orthogonal direct sum in <span class="math inline">\(L^2(G)\)</span> of
the subspaces <span class="math inline">\(\mathcal{A}(\pi)\)</span> for
<span class="math inline">\(\pi \in \mathop{\mathrm{Irr}}(G)\)</span>.
The functions <span id="eqn:ONB-via-matrix-coefs" class="math display">\[\label{eqn:ONB-via-matrix-coefs}\tag{28}
      \sqrt{\dim(\pi)} \pi_{i j} : G \rightarrow \mathbb{C},\]</span>
for <span class="math inline">\(\pi\)</span> running over <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span> and <span
class="math inline">\(i,j = 1..\dim(\pi)\)</span>, form an orthonormal
basis of <span class="math inline">\(\mathcal{A}(G)\)</span>. Similarly,
<span class="math inline">\(\mathcal{A}(G)^{\Delta G}\)</span> is the
orthogonal direct sum in <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span> of the
subspaces <span class="math inline">\(\mathbb{C} \chi_\pi\)</span>. In
particular, <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span> is at most
countably infinite.</em></p></li>
<li><p><em>For any <span class="math inline">\(f \in L^2(G)\)</span>,
the following are equivalent:</em></p>
<ol type="a">
<li><p><em><span class="math inline">\(f \in
\mathcal{A}(G)\)</span></em></p></li>
<li><p><em><span class="math inline">\(f\)</span> is
<em>right-finite</em>: <span class="math inline">\(\dim
\mathop{\mathrm{span}}\{f(\cdot g) : g \in G\} &lt;
\infty\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(f\)</span> is
<em>left-finite</em>: <span class="math inline">\(\dim
\mathop{\mathrm{span}}\{f(g^{-1} \cdot ) : g \in G\} &lt;
\infty\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(f\)</span> is <em>bi-finite</em>,
or simply <em>finite</em>: <span class="math inline">\(\dim
\mathop{\mathrm{span}}\{f(g_1^{-1} \cdot g_2 ) : g_1, g_2 \in G\} &lt;
\infty\)</span>.</em></p></li>
</ol></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>The proof is similar to what we did for characters (Lemma <a
href="#lem:characters-basic" data-reference-type="ref"
data-reference="lem:characters-basic">24</a>): The conjugate of a matrix
coefficient is a matrix coefficient for the conjugate representation,
namely, for <span class="math inline">\(\alpha \in
\mathop{\mathrm{End}}(\pi)^*\)</span>, we have <span
class="math inline">\(\overline{\pi _\alpha } = \overline{\pi
}_{\overline{\alpha}}\)</span> with <span
class="math inline">\(\overline{\alpha } \in
\overline{\mathop{\mathrm{End}}(\pi)^*} \cong
\mathop{\mathrm{End}}(\overline{\pi })^*\)</span>, so <span
class="math inline">\(\mathcal{A}(G)\)</span> is closed under complex
conjugation. Similarly, the sum (resp. product) of two matrix
coefficients is a matrix coefficient for the direct sum (resp. product)
of the corresponding representations, i.e., <span
class="math inline">\(\pi_{\alpha} + \pi_{\beta &#39;} = (\pi \oplus \pi
&#39;)_{\alpha \oplus \beta}\)</span> and <span
class="math inline">\(\pi_{\alpha} \pi_{\beta &#39;} = (\pi \otimes \pi
&#39;)_{\alpha \otimes \beta}\)</span> where <span
class="math inline">\(\alpha \oplus \beta \in
\mathop{\mathrm{End}}(\pi)^* \oplus \mathop{\mathrm{End}}(\pi &#39;)^*
\hookrightarrow \mathop{\mathrm{End}}(\pi \oplus \pi &#39;)^*\)</span>
and <span class="math inline">\(\alpha \otimes \beta \in
\mathop{\mathrm{End}}(\pi)^* \otimes \mathop{\mathrm{End}}(\pi &#39;)^*
\hookrightarrow \mathop{\mathrm{End}}(\pi \otimes \pi
&#39;)^*\)</span>.</p></li>
<li><p>We have seen that finite-dimensional <span
class="math inline">\((\pi,V)\)</span> may be assumed unitary and then
decomposed as orthogonal direct sums <span class="math inline">\(W_1
\oplus \dotsb \oplus W_m\)</span> of irreducibles <span
class="math inline">\(\sigma_1,\dotsc,\sigma_m\)</span>. For each <span
class="math inline">\(k = 1..m\)</span>, fix an orthonormal basis <span
class="math inline">\(\{e_i^{(k)}\}_i\)</span> for <span
class="math inline">\(W_k\)</span>. Then <span
class="math inline">\(\mathcal{A}(\pi)\)</span> is spanned by the
functions <span class="math display">\[G \ni g \mapsto \langle
e_i^{(k)}, g e_j^{(\ell)} \rangle.\]</span> We have <span
class="math inline">\(g e_j^{(\ell)} \in W_{\ell}\)</span>, which is
orthogonal to <span class="math inline">\(e_i^{(k)}\)</span> unless
<span class="math inline">\(k = \ell\)</span>, in which case the above
function belongs to <span
class="math inline">\(\mathcal{A}(\sigma_k)\)</span>. Thus <span
class="math inline">\(\mathcal{A}(\pi) = \mathcal{A}(\sigma_1) + \dotsb
+ \mathcal{A}(\sigma_k)\)</span>. Taking unions, we obtain <span
class="math inline">\(\mathcal{A}(G) = \sum_{\pi \in
\mathop{\mathrm{Irr}}(G)} \mathcal{A}(\pi)\)</span>. The required
orthogonality follows from the Schur orthogonality relations.</p></li>
<li><p>If <span class="math inline">\(f \in \mathcal{A}(G)\)</span>,
then <span class="math inline">\(f \in \mathcal{A}(\pi)\)</span> for
some finite-dimensional <span class="math inline">\(\pi\)</span>, so the
<span class="math inline">\(G \times G\)</span>-span of <span
class="math inline">\(f\)</span> is contained in the space <span
class="math inline">\(\mathcal{A}(\pi)\)</span> whose dimension is
finite (e.g., bounded by <span
class="math inline">\(\dim(\pi)^2\)</span>). To complete the proof it
suffices to verify that if a function <span
class="math inline">\(f\)</span> is right- or left-finite, then it
belongs to <span class="math inline">\(\mathcal{A}(G)\)</span>. We treat
the case that <span class="math inline">\(f\)</span> is right-finite,
the other case being similar. Let <span class="math inline">\(V\)</span>
denote the span of the right translates <span
class="math inline">\(f(\cdot g)\)</span> of <span
class="math inline">\(f\)</span>, so that <span
class="math inline">\(\dim(V) &lt; \infty\)</span> by assumption. Take
for <span class="math inline">\(\pi\)</span> the representation of <span
class="math inline">\(G\)</span> on <span
class="math inline">\(V\)</span> given by right translation. (Note
<span><strong>as I did not in lecture</strong></span> that this is
actually a representation: <span class="math inline">\(V\)</span> is a
finite-dimensional subspace of <span
class="math inline">\(L^2(G)\)</span>, hence is closed, and so the
continuity of the action of <span class="math inline">\(G\)</span> on
<span class="math inline">\(V\)</span> follows from that of <span
class="math inline">\(G\)</span> on <span
class="math inline">\(L^2(G)\)</span>.)</p>
<p>We attempt now to define the “act on <span
class="math inline">\(f\)</span>, then evaluate at identity” functional
<span class="math inline">\(\alpha \in
\mathop{\mathrm{End}}(V)^*\)</span> by the formula <span id="eq:evaluate-at-identity-functional" class="math display">\[\label{eq:evaluate-at-identity-functional}\tag{29}
      \alpha(T) := (T f) (e),\]</span> with <span
class="math inline">\(e \in G\)</span> denoting the identity element.
(Note <span><strong>as I did not in lecture</strong></span> that this
definition does not obviously make sense, because <span
class="math inline">\(f\)</span> is merely an “<span
class="math inline">\(L^2\)</span>-function,” and so is not obviously
defined pointwise except off some unspecified set of measure zero.
However, as we will verify below (non-circularly) in §<a
href="#sec:autom-cont-finite" data-reference-type="ref"
data-reference="sec:autom-cont-finite">5.4.1</a>, our assumptions imply
that every element of <span class="math inline">\(V\)</span> is actually
represented by a <em>continuous</em> function, to which the definition
applies.) Then <span class="math inline">\(\pi_\alpha(g) = (\pi(g) f)(e)
= f(e g) = f(g)\)</span>, so <span class="math inline">\(f = \pi_\alpha
\in \mathcal{A}(\pi) \subseteq \mathcal{A}(G)\)</span>, as
required.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="sec:peter-weyl-theorem">§4.9. Peter–Weyl theorem: statement and proof
sketch</h2>
<p>We can now state the more complete form of Theorem <a
href="#thm:peter-weyl-for-chars" data-reference-type="ref"
data-reference="thm:peter-weyl-for-chars">27</a>:</p>
<div id="thm:P-W-general" class="theorem">
<p><strong>Theorem 57</strong> (Peter–Weyl theorem). <em>Let <span
class="math inline">\(G\)</span> be a compact group.</em></p>
<ol type="i">
<li><p><em><span class="math inline">\(\mathcal{A}(G)\)</span> is dense
in the space <span class="math inline">\(C(G)\)</span> of continuous
functions on <span class="math inline">\(G\)</span> equipped with the
topology defined by the supremum norm.</em></p></li>
<li><p><em><span class="math inline">\(\mathcal{A}(G)\)</span> is dense
in <span class="math inline">\(L^2(G)\)</span>, hence <span
class="math inline">\(L^2(G) = \hat{\oplus}_{\pi \in
\mathop{\mathrm{Irr}}(G)} \mathcal{A}(\pi)\)</span>; here <span
class="math inline">\(\hat{\oplus}\)</span> denotes the “Hilbert direct
sum,” i.e., the closure of the “ordinary” or “algebraic” direct sum
<span class="math inline">\(\oplus\)</span>. Thus the functions <a
href="#eqn:ONB-via-matrix-coefs" data-reference-type="eqref"
data-reference="eqn:ONB-via-matrix-coefs">\((28)\)</a>
give an orthonormal basis (in the sense of Hilbert space) for <span
class="math inline">\(L^2(G)\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(\mathcal{A}(G)^{\Delta G} =
\oplus_{\pi \in \mathop{\mathrm{Irr}}(G)} \mathbb{C} \chi_\pi\)</span>
is dense in <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span> (thus
<span class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}} =
\hat{\oplus}_{\pi \in \mathop{\mathrm{Irr}}(G)} \mathbb{C}
\chi_\pi\)</span>) and also dense in <span
class="math inline">\(C(G)^{\mathop{\mathrm{class}}}\)</span>.</em></p></li>
<li><p><em>If <span class="math inline">\((\pi,V)\)</span> is any
irreducible representation of <span class="math inline">\(G\)</span> on
any space <span class="math inline">\(V\)</span> such that “one has a
reasonable theory of <span class="math inline">\(V\)</span>-valued
integrals” (e.g., Hilbert, Banach, Frechet, or “locally convex
quasi-complete”), then <span class="math inline">\(\dim(V) &lt;
\infty\)</span>.</em></p></li>
</ol>
</div>
<p>The main assertion here is that <span
class="math inline">\(\mathcal{A}(G)\)</span> is dense in <span
class="math inline">\(L^2(G)\)</span>; we will deduce the remaining
assertions either from this one or via easy modifications of its proof.
As “warm-up,” we observe some easy special cases:</p>
<ul>
<li><p>If <span class="math inline">\(G\)</span> is a finite group, then
both <span class="math inline">\(\mathcal{A}(G)\)</span> and <span
class="math inline">\(L^2(G)\)</span> consist of all functions <span
class="math inline">\(G \rightarrow \mathbb{C}\)</span>, so there is
nothing to show.</p></li>
<li><p>A <em>profinite group</em> <span class="math inline">\(G\)</span>
is a compact group which admits an open basis <span
class="math inline">\(\mathcal{U}\)</span> at the identity element
consisting of compact open normal subgroups <span
class="math inline">\(U\)</span>. (This might not be the standard
definition, but is equivalent to it, and suits the purposes of our
discussion.) For instance, the group <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{Z}_p)\)</span>, which may be identified
with the inverse limit of the groups <span
class="math inline">\(\Gamma_k = {\mathop{\mathrm{GL}}}_n(\mathbb{Z}/p^k
\mathbb{Z})\)</span> as <span class="math inline">\(k\)</span> runs over
the positive integers, is profinite, with the compact open normal
subgroups <span class="math inline">\(U_k := \ker(G \rightarrow
\Gamma_k)\)</span> giving a neighborhood basis of the identity.</p>
<p>For any profinite <span class="math inline">\(G\)</span> and any
<span class="math inline">\(U \in \mathcal{U}\)</span>, the quotient
group <span class="math inline">\(G/U\)</span> is finite; indeed, <span
class="math inline">\(G\)</span> is compact and <span
class="math inline">\(G = \cup_{g \in G/U} g U\)</span> is an open
cover. Because continuous functions on a compact space are uniformly
continuous, we may find for each <span class="math inline">\(f \in
C(G)\)</span> and <span class="math inline">\(\varepsilon&gt; 0\)</span>
a subgroup <span class="math inline">\(U \in \mathcal{U}\)</span> so
that <span class="math inline">\(f\)</span> varies by at most <span
class="math inline">\(\varepsilon\)</span> on each coset of <span
class="math inline">\(U\)</span>, i.e., <span
class="math display">\[|f(g u) - f(g)| \leq \varepsilon\text{ for all $g
\in G$ and $u \in U$}.\]</span> Let <span class="math inline">\(C(G)^U
\subseteq C(G)\)</span> denote the space of functions <span
class="math inline">\(G \rightarrow \mathbb{C}\)</span> that are
constant on the cosets of <span class="math inline">\(U\)</span>, and
let <span class="math inline">\(f_U \in C(G)^U\)</span> be defined by
averaging <span class="math inline">\(f\)</span> over <span
class="math inline">\(U\)</span>-cosets, i.e., <span
class="math display">\[f_U(g) := \mathbb{E}_{u \in U} f(g u),\]</span>
where <span class="math inline">\(\mathbb{E}\)</span> denotes the
integral with respect to the probability Haar on the compact group <span
class="math inline">\(U\)</span>. Then <span class="math inline">\(\sup
|f - f_U| \leq \varepsilon\)</span>. Thus <span
class="math inline">\(\cup_{U \in \mathcal{U} } C(G)^U\)</span> is dense
in <span class="math inline">\(C(G)\)</span>. On the other hand, the
spaces <span class="math inline">\(C(G)^U\)</span> are
finite-dimensional and <span class="math inline">\(G \times
G\)</span>-invariant, hence contained in <span
class="math inline">\(\mathcal{A}(G)\)</span>. It follows that <span
class="math inline">\(\mathcal{A}(G)\)</span> is dense in <span
class="math inline">\(C(G)\)</span>.</p></li>
</ul>
<p>The proof for general compact groups <span
class="math inline">\(G\)</span> will be similar to what we just did in
the profinite case, but a bit more technically involved because we don’t
in general have such a spectacularly convenient neighborhood basis of
subgroups. (Think of <span
class="math inline">\(\mathop{\mathrm{U}}(1)\)</span>, which visibly has
no nontrivial subgroups contained in <span class="math inline">\(\{z \in
\mathop{\mathrm{U}}(1) : |z - 1| &lt; 1/10\}\)</span>.) We’ll construct
instead some “approximate analogues” of the maps <span
class="math inline">\(f \mapsto f_U\)</span> by convolving <span
class="math inline">\(f\)</span> with functions <span
class="math inline">\(\phi \in C(G)\)</span> that are supported in small
neighborhoods of the identity element and satisfy the normalization
<span class="math inline">\(\int_G \phi = 1\)</span>. Set <span
class="math inline">\(T_\phi f(g) := \int_{g \in G} \phi(g) f(g) \, d
g\)</span>, where <span class="math inline">\(d g\)</span> denotes the
probability Haar on <span class="math inline">\(G\)</span>. (For
instance, if <span class="math inline">\(G\)</span> is profinite and
<span class="math inline">\(\phi = \mathop{\mathrm{vol}}(U, d g)^{-1}
1_U\)</span> for some <span class="math inline">\(U \in
\mathcal{U}\)</span>, then <span class="math inline">\(T_\phi f =
f_U\)</span> as above.) If <span class="math inline">\(\phi\)</span> is
sufficiently concentrated, then <span class="math inline">\(T_\phi
f\)</span> will approximate <span class="math inline">\(f\)</span>.
Since <span class="math inline">\(G\)</span> is compact, we may assume
that <span class="math inline">\(\phi\)</span> is a class function
(corresponding to <span class="math inline">\(U\)</span> being normal).
We might as well assume also that <span
class="math inline">\(\phi\)</span> is real-valued and invariant by
inversion (corresponding to <span class="math inline">\(U\)</span> being
closed under inversion). We’ll see then that <span
class="math inline">\(T_\phi\)</span> defines a compact self-adjoint
equivariant operator on <span class="math inline">\(L^2(G)\)</span>. The
spectral theory of such operators will then allow us to approximate
<span class="math inline">\(T_\phi f\)</span> by its projection to the
eigenspaces of <span class="math inline">\(T_\phi\)</span> of eigenvalue
<span class="math inline">\(\lambda\)</span> with <span
class="math inline">\(|\lambda| &gt; \varepsilon\)</span>; since the
eigenspaces of such operators with nonzero eigenvalue are
finite-dimensional and <span class="math inline">\(G\)</span>-invariant,
this gives the required approximation of <span
class="math inline">\(T_\phi f\)</span> and hence also of <span
class="math inline">\(f\)</span> via finite functions. Details next
time.<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<p>Let’s note one final easy special case. Suppose that <span
class="math inline">\(G\)</span> is a compact <em>matrix</em> group,
i.e., a compact subgroup of some <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>. (By
Theorem <a href="#thm:compact-unitarizability" data-reference-type="ref"
data-reference="thm:compact-unitarizability">10</a> applied to the
identity representation <span class="math inline">\(G \rightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, we might assume further
that <span class="math inline">\(G\)</span> is contained in the unitary
group <span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>.) Let
<span class="math inline">\(\mathcal{O}\)</span> denote the space of
functions <span class="math inline">\(f : G \rightarrow
\mathbb{C}\)</span> given by the restriction <span
class="math inline">\(f = \tilde{f}|_G\)</span> of some function <span
class="math inline">\(\tilde{f} : {\mathop{\mathrm{GL}}}_n(\mathbb{C})
\rightarrow \mathbb{C}\)</span> for which <span
class="math inline">\(\tilde{f}(g)\)</span> is a polynomial function of
the matrix entries of <span class="math inline">\(g\)</span>. We may
write <span class="math inline">\(\mathcal{O} = \cup_{d \geq 0}
\mathcal{O}_d\)</span>, where <span
class="math inline">\(\mathcal{O}_d\)</span> denotes the subspace of
polynomials of degree at most <span class="math inline">\(d\)</span>.
Each space <span class="math inline">\(\mathcal{O}_d\)</span> is
finite-dimensional and <span class="math inline">\(G\)</span>-invariant,
hence <span class="math inline">\(\mathcal{O}_d \subseteq
\mathcal{A}(G)\)</span>, hence <span class="math inline">\(\mathcal{O}
\subseteq \mathcal{A}(G)\)</span>. Since <span
class="math inline">\(\mathcal{O}\)</span> is a <span
class="math inline">\(\mathbb{C}\)</span>-algebra that is closed under
complex conjugation and separates points on <span
class="math inline">\(G\)</span>, we deduce by Stone–Weierstrass that
<span class="math inline">\(\mathcal{O}\)</span> is dense in <span
class="math inline">\(C(G)\)</span>. It follows also that <span
class="math inline">\(\mathcal{A}(G)\)</span> is dense in <span
class="math inline">\(C(G)\)</span> (and that <span
class="math inline">\(\mathcal{A}(G) = \mathcal{O}\)</span>).</p>
<p>On a related note, we observe the following consequence of
Peter–Weyl:</p>
<div id="sec:cor-peter-weyl-matrix" class="corollary">
<p><strong>Corollary 58</strong>. <em>Let <span
class="math inline">\(G\)</span> be a compact Lie group. Then <span
class="math inline">\(G\)</span> is isomorphic to a compact matrix Lie
group.</em></p>
</div>
<p>Thus Peter–Weyl for compact <em>Lie</em> groups <span
class="math inline">\(G\)</span> is essentially equivalent to the fact
that any such <span class="math inline">\(G\)</span> is isomorphic to a
matrix Lie group.</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Enumerate <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span> as <span
class="math inline">\(V_1,V_2,\dotsc\)</span>, and let <span
class="math inline">\(G_n \leq G\)</span> denote the kernel of the map
<span class="math inline">\(G \rightarrow \mathop{\mathrm{GL}}(V_1
\oplus \dotsb \oplus V_n)\)</span> given by the direct sum of the
representations <span class="math inline">\(V_1,\dotsc,V_n\)</span>.
Then <span class="math inline">\(G_n\)</span> is a closed subgroup of
<span class="math inline">\(G\)</span>, hence a Lie subgroup, so we may
speak of its Lie algebra <span
class="math inline">\(\mathfrak{g}_n\)</span>, which is a subalgebra of
the Lie algebra <span class="math inline">\(\mathfrak{g}\)</span> of
<span class="math inline">\(G\)</span>. The subgroups <span
class="math inline">\(G_n\)</span> decrease with <span
class="math inline">\(n\)</span>, hence so do the subspaces <span
class="math inline">\(\mathfrak{g}_n\)</span>. By Peter–Weyl, that the
matrix coefficients of the irreducible representations separate points
in <span class="math inline">\(G\)</span>. It follows that <span
class="math inline">\(\cap_{n} G_n = \{1\}\)</span> and thus <span
class="math inline">\(\cap_{n} \mathfrak{g}_n = \{0\}\)</span>. Since
the <span class="math inline">\(\mathfrak{g}_n\)</span> decrease and are
finite-dimensional, we may find <span class="math inline">\(n_0\)</span>
so that <span class="math inline">\(\mathfrak{g}_{n} = \{0\}\)</span>
for <span class="math inline">\(n \geq n_0\)</span>; for such <span
class="math inline">\(n\)</span>, the Lie group <span
class="math inline">\(G_n\)</span> is thus compact and zero-dimensional,
hence finite. Using again that <span class="math inline">\(\cap_{n} G_n
= \{1\}\)</span>, we may find <span class="math inline">\(n\)</span> so
that <span class="math inline">\(G_{n} = \{1\}\)</span>. Then <span
class="math inline">\(G \rightarrow \mathop{\mathrm{GL}}(V_1 \oplus
\dotsb \oplus V_n)\)</span> is an injective homomorphism with compact
domain (and Hausdorff codomain), hence defines an isomorphism (of
topological groups) onto its image. ◻</p>
</span></div>
<p>The proof shows also that any compact group <span
class="math inline">\(G\)</span> is isomorphic to an inverse limit of
compact matrix Lie groups.</p>
<p>We’ll give the proof of Peter–Weyl below after developing some
preliminaries concerning integral operators, which are of independent
interest.</p>
<h1 id="sec:integral-operators">§5. Integral operators</h1>
<h2
id="integrating-functions-taking-values-in-hilbert-spaces">Integrating
functions taking values in Hilbert spaces</h2>
<div class="lemma">
<p><strong>Lemma 59</strong>. Let <span
class="math inline">\((\Omega,\mu)\)</span> be a locally compact space
equipped with a Radon measure, let <span
class="math inline">\(V\)</span> be a Hilbert space, and let <span
class="math inline">\(f\)</span> be an element of the space <span
class="math inline">\(C_c(\Omega \rightarrow V)\)</span> of
compactly-supported continuous functions from <span
class="math inline">\(\Omega\)</span> to <span
class="math inline">\(V\)</span>. Then there is a unique element <span
class="math inline">\(v \in V\)</span> so that for each element <span
class="math inline">\(\ell\)</span> of the continuous dual <span
class="math inline">\(V^*\)</span>, we have <span id="eq:gelfand-pettis-condition" class="math display">\[\label{eq:gelfand-pettis-condition}\tag{30}
    \ell(v) = \int_{x \in \Omega} \ell(f(x)) \, d \mu(x).\]</span> We
then use the notation <span class="math inline">\(\int_\Omega f \, d \mu
:= v \in V\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We may define <span class="math inline">\(v\)</span>
first as an algebraic functional <span class="math inline">\(V^*
\rightarrow \mathbb{C}\)</span> via <a
href="#eq:gelfand-pettis-condition" data-reference-type="eqref"
data-reference="eq:gelfand-pettis-condition">\((30)\)</a>.
By Hilbert space duality, our task reduces to showing that <span
class="math inline">\(v\)</span> belongs to the double dual of <span
class="math inline">\(V\)</span>, i.e., that <span
class="math inline">\(|\ell(v)| \leq C \|\ell\|\)</span> for some
constant <span class="math inline">\(C \geq 0\)</span> and all <span
class="math inline">\(\ell \in V^*\)</span>. We may take <span
class="math inline">\(C = C_1 C_2\)</span>, where <span
class="math inline">\(C_1 := \mu(\mathop{\mathrm{supp}}(f)) &lt;
\infty\)</span> and <span class="math inline">\(C_2 := \max_{x \in
\mathop{\mathrm{supp}}(f)} \|f(x)\| &lt; \infty\)</span>. ◻</p>
</span></div>
<p>This lemma and hence our subsequent development can be generalized
further (to Banach spaces, Frechet spaces, etc.), but the present
generality should suffice for our aims.</p>
<h2
id="definition-of-integral-operators-attached-to-representations">Definition
of integral operators attached to representations</h2>
<p>From now on we take for <span class="math inline">\(G\)</span> a
locally compact group and <span class="math inline">\((\pi,V)\)</span> a
<em>Hilbert representation</em>; by this we mean that <span
class="math inline">\(V\)</span> is a Hilbert space, without requiring
that <span class="math inline">\(\pi\)</span> be unitary.</p>
<div class="lemma">
<p><strong>Lemma 60</strong>. For every compactly-supported signed Radon
measure <span class="math inline">\(\mu\)</span> on <span
class="math inline">\(G\)</span> there is a unique bounded linear
operator <span class="math inline">\(\pi(\mu) : V \rightarrow V\)</span>
such that <span class="math display">\[\ell(\pi(\mu) v)
    = \int_{g \in G} \ell(\pi(g) v) \, d \mu(g)\]</span> for all <span
class="math inline">\(v \in V\)</span> and <span
class="math inline">\(\ell \in V\)</span>. We then use the notation
<span class="math inline">\(\pi(\mu) =: \int_{g \in G} \pi(g) \, d
\mu(g)\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Set <span class="math inline">\(\Omega :=
\mathop{\mathrm{supp}}(\mu)\)</span>. For each <span
class="math inline">\(v \in V\)</span>, we may apply the previous lemma
to the function <span class="math inline">\(f_v : \Omega \rightarrow
V\)</span> given by <span class="math inline">\(g \mapsto \pi(g)
v\)</span>. We obtain elements <span class="math inline">\(\pi(\mu) v
\in V\)</span> and a linear map <span class="math inline">\(\pi(\mu) : V
\rightarrow V\)</span>. It remains to show that <span
class="math inline">\(\pi(\mu)\)</span> is bounded. For this it suffices
to show that there exists <span class="math inline">\(C \geq 0\)</span>
(depending upon <span class="math inline">\(\Omega\)</span>) so that the
operator norm <span class="math inline">\(\|\pi(g)\|\)</span> is bounded
by <span class="math inline">\(C\)</span> for all <span
class="math inline">\(g \in \Omega\)</span>. The conclusion follows by
Banach–Steinhaus (presumably covered in the functional analysis course),
which we record here for convenience:</p>
<div class="center">
<p><em>A pointwise bounded family <span
class="math inline">\((T_\alpha)_{\alpha \in I}\)</span> of bounded
linear maps <span class="math inline">\(T_\alpha : X \rightarrow
Y\)</span> from a Banach space <span class="math inline">\(X\)</span> to
a normed space <span class="math inline">\(Y\)</span> is uniformly
bounded, i.e., if for each <span class="math inline">\(x \in X\)</span>
there exists <span class="math inline">\(C(x) \geq 0\)</span> so that
<span class="math inline">\(\|T_\alpha x\| \leq C(x) \|x\|\)</span> for
all <span class="math inline">\(\alpha\)</span>, then there exists <span
class="math inline">\(C \geq 0\)</span> so that <span
class="math inline">\(\|T_\alpha x\| \leq C \|x\|\)</span> for all <span
class="math inline">\(\alpha,x\)</span>.</em></p>
</div>
<p>We apply this to the family <span class="math inline">\((\pi(g))_{g
\in \Omega}\)</span> of bounded linear maps <span
class="math inline">\(\pi(g) : V \rightarrow V\)</span>; the pointwise
boundedness property follows from the continuity of <span
class="math inline">\(G \times V \rightarrow V\)</span>, while the
uniform boundedness gives the conclusion that we seek.</p>
<p>For convenience and as a reminder of what’s going on “under the
hood,” we record a proof of Banach–Steinhaus as quoted above. (This was
not presented in lecture, and is not otherwise relevant to the course.)
If the conclusion fails, then we can find a sequence of nonzero vectors
<span class="math inline">\(x_n \in X\)</span> and elements <span
class="math inline">\(T_n\)</span> of the family <span
class="math inline">\((T_\alpha)\)</span> so that <span
class="math inline">\(\|T_n x_n\|/ \|x_n\| \rightarrow \infty\)</span>.
After normalizing the <span class="math inline">\(x_n\)</span> by a
suitable scalar, we may arrange that <span class="math display">\[\|
x_n\| \rightarrow 0, \quad \|T_n x_n\| \rightarrow \infty.\]</span> We
now inductively choose a “sufficiently sparse” subsequence <span
class="math inline">\((x_{n_k})_{k \geq 1}\)</span>, as follows. For
<span class="math inline">\(k \geq 1\)</span>, having chosen <span
class="math inline">\(n_1 &lt; \dotsb &lt; n_{k-1}\)</span>, choose
<span class="math inline">\(n_{k}\)</span> sufficiently large that</p>
<ul>
<li><p><span class="math inline">\(\|x_{n_{k}}\| \leq
2^{-k}\)</span>,</p></li>
<li><p><span class="math inline">\(\sum_{\ell=1..k-1} \|T_{n_{\ell}}
x_{n_{k}} \| \leq 2^{-k}\)</span> (as we may, because each <span
class="math inline">\(T_{n_{\ell}}\)</span> is bounded), and</p></li>
<li><p><span class="math inline">\(\|T_{n_{k}} x_{n_{k}} \| \geq
\sum_{\ell =1..k-1} \| T_{n_{k}} x_{n_{\ell}} \| + 2^{k}\)</span> (as we
may, because the family <span class="math inline">\((T_\alpha)\)</span>
is assumed pointwise bounded).</p></li>
</ul>
<p>Since <span class="math inline">\(\sum_{k} \|x_{n_k}\| &lt;
\infty\)</span> and <span class="math inline">\(X\)</span> is complete,
we have <span class="math inline">\(x := \sum_k x_{n_k} \in X\)</span>.
But <span class="math display">\[\|T_{n_k} x\| \geq \|T_{n_k} x_{n_k}\|
- \sum_{\ell=1..k-1} \| T_{n_{k}} x_{n_{\ell}} \| - \sum_{\ell \geq k+1}
\| T_{n_{k}} x_{n_{\ell}} \| \geq 2^k - \sum_{\ell \geq k+1} 2^{-\ell}
\rightarrow \infty,\]</span> contrary to the assumed pointwise
boundedness of the family <span
class="math inline">\((T_\alpha)\)</span>. ◻</p>
</span></div>
<h2 id="basic-properties">Basic properties</h2>
<p>From now on we assume moreover (mainly for convenience) that <span
class="math inline">\(G\)</span> is <em>unimodular</em>, so that we may
fix a (left and right) Haar measure <span class="math inline">\(d
g\)</span>. For <span class="math inline">\(f \in C_c(G)\)</span>, the
above discussion then applies to <span class="math inline">\(\mu = f \,
d g\)</span>, giving us operators on <span
class="math inline">\(V\)</span> that we denote by <span
class="math inline">\(\pi(f) := \pi(f \, d g)\)</span>, thus <span
class="math inline">\(\pi(f) = \int_{g \in G} f(g) \pi(g) \, d
g\)</span>.</p>
<div id="lem:integral-ops-basic-properties" class="lemma">
<p><strong>Lemma 61</strong>. Let <span class="math inline">\(f, f_1,
f_2 \in C_c(G)\)</span> and <span class="math inline">\(g \in
G\)</span>.</p>
<ol type="i">
<li><p><span class="math inline">\(\pi(f_1) \pi(f_2) = \pi(f_1 \ast
f_2)\)</span>, where <span class="math inline">\(f_1 \ast f_2 \in
C_c(G)\)</span> denotes the convolution <span class="math display">\[f_1
\ast f_2(x) := \int_{g \in G} f_1(g) f_2(g^{-1} x) \, d
g.\]</span></p></li>
<li><p><span class="math inline">\(\pi(g) \pi(f) = \pi(f(g^{-1}
\cdot))\)</span>, <span class="math inline">\(\pi(f) \pi(g) =
\pi(f(\cdot g^{-1}))\)</span>.</p></li>
<li><p>If <span class="math inline">\(f \in
C_c(G)^{\mathop{\mathrm{class}}}\)</span>, then <span
class="math inline">\(\pi(f)\)</span> is equivariant.</p></li>
<li><p>If <span class="math inline">\((\pi,V)\)</span> is unitary, then
the adjoint <span class="math inline">\(\pi(f)^*\)</span> is given by
<span class="math inline">\(\pi(f^*)\)</span>, where <span
class="math inline">\(f^*(x) := \overline{f(x^{-1})}\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>By substituting <span class="math inline">\(g_2 \mapsto g_1^{-1}
g_2\)</span>, <span class="math display">\[\begin{align}
      \pi(f_1) \pi(f_2)
      &amp;= \int \int f_1(g_2) f_2(g_2)
        \underbrace{\pi(g_1) \pi(g_2)}{\pi(g_1 g_2)} \, d
        g_1 \, d g_2
      \\
      &amp;=
        \int (\underbrace{\int f_1(g_1) f_2(g_1^{-1} g_2) \,
        d g_1}_{(f_1 \ast f_2)(g_2)})
        \pi(g_2) \, d g_2
      \\
      &amp;=
        \pi(f_1 \ast f_2).
    
\end{align}\]</span></p></li>
<li><p>By substituting <span class="math inline">\(x \mapsto g^{-1}
x\)</span>, <span class="math inline">\(\pi(g) \pi(f) = \int f(x) \pi(g)
\pi(x) \, d x = \int f(g^{-1} x) \pi(x) \, d x = \pi(f(g^{-1}
\cdot))\)</span>; similarly for the other assertion.</p></li>
<li><p>We’ve seen that <span class="math inline">\(\pi(g) \pi(f)
\pi(g^{-1}) = \pi([x \mapsto f(g^{-1} x g)])\)</span>, which coincides
with <span class="math inline">\(\pi(f)\)</span> if <span
class="math inline">\(f\)</span> is a class function.</p></li>
<li><p>Since <span class="math inline">\(\pi\)</span> is unitary, we
have <span class="math inline">\(\pi(g)^* = \pi(g^{-1})\)</span>, hence
<span class="math inline">\(\pi(f)^* = \int \overline{f(g)} \pi(g^{-1})
\, d g\)</span>; by the change of variables <span
class="math inline">\(g \mapsto g^{-1}\)</span>, this coincides with
<span class="math inline">\(\pi(f^*)\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="sec:appr-vect-their">§5.4. Approximating vectors by their images under
integral operators</h2>
<div id="lem:approx-v-pi-f-v" class="lemma">
<p><strong>Lemma 62</strong>. For each <span class="math inline">\(v \in
V\)</span> and <span class="math inline">\(\varepsilon&gt; 0\)</span>
there exists <span class="math inline">\(f \in C_c(G)\)</span> so that
<span class="math inline">\(\|\pi(f) v - v\| \leq
\varepsilon\)</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By the continuity of the action, we may find a
neighborhood <span class="math inline">\(U\)</span> of the identity
element in <span class="math inline">\(G\)</span> so that <span
class="math inline">\(\|\pi(g) v - v\| \leq \varepsilon\)</span> for all
<span class="math inline">\(g \in U\)</span>. By Urysohn, we may find
<span class="math inline">\(f \in C_c(U)\)</span> such that <span
class="math inline">\(\int_G f \, d g = 1\)</span> and <span
class="math inline">\(f \geq 0\)</span>. Then <span
class="math display">\[\|\pi(f) v - v\| = \|\int_{g \in G} f(g) (\pi(g)
v - v) \, d g\| \leq (\int f \, d g) \varepsilon=
\varepsilon.\]</span> ◻</p>
</span></div>
<div id="lem:approx-v-pi-f-v-2" class="lemma">
<p><strong>Lemma 63</strong>. In lemma <a href="#lem:approx-v-pi-f-v"
data-reference-type="eqref"
data-reference="lem:approx-v-pi-f-v">\((62)\)</a>, we may
arrange moreover that <span class="math inline">\(f \geq 0\)</span> and
<span class="math inline">\(f(g) = f(g^{-1})\)</span>, and for <span
class="math inline">\(G\)</span> compact also that <span
class="math inline">\(f \in
C_c(G)^{\mathop{\mathrm{class}}}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Exercise. ◻</p>
</span></div>
<p>These results may be generalized and refined further. For instance,
if <span class="math inline">\(G\)</span> is a Lie group, then we may
assume that <span class="math inline">\(f\)</span> is smooth.</p>
<h3 id="sec:autom-cont-finite">§5.4.1. Automatic continuity for
finite-dimensional subrepresentations of <span
class="math inline">\(L^2(G)\)</span></h3>
<p>We now fulfill the promise made after the statement of Theorem <a
href="#thm:coeff-ring-characterizations" data-reference-type="ref"
data-reference="thm:coeff-ring-characterizations">56</a> by explaining
why for a compact group <span class="math inline">\(G\)</span>, the
finiteness (right, left or bi) of <span class="math inline">\(f \in
L^2(G)\)</span> implies that <span class="math inline">\(f\)</span> is
represented by a continuous function. Suppose for instance that <span
class="math inline">\(f\)</span> is right-finite, so that it is
contained in some finite-dimensional subspace <span
class="math inline">\(V \subseteq L^2(G)\)</span> invariant by the right
regular representation <span class="math inline">\(\rho\)</span> of
<span class="math inline">\(G\)</span>. For each <span
class="math inline">\(v \in V\)</span> and <span
class="math inline">\(\varepsilon&gt; 0\)</span>, we see by Lemma <a
href="#lem:approx-v-pi-f-v" data-reference-type="ref"
data-reference="lem:approx-v-pi-f-v">62</a> that there exists <span
class="math inline">\(\phi \in C(G)\)</span> so that <span
class="math inline">\(\|\rho(\phi) v - v\|_{L^2} \leq
\varepsilon\)</span>. In particular, the subspace of <span
class="math inline">\(V\)</span> consisting of elements of the form
<span class="math inline">\(\rho(\phi) v\)</span> is dense. Since <span
class="math inline">\(V\)</span> is finite-dimensional, it follows that
every element of <span class="math inline">\(V\)</span> is of this form.
Note that each such element is pointwise defined.</p>
<p>We verify now that every element of <span
class="math inline">\(V\)</span>, say <span class="math inline">\(v&#39;
= \rho(\phi) v\)</span>, is in fact continuous. For <span
class="math inline">\(g \in G\)</span>, we have (by Lemma <a
href="#lem:integral-ops-basic-properties" data-reference-type="ref"
data-reference="lem:integral-ops-basic-properties">61</a>) <span
class="math inline">\(\rho(g) v&#39; = \rho(\phi(g^{-1} \cdot))
v\)</span>, hence <span class="math display">\[\sup_{x \in G} |v&#39;(x
g) - v&#39;(x)| = \|\rho(g) v&#39; - v&#39;\|_{L^\infty} =
\|\rho(\phi(g^{-1} \cdot) -\phi ) v\|_{L^\infty} \leq \|\rho(\phi(g^{-1}
\cdot) -\phi )\|_{L^2} \| v\|_{L^2},\]</span> in the last step by
Cauchy–Schwarz. Since the left regular representation of <span
class="math inline">\(G\)</span> on <span
class="math inline">\(L^2(G)\)</span> is continuous, the required
continuity of <span class="math inline">\(v&#39;\)</span> follows.</p>
<h2 id="some-functional-analytic-considerations">Some
functional-analytic considerations</h2>
<p>Recall (from, e.g., §<a href="#sec:spectr-theory-comp"
data-reference-type="ref"
data-reference="sec:spectr-theory-comp">1.5</a>) the definition of a
compact operator on a Hilbert space.</p>
<p>I don’t think the following definition is standard, but I like
it.</p>
<div id="defn:compact-type" class="definition">
<p><strong>Definition 64</strong>. We say that <span
class="math inline">\((\pi,V)\)</span> is of <em>compact type</em> if
<span class="math inline">\(\pi(f)\)</span> is compact for each <span
class="math inline">\(f \in C_c(G)\)</span>.</p>
</div>
<p>We recall a bit more functional analysis background.</p>
<div class="lemma">
<p><strong>Lemma 65</strong>. Let <span
class="math inline">\((X,\mu)\)</span> be a locally compact space
equipped with a positive Borel measure <span
class="math inline">\(\mu\)</span> such that <span
class="math inline">\(V := L^2(X)\)</span> is a separable Hilbert space.
Let <span class="math inline">\(k \in L^2(X \times X)\)</span>. Then we
may define a bounded operator <span class="math inline">\(T : V
\rightarrow V\)</span> by <span class="math inline">\(T v(x) = \int_{y}
k(x,y) \, d \mu(y)\)</span>. Any such operator is compact.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof sketch; omitted in lecture." data-folded-text="Proof sketch; omitted in lecture. (...)">Proof sketch; omitted in lecture.</em></a>
<span class="proof-content"> Choose an orthonormal
basis <span class="math inline">\(e_1,e_2,\dotsc\)</span> for <span
class="math inline">\(L^2(X)\)</span> and set <span
class="math inline">\(a_{i j} := \langle T e_i, e_j \rangle\)</span>.
Then <span class="math inline">\(\sum_{i,j} |a_{i j}|^2 = \|k\|_{L^2(X
\times X)}^2 &lt; \infty\)</span>. Let <span class="math inline">\(v =
\sum_j v_j e_j \in V\)</span>. Then <span class="math inline">\(T v =
\sum_i b_i e_i\)</span> with <span class="math inline">\(b_i := \sum_j
a_{i j} v_j\)</span>. By Cauchy–Schwartz, <span
class="math inline">\(|b_i|^2 \leq \|v\|^2 C_i\)</span>, where <span
class="math inline">\(C_i := \sum_j |a_{i j}|^2\)</span>. Thus the image
under <span class="math inline">\(T\)</span> of the unit ball in <span
class="math inline">\(V\)</span> is contained in the set <span
class="math inline">\(\{\sum b_i e_i : |b_i|^2 \leq C_i \}\)</span>.
Using that <span class="math inline">\(\sum_i C_i &lt; \infty\)</span>
and a diagonalization argument, we verify readily that this set is
precompact. ◻</p>
</span></div>
<div id="thm:G-compact-implies-compact-type" class="lemma">
<p><strong>Lemma 66</strong>. If <span class="math inline">\(G\)</span>
is a compact group, then its right regular representation <span
class="math inline">\((\rho,L^2(G))\)</span> is of compact type.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> For <span class="math inline">\(f \in C_c(G) =
C(G)\)</span> and <span class="math inline">\(v \in L^2(G)\)</span>, we
may write <span class="math inline">\(\rho(f) v(x) = \int f(y) v(x y) \,
d y = \int v(y) k(x,y) \, d y\)</span>, where <span
class="math inline">\(k(x,y) := f(x^{-1} y)\)</span>. Thus the previous
lemma gives the required conclusion. (Sketch of a slightly more direct
proof, omitted in lecture: since <span class="math inline">\(G\)</span>
is compact and <span class="math inline">\(k\)</span> is continuous, it
is uniformly continuous, and so the function <span
class="math inline">\((x,y) \mapsto k(x^{-1} y)\)</span> may be
approximated uniformly by step functions; thus <span
class="math inline">\(\rho(f)\)</span> is approximated in norm by finite
rank operators, hence is compact.) ◻</p>
</span></div>
<h2 id="proof-of-the-l2-density-part-of-the-peterweyl-theorem">Proof of
the <span class="math inline">\(L^2\)</span>-density part of the
Peter–Weyl theorem</h2>
<p>We now prove part (ii) of Theorem <a href="#thm:P-W-general"
data-reference-type="ref" data-reference="thm:P-W-general">57</a>. Let
<span class="math inline">\(G\)</span> be a compact group, <span
class="math inline">\(v \in L^2(G)\)</span> and <span
class="math inline">\(\varepsilon&gt; 0\)</span>. Let <span
class="math inline">\(\rho\)</span> denote the right regular
representation. By lemma <a href="#lem:approx-v-pi-f-v-2"
data-reference-type="ref" data-reference="lem:approx-v-pi-f-v-2">63</a>,
we may find <span class="math inline">\(f \in
C_c(G)^{\mathop{\mathrm{class}}}\)</span> so that <span
class="math inline">\(f \geq 0, f(g^{-1}) = f(g)\)</span> and <span id="eq:T-v-approx-v" class="math display">\[\label{eq:T-v-approx-v}\tag{31}
  \|\rho(f) v - v\| \leq \varepsilon.\]</span> Then <span
class="math inline">\(f^* = f\)</span>, so <span class="math inline">\(T
:= \rho(f)\)</span> is self-adjoint. By lemma <a
href="#thm:G-compact-implies-compact-type" data-reference-type="ref"
data-reference="thm:G-compact-implies-compact-type">66</a>, <span
class="math inline">\(T\)</span> is compact. Set <span
class="math inline">\(V := L^2(G)\)</span>. By Theorem <a
href="#thm:spectral-theorem-compact" data-reference-type="ref"
data-reference="thm:spectral-theorem-compact">4</a>, we may write <span
class="math inline">\(V\)</span> as the orthogonal Hilbert direct sum of
the eigenspaces <span class="math inline">\(V_\lambda\)</span> of <span
class="math inline">\(T\)</span>, taken over <span
class="math inline">\(\lambda \in \mathbb{R}\)</span>; moreover, setting
<span class="math inline">\(V&#39; := \oplus_{|\lambda| \geq
\varepsilon} V_\lambda\)</span> and <span
class="math inline">\(V&#39;&#39; := \oplus_{|\lambda| &lt; \varepsilon}
V_\lambda\)</span>, the space <span
class="math inline">\(V&#39;\)</span> is finite-dimensional. Since <span
class="math inline">\(f\)</span> is a class function, we know (by lemma
<a href="#lem:integral-ops-basic-properties" data-reference-type="ref"
data-reference="lem:integral-ops-basic-properties">61</a>) that the
operator <span class="math inline">\(T\)</span> is equivariant (i.e.,
<span class="math inline">\(\rho(g) T = T \rho(g)\)</span> for all <span
class="math inline">\(g \in G\)</span>), thus its eigenspaces <span
class="math inline">\(V_\lambda\)</span> and thus their sums <span
class="math inline">\(V&#39;\)</span> and <span
class="math inline">\(V&#39;&#39;\)</span> are <span
class="math inline">\(\rho(G)\)</span>-invariant. Thus <span id="eq:V&#39;-finite" class="math display">\[\label{eq:V&#39;-finite}\tag{}
  V&#39; \subseteq \mathcal{A}(G).\]</span> Let <span
class="math inline">\(v&#39; \in V&#39;\)</span> and <span
class="math inline">\(v&#39;&#39; \in V&#39;&#39;\)</span> denote the
components of <span class="math inline">\(v\)</span>, so that <span
class="math inline">\(v = v&#39; + v&#39;&#39;\)</span>. We have <span id="eq:estimate-T-v-double-prime" class="math display">\[\label{eq:estimate-T-v-double-prime}\tag{33}
  \|T v&#39;&#39;\|
  = \|\sum_{|\lambda| &lt; \varepsilon} \lambda v_\lambda \|
  \leq \varepsilon\|v\|.\]</span> By <a href="#eq:T-v-approx-v"
data-reference-type="eqref"
data-reference="eq:T-v-approx-v">\((31)\)</a> and <a
href="#eq:estimate-T-v-double-prime" data-reference-type="eqref"
data-reference="eq:estimate-T-v-double-prime">\((33)\)</a>,
we deduce that <span class="math display">\[\|v - T v&#39;\| \leq
\varepsilon(1 + \|v\|).\]</span> On the other hand, <span
class="math inline">\(T v&#39; = \sum_{|\lambda| \geq \varepsilon}
\lambda v_\lambda \in V&#39; \subseteq \mathcal{A}(G)\)</span>. Thus
<span class="math inline">\(\mathcal{A}(G)\)</span> is dense in <span
class="math inline">\(L^2(G)\)</span>.<a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<h2
id="proof-of-the-uniform-density-part-of-the-peterweyl-theorem">Proof of
the uniform density part of the Peter–Weyl theorem</h2>
<p>We now deduce part (i) of Theorem <a href="#thm:P-W-general"
data-reference-type="ref" data-reference="thm:P-W-general">57</a>. We
retain the above notation. Let <span class="math inline">\(v \in
C(G)\)</span> and <span class="math inline">\(\varepsilon&gt;
0\)</span>. Since <span class="math inline">\(G\)</span> is compact,
<span class="math inline">\(v\)</span> is uniformly continuous; by an
easy variant of Lemma <a href="#lem:approx-v-pi-f-v"
data-reference-type="ref" data-reference="lem:approx-v-pi-f-v">62</a>,
we may thus find <span class="math inline">\(f \in C(G)\)</span> so that
<span class="math inline">\(\|\rho(f) v - v\|_{L^\infty} \leq
\varepsilon\)</span>. By the <span
class="math inline">\(L^2\)</span>-density part of the Peter–Weyl
theorem that we have already proved, we may find <span
class="math inline">\(f&#39; \in \mathcal{A}(G)\)</span> so that <span
class="math inline">\(\|f - f&#39;\|_{L^2} \leq \varepsilon\)</span>.
Since <span class="math inline">\((G, d g)\)</span> is a probability
space, it follows in particular that <span class="math inline">\(\|f -
f&#39;\|_{L^1} \leq \varepsilon\)</span>. Since <span
class="math display">\[\rho(f) v - \rho(f&#39;) v = \int_{f \in G} (f -
f&#39;)(g) \pi(g) v \, d g\]</span> and <span
class="math inline">\(\|\pi(g) v\|_{L^\infty} =
\|v\|_{L^\infty}\)</span>, it follows that <span
class="math display">\[\|\rho(f) v - \rho(f&#39;) v\|_{L^\infty} \leq
\|f - f&#39;\|_{L^1} \|v\|_{L^\infty} \leq
\varepsilon\|v\|_{L^\infty}.\]</span> Thus <span
class="math display">\[\|\rho(f&#39;) v - v \| \leq \varepsilon(1 +
\|v\|_{L^\infty}).\]</span> Observe finally that for any <span
class="math inline">\(g \in G\)</span>, we have <span
class="math display">\[\rho(g) \rho (f&#39;) v = \rho(f&#39;(g^{-1}
\cdot )) v.\]</span> Thus if <span class="math inline">\(W\)</span> is
any left-<span class="math inline">\(G\)</span>-invariant subspace of
<span class="math inline">\(\mathcal{A}(G)\)</span> that contains <span
class="math inline">\(f&#39;\)</span>, then <span
class="math inline">\(\rho (f&#39;) v\)</span> belongs to the <span
class="math inline">\(\rho(G)\)</span>-invariant finite-dimensional
space <span class="math inline">\(\rho(W) v\)</span>, and so <span
class="math inline">\(\rho (f&#39;) v \in \mathcal{A}(G)\)</span>. We
conclude as required that <span
class="math inline">\(\mathcal{A}(G)\)</span> is dense in <span
class="math inline">\(C(G)\)</span>.</p>
<p>Part (iii) of the Peter–Weyl theorem can be proved analogously, or
deduced from parts (i) and (ii) by a simple averaging trick; we’ll take
the latter approach. Given an element <span
class="math inline">\(v\)</span> of <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span> or <span
class="math inline">\(C(G)^{\mathop{\mathrm{class}}}\)</span> and <span
class="math inline">\(\varepsilon&gt; 0\)</span>, we first find <span
class="math inline">\(v&#39; \in \mathcal{A}(G)\)</span> so that <span
class="math inline">\(\|v&#39; - v\| \leq \varepsilon\)</span>, where
<span class="math inline">\(\|.\|\)</span> denotes either the <span
class="math inline">\(L^2\)</span>-norm or <span
class="math inline">\(L^\infty\)</span>-norm. We then introduce the
averaging operator <span class="math display">\[\mathbb{E} :
\{\text{functions }f: G \rightarrow \mathbb{C}\} \rightarrow
\{\text{class functions } \mathbb{E} f: G \rightarrow
\mathbb{C}\}\]</span> <span class="math display">\[\mathbb{E} f(x) :=
\int_{g \in G} f(g x g^{-1}) \, d g.\]</span> Since <span
class="math inline">\(f\)</span> and <span class="math inline">\(x
\mapsto f(g x g^{-1})\)</span> have the same norms, the triangle
inequality implies that <span class="math inline">\(\|\mathbb{E} f\|
\leq \|f\|\)</span>. Set <span class="math inline">\(v&#39;&#39; :=
\mathbb{E} v&#39;\)</span>. Then <span class="math inline">\(v&#39;&#39;
\in \mathcal{A}(G)^{\mathop{\mathrm{class}}}\)</span>. Since <span
class="math inline">\(v\)</span> is a class function, we have <span
class="math inline">\(v = \mathbb{E} v\)</span>, and so <span
class="math inline">\((v&#39;&#39; - v) = \mathbb{E} (v&#39; -
v)\)</span>, hence <span class="math inline">\(\|v&#39;&#39; - v\| \leq
\|v&#39; - v\| \leq \varepsilon\)</span>, giving the required
approximation of <span class="math inline">\(v\)</span> by an element of
<span
class="math inline">\(\mathcal{A}(G)^{\mathop{\mathrm{class}}}\)</span>.</p>
<h2 id="sec:finite-dimens-irred">§5.8. Finite-dimensionality of
irreducibles</h2>
<p>We prove part (iv) of Peter–Weyl in the special case of an
irreducible Hilbert representation <span
class="math inline">\((\pi,V)\)</span>; the more general conclusion can
be deduced similarly after developing integration more generally. The
proof is very similar to that of the <span
class="math inline">\(C(G)\)</span>-density assertion (indeed, a unified
statement and proof involving Banach space representations could be
given, but I feel like it doesn’t hurt to see the argument essentially
repeated, since the method is so widely applicable). Let <span
class="math inline">\(v\)</span> be a nonzero element of <span
class="math inline">\(V\)</span>, and let <span
class="math inline">\(\varepsilon&gt; 0\)</span> be sufficiently small.
We can find an open neighborhood <span class="math inline">\(U\)</span>
of the identity element of <span class="math inline">\(G\)</span> so
that <span class="math inline">\(\|\pi(g) v - v\| \leq
\varepsilon\)</span> for all <span class="math inline">\(g \in
U\)</span>. Take <span class="math inline">\(f \in C_c(U)\)</span> with
<span class="math inline">\(f \geq 0, \int f = 1\)</span>. Then <span
class="math inline">\(\|\pi(f) v - v\| \leq \varepsilon\)</span>. Use
the <span class="math inline">\(L^2\)</span>-density part of the
Peter–Weyl theorem to produce <span class="math inline">\(f&#39; \in
C(G)\)</span> so that <span class="math inline">\(\|f - f&#39;\|_{L^2}
\leq \varepsilon\)</span>. Then likewise <span class="math inline">\(\|f
- f&#39;\|_{L^1} \leq \varepsilon\)</span>, and so, as before, <span
class="math inline">\(\|\pi(f&#39;) v - v \| \leq \varepsilon(1 +
\|v\|)\)</span>. For small enough <span
class="math inline">\(\varepsilon\)</span>, this implies in particular
that <span class="math inline">\(\pi(f&#39;) v \neq 0\)</span>. Since
<span class="math inline">\(f&#39;\)</span> belongs to <span
class="math inline">\(\mathcal{A}(G)\)</span>, it is contained in some
finite-dimensional <span class="math inline">\(G \times
G\)</span>-invariant subspace <span class="math inline">\(W\)</span>.
Then <span class="math inline">\(\pi (f&#39;) v\)</span> belongs to the
space <span class="math inline">\(\pi(W) v := \{\pi(w) v : w \in
W\}\)</span>. The latter space is finite-dimensional (with dimension
bounded by <span class="math inline">\(\dim(W)\)</span>) and nonzero
(because it contains <span class="math inline">\(\pi (f&#39;)
v\)</span>). Most significantly, it is invariant: for <span
class="math inline">\(w \in W\)</span> and <span class="math inline">\(g
\in G\)</span>, we have (by Lemma <a
href="#lem:integral-ops-basic-properties" data-reference-type="ref"
data-reference="lem:integral-ops-basic-properties">61</a>) <span
class="math display">\[\pi(g) \pi(w) v = \pi(w(g^{-1} \cdot ))
v.\]</span> Since <span class="math inline">\(V\)</span> is irreducible,
this forces <span class="math inline">\(V = \rho(W) v\)</span>, hence
<span class="math inline">\(\dim(V) \leq \dim(W) &lt; \infty\)</span>,
as required.</p>
<h2 id="sec:four-analys-comp">§5.9. Fourier analysis on a compact group <span
class="math inline">\(G\)</span></h2>
<p>Given <span class="math inline">\(f \in C(G)\)</span> (say), its
Fourier transform is defined to be the collection <span
class="math inline">\((\pi(f))_{\pi \in
\mathop{\mathrm{Irr}}(G)}\)</span> of integral operators that it induces
on the (equivalence classes of) finite-dimensional irreducible
representations of <span class="math inline">\(G\)</span>. We can
restate some of our results concerning orthogonality and completeness of
matrix coefficients in terms of these collections of operators. In
preparation for doing so, we define on any finite-dimensional Hilbert
space <span class="math inline">\(V\)</span> the <em>Hilbert–Schmidt
inner product</em> of <span class="math inline">\(T_1, T_2 \in
\mathop{\mathrm{End}}(V)\)</span> by the formula <span
class="math display">\[\langle T_1, T_2 \rangle :=
\mathop{\mathrm{trace}}(T_1 T_2^*),\]</span> where as before <span
class="math inline">\(T_2^*\)</span> denotes the hermitian adjoint,
given with respect to an orthonormal basis by the conjugate transpose.
If <span class="math inline">\(T_1\)</span> and <span
class="math inline">\(T_2\)</span> are respected by matrices <span
class="math inline">\((a_{i j})\)</span> and <span
class="math inline">\((b_{ij})\)</span> defined with respect to an
orthonormal basis, then we may verify readily that <span
class="math display">\[\langle T_1, T_2 \rangle = \sum_{i,j} a_{i j}
\overline{b_{i j}}.\]</span> This is the dual of the inner product
considered in §<a href="#sec:schur-orthogonality"
data-reference-type="ref"
data-reference="sec:schur-orthogonality">4.7</a>.</p>
<div class="theorem">
<p><strong>Theorem 67</strong>. </p>
<ol type="i">
<li><p><em>For <span class="math inline">\(f_1, f_2 \in C(G)\)</span>,
<span class="math display">\[\langle f_1, f_2 \rangle_{L^2(G)} =
\sum_{\pi \in \mathop{\mathrm{Irr}}(G)} \dim(\pi) \langle \pi(f_1),
\pi(f_2) \rangle.\]</span></em></p></li>
<li><p><em>Under “some assumptions” on <span
class="math inline">\(f\)</span>, <span id="eq:pointwise-fourier-expn" class="math display">\[\label{eq:pointwise-fourier-expn}\tag{34}
      f(1)
      = \sum_{\pi \in \mathop{\mathrm{Irr}}(G)}
      \dim(\pi) \chi_\pi(f),\]</span> where <span
class="math display">\[\chi_\pi(f) := \mathop{\mathrm{trace}}(\pi(f)) =
\int_{g \in G} f(g) \chi_\pi(g) \, d g.\]</span> For instance, a
sufficient assumption is that <span class="math inline">\(f\)</span>
have the form <span class="math inline">\(f_1 \ast f_2\)</span> for some
<span class="math inline">\(f_1, f_2 \in L^2(G)\)</span>.</em></p></li>
<li><p><em>For <span class="math inline">\(\sigma \in
\mathop{\mathrm{Irr}}(G)\)</span>, define <span
class="math inline">\(\alpha_\sigma := \dim(\sigma)
\overline{\chi_\sigma } \in C(G)\)</span>. Then for each <span
class="math inline">\(\pi \in \mathop{\mathrm{Irr}}(G)\)</span>, we have
<span id="eq:alpha-sigma-acts-on-pi" class="math display">\[\label{eq:alpha-sigma-acts-on-pi}\tag{35}
      \pi(\alpha_\sigma)
      =
\begin{cases}
        0  &amp; \text{ if } \pi \not\cong \sigma, \\
        1 &amp; \text{ if } \pi \cong \sigma.
      \end{cases}\]</span> Moreover, for <span
class="math inline">\(\sigma_1, \sigma_2 \in
\mathop{\mathrm{Irr}}(G)\)</span>, <span id="eqn:convolving-idemps" class="math display">\[\label{eqn:convolving-idemps}\tag{36}
      \alpha_{\sigma_1} \ast \alpha_{\sigma_2}
      =
\begin{cases}
        \alpha_{\sigma} &amp; \text{ if }
        \sigma_1 = \sigma_2 =: \sigma, \\
        0 &amp; \text{ otherwise}.
      \end{cases}\]</span></em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>With respect to an orthonormal basis of <span
class="math inline">\(\pi\)</span>, we have <span
class="math display">\[\pi(f)_{i j}
      = \int_{g \in G}
      f(g) \pi_{i j}(g) \, d g,\]</span> so <span
class="math inline">\(\langle \pi(f_1), \pi(f_2) \rangle = \langle f_1,
\overline{\pi_{i j}} \rangle \langle \overline{\pi_{i j}}, f_2
\rangle\)</span>. The conclusion follows from part (i) of the Peter–Weyl
theorem, which we have seen implies that the function <span
class="math inline">\(\sqrt{\dim(\pi)} \pi_{i j}\)</span> (and hence
likewise the functions <span class="math inline">\(\sqrt{\dim(\pi)}
\overline{\pi_{i j}}\)</span>) form an orthonormal basis of <span
class="math inline">\(L^2(G)\)</span>.</p></li>
<li><p>Suppose for instance that <span class="math inline">\(f = f_1
\ast f_2\)</span> with <span class="math inline">\(f_1, f_2 \in
L^2(G)\)</span>. Then <span class="math inline">\(f(1) = \int_{g \in G}
f_1(g) f_2(g^{-1}) \, d g = \langle f_1, f_2^* \rangle\)</span>, while
<span class="math inline">\(\langle \pi(f_1), \pi(f_2^*) \rangle =
\mathop{\mathrm{trace}}(\pi(f_1) \pi(f_2)) =
\mathop{\mathrm{trace}}(\pi(f_1 \ast f_2)) = \chi_\pi(f)\)</span>; the
required conclusion thus follows from part (i).</p></li>
<li><p>Using the expansion <span class="math inline">\(\chi_\sigma =
\sum_{k } \sigma_{k k}\)</span>, we compute that <span
class="math display">\[\begin{align}
      \pi(\alpha_\sigma)_{i j}
      &amp;=
        \int_{g \in G}
        \alpha_\sigma(g) \pi_{i j}(g) \, d g
      \\
      &amp;=
        \sum_k
        \dim(\sigma)
        \langle \pi_{i j}, \sigma_{k k} \rangle
      \\
      &amp;= \delta_{\sigma,\pi}
        \sum_k
        \delta_{i k}
        \delta_{j k}
      \\
      &amp;= \delta_{\sigma,\pi}
        \delta_{i j}.
    
\end{align}\]</span> These matrix entries are of the required
form.</p>
<p>To prove <a href="#eqn:convolving-idemps" data-reference-type="eqref"
data-reference="eqn:convolving-idemps">\((36)\)</a>, it
suffices by the injectivity of the association <span
class="math inline">\(f \mapsto (\pi(f))_{\pi \in
\mathop{\mathrm{Irr}}(G)}\)</span> to check that <span
class="math inline">\(\pi(\alpha_{\sigma_1} \ast
\alpha_{\sigma_2})\)</span> is given by <span
class="math inline">\(\pi(\alpha_\sigma)\)</span> when <span
class="math inline">\(\sigma_1 \cong \sigma_2\)</span> and vanishes
otherwise, which follows from <a href="#eq:alpha-sigma-acts-on-pi"
data-reference-type="eqref"
data-reference="eq:alpha-sigma-acts-on-pi">\((35)\)</a>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<p>The pointwise decomposition <a href="#eq:pointwise-fourier-expn"
data-reference-type="eqref"
data-reference="eq:pointwise-fourier-expn">\((34)\)</a>
fails in general for <span class="math inline">\(f \in C(G)\)</span>, as
one can see already when <span class="math inline">\(G =
\mathop{\mathrm{U}}(1)\)</span>; there are well-known constructions of
continuous functions on the circle whose Fourier series do not converge
pointwise. A sufficient condition for the validity of <a
href="#eq:pointwise-fourier-expn" data-reference-type="eqref"
data-reference="eq:pointwise-fourier-expn">\((34)\)</a>
is that <span class="math inline">\(f\)</span> be smooth. (A <em>smooth
function</em> on a compact Lie group is what you’d expect. A general
compact group <span class="math inline">\(G\)</span> can be written, as
indicated in §<a href="#sec:peter-weyl-theorem"
data-reference-type="ref"
data-reference="sec:peter-weyl-theorem">4.9</a>, as an inverse limit of
compact Lie groups <span class="math inline">\(G_n\)</span>; a smooth
function on <span class="math inline">\(G\)</span> is then a function
that factors through a smooth function on one of the quotients <span
class="math inline">\(G_n\)</span> of <span
class="math inline">\(G\)</span>.) The proof isn’t so different from the
case <span class="math inline">\(G = \mathop{\mathrm{U}}(1)\)</span>,
but we won’t go into it. Lipschitz continuity should also suffice.</p>
<h2 id="sec:isotyp-decomp">§5.10. Isotypic decomposition</h2>
<div class="definition">
<p><strong>Definition 68</strong>. Let <span
class="math inline">\((\pi,V)\)</span> be a representation of a compact
group <span class="math inline">\(G\)</span>, and let <span
class="math inline">\(\sigma \in \mathop{\mathrm{Irr}}(G)\)</span>. We
say that a nonzero vector <span class="math inline">\(v \in V\)</span>
is <em><span class="math inline">\(\sigma\)</span>-isotypic</em> if
there are closed invariant subspaces <span
class="math inline">\(W_1,\dotsc,W_n\)</span> of <span
class="math inline">\(V\)</span>, with each <span
class="math inline">\(W_j\)</span> isomorphic to <span
class="math inline">\(\sigma\)</span>, so that <span
class="math inline">\(v \in \sum_{j} W_j\)</span>. We write <span
class="math inline">\(V(\sigma) := \{0\} \cup \{\text{$\sigma$-isotypic
} v \in V\}\)</span>.</p>
</div>
<div id="thm:isotyp-decomp-1" class="theorem">
<p><strong>Theorem 69</strong>. <em>Let <span
class="math inline">\((\pi,V)\)</span> be a Hilbert representation of
the compact group <span class="math inline">\(G\)</span>.</em></p>
<ol type="i">
<li><p><em><span class="math inline">\(\pi(\alpha_\sigma)\)</span>
defines a projection <span class="math inline">\(V \rightarrow
V(\sigma)\)</span>; if <span class="math inline">\(\pi\)</span> is
unitary, then it is the orthogonal projection.</em></p></li>
<li><p><em><span class="math inline">\(V = \hat{\oplus }_{\sigma \in
\mathop{\mathrm{Irr}}(G)} V(\sigma)\)</span>.</em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>If <span class="math inline">\(v \in V\)</span>, then <span
class="math inline">\(\pi(\alpha_\sigma) v\)</span> is contained in the
space <span class="math inline">\(\pi(\mathcal{A}(\overline{\sigma }))
v\)</span>. By Lemma <a href="#lem:integral-ops-basic-properties"
data-reference-type="ref"
data-reference="lem:integral-ops-basic-properties">61</a>), the map
<span class="math display">\[\mathcal{A}(\overline{\sigma }) \ni f
\mapsto \pi(f) v \in V\]</span> is equivariant for the left regular
representation on the domain. We have seen that <span
class="math inline">\(\mathcal{A}(\overline{\sigma }) \cong
\mathcal{A}(\sigma ^*) \cong \mathop{\mathrm{End}}(\sigma^*) \cong
\sigma \otimes \sigma^*\)</span> as <span class="math inline">\(G \times
G\)</span>-representations. Under the left regular representation, <span
class="math inline">\(\mathcal{A}(\overline{\sigma })\)</span> is thus
isomorphic to <span class="math inline">\(\sigma^{\oplus
\dim(\sigma)}\)</span>, so we may write <span class="math inline">\(v =
\sum_{j=1}^{\dim(\sigma)} \pi(f_j) v\)</span> with each <span
class="math inline">\(f_j\)</span> in a subspace <span
class="math inline">\(\tilde{W}_j\)</span> of <span
class="math inline">\(\mathcal{A}(\overline{\sigma })\)</span>
isomorphic to <span class="math inline">\(\sigma\)</span>. Setting <span
class="math inline">\(v_j := \pi(f_j) v \in W_j :=
\pi(\tilde{W}_j)\)</span>, we have <span class="math inline">\(v = \sum
v_j\)</span>. If <span class="math inline">\(W_j\)</span> is nonzero,
then the irreducibility of <span class="math inline">\(\sigma\)</span>
implies that <span class="math inline">\(W_j \cong \sigma\)</span>. It
follows that <span class="math inline">\(v\)</span> is <span
class="math inline">\(\sigma\)</span>-isotypic.</p>
<p>If <span class="math inline">\(v \in V(\sigma)\)</span>, then <span
class="math inline">\(\pi(\alpha_\sigma) v = v\)</span>, because <span
class="math inline">\(\pi(\alpha_\sigma)\)</span> acts by the identity
on each of the subspaces <span class="math inline">\(W_j\)</span> that
arise in the definition of “<span
class="math inline">\(\sigma\)</span>-isotypic.”</p>
<p>We have shown that <span
class="math inline">\(\pi(\alpha_\sigma)\)</span> defines a projection
<span class="math inline">\(V \rightarrow V(\sigma)\)</span>. We have
<span class="math inline">\(\alpha_\sigma^*(g) =
\overline{\alpha_\sigma(g^{-1})} = \dim(\sigma) \chi_\sigma(g^{-1}) =
\dim(\sigma) \overline{\chi_\sigma(g)} = \alpha_\sigma(g)\)</span>, so
if <span class="math inline">\(\pi\)</span> is unitary, then (by Lemma
<a href="#lem:integral-ops-basic-properties" data-reference-type="ref"
data-reference="lem:integral-ops-basic-properties">61</a>) <span
class="math inline">\(\pi(\alpha_\sigma)\)</span> is self-adjoint, and
so defines the orthogonal projection.</p></li>
<li><p>We argue essentially as in §<a href="#sec:finite-dimens-irred"
data-reference-type="ref"
data-reference="sec:finite-dimens-irred">5.8</a>: for each <span
class="math inline">\(v \in V\)</span> and <span
class="math inline">\(\varepsilon&gt; 0\)</span>, we can find <span
class="math inline">\(f \in C(G)^{\mathop{\mathrm{class}}}\)</span> so
that <span class="math inline">\(\|\pi(f) v - v\| \leq
\varepsilon\)</span>. We can then decompose <span
class="math inline">\(f\)</span> in <span
class="math inline">\(L^2(G)^{\mathop{\mathrm{class}}}\)</span> as <span
class="math inline">\(\sum_{\sigma \in \mathop{\mathrm{Irr}}(G)}
c_\sigma \alpha_\sigma\)</span>, say; in particular, we can find a
finite subset <span class="math inline">\(\Sigma\)</span> of <span
class="math inline">\(\mathop{\mathrm{Irr}}(G)\)</span> so that <span
class="math inline">\(f&#39; := \sum_{\sigma \in \Sigma} c_\sigma
\alpha_\sigma\)</span> satisfies <span class="math inline">\(\|f&#39; -
f\|_{L^2} \leq \varepsilon\)</span>. Arguing as before, we get <span
class="math inline">\(\|\pi(f&#39;) v - v\| \leq \varepsilon(1 +
\|v\|)\)</span>. But <span class="math inline">\(\pi(f&#39;) v =
\sum_{\sigma \in \Sigma} c_\sigma \pi(\alpha_\sigma) v \in
\oplus_{\sigma \in \Sigma} V(\sigma)\)</span>. Thus <span
class="math inline">\(\sum V(\sigma)\)</span> is dense in <span
class="math inline">\(V\)</span>. The sum is direct because if <span
class="math inline">\(v \in V(\sigma_1) \cap V(\sigma_2)\)</span> with
<span class="math inline">\(\sigma_1 \not\cong \sigma_2\)</span>, then
<span class="math inline">\(v = \pi(\alpha_{\sigma_1})
\pi(\alpha_{\sigma_2}) v = \pi(\alpha_{\sigma_1} \ast \alpha_{\sigma_2})
v\)</span>, which vanishes thanks to <a href="#eqn:convolving-idemps"
data-reference-type="eqref"
data-reference="eqn:convolving-idemps">\((36)\)</a>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<p><a href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a></p>
<h2 id="decompositions-of-compact-type-representations">Decompositions
of compact-type representations</h2>
<p>The decompositions of representations of a compact group noted above
(e.g., in theorems <a href="#thm:complete-reducibility-compact-group"
data-reference-type="ref"
data-reference="thm:complete-reducibility-compact-group">22</a>, <a
href="#thm:P-W-general" data-reference-type="ref"
data-reference="thm:P-W-general">57</a> and <a
href="#thm:isotyp-decomp-1" data-reference-type="ref"
data-reference="thm:isotyp-decomp-1">69</a>) do not hold in general when
<span class="math inline">\(G\)</span> is non-compact and <span
class="math inline">\(V\)</span> is infinite-dimensional. The main issue
is that there may then exist nontrivial representations having no
irreducible subrepresentations. For instance, the (right) regular
representation of <span class="math inline">\(\mathbb{R}\)</span> on
<span class="math inline">\(L^2(\mathbb{R})\)</span> has the property. A
basic result of Gelfand–Graev–Piatetski-Shapiro shows that a sufficient
condition on the representation for it to decompose as a sum of
irreducibles is that it be unitary and of compact type (Definition <a
href="#defn:compact-type" data-reference-type="ref"
data-reference="defn:compact-type">64</a>). This is very handy in
applications involving non-compact groups. Recall that
“subrepresentation” means “closed invariant subspace.”</p>
<div class="theorem">
<p><strong>Theorem 70</strong>. <em>Let <span
class="math inline">\(G\)</span> be locally compact and unimodular, and
let <span class="math inline">\((\pi,V)\)</span> be a unitary Hilbert
representation of compact type. Then <span
class="math inline">\(V\)</span> decomposes as a Hilbert direct sum of
irreducible subrepresentations <span class="math inline">\(V_j\)</span>,
each occurring with finite multiplicity (i.e., for each <span
class="math inline">\(j\)</span>, the number of <span
class="math inline">\(k\)</span> with <span class="math inline">\(V_j
\cong V_k\)</span> is finite).</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By Zorn’s lemma, we may find a maximal collection
<span class="math inline">\((V_j)\)</span> of mutually orthogonal
irreducible subrepresentations <span class="math inline">\(V_j\)</span>
of <span class="math inline">\(V\)</span>. We must show that <span
class="math inline">\(\oplus V_j\)</span> is dense in <span
class="math inline">\(V\)</span>. If not, then its orthogonal complement
<span class="math inline">\(V&#39;\)</span> is a nonzero representation,
satisfying the same hypotheses as <span
class="math inline">\(V\)</span>, which contains no irreducible
subrepresentations. Replacing <span class="math inline">\(V\)</span> by
<span class="math inline">\(V&#39;\)</span> if necessary, our task is
thus to show that if <span class="math inline">\(V\)</span> is nonzero,
then it contains at least one irreducible subrepresentation.</p>
<p>The results of §<a href="#sec:appr-vect-their"
data-reference-type="ref" data-reference="sec:appr-vect-their">5.4</a>
(applied to any nonzero vector <span class="math inline">\(v \in
V\)</span>, and with <span class="math inline">\(\varepsilon\)</span>
taken sufficiently small in terms of <span
class="math inline">\(v\)</span>) imply that there exists <span
class="math inline">\(f \in C_c(G)\)</span>, real-valued and with <span
class="math inline">\(f(g) = f(g^{-1})\)</span>, so that the integral
operator <span class="math inline">\(\pi(f)\)</span> is not identically
zero. Since <span class="math inline">\(\pi\)</span> is assumed of
compact type, the operator <span class="math inline">\(\pi(f)\)</span>
is compact. By construction, it is self-adjoint. By the spectral theory
of self-adjoint compact operators, we may find a nonzero real number
<span class="math inline">\(\lambda\)</span> so that the <span
class="math inline">\(\lambda\)</span>-eigenspace <span
class="math inline">\(V_\lambda\)</span> of <span
class="math inline">\(\pi(f)\)</span> is nonzero and
finite-dimensional.</p>
<p>Take any nonzero <span class="math inline">\(v \in
V_\lambda\)</span>, let <span class="math inline">\(G v\)</span> denote
its orbit under <span class="math inline">\(G\)</span>, and let <span
class="math inline">\(\langle G v \rangle\)</span> denote the closure of
the span of <span class="math inline">\(G v\)</span>. Then <span
class="math inline">\(\langle G v \rangle\)</span> is a
subrepresentation of <span class="math inline">\(V\)</span>; it is the
smallest subrepresentation containing <span
class="math inline">\(v\)</span>.</p>
<p>The key observation is that any decomposition of the representation
<span class="math inline">\(\langle G v \rangle\)</span> descends to a
decomposition of the vector <span class="math inline">\(v\)</span>
inside the finite-dimensional eigenspace <span
class="math inline">\(V_\lambda\)</span>. Indeed, if <span
class="math inline">\(\langle G v \rangle\)</span> is not reducible,
then it contains a nonzero proper subrepresentation <span
class="math inline">\(W_1\)</span>, whose orthogonal complement <span
class="math inline">\(W_1&#39;\)</span> in <span
class="math inline">\(\langle G v \rangle\)</span> is likewise
invariant, giving a decomposition <span class="math inline">\(\langle G
v \rangle = W_1 \oplus W_1&#39;\)</span>. The subspaces in this
decomposition are invariant by <span class="math inline">\(G\)</span>,
hence also by <span class="math inline">\(T := \pi(f) -
\lambda\)</span>, so writing <span class="math inline">\(v = v_1 +
v_1&#39;\)</span> with <span class="math inline">\(v_1 \in W_1\)</span>
and <span class="math inline">\(v_1&#39; \in W_1&#39;\)</span>, we
deduce from the identity <span class="math inline">\(T v = 0\)</span>
that in fact <span class="math inline">\(T v_1 = T v_1&#39; =
0\)</span>, hence that <span class="math inline">\(v_1, v_1&#39; \in
V_\lambda\)</span>.</p>
<p>We know that <span class="math inline">\(v_1\)</span> and <span
class="math inline">\(v_1&#39;\)</span> are both nonzero, because if
(say) <span class="math inline">\(v_1&#39; = 0\)</span>, then <span
class="math inline">\(v\)</span> belongs to the proper subrepresentation
<span class="math inline">\(W_1\)</span> of <span
class="math inline">\(\langle G v \rangle\)</span>, contrary to the
construction of the latter. Since <span
class="math inline">\(v_1&#39;\)</span> belongs to <span
class="math inline">\(V_\lambda\)</span> and to <span
class="math inline">\(\langle G v \rangle\)</span> but not to <span
class="math inline">\(W_1\)</span>, we have the strict containment <span id="eq:GGPS-monotonicity" class="math display">\[\label{eq:GGPS-monotonicity}\tag{37}
    V_\lambda \cap \langle G v_1 \rangle
    \subseteq
    V_\lambda \cap W_1
    \subsetneq
    V_\lambda \cap \langle G v \rangle\]</span> between
finite-dimensional spaces. We now repeat the same construction but with
<span class="math inline">\(v\)</span> replaced by <span
class="math inline">\(v_1\)</span>. If <span
class="math inline">\(\langle G v_1 \rangle\)</span> is reducible, then
we may decompose it as <span class="math inline">\(W_2 \oplus
W_2&#39;\)</span> and likewise <span class="math inline">\(v_1\)</span>
as <span class="math inline">\(v_2 + v_2&#39;\)</span>, with <span
class="math inline">\(v_2, v_2&#39; \in V_\lambda\)</span>. If <span
class="math inline">\(\langle G v_2 \rangle\)</span> is reducible, then
we may decompose <span class="math inline">\(v_2 = v_3 +
v_3&#39;\)</span>. Thanks to <a href="#eq:GGPS-monotonicity"
data-reference-type="eqref"
data-reference="eq:GGPS-monotonicity">\((37)\)</a>, this
procedure gives us an irreducible subrepresentation after at most <span
class="math inline">\(\dim(V_\lambda \cap \langle G v \rangle)\)</span>
iterations.</p>
<p>The slicker way to write the proof is of course to assume from the
outset that <span class="math inline">\(v\)</span> was chosen to
minimize the dimension of <span class="math inline">\(V_{\lambda} \cap
\langle G v \rangle\)</span>; reducibility of <span
class="math inline">\(\langle G v \rangle\)</span> then gives a
contradiction.</p>
<p>For the finiteness of multiplicity, we can find for each <span
class="math inline">\(V_j\)</span> a self-adjoint integral operator
<span class="math inline">\(\pi(f)\)</span> having some nonzero
eigenvalue <span class="math inline">\(\lambda\)</span> in <span
class="math inline">\(V_j\)</span>. The same eigenvalue then shows up in
every <span class="math inline">\(V_k\)</span> that is isomorphic to
<span class="math inline">\(V_j\)</span>. Since <span
class="math inline">\(\pi(f)\)</span> is assumed compact, its
eigenspaces are finite-dimensional, and so the number of such <span
class="math inline">\(V_k\)</span> is finite. ◻</p>
</span></div>
<h1 id="algebraicity-of-compact-lie-groups">Algebraicity of compact Lie
groups</h1>
<p>Our goal is to explain the meaning and proof of the phrase “every
compact Lie group is algebraic.” This serves both as an application of
the theory developed so far and as a tool for further study also of
non-compact groups.</p>
<h2 id="preliminaries-on-algebraic-groups">Preliminaries on algebraic
groups</h2>
<p>First, we need to “review” some basics on algebraic groups.</p>
<div class="definition">
<p><strong>Definition 71</strong>. Let <span
class="math inline">\(k\)</span> be an infinite field and <span
class="math inline">\(n \geq 0\)</span>. For a collection <span
class="math inline">\(S \subseteq k[x_1,\dotsc,x_n]\)</span> of
polynomials, the <em>vanishing locus</em> <span
class="math inline">\(V(S)\)</span> is the set <span
class="math display">\[V(S) := \{p \in k^n : f(p) = 0 \text{ for all } f
\in S\}\]</span> of common zeros. An <em>algebraic subset</em> of <span
class="math inline">\(k^n\)</span> is a subset of the form <span
class="math inline">\(V(S)\)</span> for some <span
class="math inline">\(S\)</span>; that is to say, it is a subset defined
by polynomial equations.</p>
<p>The <em>vanishing ideal</em> of a subset <span
class="math inline">\(X\)</span> of <span
class="math inline">\(k^n\)</span> is given by <span
class="math display">\[I(X) := \{f \in k[x_1,\dotsc,x_n] : f(p) = 0
\text{ for all } p \in X\}.\]</span> The <em>coordinate ring</em> of an
algebraic subset <span class="math inline">\(X \subseteq k^n\)</span> is
the ring <span class="math display">\[k[X] :=
k[x_1,\dotsc,x_n]/I(X),\]</span> which may be regarded as the space of
“polynomial functions from <span class="math inline">\(X\)</span> to
<span class="math inline">\(k\)</span>.” The <em>Zariski topology</em>
on <span class="math inline">\(k^n\)</span> (or any algebraic subset
thereof) is that for which the closed subsets are the algebraic
sets.</p>
</div>
<p>We note that Hilbert’s basis theorem implies that for each <span
class="math inline">\(S\)</span> there exists a finite subset <span
class="math inline">\(S_0 \subset S\)</span> so that <span
class="math inline">\(V(S) = V(S_0)\)</span>, so that any algebraic set
may be defined by finitely-many polynomial equations.</p>
<p>It’s not hard to check that the “Zariski topology” as described above
defines an actual topology. By comparison, a basic theorem in topology
says that in a nice enough topological space <span
class="math inline">\(X\)</span> (e.g., a compact metric space), for any
closed subset <span class="math inline">\(Z \subseteq X\)</span> there
exists a continuous function <span class="math inline">\(f : X
\rightarrow \mathbb{R}\)</span> so that <span class="math inline">\(Z =
\{p \in X : f(p) = 0 \}\)</span>, hence that the closed subsets of <span
class="math inline">\(X\)</span> are precisely those that can be defined
by <em>continuous</em> equations. The analogy with the Zariski topology
should be clear.</p>
<p><em>Morphisms</em> between algebraic sets <span
class="math inline">\(X \subseteq k^m\)</span> and <span
class="math inline">\(Y \subseteq k^n\)</span> are maps <span
class="math inline">\(X \rightarrow Y\)</span> defined by polynomials in
the coordinates. They are obviously Zariski continuous. We obtain in
this way a category, with objects the algebraic sets and morphisms the
morphisms. An <em>affine variety</em> is basically the same thing as an
algebraic set, but (by some conventions) without emphasis on any
particular embedding in some <span
class="math inline">\(k^n\)</span>.</p>
<p>Given two sets <span class="math inline">\(X \subseteq k^m\)</span>
and <span class="math inline">\(Y \subseteq k^n\)</span>, we may define
their product <span class="math inline">\(X \times Y \subseteq
k^{m+n}\)</span>. If <span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> are algebraic, then so is <span
class="math inline">\(X \times Y\)</span>: if <span
class="math inline">\(X = V(S_1)\)</span> and <span
class="math inline">\(Y = V(S_2)\)</span>, then <span
class="math inline">\(X \times Y = V(\{f_1 \otimes f_2 : f_1 \in S_1,
f_2 \in S_2\})\)</span>, where <span class="math inline">\((f_1 \otimes
f_2)(p,q) := f_1(p) f_2(q)\)</span> for <span class="math inline">\(p
\in k^m, q \in k^n\)</span>. We may thus speak of the Zariski topology
on <span class="math inline">\(X \times Y\)</span> with respect to <span
class="math inline">\(k^{m + n}\)</span>. We caution that this is not in
general the same as the product of the Zariski topologies on <span
class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span>.</p>
<p>Given an algebraic set <span class="math inline">\(X\)</span>, we’ll
sometimes abuse notation slightly by defining <span
class="math inline">\(V(S)\)</span> for a subset <span
class="math inline">\(S\)</span> of <span
class="math inline">\(k[X]\)</span> to be the set of common zeros inside
<span class="math inline">\(X\)</span> of elements of <span
class="math inline">\(S\)</span>, and, for a subset <span
class="math inline">\(Y\)</span> of <span
class="math inline">\(X\)</span>, by <span
class="math inline">\(I(Y)\)</span> the ideal in <span
class="math inline">\(k[X]\)</span> consisting of <span
class="math inline">\(f\)</span> that vanish on <span
class="math inline">\(Y\)</span>. Any such abuse should be clear by
context.</p>
<p>As a basic example of reasoning with these definitions, we verify the
following:</p>
<div class="lemma">
<p><strong>Lemma 72</strong>. For any subset <span
class="math inline">\(X \subseteq k^n\)</span>, the Zariski closure
<span class="math inline">\(\mathop{\mathrm{Zcl}}(X)\)</span> is equal
to <span class="math inline">\(V(I(X))\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Well, <span class="math inline">\(V(I(X))\)</span>
contains <span class="math inline">\(X\)</span> (“<span
class="math inline">\(X\)</span> vanishes under any polynomial that
vanishes on <span class="math inline">\(X\)</span>”), and <span
class="math inline">\(V(I(X))\)</span> is algebraic, hence Zariski
closed. Conversely, let <span class="math inline">\(Y\)</span> be any
Zariski closed set containing <span class="math inline">\(X\)</span>,
thus <span class="math inline">\(Y = V(T)\)</span> for some <span
class="math inline">\(T \subseteq k[x_1,\dotsc,x_n]\)</span>. Since
<span class="math inline">\(X \subseteq V(T)\)</span> (“<span
class="math inline">\(X\)</span> vanishes under every element of <span
class="math inline">\(T\)</span>”), we have <span
class="math inline">\(T \subseteq I(X)\)</span> (“every element of <span
class="math inline">\(T\)</span> vanishes on <span
class="math inline">\(X\)</span>”), and so <span
class="math inline">\(V(T) \supseteq V(I(X))\)</span> (“the more
equations, the fewer solutions”). Thus <span
class="math inline">\(V(I(X))\)</span> is the smallest Zariski closed
set containing <span class="math inline">\(X\)</span>, as
required. ◻</p>
</span></div>
<p>The group <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(k)\)</span> of invertible
matrices is not obviously algebraic, because it is defined inside the
ambient space of matrices <span class="math inline">\(M_n(k) \cong
k^{n^2}\)</span> by the polynomial <em>inequation</em> <span
class="math inline">\(\det \neq 0\)</span> rather than by a system of
polynomial <em>equations</em>. We “make it algebraic” by using the
embedding <span class="math display">\[{\mathop{\mathrm{GL}}}_n(k) \cong
\{(x,y) \in M_n(k)^2 : x y = 1 \} \subseteq M_n(k)^2 \cong k^{2
n^2}\]</span> <span class="math display">\[g \mapsto (g,
g^{-1}),\]</span> to view <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(k)\)</span> as an algebraic
subset of <span class="math inline">\(k^{2 n^2}\)</span>. Then the
coordinate ring <span
class="math inline">\(k[{\mathop{\mathrm{GL}}}_n(k)]\)</span> consists of
functions <span class="math inline">\({\mathop{\mathrm{GL}}}_n \rightarrow
k\)</span> given by polynomials in the entries of a matrix together with
its inverse.</p>
<div id="sec:alg-gp-ad-hoc" class="definition">
<p><strong>Definition 73</strong>. An <em>algebraic group</em> is an
abstract subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(k)\)</span> that is also an
algebraic set.</p>
</div>
<p>When <span class="math inline">\(k = \mathbb{C}\)</span>, we speak of
a complex algebraic group. When <span class="math inline">\(k =
\mathbb{R}\)</span>, we speak of a real algebraic group. Note that we
may think of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> as a
real algebraic subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_{2n}(\mathbb{R})\)</span>.
Note also that algebraic groups over <span class="math inline">\(k =
\mathbb{R}\)</span> or <span class="math inline">\(\mathbb{C}\)</span>
are Lie groups (e.g., by the general theorem that closed subgroups of
matrix groups are Lie groups).</p>
<p>Definition <a href="#sec:alg-gp-ad-hoc" data-reference-type="ref"
data-reference="sec:alg-gp-ad-hoc">73</a> is a bit <em>ad hoc</em>. In
much the same way that we defined compact Lie groups first without
reference to any matrix embedding and then showed as a consequence
(Corollary <a href="#sec:cor-peter-weyl-matrix"
data-reference-type="ref"
data-reference="sec:cor-peter-weyl-matrix">58</a>) of the Peter–Weyl
theorem that such an embedding exists, one might more properly define an
algebraic group to be an algebraic set equipped with a group law for
which multiplication and inversion are described in coordinates via
polynomials. Arguments similar to those in the proof of Corollary <a
href="#sec:cor-peter-weyl-matrix" data-reference-type="ref"
data-reference="sec:cor-peter-weyl-matrix">58</a> then confirm that this
apparently more general definition is ultimately equivalent to what
we’ve given here.</p>
<div id="lem:zcl-gp-alg" class="lemma">
<p><strong>Lemma 74</strong>. If <span class="math inline">\(G\)</span>
is an algebraic group and <span class="math inline">\(H &lt; G\)</span>
is an abstract subgroup, then the Zariski closure <span
class="math inline">\(\mathop{\mathrm{Zcl}}(H)\)</span> of <span
class="math inline">\(H\)</span> inside <span
class="math inline">\(G\)</span> is an algebraic subgroup of <span
class="math inline">\(G\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We just need to check that <span
class="math inline">\(\mathop{\mathrm{Zcl}}(H)\)</span> is closed under
multiplication and inversion. We check this for multiplication, leaving
the case of inversion to the reader (alternatively, one could get fancy
and consider maps like <span class="math inline">\((p,q) \mapsto p
q^{-1}\)</span>). Let <span class="math inline">\(p,q \in
\mathop{\mathrm{Zcl}}(H)\)</span>, and let <span class="math inline">\(p
q \in U \subseteq G\)</span> be a neighborhood. Since matrix
multiplication is described by polynomials, it is Zariski continuous,
and so we can find a neighborhood <span class="math inline">\(p \in V_1
\subseteq G\)</span> so that <span class="math inline">\(p&#39; q \in
U\)</span> for all <span class="math inline">\(p&#39; \in V_1\)</span>.
Since <span class="math inline">\(p\)</span> belongs to the closure of
<span class="math inline">\(H\)</span>, we know that <span
class="math inline">\(V_1\)</span> intersects <span
class="math inline">\(H\)</span>, so choose some <span
class="math inline">\(p&#39; \in V_1 \cap H\)</span>. Then <span
class="math inline">\(p&#39; q \in U\)</span>, so by the same argument,
we can find a neighborhood <span class="math inline">\(q \in V_2
\subseteq G\)</span> so that <span class="math inline">\(p&#39; q&#39;
\in U\)</span> for all <span class="math inline">\(q&#39; \in
V_2\)</span>. Since <span class="math inline">\(q\)</span> is in the
closure of <span class="math inline">\(H\)</span>, we know that <span
class="math inline">\(V_2\)</span> intersects <span
class="math inline">\(H\)</span>, so we may find some <span
class="math inline">\(q&#39; \in V_2 \cap H\)</span>. Since <span
class="math inline">\(H\)</span> is a subgroup, we then have <span
class="math inline">\(p&#39; q&#39; \in U \cap H\)</span>, so <span
class="math inline">\(U\)</span> intersects <span
class="math inline">\(H\)</span>. Since <span
class="math inline">\(U\)</span> was arbitrary, we conclude that <span
class="math inline">\(p q \in \mathop{\mathrm{Zcl}}(H)\)</span>. ◻</p>
</span></div>
<h2 id="complexification-of-a-compact-lie-group">Complexification of a
compact Lie group</h2>
<p>Now let <span class="math inline">\(K\)</span> be a compact subgroup
of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, hence
a Lie subgroup. Recall also, by Corollary <a
href="#sec:cor-peter-weyl-matrix" data-reference-type="ref"
data-reference="sec:cor-peter-weyl-matrix">58</a>, that every compact
Lie group is of this form. Since the standard representation <span
class="math inline">\(K \hookrightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> is unitarizable, we know
that <span class="math inline">\(K\)</span> is conjugate to a subgroup
of <span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. Let’s
assume for convenience that in fact <span class="math inline">\(K \leq
\mathop{\mathrm{U}}(n)\)</span>. Let <span
class="math inline">\(G\)</span> denote the complex Zariski closure of
<span class="math inline">\(K\)</span> in <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, thus
<span class="math display">\[G = \{g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{C}) : f(g) = 0 \text{ for all } f \in
\mathbb{C}[{\mathop{\mathrm{GL}}}_n(\mathbb{C})] \text{ with } f|_K = 0
\},\]</span> where as before <span
class="math inline">\(\mathbb{C}[{\mathop{\mathrm{GL}}}_n(\mathbb{C})]\)</span>
denotes the space of functions <span class="math inline">\(f :
{\mathop{\mathrm{GL}}}_n (\mathbb{C} ) \rightarrow \mathbb{C}\)</span>
given by polynomials in the entries of a matrix together with its
inverse. (For example, if <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, then <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>.) We denote by <span
class="math display">\[\Theta : {\mathop{\mathrm{GL}}}_n(\mathbb{C})
\rightarrow {\mathop{\mathrm{GL}}}_n(\mathbb{C})\]</span> the “inverse
conjugate transpose” map <span class="math display">\[\Theta(g) := {}^t
\overline{g}^{-1} = (g^*)^{-1}, \quad g^* := {}^t \overline{g}\]</span>
and by <span class="math display">\[\theta :
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C}) \rightarrow
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\]</span> <span
class="math display">\[\theta(x) := - {}^t \overline{x} = - x^*, \quad
x^* := {}^t \overline{x}\]</span> its differential. Observe that <span
class="math inline">\(\mathop{\mathrm{U}}(n) = \{ g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{C}) : \Theta(g) = g\}\)</span> and <span
class="math inline">\(\mathfrak{u}(n) = \{ x \in
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C}) : \theta(x) =
x\}\)</span>.</p>
<div id="thm:complexification-compact-lie-basic-properties"
class="theorem">
<p><strong>Theorem 75</strong>. <em>With notation and assumptions as
above:</em></p>
<ol type="i">
<li><p><em><span class="math inline">\(G\)</span> is a complex algebraic
group that is closed under <span
class="math inline">\(\Theta\)</span>.</em></p></li>
<li><p><em>The map <span class="math inline">\(\mathbb{C}[G] \rightarrow
\{\text{functions } K \rightarrow \mathbb{C} \}\)</span> given by
restriction <span class="math inline">\(f \mapsto f|_K\)</span> induces
an isomorphism <span class="math inline">\(\mathbb{C}[G] \cong
\mathcal{A}(K)\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(K = G \cap
\mathop{\mathrm{U}}(n)\)</span>. In particular, <span
class="math inline">\(K\)</span> is a real algebraic group.<a
href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></em></p></li>
<li><p><em><span class="math inline">\(K\)</span> is a maximal compact
subgroup of G.</em></p></li>
<li><p><em><span class="math inline">\(\mathfrak{g}\)</span> is closed
under <span class="math inline">\(\theta\)</span>. We have <span
class="math inline">\(\mathfrak{k} = \mathfrak{g} \cap \mathfrak{u}(n) =
\{x \in \mathfrak{g} : \theta(x) = x \}\)</span>. Setting <span
class="math inline">\(\mathfrak{p} := \{x \in \mathfrak{g} : \theta(x) =
- x\}\)</span>, we have <span class="math inline">\(\mathfrak{p} = i
\mathfrak{k}\)</span> and <span class="math inline">\(\mathfrak{g} =
\mathfrak{k} \oplus \mathfrak{p}\)</span>.</em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>By lemma <a href="#lem:zcl-gp-alg" data-reference-type="ref"
data-reference="lem:zcl-gp-alg">74</a>, <span
class="math inline">\(G\)</span> is a complex algebraic group. Since
<span class="math inline">\(\Theta\)</span> fixes <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> pointwise and
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> contains
<span class="math inline">\(K\)</span>, we have in particular <span
class="math inline">\(\Theta(K) = K\)</span>. It follows that the space
<span class="math inline">\(I(K)\)</span> of polynomials <span
class="math inline">\(f \in
\mathbb{C}[{\mathop{\mathrm{GL}}}_n(\mathbb{C})]\)</span> that vanish on
<span class="math inline">\(K\)</span> is closed under the map <span
class="math display">\[f \mapsto \overline{f \circ \Theta} : g \mapsto
\overline{f(\Theta(g))} = \overline{f({}^t \overline{g}^{-1})},\]</span>
hence that <span class="math inline">\(G = V(I(K))\)</span> is closed
under <span class="math inline">\(\Theta\)</span>.</p></li>
<li><p>We observe first (as in the discussion of §<a
href="#sec:peter-weyl-theorem" data-reference-type="ref"
data-reference="sec:peter-weyl-theorem">4.9</a>) that <span
class="math inline">\(f|_K\)</span> belongs to <span
class="math inline">\(\mathcal{A}(K)\)</span>: indeed, <span
class="math inline">\(\mathbb{C}[G]\)</span> is the union over <span
class="math inline">\(d \geq 0\)</span> of the subspaces defined by
polynomials of degree bounded by <span class="math inline">\(d\)</span>,
each of which is finite-dimensional and <span
class="math inline">\(K\)</span>-invariant. We thus get a well-defined
map of <span class="math inline">\(\mathbb{C}\)</span>-algebras <span
class="math inline">\(\mathbb{C}[G] \rightarrow \mathcal{A}(K)\)</span>.
The injectivity of this map is clear from the definitions of <span
class="math inline">\(G\)</span> and of <span
class="math inline">\(\mathbb{C}[G] =
\mathbb{C}[{\mathop{\mathrm{GL}}}_n(\mathbb{C})]/I(K)\)</span>: if <span
class="math inline">\(f|_K = 0\)</span>, then <span
class="math inline">\(f \in I(K)\)</span>, i.e., <span
class="math inline">\(f = 0\)</span> as an element of <span
class="math inline">\(\mathbb{C}[G]\)</span>. We henceforth identify
<span class="math inline">\(\mathbb{C}[G]\)</span> with its image in
<span class="math inline">\(\mathcal{A}(K)\)</span>. It remains to show
that in fact <span class="math inline">\(\mathbb{C}[G] =
\mathcal{A}(K)\)</span>. To that end, observe first that <span
class="math inline">\(\mathbb{C}[G]\)</span> is invariant under the
action of <span class="math inline">\(K \times K\)</span> on <span
class="math inline">\(\mathcal{A}(K)\)</span> by left and right
translation (using here that matrix multiplication is described by
polynomials and that <span class="math inline">\(K\)</span> is a
subgroup of <span class="math inline">\(G\)</span>). Recall next that
<span class="math inline">\(\mathcal{A}(K)\)</span> is an orthogonal
direct sum of finite-dimensional subspaces <span
class="math inline">\(\mathcal{A}(\pi)\)</span>, taken over <span
class="math inline">\(\pi \in \mathop{\mathrm{Irr}}(K)\)</span>. Note
finally, thanks to the identity <span class="math inline">\(g =
\Theta(g)\)</span> satisfied by every <span class="math inline">\(g \in
K\)</span>, that <span class="math inline">\(\mathbb{C}[G]\)</span>
contains all polynomials in the real and imaginary parts of the entries
of a matrix <span class="math inline">\(g \in K\)</span> together with
its inverse. It follows by Stone-Weierstrass (as in the discussion of
§<a href="#sec:peter-weyl-theorem" data-reference-type="ref"
data-reference="sec:peter-weyl-theorem">4.9</a>) that <span
class="math inline">\(\mathbb{C}[G]\)</span> is dense in <span
class="math inline">\(\mathcal{A}(K)\)</span> with respect to the
topology of <span class="math inline">\(C(G)\)</span>.</p>
<p>To complete the proof, we just need to check that any <span
class="math inline">\(K \times K\)</span>-invariant dense subspace of
<span class="math inline">\(\mathcal{A}(K)\)</span> is actually equal to
<span class="math inline">\(\mathcal{A}(K)\)</span>. Maybe there’s a
simpler way to see this, but let’s see. We claim that for any finite
subset <span class="math inline">\(\Pi\)</span> of <span
class="math inline">\(\mathop{\mathrm{Irr}}(K)\)</span> and any <span
class="math inline">\(K \times K\)</span>-invariant subspace <span
class="math inline">\(V\)</span> of <span
class="math inline">\(\oplus_{\pi \in \Pi} \mathcal{A}(\pi)\)</span>,
one has <span class="math inline">\(V = \oplus_{\pi \in \Pi_0}
\mathcal{A}(\pi)\)</span> for some subset <span
class="math inline">\(\Pi_0\)</span> of <span
class="math inline">\(\Pi\)</span>. (To see that the claim suffices,
note that for each <span class="math inline">\(\pi \in
\mathop{\mathrm{Irr}}(K)\)</span>, we may find <span
class="math inline">\(f \in \mathbb{C}[G]\)</span> so that the component
<span class="math inline">\(f_\pi \in \mathcal{A}(\pi)\)</span> of <span
class="math inline">\(f\)</span> is nonzero, because otherwise <span
class="math inline">\(\mathbb{C}[G]\)</span> would be contained in the
proper closed subspace of <span
class="math inline">\(\mathcal{A}(K)\)</span> given by the orthogonal
complement of <span class="math inline">\(\mathcal{A}(\pi)\)</span>;
then take for <span class="math inline">\(\Pi\)</span> the set of all
<span class="math inline">\(\pi &#39;\)</span> for which <span
class="math inline">\(f_{\pi &#39;} \neq 0\)</span> and for <span
class="math inline">\(V\)</span> the span of the <span
class="math inline">\(K \times K\)</span>-orbit of <span
class="math inline">\(f\)</span>. It follows from the claim that then
<span class="math inline">\(\mathbb{C}[G]\)</span> contains <span
class="math inline">\(\mathcal{A}(\pi)\)</span>. Since <span
class="math inline">\(\pi\)</span> was arbitrary, we conclude that <span
class="math inline">\(\mathbb{C}[G] = \mathcal{A}(K)\)</span>.) The
claim follows immediately from character theory for <span
class="math inline">\(K \times K\)</span>, which gives that <span
class="math inline">\(\chi_V = \sum_{\pi \in \Pi} n(\pi)
\overline{\chi_\pi } \otimes \chi_\pi\)</span> for some <span
class="math inline">\(n(\pi) \in \{0,1\}\)</span>; here <span
class="math inline">\((\overline{\chi_\pi } \otimes \chi_\pi)(g_1,g_2)
:= \overline{\chi _\pi }(g_1) \chi_\pi(g_2)\)</span>.</p></li>
<li><p>Set <span class="math inline">\(M := G \cap
\mathop{\mathrm{U}}(n)\)</span>, so that <span class="math inline">\(K
\leq M \leq G\)</span>. Then <span class="math inline">\(M\)</span> is
compact, and <span class="math inline">\(G\)</span> is also the Zariski
closure of <span class="math inline">\(M\)</span>, so by what we’ve
already shown, the map <span class="math inline">\(\mathbb{C}[G]
\rightarrow \mathcal{A}(M)\)</span> is an isomorphism, hence in
particular has dense image in <span class="math inline">\(C(M)\)</span>.
It follows readily that <span class="math inline">\(M = K\)</span>.
Indeed, suppose otherwise that <span class="math inline">\(M\)</span> is
strictly larger than <span class="math inline">\(K\)</span>. We let
<span class="math inline">\(M\)</span> act on <span
class="math inline">\(C(M)\)</span> and <span
class="math inline">\(\mathcal{A}(M)\)</span> by the right regular
representation, and use superscripts as in <span
class="math inline">\(C(M)^K\)</span> to denote the fixed subspace, as
usual. We argue as follows:</p>
<ul>
<li><p><em><span class="math inline">\(C(M)^K\)</span> contains
non-constant functions.</em> Indeed, take any nonzero nonnegative <span
class="math inline">\(f \in C(M)\)</span> that vanishes on <span
class="math inline">\(K\)</span>, and consider the function <span
class="math inline">\(M \ni x \mapsto \int_{k \in K} f(x k)\)</span>,
where here and henceforth <span class="math inline">\(\int\)</span>
denotes an integral with respect to the probability Haar.</p></li>
<li><p><em><span class="math inline">\(\mathbb{C}[G]^K\)</span> contains
non-constant functions.</em> We have seen that <span
class="math inline">\(\mathbb{C}[G]\)</span> maps isomorphically to
<span class="math inline">\(\mathcal{A}(M)\)</span>, hence has dense
image in <span class="math inline">\(C(M)\)</span>. Take <span
class="math inline">\(f \in C(M)^K\)</span> non-constant, thus <span
class="math inline">\(f(x_1) \neq f(x_2)\)</span> for some <span
class="math inline">\(x_1, x_2 \in M\)</span>. Choose <span
class="math inline">\(\varepsilon&gt; 0\)</span> so that <span
class="math inline">\(|f(x_1) - f(x_2)| \geq 3 \varepsilon\)</span>.
Choose <span class="math inline">\(f&#39; \in \mathbb{C}[G]\)</span> so
that <span class="math inline">\(\|f - f&#39;\|_{\infty} \leq
\varepsilon\)</span>. Set <span class="math inline">\(f&#39;&#39;(x) :=
\int_{k \in K} f&#39;(x k)\)</span>. Then <span
class="math inline">\(f&#39;&#39; \in \mathbb{C}[G]^K\)</span>. By the
right <span class="math inline">\(K\)</span>-invariance of <span
class="math inline">\(f\)</span>, we have <span class="math inline">\((f
- f&#39;&#39;)(x) = \int_{k \in K} (f - f&#39;)(x k)\)</span>, hence by
the triangle inequality we have <span class="math inline">\(\|f -
f&#39;&#39;\|_{\infty} \leq \|f - f&#39; \|_{\infty} \leq
\varepsilon\)</span>. By another application of the triangle inequality,
we deduce that <span class="math inline">\(|f&#39;&#39;(x_1) -
f&#39;&#39;(x_2)| \geq \varepsilon\)</span>. Thus <span
class="math inline">\(f&#39;&#39;\)</span> is non-constant.</p></li>
<li><p><em>We obtain a contradiction.</em> We have seen that <span
class="math inline">\(\mathbb{C}[G]\)</span> injects into <span
class="math inline">\(\mathcal{A}(K)\)</span>, hence likewise <span
class="math inline">\(\mathbb{C}[G]^K\)</span> into <span
class="math inline">\(\mathcal{A}(K)^K\)</span>, but every element of
<span class="math inline">\(\mathcal{A}(K)^K\)</span> is manifestly
constant.</p></li>
</ul></li>
<li><p>If <span class="math inline">\(M\)</span> is a larger compact
subgroup, then we may assume (after conjugating) that it is contained in
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. Then both
<span class="math inline">\(M\)</span> and <span
class="math inline">\(K\)</span> are contained in <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> and have <span
class="math inline">\(G\)</span> as their Zariski closure, so by (iii),
we have <span class="math inline">\(K = G \cap \mathop{\mathrm{U}}(n) =
M\)</span>.</p></li>
<li><p>The identity <span class="math inline">\(\mathfrak{k} =
\mathfrak{g} \cap \mathfrak{u}(n)\)</span> follows from part (iii).
Since <span class="math inline">\(\theta^2 = 1\)</span>, we can
decompose <span class="math inline">\(\mathfrak{g}\)</span> into its
<span class="math inline">\(\pm 1\)</span> eigenspaces for <span
class="math inline">\(\theta\)</span>, i.e., <span
class="math inline">\(\mathfrak{g} = \mathfrak{k} \oplus
\mathfrak{p}\)</span>; explicitly, <span class="math inline">\(x = x^+ +
x^-\)</span>, where <span class="math inline">\(x^+ \in \mathfrak{k},
x^- \in \mathfrak{p}\)</span> are given by <span
class="math inline">\(x^{\pm} := (x \pm \theta (x))/2\)</span>. Since
<span class="math inline">\(\theta\)</span> is anti-linear,
multiplication by <span class="math inline">\(i\)</span> induces an
isomorphism <span class="math inline">\(x^+ \cong x^-\)</span>, i.e.,
<span class="math inline">\(\mathfrak{p} = i
\mathfrak{k}\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<div id="rmk:theta-vs-sigma" class="remark">
<p><strong>Remark 76</strong>. It wasn’t essential to refer to the group
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> here. The
definition of <span class="math inline">\(G\)</span> doesn’t involve it.
The involution <span class="math inline">\(f \mapsto \overline{f \circ
\Theta}\)</span> on <span class="math inline">\(\mathbb{C}[G]\)</span>
corresponds under the isomorphism <span
class="math inline">\(\mathbb{C}[G] \cong \mathcal{A}(K)\)</span> to the
involution <span class="math inline">\(\sigma\)</span> on <span
class="math inline">\(\mathcal{A}(K)\)</span> given by <span
class="math inline">\(\sigma(f)(k) = \overline{f(k)}\)</span> for all
<span class="math inline">\(k \in K\)</span>.</p>
</div>
<h2 id="a-glimpse-of-tannakian-duality">A glimpse of Tannakian
duality</h2>
<p>Here we address the question: how can we describe a compact Lie group
<span class="math inline">\(K\)</span> in terms of its coefficient ring
<span class="math inline">\(\mathcal{A}(K)\)</span>? We warm-up with
some motivating analogues.</p>
<ul>
<li><p>For an algebraic set <span class="math inline">\(X \subseteq
k^n\)</span> (over an infinite field <span
class="math inline">\(k\)</span>) with coordinate ring <span
class="math inline">\(k[X] = k[x_1,\dotsc,x_n]/I(X)\)</span>, we have a
bijection <span class="math display">\[X \leftrightarrow
{\mathop{\mathrm{Hom}}}_k(k[X],k)\]</span> <span class="math display">\[p
\mapsto [f \mapsto f(p)]\]</span> <span
class="math display">\[(\ell(x_1),\dotsc,\ell(x_n)) \mapsfrom
\ell\]</span> between points of <span class="math inline">\(X\)</span>
and functionals on the coordinate ring. Moreover, we can reconstruct
<span class="math inline">\(X\)</span> from the abstract <span
class="math inline">\(k\)</span>-algebra <span
class="math inline">\(k[X]\)</span> by choosing a system of generators
<span class="math inline">\(x_1,\dotsc,x_n\)</span>.</p></li>
<li><p>For an algebraic group <span class="math inline">\(G\)</span>
over <span class="math inline">\(k\)</span>, we can recover <span
class="math inline">\(G\)</span> as an algebraic set from <span
class="math inline">\({\mathop{\mathrm{Hom}}}_k(k[G],k)\)</span>, as
above, but we’d also like to keep track of the group law <span
class="math inline">\(G \times G \rightarrow G\)</span>. It corresponds
to the pullback map <span class="math display">\[\Delta : k[G]
\rightarrow k[G \times G] \cong k[G] \otimes k[G],\]</span> called
<em>comultiplication</em>, and characterized by the identity <span
class="math display">\[\Delta(f)(g_1,g_2) = f(g_1 g_2) \text{ for all }
f \in k[G] \text{ and } g_1,g_2 \in G.\]</span></p></li>
</ul>
<p>Now let <span class="math inline">\(K \leq
\mathop{\mathrm{U}}(n)\)</span> be a compact Lie group, with Zariski
closure <span class="math inline">\(G \leq
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> as above. Then <span id="eq:G-via-tannaka" class="math display">\[\label{eq:G-via-tannaka}\tag{38}
  G \cong {\mathop{\mathrm{Hom}}}_{\mathbb{C}}(\mathbb{C}[G],\mathbb{C})
\cong
{\mathop{\mathrm{Hom}}}_{\mathbb{C}}(\mathcal{A}(K),\mathbb{C}).\]</span>
The comultiplication <span class="math inline">\(\Delta\)</span> on
<span class="math inline">\(\mathbb{C}[G]\)</span> corresponds under the
isomorphism with <span class="math inline">\(\mathcal{A}(K)\)</span> to
the map <span class="math display">\[\Delta : \mathcal{A}(K) \rightarrow
\mathcal{A}(K) \otimes \mathcal{A}(K)\]</span> described explicitly in
terms of matrix coefficients by the usual matrix multiplication rule
<span class="math display">\[\Delta(\pi_{i j}) = \sum_{k} \pi_{i k}
\otimes \pi_{k j}\]</span> and in basis-free manner as the map induced
by the maps <span class="math inline">\(\mathop{\mathrm{End}}(V)^*
\rightarrow \mathop{\mathrm{End}}(V)^* \otimes
\mathop{\mathrm{End}}(V)^*\)</span> (<span
class="math inline">\(V\)</span> a finite-dimensional representation of
<span class="math inline">\(G\)</span>) coming from the multiplication
maps <span class="math inline">\(\mathop{\mathrm{End}}(V) \otimes
\mathop{\mathrm{End}}(V) \rightarrow
\mathop{\mathrm{End}}(V)\)</span>.</p>
<p>These observations already show that <span
class="math inline">\(G\)</span> is determined as an algebraic group by
the pair <span class="math inline">\((\mathcal{A}(K),\Delta)\)</span>;
in particular, <span class="math inline">\(G\)</span> is independent of
the choice of linear embedding used in its construction. We will
henceforth refer to <span class="math inline">\(G\)</span> as the
<em>complexification</em> of <span class="math inline">\(K\)</span>.</p>
<p>We can say something similar about <span
class="math inline">\(K\)</span>:</p>
<div class="theorem">
<p><strong>Theorem 77</strong>. <em>Let <span
class="math inline">\(K\)</span> be a compact Lie group. Then the map
<span class="math inline">\(k \mapsto [f \mapsto f(k)]\)</span> defines
a bijection <span id="eq:K-via-tannaka" class="math display">\[\label{eq:K-via-tannaka}\tag{39}
    K \leftrightarrow \{\ell \in
    {\mathop{\mathrm{Hom}}}_{\mathbb{C}}(\mathcal{A}(K),\mathbb{C})
    :
    \ell(\sigma(f)) = \overline{f}
    \text{ for all } f \in \mathcal{A}(K)
    \},\]</span> where <span class="math inline">\(\sigma :
\mathcal{A}(K) \rightarrow \mathcal{A}(K)\)</span> is given by complex
conjugation. The group law on <span class="math inline">\(K\)</span> is
described by <span class="math inline">\(\Delta\)</span>, i.e., for all
<span class="math inline">\(f \in \mathcal{A}(K)\)</span> and <span
class="math inline">\(k_1,k_2 \in K\)</span>, we have <span
class="math inline">\(f(k_1 k_2) = \Delta(f)
(k_1,k_2)\)</span>.</em></p>
</div>
<p>Informally, “<span
class="math inline">\((\mathcal{A}(K),\Delta)\)</span> determines <span
class="math inline">\(K\)</span>.”</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(G\)</span> be as
constructed above, and let <span class="math inline">\(\ell\)</span> be
an element of the RHS of <a href="#eq:K-via-tannaka"
data-reference-type="eqref"
data-reference="eq:K-via-tannaka">\((39)\)</a>. By <a
href="#eq:G-via-tannaka" data-reference-type="eqref"
data-reference="eq:G-via-tannaka">\((38)\)</a>, we may write
<span class="math inline">\(\ell(f) = f(g)\)</span> for some <span
class="math inline">\(g \in G\)</span>. By Remark <a
href="#rmk:theta-vs-sigma" data-reference-type="ref"
data-reference="rmk:theta-vs-sigma">76</a>, we have <span
class="math inline">\(\overline{f(\Theta(g))} = f(g)\)</span> for all
<span class="math inline">\(f \in \mathbb{C}[G]\)</span>, hence <span
class="math inline">\(\Theta(g) = g\)</span>. By Theorem <a
href="#thm:complexification-compact-lie-basic-properties"
data-reference-type="ref"
data-reference="thm:complexification-compact-lie-basic-properties">75</a>,
we conclude that <span class="math inline">\(g \in K\)</span>. ◻</p>
</span></div>
<p>There’s much more to say about this topic than we will here. Some
keywords: Tannaka–Krein duality, Hopf algebras.</p>
<h2 id="sec:cartan-decomposition">§6.4. Cartan decomposition</h2>
<p>Set <span class="math display">\[P(n) := \{g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{C}) : p^* = p, \text{ positive-definite}
\},\]</span> <span class="math display">\[\mathfrak{p}(n) := \{x \in
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C}) : x^* = x
\}.\]</span> Then the map <span class="math inline">\(\exp :
\mathfrak{p}(n) \rightarrow P(n)\)</span> is a bijection; indeed, by the
spectral theorem for hermitian matrices, we have for each <span
class="math inline">\(x \in \mathfrak{p}(n)\)</span> and <span
class="math inline">\(p \in P(n)\)</span> that <span
class="math display">\[x \sim
  \begin{pmatrix}
    x_1 &amp;  &amp;  \\
    &amp; \dotsb  &amp;  \\
    &amp; &amp; x_n
  \end{pmatrix}
, \quad p \sim
  \begin{pmatrix}
    p_1 &amp;  &amp;  \\
    &amp; \dotsb  &amp;  \\
    &amp; &amp; p_n
  \end{pmatrix}\]</span> for some <span class="math inline">\(x_i \in
\mathbb{R}, p_j \in \mathbb{R}_{&gt;0}\)</span>, where <span
class="math inline">\(\sim\)</span> denotes conjugacy. We deduce readily
that <span class="math inline">\(\exp : \mathfrak{p}(n) \rightarrow
P(n)\)</span> and <span class="math inline">\(\log : P(n) \rightarrow
\mathfrak{p}(n)\)</span> (with the latter defined by the “functional
calculus,” i.e., by taking the logarithm of each diagonal entry) define
mutually inverse bijections. Note that for <span class="math inline">\(p
\in P(n)\)</span>, we can define <span
class="math inline">\(p^t\)</span> for any complex number <span
class="math inline">\(t\)</span>, either via the logarithm as <span
class="math inline">\(\exp(t \log p)\)</span> or directly via the
functional calculus.</p>
<p>The following might be known from linear algebra:</p>
<div class="lemma">
<p><strong>Lemma 78</strong> (Polar decomposition). The map <span
class="math inline">\(\mathop{\mathrm{U}}(n) \times P(n) \rightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> given by <span
class="math inline">\((k,p) \mapsto k p\)</span> is bijective.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Injectivity: if <span class="math inline">\(g = k
p\)</span>, then <span class="math inline">\(g^* g = p^* k^* k p =
p^2\)</span>, so <span class="math inline">\(p = \sqrt{p^2} :=
\exp(\tfrac{1}{2} \log p)\)</span> and thus also <span
class="math inline">\(k = g p^{-1}\)</span> are determined by <span
class="math inline">\(g\)</span>. Surjectivity: observe that <span
class="math inline">\(g^* g \in P(n)\)</span> and define <span
class="math inline">\(p := \sqrt{g^* g} \in P(n)\)</span>, <span
class="math inline">\(k := g p^{-1} \in
\mathop{\mathrm{U}}(n)\)</span>. ◻</p>
</span></div>
<div id="lem:polar-decomp" class="lemma">
<p><strong>Lemma 79</strong>. The map <span
class="math display">\[\mathop{\mathrm{U}}(n) \times \mathfrak{p}(n)
\rightarrow {\mathop{\mathrm{GL}}}_n(\mathbb{C})\]</span> <span
class="math display">\[(k,x) \mapsto k \exp(x)\]</span> is a
diffeomorphism.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We have already checked the bijectivity. The forward
map is smooth. We need to know that the inverse is smooth. This boils
down to the fact that <span class="math inline">\(\exp : \mathfrak{p}(n)
\rightarrow P(n)\)</span> is submersive, which is a consequence of the
following lemma and the fact that for <span class="math inline">\(x \in
\mathfrak{p}(n)\)</span>, the eigenvalues of <span
class="math inline">\({\mathop{\mathrm{ad}}}_x\)</span> are real. ◻</p>
</span></div>
<p>The following is part of the BCHD law, and describes the derivative
of the exponential map on any Lie group.</p>
<div id="lem:deriv-of-expo" class="lemma">
<p><strong>Lemma 80</strong>. Let <span class="math inline">\(G\)</span>
be any Lie group, Fix <span class="math inline">\(x \in
\mathfrak{g}\)</span>. Let <span class="math inline">\(z \in
\mathfrak{g}\)</span> be small enough. Let <span class="math inline">\(y
\in \mathfrak{g}\)</span> be the small element for which <span
class="math display">\[\exp(x + z) = \exp(x) \exp(y).\]</span> Then
<span class="math display">\[y = F({\mathop{\mathrm{ad}}}_x) z +
\operatorname{O}(|z|^2),\]</span> where <span
class="math display">\[F(t) := \frac{1 - e^{-t }}{t}
    = 1 - \frac{t}{2!}
    + \frac{t^2}{3!} - \dotsb.\]</span> In particular, <span
class="math inline">\(\exp\)</span> is a local diffeomorphism at <span
class="math inline">\(x\)</span> iff <span
class="math inline">\(F({\mathop{\mathrm{ad}}}_x)\)</span> is invertible
iff <span class="math inline">\({\mathop{\mathrm{ad}}}_x\)</span> has no
eigenvalues of the form <span class="math inline">\(2 \pi i k\)</span>,
with <span class="math inline">\(0 \neq k \in \mathbb{Z}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> (Omitted from lecture.) For <span
class="math inline">\(t \in [0,1]\)</span>, set <span
class="math inline">\(f(t) := \log (\exp(-t x) \exp(t (x+z)))\)</span>,
so that <span class="math inline">\(f(0) = 0\)</span> and <span
class="math inline">\(f(1) = y\)</span>. We compute that for small <span
class="math inline">\(\varepsilon&gt; 0\)</span>, <span
class="math display">\[f(t + \varepsilon)
    = {\mathop{\mathrm{Ad}}}_{-t x} (\varepsilon z) + t z +
\operatorname{O}(\varepsilon|z|^2 + \varepsilon^2),\]</span> where <span
class="math inline">\({\mathop{\mathrm{Ad}}}_x :=
e^{{\mathop{\mathrm{ad}}}_x} = \mathop{\mathrm{Ad}}(e^x)\)</span>. (To see
this, first write <span class="math inline">\(\exp(-(t + \varepsilon) x)
\exp((t+\varepsilon)(x+z)) = \exp(-t x) \exp(-\varepsilon x)
\exp(\varepsilon(x+z)) \exp(t(x+z))\)</span>, then approximate <span
class="math inline">\(\exp(-\varepsilon x) \exp(\varepsilon(x+z)) =
\exp(\varepsilon z + \operatorname{O}(\varepsilon^2))\)</span> and
deduce that <span class="math inline">\(f(t+\varepsilon) =
\log(\exp({\mathop{\mathrm{Ad}}}_{-t x}(\varepsilon z) +
\operatorname{O}(\varepsilon^2)) \exp(\operatorname{O}(z))) =
{\mathop{\mathrm{Ad}}}_{-t x}(\varepsilon z) +
\operatorname{O}(\varepsilon|z|^2 + \varepsilon^2)\)</span>, as
required.) Thus <span class="math display">\[f&#39;(t) =
{\mathop{\mathrm{Ad}}}_{-t x}(z) + \operatorname{O}(|z|^2)\]</span> and so
<span class="math display">\[y = \int_{t = 0}^{1} e^{-t
{\mathop{\mathrm{ad}}}_x} z \, d t + \operatorname{O}(|z|^2),\]</span>
which leads to the required conclusion by the formula <span
class="math inline">\(\int_{t=0}^1 e^{-t u} \, d t =
F(u)\)</span>. ◻</p>
</span></div>
<div class="theorem">
<p><strong>Theorem 81</strong>. <em>Let <span
class="math inline">\(K\)</span> be a compact Lie group, with
complexification <span class="math inline">\(G\)</span>. Write <span
class="math inline">\(\mathfrak{g} = \mathfrak{k} \oplus
\mathfrak{p}\)</span> as in Theorem <a
href="#thm:complexification-compact-lie-basic-properties"
data-reference-type="ref"
data-reference="thm:complexification-compact-lie-basic-properties">75</a>.
Then the map <span class="math display">\[K \times \mathfrak{p}
\rightarrow G\]</span> <span class="math display">\[(k,x) \mapsto k
\exp(x)\]</span> is a diffeomorphism. In particular,</em></p>
<ul>
<li><p><em><span class="math inline">\(K\)</span> is a deformation
retract of <span class="math inline">\(G\)</span>,</em></p></li>
<li><p><em><span class="math inline">\(K\)</span> meets every connected
component of <span class="math inline">\(G\)</span>,</em></p></li>
<li><p><em><span class="math inline">\(K\)</span> is connected if and
only if <span class="math inline">\(G\)</span> is
connected,</em></p></li>
</ul>
<p><em>and so on.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> In view of Lemma <a href="#lem:polar-decomp"
data-reference-type="ref" data-reference="lem:polar-decomp">79</a>, we
just need to check that if <span class="math inline">\(g \in G\)</span>
is written <span class="math inline">\(g = k p\)</span> with <span
class="math inline">\(k \in \mathop{\mathrm{U}}(n)\)</span> and <span
class="math inline">\(p \in P(n)\)</span>, then in fact <span
class="math inline">\(p \in P := \exp(\mathfrak{p})\)</span>; it follows
then <span class="math inline">\(p \in G\)</span>, hence that <span
class="math inline">\(k = g p^{-1} \in G \cap \mathop{\mathrm{U}}(n) =
K\)</span>. It will suffice to show that <span class="math inline">\(p^t
\in G\)</span> for all <span class="math inline">\(t \in
\mathbb{R}\)</span>, because then <span
class="math inline">\(\partial_{t=0} p^t\)</span> belongs to <span
class="math inline">\(\mathfrak{g} \cap \mathfrak{p}(n) =
\mathfrak{p}\)</span>. Since <span class="math inline">\(G =
V(I(G))\)</span>, it will suffice to show for each <span
class="math inline">\(f \in I(G)\)</span> that <span
class="math inline">\(f(p^t) = 0\)</span> for all <span
class="math inline">\(t \in \mathbb{R}\)</span>. Since <span
class="math inline">\(p^2 = g^* g\)</span> and <span
class="math inline">\(G\)</span> is a group, we know that <span
class="math inline">\(f(p^{t}) = 0\)</span> for all <span
class="math inline">\(t \in 2 \mathbb{Z}\)</span>. Let <span
class="math inline">\(e^{x_1},\dotsc,e^{x_n}\)</span> denote the
diagonal entries of <span class="math inline">\(p\)</span> with respect
to some basis. Then <span class="math inline">\(f(p^t)\)</span> is a
polynomial in the quantities <span class="math inline">\(e^{\pm t x_1},
\dotsc, e^{\pm t x_n}\)</span>. Collecting common exponents, we may
write <span class="math display">\[f(p^t) = \sum_{\gamma \in \Gamma}
c_\gamma e^{\gamma t}\]</span> for some finite subset <span
class="math inline">\(\Gamma\)</span> of <span
class="math inline">\(\mathbb{R}\)</span> and some nonzero complex
coefficients <span class="math inline">\(c_\gamma\)</span>. Suppose for
the sake of contradiction that <span
class="math inline">\(f(p^t)\)</span> is nonzero. Then <span
class="math inline">\(\Gamma\)</span> is nonempty. Let <span
class="math inline">\(\gamma \in \Gamma\)</span> be the largest element.
Then <span class="math inline">\(\lim_{t \rightarrow \infty} e^{- \gamma
t} f(p^t) = c_\gamma \neq 0\)</span>. But <span
class="math inline">\(f(p^t) = 0\)</span> for all <span
class="math inline">\(t \in 2 \mathbb{Z}\)</span>, giving the required
contradiction. ◻</p>
</span></div>
<h2 id="algebraic-representations">Algebraic representations</h2>
<div class="definition">
<p><strong>Definition 82</strong>. A <em>morphism</em> of algebraic
groups is a group homomorphism that is also a morphism of the underlying
algebraic sets, i.e., a map described in coordinates by polynomials.</p>
<p>Let <span class="math inline">\(G\)</span> be an algebraic group over
an infinite field <span class="math inline">\(k\)</span>. An
<em>algebraic representation</em> of <span
class="math inline">\(G\)</span> is a finite-dimensional <span
class="math inline">\(k\)</span>-vector space <span
class="math inline">\(V\)</span> equipped with a morphism of algebraic
groups <span class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span>.</p>
</div>
<div id="thm:alg-rep" class="theorem">
<p><strong>Theorem 83</strong>. <em>Let <span
class="math inline">\(K\)</span> be a compact Lie group. Let <span
class="math inline">\(G\)</span> denote its complexification. Then
algebraic representations <span
class="math inline">\((\sigma,W)\)</span> of <span
class="math inline">\(G\)</span> are in natural bijection with
finite-dimensional representations <span
class="math inline">\((\pi,V)\)</span> of <span
class="math inline">\(K\)</span>. The bijection sends <span
class="math inline">\(V\)</span> to <span
class="math inline">\(W\)</span> and <span
class="math inline">\(W\)</span> to <span
class="math inline">\(V\)</span>. To get from <span
class="math inline">\(\sigma\)</span> to <span
class="math inline">\(\pi\)</span>, one restricts. To get from <span
class="math inline">\(\pi\)</span> to <span
class="math inline">\(\sigma\)</span>, one writes <span
class="math inline">\(\pi\)</span> in matrix form as <span
class="math inline">\((\pi_{i j})\)</span>, with <span
class="math inline">\(\pi_{i j} \in \mathcal{A}(K)\)</span>; one then
uses the isomorphism <span class="math inline">\(\mathcal{A}(K) \cong
\mathbb{C}[G]\)</span> to identify each <span
class="math inline">\(\pi_{i j}\)</span> with a regular function on
<span class="math inline">\(G\)</span>, and takes <span
class="math inline">\(\sigma = (\pi_{i j})\)</span> the algebraic
representation whose matrix entries are given by those regular
functions.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The reader is encouraged to check that this follows
readily from Theorem <a
href="#thm:complexification-compact-lie-basic-properties"
data-reference-type="ref"
data-reference="thm:complexification-compact-lie-basic-properties">75</a>. ◻</p>
</span></div>
<p><a href="#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a></p>
<h2 id="reductive-groups">Reductive groups</h2>
<p>Which groups <span class="math inline">\(G\)</span> arise as in
Theorem <a href="#thm:complexification-compact-lie-basic-properties"
data-reference-type="ref"
data-reference="thm:complexification-compact-lie-basic-properties">75</a>,
i.e., as the Zariski closure of a compact subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>?
Recall that an element <span class="math inline">\(g \in
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> is <em>unipotent</em> if
<span class="math inline">\((g - 1)^n = 0\)</span>. We say that a
subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> is
<em>unipotent</em> if each of its elements is unipotent.</p>
<div class="definition">
<p><strong>Definition 84</strong>. A complex algebraic group <span
class="math inline">\(G \leq {\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>
is called <em>reductive</em> if it contains no nontrivial (i.e., other
than <span class="math inline">\(\{1\}\)</span>) normal unipotent
subgroups.</p>
</div>
<p>For instance, the group <span class="math inline">\(\begin{pmatrix}
  1 &amp; \mathbb{C}  \\
  &amp; 1
\end{pmatrix}\)</span> is not reductive, because the whole group is
unipotent.</p>
<div id="thm:reductive-groups" class="theorem">
<p><strong>Theorem 85</strong>. <em>Let <span class="math inline">\(G
\leq {\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> be a complex algebraic
group. The following are equivalent:</em></p>
<ol type="i">
<li><p><em><span class="math inline">\(G\)</span> is
reductive.</em></p></li>
<li><p><em><span class="math inline">\(G\)</span> has a Zariski dense
compact subgroup <span class="math inline">\(K\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(G\)</span> is conjugate to a
group that is closed under <span class="math inline">\(\Theta : g
\mapsto {}^t \overline{g} ^{-1}\)</span>.</em></p></li>
<li><p><em>Every algebraic representation <span
class="math inline">\(V\)</span> of <span
class="math inline">\(G\)</span> is completely reducible, i.e.,
decomposes as a direct sum <span class="math inline">\(\oplus
W_i\)</span> of invariant irreducible subspaces.</em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The proof that (i) implies (iii) implies (ii) is
lengthy, and will not be discussed in detail. The basic idea is to
complete most of the classifications of reductive algebraic groups and
of compact Lie groups, and to observe that the same objects (root data)
arise in both classifications. We will soon discuss these ideas for
compact Lie groups; a parallel discussion applies in the algebraic
setting.</p>
<p>That (ii) implies (iii) follows from Theorem <a
href="#thm:complexification-compact-lie-basic-properties"
data-reference-type="ref"
data-reference="thm:complexification-compact-lie-basic-properties">75</a>.</p>
<p>Let’s assume (ii) and deduce (iv). We have seen (Theorem <a
href="#thm:complete-reducibility-compact-group"
data-reference-type="ref"
data-reference="thm:complete-reducibility-compact-group">22</a>) that
<span class="math inline">\(V\)</span> decomposes as a direct sum <span
class="math inline">\(\oplus W_i\)</span> of <span
class="math inline">\(K\)</span>-invariant <span
class="math inline">\(K\)</span>-irreducible subspaces. We claim that if
a subspace <span class="math inline">\(W \subseteq V\)</span> of <span
class="math inline">\(V\)</span> is <span
class="math inline">\(K\)</span>-invariant, then it is likewise <span
class="math inline">\(G\)</span>-invariant. It’s obvious that any <span
class="math inline">\(K\)</span>-irreducible <span
class="math inline">\(G\)</span>-invariant subspace is likewise <span
class="math inline">\(G\)</span>-irreducible, so the claim suffices. To
verify the claim, the point is that leaving a subspace invariant is an
algebraic condition, which thus extends Zariski-continuously from <span
class="math inline">\(K\)</span> to <span
class="math inline">\(G\)</span>. In more detail, consider the set <span
class="math inline">\(X := \{g \in \mathop{\mathrm{GL}}(V) : g W
\subseteq W\}\)</span>. Then <span class="math inline">\(X\)</span> is
algebraic; for instance, if we extend a basis <span
class="math inline">\(e_1,\dotsc,e_m\)</span> for <span
class="math inline">\(W\)</span> to a basis <span
class="math inline">\(e_1,\dotsc,e_n\)</span> for <span
class="math inline">\(V\)</span> and denote by <span
class="math inline">\(e_1^*,\dotsc,e_n^*\)</span> the corresponding dual
basis, then <span class="math inline">\(X = \{g : e_j^*(g e_i) = 0
\text{ for } i=1..m, j=m+1..n\}\)</span>. Let <span
class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> denote the action map. Then <span
class="math inline">\(\pi^{-1}(X)\)</span> is algebraic. Since <span
class="math inline">\(W\)</span> is <span
class="math inline">\(K\)</span>-invariant, we have <span
class="math inline">\(K \subseteq \pi^{-1}(X)\)</span>. Since <span
class="math inline">\(K\)</span> is Zariski dense in <span
class="math inline">\(G\)</span>, it follows that <span
class="math inline">\(G \subseteq \pi^{-1}(X)\)</span>, hence that <span
class="math inline">\(X\)</span> is <span
class="math inline">\(G\)</span>-invariant, as required.</p>
<p>Let’s finally assume (iv) and deduce (i). Let <span
class="math inline">\(N\)</span> be a normal unipotent subgroup. We must
show that <span class="math inline">\(N = \{1\}\)</span>. Let <span
class="math inline">\(V = \mathbb{C}^n\)</span> denote the standard
representation of <span class="math inline">\(G\)</span>, thus <span
class="math inline">\(G \subseteq \mathop{\mathrm{GL}}(V)\)</span>. By
assumption, <span class="math inline">\(V = \oplus W_i\)</span> with
each <span class="math inline">\(W_i\)</span> an irreducible
subrepresentation. By Engel’s theorem (or perhaps a variant), the fixed
space <span class="math inline">\(W_i^N = \{w \in W_i : n w_i = w_i
\text{ for all } n \in N\}\)</span> is nontrivial. Since <span
class="math inline">\(N\)</span> is normal, <span
class="math inline">\(W_i^N\)</span> is <span
class="math inline">\(G\)</span>-invariant. (Indeed, if <span
class="math inline">\(v \in W_i^N\)</span>, <span
class="math inline">\(g \in G\)</span> and <span class="math inline">\(n
\in N\)</span>, then <span class="math inline">\(n&#39; := g^{-1} n g
\in N\)</span>, so <span class="math inline">\(n g v = g n&#39; v = g
v\)</span>, hence <span class="math inline">\(g v \in W_i^N\)</span>.)
Since <span class="math inline">\(W_i\)</span> is irreducible, it
follows that <span class="math inline">\(W_i = W_i^N\)</span>, hence
that <span class="math inline">\(V = V^N\)</span>. This says that every
element <span class="math inline">\(n\)</span> of <span
class="math inline">\(N\)</span> fixes every element of <span
class="math inline">\(V\)</span>, i.e., that <span
class="math inline">\(n = 1\)</span>, i.e., that <span
class="math inline">\(N = \{1\}\)</span>, as required. ◻</p>
</span></div>
<h2 id="unitary-trick">Unitary trick</h2>
<p>We record a further variant of the above considerations. We focus on
an example; what’s relevant here is that <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> and
<span class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span> are
connected and simply-connected. Note that by the Cartan decomposition
(§<a href="#sec:cartan-decomposition" data-reference-type="ref"
data-reference="sec:cartan-decomposition">6.4</a>), knowing either of
these properties for one of these groups implies the same property for
the other group.</p>
<div id="thm:unitary-trick" class="theorem">
<p><strong>Theorem 86</strong>. <em>Let <span
class="math inline">\(V\)</span> be a finite-dimensional complex vector
space. The following are all in natural bijection:</em></p>
<ol>
<li><p><em>Algebraic representations <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C}) \rightarrow
\mathop{\mathrm{GL}}(V)\)</span></em></p></li>
<li><p><em>Holomorphic representations <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C}) \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> (i.e., morphisms of complex Lie
groups)</em></p></li>
<li><p><em>Holomorphic representations <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})
\rightarrow \mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}(V)\)</span>
(i.e., morphisms of complex Lie algebras)</em></p></li>
<li><p><em>Representations <span
class="math inline">\(\mathop{\mathrm{SU}}(n) \rightarrow
\mathop{\mathrm{GL}}(V)\)</span></em></p></li>
<li><p><em>Representations <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(n)
\rightarrow \mathop{\mathrm{GL}}(V)\)</span></em></p></li>
<li><p><em>Representations <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{R}) \rightarrow
\mathop{\mathrm{GL}}(V)\)</span></em></p></li>
<li><p><em>Representations <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{R})
\rightarrow \mathop{\mathrm{GL}}(V)\)</span></em></p></li>
</ol>
<p><em>These bijections are compatible with irreducibility and direct
sum decompositions. Any such representation is completely reducible,
i.e., decomposes as a direct sum of irreducible
representations.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We go from (1) to (2) using that polynomials are
holomorphic. We’ll leave it as a homework problem to show that any
holomorphic representation of a complex reductive group is automatically
polynomial, giving the arrow from (2) to (1). (2) and (3) are equivalent
by Lie theory and the fact that <span
class="math inline">\({\mathop{\mathrm{SL}}}_n(\mathbb{C})\)</span> is
connected and simply-connected. (4) and (5) are likewise equivalent
thanks to the analogous properties for <span
class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span>. (3), (5) and (7)
are all equivalent thanks to the identities <span
class="math display">\[\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(n)
\oplus i \mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(n) =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{C})
    = {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{R}) \oplus i
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_n(\mathbb{R})\]</span> and
the fact that an <span class="math inline">\(\mathbb{R}\)</span>-linear
map <span class="math inline">\(W \rightarrow U\)</span> from a real
vector space <span class="math inline">\(W\)</span> to a complex vector
space <span class="math inline">\(U\)</span> extends uniquely to a <span
class="math inline">\(\mathbb{C}\)</span>-linear map <span
class="math inline">\(W_{\mathbb{C}} \rightarrow U\)</span> from the
complexification <span class="math inline">\(W_{\mathbb{C}} = W
\otimes_{\mathbb{R}} \mathbb{C} = W \oplus i W\)</span>. We go from (2)
to (6) by restricting and from (6) to (7) by differentiating. That these
bijections are compatible with irreducibility and decompositions is
either clear or follows as in the proof of Theorem <a
href="#thm:reductive-groups" data-reference-type="ref"
data-reference="thm:reductive-groups">85</a>. We’ve seen that complete
reducibility holds for representations of <span
class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span>, so the same
follows for each of the other classes of representations. ◻</p>
</span></div>
<p>We’ve already (§<a href="#sec:some-groups-closely"
data-reference-type="ref"
data-reference="sec:some-groups-closely">3.7</a>) classified the
(irreducible) finite-dimensional representations of <span
class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span>, so the stated
equivalence tells us that we’ve implicitly classified each of the other
six classes of representations.</p>
<p>We note that Theorems <a href="#thm:alg-rep"
data-reference-type="ref" data-reference="thm:alg-rep">83</a> and <a
href="#thm:unitary-trick" data-reference-type="ref"
data-reference="thm:unitary-trick">86</a> are mostly independent.</p>
<p>We record the homework problem promised above as a theorem:</p>
<div class="theorem">
<p><strong>Theorem 87</strong>. <em>Let <span
class="math inline">\(G\)</span> be a reductive complex algebraic group
and <span class="math inline">\(V\)</span> a finite-dimensional complex
vector space. Then any holomorphic representation <span
class="math inline">\(\pi : G \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> is algebraic.</em></p>
</div>
<p>Note that by contrast, non-reductive groups can have holomorphic
non-algebraic representations, e.g., <span
class="math display">\[\begin{pmatrix}
    1 &amp; \mathbb{C}  \\
    &amp; 1
  \end{pmatrix}
  \ni
  \begin{pmatrix}
    1 &amp; z \\
    &amp; 1
  \end{pmatrix}
  \mapsto
  \begin{pmatrix}
    e^z &amp;  \\
    &amp; 1
  \end{pmatrix}
  \in {\mathop{\mathrm{GL}}}_2(\mathbb{C}).\]</span></p>
<p>We’ve only scratched the tip of the iceberg here; for further reading
I recommend the book by Onishchik–Vinberg.</p>
<h1 id="structure-of-compact-lie-groups">Structure of compact Lie
groups</h1>
<p>We aim next to show that any compact Lie group <span
class="math inline">\(K\)</span> has structure similar to that observed
in §<a href="#sec:char-theory-comp" data-reference-type="ref"
data-reference="sec:char-theory-comp">3</a> for the unitary groups.
We’ll use this to classify such <span class="math inline">\(K\)</span>
together with their representations.</p>
<h2 id="sec:notat-relat-torus">§7.1. Notation related to a torus</h2>
<p>Let <span class="math inline">\(T\)</span> be an <span
class="math inline">\(n\)</span>-dimensional torus. Recall from §<a
href="#sec:char-theory-comp" data-reference-type="ref"
data-reference="sec:char-theory-comp">3</a> that this means that <span
class="math inline">\(T\)</span> is a connected compact abelian Lie
group of dimension <span class="math inline">\(n\)</span> and that any
such <span class="math inline">\(T\)</span> is isomorphic to <span
class="math inline">\(\mathop{\mathrm{U}}(1)^n\)</span>. We may fix such
an isomorphism and regard <span class="math inline">\(T\)</span> as the
diagonal subgroup of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. In §<a
href="#sec:char-theory-comp" data-reference-type="ref"
data-reference="sec:char-theory-comp">3</a>, we worked with the explicit
coordinates defined by this embedding. It’ll be useful now to work in a
more basis-free manner. This requires setting up a bit of notation.</p>
<p>The <em>character group</em> of <span
class="math inline">\(T\)</span> is <span class="math display">\[X(T) :=
\mathop{\mathrm{Hom}}(T,\mathop{\mathrm{U}}(1)),\]</span> while the
<em>cocharacter group</em> is <span class="math display">\[X^\vee (T) :=
\mathop{\mathrm{Hom}}(\mathop{\mathrm{U}}(1),T).\]</span> We view these
as additive groups. They are free <span
class="math inline">\(\mathbb{Z}\)</span>-modules of rank <span
class="math inline">\(n\)</span>. We can identify <span
class="math inline">\(X(T)\)</span> and with <span
class="math inline">\(\mathbb{Z}^n\)</span> by associating to <span
class="math inline">\(\lambda, \gamma \in \mathbb{Z}^n\)</span> the
character <span class="math display">\[T \ni t \mapsto t^{\lambda} :=
t_1^{\lambda_1} \dotsb t_n^{\lambda_n}\]</span> and the cocharacter
<span class="math display">\[\mathop{\mathrm{U}}(1) \ni z \mapsto
z^{\gamma} :=
\mathop{\mathrm{diag}}(z^{\gamma_1},\dotsc,z^{\gamma_n}).\]</span></p>
<p>There is a natural pairing <span class="math display">\[\langle ,
\rangle : X(T) \otimes_{\mathbb{Z}} X^\vee(T) \rightarrow
\mathbb{Z}\]</span> given by observing that the composition <span
class="math inline">\(\mathop{\mathrm{U}}(1) \rightarrow T \rightarrow
\mathop{\mathrm{U}}(1)\)</span> is a morphism <span
class="math inline">\(\mathop{\mathrm{U}}(1) \rightarrow
\mathop{\mathrm{U}}(1)\)</span>, and that any such morphism is of the
form <span class="math inline">\(z \mapsto z^k\)</span> for some integer
<span class="math inline">\(k\)</span> (e.g., by §<a
href="#sec:conn-comp-abel" data-reference-type="ref"
data-reference="sec:conn-comp-abel">2.6</a>). For <span
class="math inline">\(\lambda, \gamma \in \mathbb{Z}^n\)</span>, we have
<span class="math inline">\((z^\gamma)^{\lambda} = z^{\gamma_1 \lambda_1
+ \dotsb + \gamma_n \lambda_n}\)</span>, so <span
class="math inline">\(\langle \lambda, \gamma \rangle = \gamma_1
\lambda_1 + \dotsb + \gamma_n \lambda_n\)</span>.</p>
<p>We denote by <span class="math inline">\(\mathfrak{t}\)</span> the
Lie algebra of <span class="math inline">\(T\)</span> and by <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}} =
\mathfrak{t}\otimes_{\mathbb{R}} \mathbb{C} = \mathfrak{t} \oplus i
\mathfrak{t}\)</span> its complexification. We may identify <span
class="math display">\[\mathfrak{t}_{\mathbb{C}} =
  \begin{pmatrix}
    \mathbb{C}  &amp;  &amp;  \\
    &amp; \ddots  &amp;  \\
    &amp; &amp; \mathbb{C}
  \end{pmatrix}
.\]</span> We (somewhat awkwardly) set <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}} := i
\mathfrak{t}\)</span>, so that <span id="eq:describe-t-R" class="math display">\[\label{eq:describe-t-R}\tag{40}
  \mathfrak{t}_{\mathbb{R}} =
  \begin{pmatrix}
    \mathbb{R}  &amp;  &amp;  \\
    &amp; \ddots  &amp;  \\
    &amp; &amp; \mathbb{R}
  \end{pmatrix}
.\]</span> We obtain a surjective covering map <span
class="math display">\[\mathfrak{t}_{\mathbb{R}} \rightarrow T\]</span>
<span class="math display">\[x \mapsto \exp(i x).\]</span></p>
<p>We write <span class="math inline">\(\mathfrak{t}_{\mathbb{C}}^* :=
{\mathop{\mathrm{Hom}}}_{\mathbb{C}}(\mathfrak{t}_{\mathbb{C}},\mathbb{C})
\cong \mathbb{C}^n\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^* :=
{\mathop{\mathrm{Hom}}}_{\mathbb{R}}(\mathfrak{t}_{\mathbb{R}},\mathbb{R})
\cong \mathbb{R}^n\)</span>. We may identify <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> with the
subspace of <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}^*\)</span> mapping <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> to <span
class="math inline">\(\mathbb{R}\)</span>. The identification of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> with <span
class="math inline">\(\mathbb{R}^n\)</span> is given by <span
class="math inline">\(\lambda = (\lambda_1,\dotsc,\lambda_n)\)</span> if
<span class="math inline">\(\lambda(x) = \lambda_1 x_1 + \dotsb +
\lambda_n x_n\)</span> for <span class="math inline">\(x =
\mathop{\mathrm{diag}}(x_1,\dotsc,x_n) \in
\mathfrak{t}_{\mathbb{R}}\)</span>.</p>
<p>Each <span class="math inline">\(\lambda \in X(T)\)</span> identifies
with an element <span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{R}}^*\)</span>; this identification is determined
by requiring that for every <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{R}}\)</span> (so that <span
class="math inline">\(\exp(i x) \in T\)</span>), we have <span
class="math display">\[(\exp(i x))^{\lambda} = e^{i
\lambda(x)}.\]</span> We write <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^* \subseteq
\mathfrak{t}_{\mathbb{R}}^*\)</span> for the image of <span
class="math inline">\(X(T)\)</span> under this identification. The
identification above of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> with <span
class="math inline">\(\mathbb{R}^n\)</span> then carries <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span> to <span
class="math inline">\(\mathbb{Z}^n\)</span>.</p>
<p>Each <span class="math inline">\(\gamma \in X^\vee(T)\)</span>
identifies with an element <span class="math inline">\(\gamma \in
\mathfrak{t}_{\mathbb{R}}\)</span>, characterized as follows: for <span
class="math inline">\(\theta \in \mathbb{R}\)</span> (so that <span
class="math inline">\(\exp(i \theta) \in
\mathop{\mathrm{U}}(1)\)</span>), <span class="math display">\[(\exp(i
\theta))^{\gamma} = \exp(i \theta \gamma).\]</span> We denote by <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}} \subseteq
\mathfrak{t}_{\mathbb{R}}\)</span> the image of <span
class="math inline">\(X^\vee(T)\)</span> under this identification. Then
under <a href="#eq:describe-t-R" data-reference-type="eqref"
data-reference="eq:describe-t-R">\((40)\)</a>, we have <span id="eq:describe-t-Z" class="math display">\[\label{eq:describe-t-Z}\tag{41}
  \mathfrak{t}_{\mathbb{Z}} =
  \begin{pmatrix}
    \mathbb{Z}  &amp;  &amp;  \\
    &amp; \ddots  &amp;  \\
    &amp; &amp; \mathbb{Z}
  \end{pmatrix}
.\]</span></p>
<p>We note that <span class="math inline">\(X(T)\)</span> and <span
class="math inline">\(X^\vee(T)\)</span> identify respectively with
<span class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span>, and the
pairing <span class="math inline">\(X(T) \otimes X^\vee(T) \rightarrow
\mathbb{Z}\)</span> (tensor product over <span
class="math inline">\(\mathbb{Z}\)</span>) discussed above corresponds
to the natural pairing <span class="math inline">\(\langle , \rangle :
\mathfrak{t}_{\mathbb{Z}} \otimes \mathfrak{t}_{\mathbb{Z}}^*
\rightarrow \mathbb{Z}\)</span> induced by the canonical duality between
<span class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> with
<span class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span>. In
coordinates, <span class="math inline">\(\langle \lambda, \gamma \rangle
= \lambda_1 \gamma_1 + \dotsb + \lambda_n \gamma_n\)</span>, as
before.</p>
<p>We should note that <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span> depend upon
<span class="math inline">\(T\)</span>, not just upon <span
class="math inline">\(\mathfrak{t}\)</span>.</p>
<p>Recall (§<a href="#sec:conn-comp-abel" data-reference-type="ref"
data-reference="sec:conn-comp-abel">2.6</a>) that every
finite-dimensional irreducible representation of <span
class="math inline">\(T\)</span> is one-dimensional and of the form
<span class="math inline">\(t \mapsto t^{\lambda}\)</span> for some
<span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{Z}}^*\)</span>. Given a finite-dimensional
representation <span class="math inline">\(V\)</span> of <span
class="math inline">\(T\)</span>, recall (§<a
href="#sec:weight-decmop-U-n" data-reference-type="ref"
data-reference="sec:weight-decmop-U-n">3.3</a>) that we may decompose
<span class="math display">\[V = \oplus_{\lambda \in
\mathfrak{t}_{\mathbb{Z}}^*} V^{\lambda},\]</span> where <span
class="math inline">\(V^{\lambda} = \{v \in V : t v = t^{\Lambda} v
\text{ for all } t \in T\}\)</span> is the weight space with weight
<span class="math inline">\(\lambda\)</span>.</p>
<h2 id="sec:maxim-tori:-defin">§7.2. Maximal tori: definition and
existence</h2>
<p>Let <span class="math inline">\(K\)</span> be a compact Lie group. By
a <em>torus</em> <span class="math inline">\(T \leq K\)</span> we mean a
closed subgroup that is a torus. Note that if <span
class="math inline">\(T\)</span> is an abstract torus and <span
class="math inline">\(j : T \hookrightarrow K\)</span> is a injective
immersive Lie group morphism (i.e., a “virtual Lie subgroup”), then
<span class="math inline">\(j(T)\)</span> is the image under a
continuous map of a compact set, hence <span
class="math inline">\(j(T)\)</span> compact, hence (since <span
class="math inline">\(K\)</span> is Hausdorff) <span
class="math inline">\(j(T)\)</span> is closed, and so <span
class="math inline">\(j(T)\)</span> is a torus in <span
class="math inline">\(G\)</span>.</p>
<div class="definition">
<p><strong>Definition 88</strong>. A <em>maximal torus</em> <span
class="math inline">\(T\)</span> of <span
class="math inline">\(K\)</span> is a torus <span
class="math inline">\(T \leq K\)</span> that is not contained in any
strictly larger torus in <span class="math inline">\(K\)</span>.</p>
</div>
<div id="item:existence-nontrivial-tori" class="lemma">
<p><strong>Lemma 89</strong>. <span
id="lem:maximal-tori-vs-maxl-ab-subalg"
label="lem:maximal-tori-vs-maxl-ab-subalg"></span> Let <span
class="math inline">\(K\)</span> be a compact Lie group.</p>
<ol type="i">
<li><p>A torus <span class="math inline">\(T \leq K\)</span> is maximal
if and only if <span class="math inline">\(\mathfrak{t}\)</span> is a
maximal abelian subalgebra of <span
class="math inline">\(\mathfrak{k}\)</span>.</p></li>
<li><p>Maximal tori exist in <span
class="math inline">\(K\)</span>.</p></li>
<li><p>If <span class="math inline">\(\dim(K) &gt; 0\)</span>, then
nontrivial tori exist in <span class="math inline">\(K\)</span>.
</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>We will verify the equivalence in contrapositive form.</p>
<p>If <span class="math inline">\(S\)</span> is a torus in <span
class="math inline">\(K\)</span> that strictly contains <span
class="math inline">\(T\)</span>, then (by the Lie correspondence) <span
class="math inline">\(\mathfrak{s}\)</span> is an abelian subalgebra of
<span class="math inline">\(\mathfrak{k}\)</span> that strictly contains
<span class="math inline">\(\mathfrak{t}\)</span>.</p>
<p>Conversely, suppose <span class="math inline">\(\mathfrak{s}\)</span>
is an abelian subalgebra of <span
class="math inline">\(\mathfrak{k}\)</span> that strictly contains <span
class="math inline">\(\mathfrak{t}\)</span>. Let <span
class="math inline">\(x \in \mathfrak{s} - \mathfrak{t}\)</span>. Then
<span class="math inline">\(\exp(\mathbb{R} x)\)</span> commutes with
<span class="math inline">\(T\)</span>, so <span
class="math inline">\(\exp(\mathbb{R} x) T\)</span> is an abelian
subgroup of <span class="math inline">\(G\)</span>. Its closure <span
class="math inline">\(\overline{\exp(\mathbb{R} x) T}\)</span> is a
closed abelian subgroup of <span class="math inline">\(G\)</span>, hence
compact. The connected component <span class="math inline">\(T&#39; :=
(\overline{\exp(\mathbb{R} x) T})^0\)</span> of that closure is then
connected, compact and abelian, hence is a torus. Since <span
class="math inline">\(x \in \mathop{\mathrm{Lie}}(T&#39;) -
\mathfrak{t}\)</span>, we see that <span
class="math inline">\(T&#39;\)</span> strictly contains <span
class="math inline">\(T\)</span>.</p></li>
<li><p>Use that the dimensions of the (abelian) subalgebras of <span
class="math inline">\(\mathfrak{k}\)</span> are bounded from
above.</p></li>
<li><p>Consider <span class="math inline">\((\overline{\exp(\mathbb{R}
x)})^0\)</span> for any <span class="math inline">\(0 \neq x \in
\mathfrak{k}\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="roots-and-root-space-decomposition">Roots and root space
decomposition</h2>
<p>Let <span class="math inline">\(K\)</span> be a compact Lie group
with maximal torus <span class="math inline">\(T\)</span>. Let <span
class="math inline">\(G\)</span> denote the complexification of <span
class="math inline">\(K\)</span>, so that <span
class="math inline">\(\mathfrak{g}\)</span> is the complexification of
<span class="math inline">\(\mathfrak{k}\)</span>. We then have the
(complexified) adjoint representation <span
class="math display">\[\mathop{\mathrm{Ad}}: K \rightarrow
\mathop{\mathrm{GL}}(\mathfrak{g}),\]</span> which we may restrict to
<span class="math inline">\(T\)</span> and decompose: <span id="eq:decmopose-Ad-g-into-weightspaces" class="math display">\[\label{eq:decmopose-Ad-g-into-weightspaces}\tag{42}
  \mathfrak{g} =
  \oplus_{\lambda \in \mathfrak{t}_{\mathbb{Z}}^*}
  \mathfrak{g}^{\lambda}.\]</span></p>
<div class="definition">
<p><strong>Definition 90</strong>. A <em>root</em> for <span
class="math inline">\((K,T)\)</span> is a nonzero element <span
class="math inline">\(\alpha\)</span> of <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span> for which
<span class="math inline">\(\mathfrak{g}^{\alpha}\)</span> is nonzero.
We denote by <span class="math inline">\(\Phi := \Phi(K:T)\)</span> the
set of roots, and refer to <span
class="math inline">\(\mathfrak{g}^{\alpha}\)</span> as the <em>root
space</em> attached to the root <span
class="math inline">\(\alpha\)</span>.</p>
</div>
<p>For instance, suppose that <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, with <span class="math inline">\(T =
\mathop{\mathrm{U}}(1)^n \hookrightarrow K\)</span> the diagonal
subgroup. We’ve seen (§<a href="#sec:weight-decmop-U-n"
data-reference-type="ref"
data-reference="sec:weight-decmop-U-n">3.3</a>) that <span
class="math inline">\(\Phi\)</span> consists of the set of differences
<span class="math inline">\(\varepsilon_i - \varepsilon_j\)</span>,
where <span class="math inline">\(i,j\)</span> are distinct elements of
<span class="math inline">\(\{1..n\}\)</span> and <span
class="math inline">\(\varepsilon_i\)</span> denote the standard basis
elements of <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span>. The root
space <span
class="math inline">\(\mathfrak{g}^{\varepsilon_i-\varepsilon_j}\)</span>
is spanned by the elementary matrix <span class="math inline">\(E_{i
j}\)</span>, for which <span
class="math inline">\(\mathop{\mathrm{Ad}}(t) E_{i j} = (t_i / t_j) E_{i
j} = t^{\varepsilon_i - \varepsilon_j} E_{i j}\)</span>. For instance,
if <span class="math inline">\(n = 3\)</span>, then <span
class="math display">\[\mathop{\mathrm{Ad}}
\begin{pmatrix}
    t_1 &amp;  &amp;  \\
    &amp; t_2 &amp;  \\
    &amp; &amp; t_3
  \end{pmatrix}
  \begin{pmatrix}
    a_{11} &amp; a _{12} &amp;  a _{13} \\
    a _{21} &amp; a _{22} &amp; a _{23} \\
    a _{31} &amp; a _{32} &amp; a _{33}
  \end{pmatrix}
  =
  \begin{pmatrix}
    a_{11} &amp; (t_1/t_2) a _{12} &amp;  (t_1/t_3)a _{13} \\
    (t_2/t_1) a _{21} &amp; a _{22} &amp; (t_2/t_3) a _{23} \\
    (t_3/t_1) a _{31} &amp; (t_3/t_2) a _{32} &amp; a _{33}
  \end{pmatrix}
.\]</span> We might observe in this case that <span
class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\)</span> is the
direct sum of the diagonal subspace <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> and the root
spaces, each of which is one-dimensional. We’ll see eventually that
these features are general, i.e., hold for any compact Lie group. For
starters:</p>
<div class="lemma">
<p><strong>Lemma 91</strong>. Let <span class="math inline">\(K\)</span>
be a compact Lie group with maximal torus <span
class="math inline">\(T\)</span> and <span
class="math inline">\(\mathfrak{g}\)</span> as usual. Then <span id="eq:root-space-decomp" class="math display">\[\label{eq:root-space-decomp}\tag{43}
    \mathfrak{g} = \mathfrak{t}_{\mathbb{C}} \oplus (\oplus_{\alpha \in
\Phi} \mathfrak{g}^{\alpha}).\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By <a href="#eq:decmopose-Ad-g-into-weightspaces"
data-reference-type="eqref"
data-reference="eq:decmopose-Ad-g-into-weightspaces">\((42)\)</a>,
it suffices to show that <span class="math inline">\(\mathfrak{g}^0 =
\{x \in \mathfrak{g} : \mathop{\mathrm{Ad}}(t) x = x \text{ for all } t
\in T\}\)</span> is equal to <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>. We note that
<span class="math inline">\(\mathfrak{g}^0\)</span> is closed under
complex conjugation, hence <span class="math inline">\(\mathfrak{g}^0 =
\mathfrak{k}^0 \oplus i \mathfrak{k}^0\)</span> with <span
class="math inline">\(\mathfrak{k}^0 := \{x \in \mathfrak{k} :
\mathop{\mathrm{Ad}}(t) x = x \text{ for all } t \in T\}\)</span>;
indeed if <span class="math inline">\(x \in \mathfrak{g}\)</span>, then
we may write <span class="math inline">\(x = x_1 + i x_2\)</span> with
<span class="math inline">\(x_1,x_2 \in \mathfrak{k}\)</span>, while for
<span class="math inline">\(t \in T\)</span> we have <span
class="math inline">\(\mathop{\mathrm{Ad}}(t) x =
\mathop{\mathrm{Ad}}(t) x_1 + i \mathop{\mathrm{Ad}}(t) x_2\)</span>,
hence <span class="math inline">\(x \in \mathfrak{g}^0\)</span> iff
<span class="math inline">\(x_1,x_2 \in \mathfrak{k}^0\)</span>, which
leads to the required decomposition. It is thus enough to show that
<span class="math inline">\(\mathfrak{k}^0 = \mathfrak{t}\)</span>.
Suppose otherwise that there exists <span class="math inline">\(x \in
\mathfrak{k}^0 - \mathfrak{t}\)</span>. Then <span
class="math inline">\(\mathbb{R} x \oplus \mathfrak{t}\)</span> is an
abelian subalgebra of <span class="math inline">\(\mathfrak{k}\)</span>
(note that <span class="math inline">\([x,\mathfrak{t}] = \{0\}\)</span>
because <span class="math inline">\(\mathop{\mathrm{Ad}}(t) x =
x\)</span> for all <span class="math inline">\(t \in T\)</span>) that
strictly contains <span class="math inline">\(\mathfrak{t}\)</span>.
Since <span class="math inline">\(T\)</span> is a maximal torus, we
obtain a contradiction via Lemma <a
href="#lem:maximal-tori-vs-maxl-ab-subalg" data-reference-type="ref"
data-reference="lem:maximal-tori-vs-maxl-ab-subalg">89</a>. ◻</p>
</span></div>
<p>The root spaces of <span class="math inline">\(\mathfrak{g}\)</span>
move the weight spaces of any other representation <span
class="math inline">\(V\)</span> predictably, as we now explain. Let
<span class="math inline">\(K\)</span> be a compact Lie group with
maximal torus <span class="math inline">\(T\)</span> and
complexification <span class="math inline">\(G\)</span>. Let <span
class="math inline">\(\pi : K \rightarrow
\mathop{\mathrm{GL}}(V)\)</span> be a finite-dimensional representation
of <span class="math inline">\(K\)</span>. It induces a representation
<span class="math inline">\(d \pi : \mathfrak{k} \rightarrow
\mathop{\mathrm{End}}(V)\)</span> of the Lie algebra, which complexifies
to a holomorphic representation <span class="math inline">\(d \pi :
\mathfrak{g} \rightarrow \mathop{\mathrm{End}}(V)\)</span> of the
complexified Lie algbera. The basic relationship between these is that
for <span class="math inline">\(g \in K\)</span>, <span
class="math inline">\(x \in \mathfrak{g}\)</span> and <span
class="math inline">\(v \in V\)</span>, we have <span
class="math display">\[\pi(g) d \pi(x) v = d \pi(\mathop{\mathrm{Ad}}(g)
x) \pi(g) v.\]</span> Abbreviating <span class="math inline">\(g v :=
\pi(g) v\)</span> and <span class="math inline">\(x v := d \pi(x)
v\)</span> and <span class="math inline">\(g x g^{-1} :=
\mathop{\mathrm{Ad}}(g) x\)</span>, this identity reads more simply as
<span class="math display">\[g x v = (g x g^{-1}) g v.\]</span></p>
<div id="lem:root-spaces-permute-weight-spaces" class="lemma">
<p><strong>Lemma 92</strong>. For <span
class="math inline">\(\alpha,\lambda \in
\mathfrak{t}_{\mathbb{Z}}^*\)</span>, we have <span
class="math display">\[d \pi(\mathfrak{g}^\alpha) V^{\lambda} \subseteq
V^{\lambda + \alpha}.\]</span> In particular, taking <span
class="math inline">\((\pi,V) =
(\mathop{\mathrm{Ad}},\mathfrak{g})\)</span>, we have for any <span
class="math inline">\(\alpha, \beta \in
\mathfrak{t}_{\mathbb{Z}}^*\)</span> that <span
class="math display">\[\subseteq
\mathfrak{g}^{\alpha+\beta}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(x \in
\mathfrak{g}^*\)</span>, <span class="math inline">\(v \in V^{\lambda},
t \in T\)</span>. Then <span class="math display">\[\pi(t) (d \pi(x) v)
    = d \pi(\mathop{\mathrm{Ad}}(t) x) \pi(t) v
    = d \pi(t^\alpha x) \pi(t) v
    = d \pi(t^\alpha  x) t^{\lambda} v
    = t^{\lambda+\alpha} d \pi(x) v,\]</span> so <span
class="math inline">\(d \pi(x) v \in V^{\lambda+\alpha}\)</span>, as
required. We record the same argument but expressed using the above
abbreviations: <span class="math display">\[t x v = (t x t^{-1}) t v =
(t^{\alpha} x) (t^{\lambda} v)= t^{\lambda + \alpha} x v.\]</span> The
conclusion regarding <span class="math inline">\(\alpha, \beta\)</span>
is immediate, but it’s worth repeating the proof in that special case
for the sake of illustration: for <span class="math inline">\(x \in
\mathfrak{g}^\alpha\)</span>, <span class="math inline">\(y \in
\mathfrak{g}^{\beta}\)</span> and <span class="math inline">\(t \in
T\)</span>, we have <span class="math display">\[\mathop{\mathrm{Ad}}(t)
[x,y] = [\mathop{\mathrm{Ad}}(t) x, \mathop{\mathrm{Ad}}(t) y] =
[t^{\alpha} x, t^{\beta} y] = t^{\alpha + \beta}[x,y],\]</span> hence
<span class="math inline">\([x,y] \in
\mathfrak{g}^{\alpha+\beta}\)</span>. ◻</p>
</span></div>
<p><a href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>By choosing a unitary structure on a faithful representation of <span
class="math inline">\(K\)</span> and then taking an orthonormal basis
consisting of weight vectors for <span class="math inline">\(T\)</span>,
we obtain an embedding <span class="math inline">\(K \hookrightarrow
\mathop{\mathrm{U}}(n)\)</span> that carries <span
class="math inline">\(T\)</span> to a subgroup of the diagonal subgroup
of <span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. We have
noted (Theorem <a
href="#thm:complexification-compact-lie-basic-properties"
data-reference-type="ref"
data-reference="thm:complexification-compact-lie-basic-properties">75</a>)
that then the complexified Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> is closed under <span
class="math inline">\(\theta : x \mapsto - x^*\)</span>, where <span
class="math inline">\(x^* := {}^t \overline{x}\)</span>. This fact has
an important consequence:</p>
<div id="lem:negative-roots-exist" class="lemma">
<p><strong>Lemma 93</strong>. If <span class="math inline">\(\alpha \in
\Phi\)</span>, then <span class="math inline">\(- \alpha \in
\Phi\)</span>, and <span class="math inline">\(\dim(\mathfrak{g}^\alpha)
= \dim(\mathfrak{g}^{-\alpha})\)</span>.</p>
</div>
<p>For example, if <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span> and (with notation as before) <span
class="math inline">\(\alpha = \varepsilon_i - \varepsilon_j\)</span>,
then <span class="math inline">\(\mathfrak{g}^\alpha = \mathbb{C} E_{i
j}\)</span>, <span class="math inline">\(\theta(E_{ij}) = - E_{j
i}\)</span>, <span class="math inline">\(- \alpha = \varepsilon_j -
\varepsilon_i\)</span>.</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since <span
class="math inline">\(\mathfrak{g}\)</span> is closed under <span
class="math inline">\(\theta\)</span>, it is enough to show that <span
class="math inline">\(\theta(\mathfrak{g}^\alpha) \subseteq
\mathfrak{g}^{-\alpha}\)</span>. (Equality then follows from, for
instance, the involutivity of <span
class="math inline">\(\theta\)</span> and the same argument applied to
<span class="math inline">\(-\alpha\)</span>.) Let <span
class="math inline">\(x \in \mathfrak{g}^\alpha\)</span>, and let <span
class="math inline">\(t \in T\)</span>. With matrix realizations as
above, we have <span class="math inline">\(t^* = t^{-1}\)</span>
(indeed, we may write <span class="math inline">\(t =
\mathop{\mathrm{diag}}(e^{i \theta_1}, \dotsc e^{i \theta_n})\)</span>,
which makes this obvious), while <span class="math inline">\(A^* B^* =
(B A)^*\)</span> for any matrices <span
class="math inline">\(A,B\)</span>, thus <span
class="math display">\[\begin{align}
    \mathop{\mathrm{Ad}}(t) \theta(x)
    &amp;=
      -
      t
      x^*
      t^{-1}
      =
      - (t^{-1})^* x^* t^*
    \\
    &amp;=
      -
      (t x t^{-1})^*
      =
      - (\mathop{\mathrm{Ad}}(t) x)^*
      = -(t^\alpha x)^*
      =
      \overline{t^\alpha } \theta(x)
      = t^{-\alpha} \theta(x).
  
\end{align}\]</span> Since <span class="math inline">\(t\)</span> was
arbitrary, we deduce as required that <span
class="math inline">\(\theta(x) \in
\mathfrak{g}^{-\alpha}\)</span>. ◻</p>
</span></div>
<h2 id="generators">Generators</h2>
<p>Tori are topologically cyclic, and this fact is very useful.</p>
<div class="definition">
<p><strong>Definition 94</strong>. Let <span
class="math inline">\(T\)</span> be any torus. A <em>generator</em>
<span class="math inline">\(t \in T\)</span> is an element such that
<span class="math inline">\(\overline{\langle t \rangle} = T\)</span>;
here <span class="math inline">\(\langle t \rangle := \{t^n : n \in
\mathbb{Z} \}\)</span> denotes the subgroup generated by <span
class="math inline">\(t\)</span>, and the closure of that subgroup <span
class="math inline">\(\overline{\langle t \rangle}\)</span>.</p>
</div>
<div id="lem:generators-exist" class="lemma">
<p><strong>Lemma 95</strong>. Let <span class="math inline">\(T\)</span>
be any torus. Then generators of <span class="math inline">\(T\)</span>
exist and are dense.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Write <span class="math inline">\(n =
\dim(T)\)</span>, so that <span class="math inline">\(T \cong
(\mathbb{R}/\mathbb{Z})^n\)</span> and <span class="math inline">\(t =
(x_1,\dotsc,x_n)\)</span>. In the case <span
class="math inline">\(n=1\)</span>, Weyl’s equidistribution criterion
implies that <span class="math inline">\(t\)</span> is a generator iff
<span class="math inline">\(x_1 \notin \mathbb{Q}\)</span>. For general
<span class="math inline">\(n\)</span>, the same criterion says that
<span class="math inline">\(t\)</span> is a generator iff <span
class="math inline">\(1,x_1,\dotsc,x_n\)</span> are linearly independent
over <span class="math inline">\(\mathbb{Q}\)</span>. These conditions
are obviously satisfied by a dense collection of elements.</p>
<p>Alternatively, here’s an elementary pigeonhole argment (which I think
I learned from Adams’ book). For each <span class="math inline">\(t \in
T\)</span> and <span class="math inline">\(\varepsilon&gt; 0\)</span>,
write <span class="math inline">\(B_t(\varepsilon)\)</span> for the open
<span class="math inline">\(\varepsilon\)</span>-ball at <span
class="math inline">\(t\)</span>, defined with respect to the Euclidean
metric on <span
class="math inline">\((\mathbb{R}/\mathbb{Z})^n\)</span>. Fix an
enumeration <span class="math inline">\((t_i,\varepsilon_i)\)</span>,
indexed by <span class="math inline">\(i \geq 1\)</span>, of all pairs
consisting of</p>
<ul>
<li><p>an element <span class="math inline">\(t_i \in T\)</span> whose
entries with respect to the isomorphism <span class="math inline">\(T
\cong (\mathbb{R}/\mathbb{Z})^n\)</span> are rational, and</p></li>
<li><p>a rational number <span class="math inline">\(\varepsilon\in
(0,1)\)</span>.</p></li>
</ul>
<p>(Thus the <span class="math inline">\(B_{t_i}(\varepsilon_i)\)</span>
give a countable open basis for <span class="math inline">\(T\)</span>.)
Let <span class="math inline">\(U\)</span> be a closed subset of <span
class="math inline">\(T\)</span> with nonempty interior <span
class="math inline">\(U^0\)</span>. If the natural number <span
class="math inline">\(N_1\)</span> is large enough, then <span
class="math inline">\(N_1 U := \{N_1 u : u \in U\}\)</span> coincides
with <span class="math inline">\(T\)</span>. Thus <span
class="math inline">\(U_1 := \{u \in U : |N_1 u - t_1| \leq
\varepsilon_1/2 \}\)</span> is a closed subset of <span
class="math inline">\(U\)</span>, with nonempty interior, such that
<span class="math inline">\(N_1 U_1 \subseteq
B_{t_1}(\varepsilon_1)\)</span>. We may similarly find a natural number
<span class="math inline">\(N_2\)</span> and a closed subset <span
class="math inline">\(U_2\)</span> of <span
class="math inline">\(U_1\)</span>, with nonempty interior, so that
<span class="math inline">\(N_2 U_2 \subseteq
B_{t_2}(\varepsilon_2)\)</span>. Continuing in this way, we obtain a
descending chain of closed subsets with nonempty interiors <span
class="math inline">\(U \supset U_1 \supseteq U_2 \supseteq
\dotsb\)</span> and natural numbers <span class="math inline">\(N_1,
N_2, \dotsc\)</span> so that for each <span class="math inline">\(i \geq
1\)</span>, we have <span class="math inline">\(N_i U_i \subseteq
B_{t_i}(\varepsilon_i)\)</span>. By compactness, the intersection <span
class="math inline">\(\cap_{i \geq 1} U_i\)</span> is nonempty. Let
<span class="math inline">\(t\)</span> be any element of that
intersection. Then <span class="math inline">\(N_i t \in
B_{t_i}(\varepsilon_i)\)</span>. Hence the group <span
class="math inline">\(\langle t \rangle = \mathbb{Z} t\)</span> (here we
use additive notation for <span class="math inline">\(T \cong
(\mathbb{R}/\mathbb{Z})^n\)</span>) intersects every constituent <span
class="math inline">\(B_{t_i}(\varepsilon_i)\)</span> of an open basis
of <span class="math inline">\(T\)</span>. Hence its closure <span
class="math inline">\(\overline{\langle t \rangle }\)</span> is all of
<span class="math inline">\(T\)</span>. Since <span
class="math inline">\(U\)</span> was arbitrary, we deduce moreover that
the set of generators is dense. ◻</p>
</span></div>
<p>Generators are useful because they reduce properties involving an
entire torus to individual elements. We give an example. To state it,
recall that the centralizer and normalizer of a subgroup <span
class="math inline">\(H\)</span> of a group <span
class="math inline">\(G\)</span> are defined by <span
class="math inline">\(Z_G(H) := \{g \in G : g h g^{-1} = h \text{ for
all } h \in H\}\)</span> and <span class="math inline">\(N_G(H) := \{g
\in G : g h g^{-1} \in H \text{ for all } h \in H\}\)</span>; the
definition of <span class="math inline">\(Z_G(H)\)</span> applies more
generally to any subset <span class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span>, and we abbreviate <span
class="math inline">\(Z_G(h) := Z_G(\{h\})\)</span> when that subset
consists of a single element <span class="math inline">\(h \in
G\)</span>.</p>
<div id="lem:generators-cent-norm" class="lemma">
<p><strong>Lemma 96</strong>. Let <span class="math inline">\(K\)</span>
be a Lie group, let <span class="math inline">\(T \leq K\)</span> be any
torus, and let <span class="math inline">\(t \in T\)</span> be a
generator. Then <span class="math inline">\(Z_K(T) = Z_K(t) = \{g \in K
: g t g^{-1} = t\}\)</span> and <span class="math inline">\(N_K(T) = \{g
\in K : g t g^{-1} \in T\}\)</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We just note that the subsets <span
class="math inline">\(\{s \in T : g s g^{-1} = s\}\)</span> and <span
class="math inline">\(\{s \in T : g s g^{-1} \in T\}\)</span> are closed
subgroups of <span class="math inline">\(T\)</span>, hence they coincide
with <span class="math inline">\(T\)</span> iff they contain the
generator <span class="math inline">\(t\)</span>. ◻</p>
</span></div>
<h2
id="definition-and-finitude-of-the-weyl-group-of-a-maximal-torus">Definition
and finitude of the Weyl group of a maximal torus</h2>
<div class="definition">
<p><strong>Definition 97</strong>. Let <span
class="math inline">\(K\)</span> be a compact Lie group, with maximal
torus <span class="math inline">\(T\)</span>. The <em>Weyl group</em>
<span class="math inline">\(W := W(K:T)\)</span> is defined to be <span
class="math inline">\(N(T)/T\)</span>, where <span
class="math inline">\(N(T) := N_K(T)\)</span> denotes the normalizer of
the torus.</p>
</div>
<p>For instance, for <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, we saw that the permutation
representation <span class="math inline">\(S(n) \rightarrow
\mathop{\mathrm{U}}(n)\)</span> defines an isomorphism <span
class="math inline">\(\S(n) \cong W\)</span>.</p>
<p>We note in general that <span class="math inline">\(W\)</span> acts
on <span class="math inline">\(T\)</span> by conjugation (in a
well-defined manner): <span class="math display">\[w \cdot t := w t
w^{-1}.\]</span></p>
<p>The following basic lemma (which may be proved in a few ways) gives a
decent illustration of how to argue using the root space decomposition
<a href="#eq:root-space-decomp" data-reference-type="eqref"
data-reference="eq:root-space-decomp">\((43)\)</a>.</p>
<div class="lemma">
<p><strong>Lemma 98</strong>. Let <span class="math inline">\(K\)</span>
be a compact Lie group with maximal torus <span
class="math inline">\(T\)</span>. Then <span
class="math inline">\(N(T)^0 = T\)</span> and <span
class="math inline">\(|W| &lt; \infty\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We show first that <span class="math inline">\(N(T)^0
= T\)</span>. The containment <span class="math inline">\(N(T)^0
\supseteq T\)</span> is clear, so we just need to check that <span
class="math inline">\(\mathop{\mathrm{Lie}}(N(T)^0) \subseteq
\mathfrak{t}\)</span>. We have <span
class="math inline">\(\mathop{\mathrm{Lie}}(N(T)^0) = \{x \in
\mathfrak{k} : [x,\mathfrak{t}] \subseteq \mathfrak{t} \}\)</span>. Let
<span class="math inline">\(x \in
\mathop{\mathrm{Lie}}(N(T)^0)\)</span>. Using <a
href="#eq:root-space-decomp" data-reference-type="eqref"
data-reference="eq:root-space-decomp">\((43)\)</a>, we may
write <span class="math display">\[x = x_0 + \sum_{\alpha \in \Phi}
x_\alpha\]</span> with <span class="math inline">\(x_0 \in
\mathfrak{t}_{\mathbb{C}}\)</span> and <span
class="math inline">\(x_\alpha \in \mathfrak{g}^{\alpha}\)</span>. For
<span class="math inline">\(y \in \mathfrak{t}\)</span>, we then have
<span class="math display">\[\mathfrak{t} \ni - [x,y] = [y,x] = [y,x_0]
+ \sum_{\alpha \in \Phi} [y,x_\alpha] = \sum_{\alpha \in \Phi} \alpha(y)
x_\alpha,\]</span> hence <span class="math inline">\(\alpha(y) x_\alpha
= 0\)</span> for all <span class="math inline">\(\alpha\)</span> and all
<span class="math inline">\(y\)</span>. Since each <span
class="math inline">\(\alpha\)</span> is nonzero, we deduce that <span
class="math inline">\(x_\alpha = 0\)</span> for all <span
class="math inline">\(\alpha\)</span>, hence that <span
class="math inline">\(x = x_0\)</span>, and so <span
class="math inline">\(x \in \mathfrak{t}\)</span>, as required.</p>
<p>It follows that <span class="math inline">\(W = N(T)/N(T)^0\)</span>
is a compact <span class="math inline">\(0\)</span>-dimensional Lie
group, and so is finite. ◻</p>
</span></div>
<div class="remark">
<p><strong>Remark 99</strong>. The definition of <span
class="math inline">\(W\)</span> given here is a bit <em>ad hoc</em>.
We’ll later define <span class="math inline">\(W(K:S)\)</span>, for
<em>any</em> torus <span class="math inline">\(S\)</span>, to be the
quotient <span class="math inline">\(N_K(S)/Z_K(S)\)</span> of the
normalizer divided by the centralizer. This will be seen to coincide
with the definition given above in the case of a <em>maximal</em> torus
<span class="math inline">\(T\)</span> only after we’ve seen that <span
class="math inline">\(Z_K(T) = T\)</span> for such tori, but this is a
deep fact which will require proof. The group <span
class="math inline">\(W = W(K:T)\)</span> as defined above will be
relevant for the proof of that fact.</p>
</div>
<h2 id="sec:weyl-integr-form-general">§7.6. Weyl integral formula</h2>
<p>We want a generalization of the formula that we proved earlier for
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> (see §<a
href="#sec:weyl-integr-form" data-reference-type="ref"
data-reference="sec:weyl-integr-form">3.4</a>). That formula expressed
the integral over <span class="math inline">\(K\)</span> in terms of
integrals over conjugates of a maximal torus <span
class="math inline">\(T\)</span>. Since tori are connected, we’d better
assume that <span class="math inline">\(K\)</span> is connected to have
any hope for such a formula.</p>
<p>So let <span class="math inline">\(K\)</span> be a connected compact
Lie group, with maximal torus <span class="math inline">\(T\)</span>.
Write <span class="math inline">\(N := \dim(K)\)</span> and <span
class="math inline">\(n := \dim(T)\)</span>. The basic setup will be the
same as in the case of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. Write <span
class="math inline">\(N := \dim(K)\)</span> and <span
class="math inline">\(n := \dim(T)\)</span>. The subspace <span
class="math inline">\(\mathfrak{t} = \mathop{\mathrm{Lie}}(T)\)</span>
of <span class="math inline">\(\mathfrak{k} =
\mathop{\mathrm{Lie}}(K)\)</span> admits a natural <span
class="math inline">\(\mathop{\mathrm{Ad}}(T)\)</span>-invariant
complement <span class="math inline">\(\mathfrak{k}/\mathfrak{t} :=
\mathfrak{k} \cap (\sum_{\alpha \in \Phi}
\mathfrak{g}^{\alpha})\)</span>. Fix a nonzero <span
class="math inline">\(\omega_1 = \alpha_1 \wedge \beta_1\)</span> in
<span class="math inline">\(\Lambda^N(\mathfrak{k})\)</span>, with <span
class="math inline">\(\alpha_1 \in \Lambda^{n}(\mathfrak{t})\)</span>
and <span class="math inline">\(\beta_1 \in
\Lambda^{N-n}(\mathfrak{k}/\mathfrak{t})\)</span>. The compactness of
<span class="math inline">\(T\)</span> implies that <span
class="math inline">\(\beta_1\)</span> is <span
class="math inline">\(\mathop{\mathrm{Ad}}(T)\)</span>-invariant. We
obtain left-invariant differential forms <span
class="math inline">\(\omega \in \Omega^N(K), \alpha \in \Omega^n(T),
\beta \in \Omega^{N-n}(K/T)\)</span>. (We’ll denote here and henceforth
by <span class="math inline">\(\Omega^k(M)\)</span> for the space of
smooth <span class="math inline">\(k\)</span>-forms on a manifold <span
class="math inline">\(M\)</span>, and <span
class="math inline">\(\Omega_c^k(M)\)</span> for the subspace of
compactly-supported <span class="math inline">\(k\)</span>-forms.) The
compactness of <span class="math inline">\(K\)</span> implies that <span
class="math inline">\(\omega\)</span> is also right-invariant. We obtain
Haar measures <span
class="math inline">\(|\omega|,|\alpha|,|\beta|\)</span> on <span
class="math inline">\(K, T, K/T\)</span>. We may assume <span
class="math inline">\(\omega\)</span> and <span
class="math inline">\(\alpha\)</span> normalized so that <span
class="math inline">\(|\omega|\)</span> and <span
class="math inline">\(|\alpha|\)</span> are probability Haar measures;
the same is then true for <span class="math inline">\(|\beta|\)</span>
by the analogue of Fubini’s theorem. We define <span
class="math display">\[q : K/T \times T \rightarrow K\]</span> <span
class="math display">\[q(g, t) := g t g^{-1},\]</span> and write <span
class="math display">\[q^* \omega = \det(q) (\beta \wedge
\alpha).\]</span></p>
<div id="lem:jacobian-computation-WIF-general" class="lemma">
<p><strong>Lemma 100</strong>. </p>
<ol type="i">
<li><p>For all <span class="math inline">\((g, t) \in K/T \times
T\)</span>, we have <span class="math display">\[\det(q)(g,t) =
D(t),\]</span> where <span class="math display">\[D(t) := \det(1 -
\mathop{\mathrm{Ad}}(t) | \mathfrak{k}/\mathfrak{t}) = \prod_{\alpha \in
\Phi} (1 - t^\alpha)^{\dim(\mathfrak{g}^\alpha)}.\]</span></p></li>
<li><p>We have <span class="math inline">\(D(t) \geq 0\)</span> for all
<span class="math inline">\(t \in T\)</span>. We have <span
class="math inline">\(D(t) &gt; 0\)</span> precisely when <span
class="math inline">\(t^\alpha \neq 1\)</span> for all <span
class="math inline">\(\alpha \in \Phi\)</span>.</p></li>
</ol>
</div>
<p>We’ll see a bit later that each root space <span
class="math inline">\(\mathfrak{g}^{\alpha}\)</span> is exactly
one-dimensional, so that the dimensions appearing in the exponents may
be omitted, but we include them for now.</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The computation of <span
class="math inline">\(\det(q)\)</span> is exactly as in the case of
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>.</p>
<p>By lemma <a href="#lem:negative-roots-exist"
data-reference-type="ref"
data-reference="lem:negative-roots-exist">93</a>, we have <span
class="math inline">\(\alpha \in \Phi\)</span> iff <span
class="math inline">\(-\alpha \in \Phi\)</span>, and moreover <span
class="math inline">\(\dim \mathfrak{g}^\alpha = \dim
\mathfrak{g}^{-\alpha}\)</span>. Thus <span
class="math inline">\(D(t)\)</span> is a product taken over all distinct
pairs <span class="math inline">\(\{\alpha, - \alpha \} \subseteq
\Phi\)</span> of the <span
class="math inline">\(\dim(\mathfrak{g}^\alpha)\)</span>th power of the
quantities <span class="math inline">\((1 - t^\alpha)(1 -
t^{-\alpha})\)</span>. Each such quantity is nonnegative. (Writing <span
class="math inline">\(t^{\alpha} = e^{i \theta}\)</span>, the quantity
in question is <span class="math inline">\(2 - 2 \cos
\theta\)</span>.) ◻</p>
</span></div>
<div class="lemma">
<p><strong>Lemma 101</strong>. The formula <span
class="math display">\[D(g) := \text{ coefficient of } \lambda^{\dim(T)}
\text{ in } \det(\lambda + 1 - \mathop{\mathrm{Ad}}(g))\]</span> defines
a class function <span class="math inline">\(D : K \rightarrow
\mathbb{R}\)</span> that extends the function <span
class="math inline">\(D : T \rightarrow \mathbb{R}_{\geq 0}\)</span>
defined above.</p>
</div>
<p>We’ll see eventually that in fact <span class="math inline">\(D \geq
0\)</span> on all of <span class="math inline">\(K\)</span>.</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> For <span class="math inline">\(t \in T\)</span>,
<span class="math inline">\(\mathop{\mathrm{Ad}}(t)\)</span> acts on
both <span class="math inline">\(\mathfrak{t}\)</span> and <span
class="math inline">\(\mathfrak{k}/\mathfrak{t}\)</span>, so we may
factor the determinant of <span class="math inline">\(\lambda + 1 -
\mathop{\mathrm{Ad}}(t)\)</span> for the action on on <span
class="math inline">\(\mathfrak{k}\)</span> as the product of the
determinants for the actions on <span
class="math inline">\(\mathfrak{t}\)</span> and <span
class="math inline">\(\mathfrak{k}/\mathfrak{t}\)</span>; we have <span
class="math inline">\(\mathop{\mathrm{Ad}}(t)|_{\mathfrak{t}} =
1\)</span>, so the first of the latter two determinants is just <span
class="math inline">\(\lambda^{\dim(T)}\)</span>, while the second is
<span class="math inline">\(D(t) +
\operatorname{O}(\lambda)\)</span>. ◻</p>
</span></div>
<div class="definition">
<p><strong>Definition 102</strong>. An element <span
class="math inline">\(g \in K\)</span> is called <em>regular</em> if
<span class="math inline">\(D(g) \neq 0\)</span>. We denote by <span
class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span> the set of all
regular elements <span class="math inline">\(g \in K\)</span>, and set
<span class="math inline">\(T^{\mathop{\mathrm{reg}}} := T \cap
K^{\mathop{\mathrm{reg}}}\)</span>.</p>
</div>
<p>We observe that <span
class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span> is a
conjugacy-invariant subset of <span class="math inline">\(K\)</span> and
that <span class="math inline">\(T^{\mathop{\mathrm{reg}}} = \{t \in T :
t^\alpha \neq 1 \text{ for all } \alpha \in \Phi \}\)</span>. For
example, if <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span> and <span class="math inline">\(T \cong
\mathop{\mathrm{U}}(1)^n\)</span> is the diagonal torus, then <span
class="math inline">\(t \in T\)</span> is regular iff <span
class="math inline">\(t_i \neq t_j\)</span> for all <span
class="math inline">\(i \neq j\)</span>. It’s clear that any generator
is regular, while the converse is not true in general. Note also that
“being a generator” is intrinsic to <span
class="math inline">\(T\)</span>, while “being regular” depends also
upon the ambient group <span class="math inline">\(K\)</span>.</p>
<p>We note that for any <span class="math inline">\(w \in W\)</span> and
<span class="math inline">\((g T,t) \in K/T \times T\)</span> and <span
class="math inline">\(w \in W\)</span>, the action <span
class="math display">\[w \cdot (g T, t) := (g w^{-1} T, w \cdot t) = (g
w^{-1} T, w t w^{-1})\]</span> is well-defined. It induces defines an
action of <span class="math inline">\(W\)</span> on each fiber of <span
class="math inline">\(q\)</span>; indeed, <span
class="math display">\[q(w \cdot (g T, t)) = (g w^{-1}) (w t w^{-1}) (g
w^{-1})^{-1} = g t g^{-1} = q(g T, t).\]</span> We denote this
relationship by the diagram <span class="math display">\[W
\circlearrowright K/T \times T \xrightarrow{q} K.\]</span></p>
<p>In the <span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>
case, the fibers of <span class="math inline">\(q\)</span> correspond to
choices of orthonormal basis for a given unitary matrix; the action of
<span class="math inline">\(W\)</span> corresponds to permuting the
basis elements and is thus free, and transitive on the fiber above a
regular element because such elements admit a unique (up-to-reordering)
basis of eigenvectors.</p>
<p>The action of <span class="math inline">\(W\)</span> (on each fiber
of <span class="math inline">\(q\)</span>) is free in general, since if
<span class="math inline">\((g w T, w \cdot t) = (g T, t)\)</span> then
<span class="math inline">\(g w T = g T\)</span>, hence <span
class="math inline">\(w T = T\)</span>, i.e., <span
class="math inline">\(w \equiv 1\)</span> in <span
class="math inline">\(W\)</span>. We’ll see below that the action on
regular fibers is transitive, as in the <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> case. The action
can be far from transitive on irregular fibers; for instance, <span
class="math inline">\(q^{-1}(1) = K/T \times \{1\}\)</span>, and the
action of <span class="math inline">\(W\)</span> on <span
class="math inline">\(K/T\)</span> fails to be transitive whenever <span
class="math inline">\(\dim(K/T) &gt; 0\)</span>.</p>
<p>We’re now prepared to state the Weyl integral formula for <span
class="math inline">\(K\)</span>, together with some related
consequences:</p>
<div id="item:WIF-fun" class="theorem">
<p><strong>Theorem 103</strong>. <em><span id="thm:WIF-general"
label="thm:WIF-general"></span> Let notation and assumptions be as
above: <span class="math inline">\(K\)</span> is an <span
class="math inline">\(N\)</span>-dimensional connected compact Lie group
with <span class="math inline">\(n\)</span>-dimensional maximal torus
<span class="math inline">\(T\)</span> and Weyl group <span
class="math inline">\(W\)</span>.</em></p>
<ol type="i">
<li><p><em><span id="item:q-surj" label="item:q-surj"></span> <span
class="math inline">\(q\)</span> is surjective, i.e., <span
class="math inline">\(K = \cup_{g \in K} g T
g^{-1}\)</span>.</em></p></li>
<li><p><em><span id="item:q-cover" label="item:q-cover"></span> The
restriction <span class="math display">\[q : K/T \times
T^{\mathop{\mathrm{reg}}} \rightarrow K^{\mathop{\mathrm{reg}}}\]</span>
is a <span class="math inline">\(|W|\)</span>-to-one covering map, with
the group <span class="math inline">\(W\)</span> acting
simply-transitively on the fibers. This restriction is
orientation-preserving at every point.</em></p></li>
<li><p><em><span id="item:WIF-dif" label="item:WIF-dif"></span> For all
<span class="math inline">\(\nu \in \Omega^N(K)\)</span>, we have <span id="eq:WIF-dif" class="math display">\[\label{eq:WIF-dif}\tag{45}
      \int_{K /T \times T}
      q^* \nu = |W| \int_K \nu.\]</span></em></p></li>
<li><p><em>For all <span class="math inline">\(f \in C(K)\)</span>
(i.e., continuous <span class="math inline">\(f : K \rightarrow
\mathbb{C}\)</span>) we have <span class="math display">\[\int_{(g,t)
\in K/T \times T} D(t) f(g t g^{-1}) = |W| \int_K f,\]</span> with all
integrals taken with respect to probability Haar measures.</em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof that <a href="#item:WIF-dif" data-reference-type="ref"
data-reference="item:WIF-dif">iii</a> implies <a
href="#item:WIF-fun" data-reference-type="ref"
data-reference="item:WIF-fun">iv</a>.</em> Take <span
class="math inline">\(\nu = f \omega\)</span>, with <span
class="math inline">\(\omega \in \Omega^N(K)\)</span> as used above to
describe the probability Haar on <span class="math inline">\(K\)</span>.
Then <span class="math inline">\(q^* \nu = f q^* \omega = f D (\beta
\wedge \alpha)\)</span>. ◻</p>
</div>
<div class="proof">
<p><em>Proof that <a href="#item:WIF-dif" data-reference-type="ref"
data-reference="item:WIF-dif">iii</a> implies <a
href="#item:q-surj" data-reference-type="ref"
data-reference="item:q-surj">i</a>.</em> Let <span
class="math inline">\(E\)</span> denote the image of <span
class="math inline">\(q\)</span>. Suppose otherwise that we may find
some <span class="math inline">\(x \in K - E\)</span>. Since <span
class="math inline">\(K/T \times T\)</span> is compact and <span
class="math inline">\(q\)</span> is continuous, the set <span
class="math inline">\(E\)</span> is compact, hence closed, so we may
find an open neighborhood <span class="math inline">\(U\)</span> of
<span class="math inline">\(x\)</span> disjoint from <span
class="math inline">\(E\)</span>. Choose <span class="math inline">\(\nu
\in \Omega_c^N(U)\)</span> with <span class="math inline">\(\int \nu
\neq 0\)</span>. Then <span class="math inline">\(q^* \nu = 0\)</span>.
Using (ii), we deduce that <span class="math display">\[0 = \int q^* \nu
= |W| \int \nu \neq 0,\]</span> giving the required contradiction. ◻</p>
</div>
<div class="proof">
<p><em>Proof of <a href="#item:q-cover" data-reference-type="ref"
data-reference="item:q-cover">ii</a> and <a
href="#item:WIF-dif" data-reference-type="ref"
data-reference="item:WIF-dif">iii</a>.</em> First, let <span
class="math inline">\(x \in T^{\mathop{\mathrm{reg}}}\)</span>. Lemma <a
href="#lem:jacobian-computation-WIF-general" data-reference-type="ref"
data-reference="lem:jacobian-computation-WIF-general">100</a> implies
then that <span class="math inline">\(\det(q) &gt; 0\)</span> on <span
class="math inline">\(q^{-1}(x)\)</span>. Thus for each <span
class="math inline">\(y \in q^{-1}(x)\)</span>, the map <span
class="math inline">\(q\)</span> is an orientation-preserving local
diffeomorphism at <span class="math inline">\(y\)</span>. In particular,
<span class="math inline">\(q^{-1}(x)\)</span> is a closed <span
class="math inline">\(0\)</span>-dimensional subset of the compact set
<span class="math inline">\(K/T \times T\)</span>, and so <span
class="math inline">\(q^{-1}(x)\)</span> is finite. We may thus find a
small neighborhood <span class="math inline">\(U\)</span> of <span
class="math inline">\(x\)</span> and, for each <span
class="math inline">\(y \in q^{-1}(x)\)</span>, a small neighborhood
<span class="math inline">\(U_y\)</span> of <span
class="math inline">\(y\)</span> so that <span
class="math inline">\(q\)</span> induces diffeomorphisms <span
class="math inline">\(U_y \cong U\)</span>. By shrinking <span
class="math inline">\(U\)</span> and hence each <span
class="math inline">\(U_y\)</span> if necessary, we may assume that the
<span class="math inline">\(U_y\)</span> are all disjoint. Using the
compactness of the domain of <span class="math inline">\(q\)</span>, we
see that the image under <span class="math inline">\(q\)</span> of the
complement of <span class="math inline">\(\cup_z U_z\)</span> is
compact, hence closed, so by shrinking <span
class="math inline">\(U\)</span> if necessary, we may assume that the
image in question is disjoint from <span
class="math inline">\(U\)</span>. Then <span
class="math display">\[q^{-1}(U) = \sqcup_{y \in q^{-1}(x)}
U_y,\]</span> with the map <span class="math inline">\(q^{-1}(U)
\rightarrow U\)</span> a trivial cover.</p>
<p>We’ve noted already that <span class="math inline">\(W\)</span> acts
freely on every fiber of <span class="math inline">\(q\)</span>. We
claim now moreover that <span class="math inline">\(W\)</span> acts
<em>transitively</em> on every fiber of <span
class="math inline">\(q\)</span> in <span
class="math inline">\(U\)</span>, i.e., that <span
class="math inline">\(W\)</span> permutes the “pancakes” <span
class="math inline">\(U_y\)</span> lying above <span
class="math inline">\(U\)</span>. It suffices to verify that <span
class="math inline">\(W\)</span> acts transitively on the fibers above
any individual element <span class="math inline">\(t \in U\)</span>. By
Lemma <a href="#lem:generators-exist" data-reference-type="ref"
data-reference="lem:generators-exist">95</a>, we may take for <span
class="math inline">\(t\)</span> a generator of <span
class="math inline">\(T\)</span>. As a “basepoint” for <span
class="math inline">\(q^{-1}(t)\)</span>, we may take the pair <span
class="math inline">\((e T,t)\)</span>, with <span
class="math inline">\(e \in G\)</span> the identity element. If <span
class="math inline">\((g T,s)\)</span> is any other element of <span
class="math inline">\(q^{-1}(t)\)</span>, then <span
class="math inline">\(g s g^{-1} = t\)</span>, and so <span
class="math inline">\(g^{-1} t g = s \in T\)</span>, which (by Lemma <a
href="#lem:generators-cent-norm" data-reference-type="ref"
data-reference="lem:generators-cent-norm">96</a>) forces <span
class="math inline">\(g\)</span> to lie in <span
class="math inline">\(N(T)\)</span>, i.e., <span class="math inline">\(w
:= g T\)</span> to lie in <span class="math inline">\(W\)</span>. Thus
<span class="math inline">\((g T, s) = w \cdot (e T, t)\)</span>, and so
<span class="math inline">\(W\)</span> acts transitively on <span
class="math inline">\(q^{-1}(t)\)</span>, as required. It follows in
particular that <span class="math inline">\(\# q^{-1} (x) =\# q^{-1}(t)
= |W|\)</span>, so that for any <span class="math inline">\(\nu \in
\Omega_c^N(U)\)</span>, <span id="eq:partial-WIF-good-U" class="math display">\[\label{eq:partial-WIF-good-U}\tag{46}
    \int q^* \nu = |W| \int \nu.\]</span></p>
<p>We have nearly established <a href="#item:q-cover"
data-reference-type="ref"
data-reference="item:q-cover">ii</a>; what remains to show
is just that <span class="math inline">\(q : K/T \times
T^{\mathop{\mathrm{reg}}} \rightarrow K^{\mathop{\mathrm{reg}}}\)</span>
is surjective. The required surjectivity will follow from <a
href="#item:q-surj" data-reference-type="ref"
data-reference="item:q-surj">i</a> and hence from <a
href="#item:WIF-dif" data-reference-type="ref"
data-reference="item:WIF-dif">iii</a>, so it remains only to
establish <a href="#item:WIF-dif" data-reference-type="ref"
data-reference="item:WIF-dif">iii</a>.</p>
<p>To that end, let us call an open subset <span
class="math inline">\(U\)</span> of <span
class="math inline">\(K\)</span> <em>good</em> if <a href="#eq:WIF-dif"
data-reference-type="eqref" data-reference="eq:WIF-dif">\((45)\)</a>
holds for all <span class="math inline">\(\nu \in
\Omega_c^N(U)\)</span>. By a partition of unity argument and the
compactness of <span class="math inline">\(K\)</span>, it will suffice
to show that every element of <span class="math inline">\(K\)</span>
admits a good neighborhood. We’ve seen already in <a
href="#eq:partial-WIF-good-U" data-reference-type="eqref"
data-reference="eq:partial-WIF-good-U">\((46)\)</a> that
every element of <span
class="math inline">\(T^{\mathop{\mathrm{reg}}}\)</span> admits a good
neighborhood. The set <span
class="math inline">\(T^{\mathop{\mathrm{reg}}}\)</span> is nonempty.
The idea now will be to use Stokes’ theorem to “propagate” goodness from
any one open set to the rest. The following elementary fact from
differential geometry, known as the <em>Poincar<span>é</span>
lemma</em>, will be of use:</p>
<div class="center">
<p><em>Let <span class="math inline">\(\nu_1, \nu_2 \in
\Omega_c^N((0,1)^N)\)</span> be compactly-supported top-degree
differential forms on the open unit cube such that <span
class="math inline">\(\int \nu_1 = \int \nu_2\)</span>. Then there
exists <span class="math inline">\(\lambda \in
\Omega_c^{N-1}((0,1)^N)\)</span> so that <span
class="math inline">\(\nu_2 = \nu_1 + d \lambda\)</span>.</em></p>
</div>
<p>For example, if <span class="math inline">\(N = 1\)</span>, then
<span class="math inline">\(\nu_1 - \nu_2 = f(x) d x\)</span> for some
<span class="math inline">\(f \in C_c^\infty((0,1))\)</span> with <span
class="math inline">\(\int_0^1 f(x) \, d x = 0\)</span>, so <span
class="math inline">\(\lambda(x) := \int_{0}^x f(y) \, d y\)</span>
defines an element <span class="math inline">\(\lambda \in
C_c^\infty((0,1))\)</span> for which <span class="math inline">\(d
\lambda = \nu_1 - \nu_2\)</span>. The proof in the general case is
similar and recorded below for completeness. Assuming the
Poincar<span>é</span> lemma for the moment, we may complete the proof of
<a href="#item:WIF-dif" data-reference-type="ref"
data-reference="item:WIF-dif">iii</a> as follows:</p>
<ol>
<li><p>Say that an open subset <span class="math inline">\(U\)</span> of
<span class="math inline">\(K\)</span> is <em>small</em> if it admits a
chart <span class="math inline">\(U \cong (0,1)^N\)</span>. We claim
that <em>if <span class="math inline">\(U_1, U_2\)</span> are small,
<span class="math inline">\(U_1 \cap U_2\)</span> is nonempty, and <span
class="math inline">\(U_1\)</span> is good, then <span
class="math inline">\(U_2\)</span> is good.</em> To see this, let <span
class="math inline">\(\nu_2 \in \Omega_c^N(U_2)\)</span> be given.
Choose any <span class="math inline">\(\nu_1 \in \Omega_c^N(U_1 \cap
U_2)\)</span> with <span class="math inline">\(\int \nu_1 = \int
\nu_2\)</span>. By the Poincar<span>é</span> lemma applied in the chart
for <span class="math inline">\(U_2\)</span>, we may find <span
class="math inline">\(\lambda \in \Omega_c^{N-1}(U_2)\)</span> so that
<span class="math inline">\(\nu_2 = \nu_1 + d \lambda\)</span>. We have
<span class="math inline">\(q^* d \lambda = d q^* \lambda\)</span>,
whose integral vanishes thanks to Stokes’ theorem. By the assumed
goodness of <span class="math inline">\(U_1\)</span> and the
construction of <span class="math inline">\(\nu_1\)</span>, we deduce
that <span class="math inline">\(\int q^* \nu_2 = \int q^* \nu_1 = |W|
\int \nu_1 = |W| \int \nu_2\)</span>. Since <span
class="math inline">\(\nu_2\)</span> was arbitrary, we deduce as
required that <span class="math inline">\(U_2\)</span> is good.</p></li>
<li><p>We have seen that there exists <em>some</em> small good subset
<span class="math inline">\(U\)</span> of <span
class="math inline">\(K\)</span> (namely, any small enough open
neighborhood of a regular element of <span
class="math inline">\(T\)</span>). It will suffice to show that any
other small open subset <span class="math inline">\(U&#39;\)</span> of
<span class="math inline">\(K\)</span> is likewise good. To that end,
let us choose a curve <span class="math inline">\(\gamma : [0,1]
\rightarrow K\)</span> with <span class="math inline">\(\gamma(0) \in
U\)</span> and <span class="math inline">\(\gamma(1) \in
U&#39;\)</span>. We can find for each <span class="math inline">\(s \in
[0,1]\)</span> a good neighborhood of <span
class="math inline">\(\gamma(s)\)</span>. By a compactness argument
applied to the preimages of those neighborhoods, we may find a sequence
<span class="math inline">\(U = U_0, U_1, \dotsc, U_{m-1}, U_m =
U&#39;\)</span> of small open subsets of <span
class="math inline">\(K\)</span> with <span class="math inline">\(U_j
\cap U_{j-1} \neq \emptyset\)</span> for all <span
class="math inline">\(j=1..m\)</span>. By what was shown above, the
goodness of <span class="math inline">\(U_0 = U\)</span> inductively
implies the goodness of every <span class="math inline">\(U_j\)</span>,
hence in particular of <span
class="math inline">\(U&#39;\)</span>.</p></li>
</ol>
<p>The proof is now complete. ◻</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof of the Poincar<span>é</span> lemma." data-folded-text="Proof of the Poincar<span>é</span> lemma. (...)">Proof of the Poincar<span>é</span> lemma.</em></a>
<span class="proof-content"> (Omitted from
lecture, recorded here for completeness; probably a good exercise.)
Let’s work with <span class="math inline">\(n\)</span> instead of <span
class="math inline">\(N\)</span>. Write <span
class="math display">\[\nu_1 - \nu_2 = f(x_1,\dotsc,x_n) \, d x_1 \wedge
\dotsb \wedge d x_n.\]</span> By hypothesis, <span
class="math inline">\(f\)</span> is supported in <span
class="math inline">\((0,1)^n\)</span> and has mean zero. Our aim is to
show that <span class="math inline">\(f(x_1,\dotsc,x_n) \, d x_1 \wedge
\dotsb \wedge d x_n\)</span> is of the form <span
class="math inline">\(d \lambda\)</span> for some <span
class="math inline">\((n-1)\)</span>-form <span
class="math inline">\(\lambda\)</span> supported in <span
class="math inline">\((0,1)^n\)</span>. Equivalently, we must show that
<span id="eq:f-as-sum-of-partial-gs" class="math display">\[\label{eq:f-as-sum-of-partial-gs}\tag{47}
    f = \sum_{j=1}^n \partial_j g_j\]</span> for some <span
class="math inline">\(g_1,\dotsc,g_n\)</span> supported in <span
class="math inline">\((0,1)^n\)</span>, where <span
class="math inline">\(\partial_j\)</span> denotes the partial derivative
taken with respect to <span class="math inline">\(x_j\)</span>.</p>
<p>We induct on <span class="math inline">\(n\)</span>. The case <span
class="math inline">\(n = 0\)</span> is tautological, while the case
<span class="math inline">\(n = 1\)</span> was treated above. For the
case <span class="math inline">\(n \geq 2\)</span>, we apply our
inductive hypothesis to write <span class="math display">\[\int_{y=0}^1
f(y,x_2,\dotsc,x_n) \, d y = \sum_{j=2..n} \partial_{j}
h_j(x_2,\dotsc,x_n).\]</span> Fixing <span class="math inline">\(\chi
\in C_c^\infty((0,1))\)</span> with <span class="math inline">\(\int
\chi = 1\)</span>, the function <span
class="math display">\[g_j(x_1,\dotsc,x_n) :=
    \chi(x_1) h_j(x_2,\dotsc,x_n)\]</span> is supported in <span
class="math inline">\((0,1)^n\)</span>. Set <span
class="math inline">\(f&#39; := f - \sum_{j \geq 2} \partial_j
g_j\)</span>. Then <span class="math display">\[\int_{y=0}^1
f&#39;(y,x_2,\dotsc,x_n) \, d y = 0 \text{ for all }
x_2,\dotsc,x_n,\]</span> so that <span
class="math display">\[g_1(x_1,\dotsc,x_n) := \int_{y=0}^{x_1}
f&#39;(y,x_2,\dotsc,x_n) \, d y\]</span> is supported in <span
class="math inline">\((0,1)^n\)</span> and satisfies <span
class="math inline">\(\partial_1 g_1 = f&#39;\)</span>. The required
identity <a href="#eq:f-as-sum-of-partial-gs"
data-reference-type="eqref"
data-reference="eq:f-as-sum-of-partial-gs">\((47)\)</a>
then holds by construction. ◻</p>
</span></div>
<div class="remark">
<p><strong>Remark 104</strong>. I wanted to present the proof as
elementarily as possible, but I would be remiss not to mention that what
the above arguments “really” show is that for any connected <span
class="math inline">\(N\)</span>-manifold <span
class="math inline">\(M\)</span>, the compactly-supported top-degree de
Rham cohomology group <span class="math display">\[H^N_c(M) :=
\Omega_c^N(M) / d \Omega_c^{N-1}(M),\]</span> with coefficients taken in
either <span class="math inline">\(k = \mathbb{R}\)</span> or <span
class="math inline">\(\mathbb{C}\)</span>, is isomorphic to <span
class="math inline">\(k\)</span>, with the isomorphism <span id="eq:HNc-isom-k" class="math display">\[\label{eq:HNc-isom-k}\tag{48}
    H^N_c(M) \xrightarrow{\cong} k\]</span> defined by integrating an
<span class="math inline">\(N\)</span>-form over <span
class="math inline">\(M\)</span>. (Convince yourself that our arguments
actually establish this.) Since <span class="math inline">\(K/T \times
T\)</span> and <span class="math inline">\(K\)</span> are both connected
compact <span class="math inline">\(N\)</span>-manifolds, we can replace
<span class="math inline">\(H^N_c\)</span> with <span
class="math inline">\(H^N\)</span>, and the formula <a
href="#eq:WIF-dif" data-reference-type="eqref"
data-reference="eq:WIF-dif">\((45)\)</a> says that the dual map
<span class="math inline">\(q^*\)</span> on de Rham cohomlogy fits into
a commutative diagram <span class="math display">\[\begin{CD}         
      H^N(K)   @&gt;q^*&gt;&gt;H^N(K/T \times T)\\
      @V\cong VV  @VV\cong V \\
      k @&gt;&gt;|W|&gt; k,\\
    \end{CD}\]</span> where we write <span
class="math inline">\(|W|\)</span> for the “multiplication by <span
class="math inline">\(|W|\)</span>” map. We know that every continuous
<span class="math inline">\(k\)</span>-linear map <span
class="math inline">\(k \rightarrow k\)</span> is given by
multiplication by <em>something</em>, so the issue is just to compute
the proportionality constant for at least one <span
class="math inline">\(N\)</span>-form <span
class="math inline">\(\nu\)</span>. We managed to do this for all <span
class="math inline">\(\nu\)</span> supported in a small enough
neighborhood of a regular element of the torus.</p>
<p>It’s also worth noting that one can see <em>a priori</em> that
proportionality constant (in this case <span
class="math inline">\(|W|\)</span>) must an <em>integer</em> by applying
the comparison isomorphism relating de Rham cohomology to singular
cohomology and working instead with <span
class="math inline">\(\mathbb{Z}\)</span>-coefficients for the latter,
using Poincar<span>é</span> duality to obtain the analogue over <span
class="math inline">\(\mathbb{Z}\)</span> of the integration isomorphism
<a href="#eq:HNc-isom-k" data-reference-type="eqref"
data-reference="eq:HNc-isom-k">\((48)\)</a>. For details see the
BTD course reference.</p>
</div>
<div class="remark">
<p><strong>Remark 105</strong>. The intuitive idea behind the proof of
the surjectivity assertion <a href="#item:q-surj"
data-reference-type="ref" data-reference="item:q-surj">i</a>
of Theorem <a href="#thm:WIF-general" data-reference-type="ref"
data-reference="thm:WIF-general">103</a> may be
illustrated as follows. Let <span class="math inline">\(C\)</span> be a
smooth periodic oriented curve in the “cylinder” <span
class="math inline">\(X := \mathbb{R}/\mathbb{Z} \times
\mathbb{R}\)</span>, thus <span class="math inline">\(C\)</span> is the
image of some smooth map <span class="math inline">\(\gamma :
\mathbb{R}/\mathbb{Z} \rightarrow X\)</span>. Consider the map <span
class="math inline">\(\phi : C \rightarrow
\mathbb{R}/\mathbb{Z}\)</span> given by the projection <span
class="math inline">\((x,y) \mapsto x\)</span> onto the first
coordinate. Suppose that <span class="math inline">\(\phi\)</span> fails
to be surjective; say <span class="math inline">\(x_0 \notin
\phi(C)\)</span>. Take a “generic” nonempty fiber <span
class="math inline">\(\phi^{-1}(x)\)</span>. It’s then intuitively
plausible that the signed sum of the orientations of the elements <span
class="math inline">\(y \in \phi^{-1}(x)\)</span> must be zero, because
the trajectories along <span class="math inline">\(C\)</span> departing
from such elements and moving in the direction of <span
class="math inline">\(x_0\)</span> must pair off with one another in a
complementary fashion to be compatible with <span
class="math inline">\(\phi^{-1}(x_0)\)</span> being empty. This
intuitive plausibility is in fact the case, and may be formulated and
proved rigorously by the above arguments. This explains why <span
class="math inline">\(q\)</span> failing to be surjective is
incompatible with the fact that <span
class="math inline">\(\det(q)\)</span> is everywhere positive, the
latter of which implies that the orientations sum to <span
class="math inline">\(|W|\)</span> rather than to <span
class="math inline">\(0\)</span>.</p>
</div>
<p><a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a></p>
<h2 id="consequences-of-the-conjugacy-theorem">Consequences of the
conjugacy theorem</h2>
<p>Let <span class="math inline">\(K\)</span> be a compact connected Lie
group. We saw above that for any maximal torus <span
class="math inline">\(T\)</span>, we have <span class="math inline">\(K
= \cup_{g \in K} g T g^{-1}\)</span>. We now explore some consequences
of this fact.</p>
<div id="thm:exp-onto" class="theorem">
<p><strong>Theorem 106</strong>. <em>Every element of <span
class="math inline">\(K\)</span> is contained in some maximal torus, the
exponential map <span class="math inline">\(\exp : \mathfrak{k}
\rightarrow K\)</span> is onto, and every <span class="math inline">\(x
\in K\)</span> is contained in the connected component <span
class="math inline">\(Z_K(x)^0\)</span> of its centralizer.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> If <span class="math inline">\(T\)</span> is a
maximal torus, then its conjugates <span class="math inline">\(g T
g^{-1}\)</span> are also maximal tori, and we’ve seen that every element
of <span class="math inline">\(K\)</span> belongs to one of these. Since
for any torus <span class="math inline">\(T\)</span> the exponential map
<span class="math inline">\(\exp : \mathfrak{t} \rightarrow T\)</span>
is surjective, we deduce the corresponding result for <span
class="math inline">\(K\)</span>. The final assertion is clear when
<span class="math inline">\(x\)</span> is contained in the maximal torus
<span class="math inline">\(T\)</span>, because then <span
class="math inline">\(g \in T \leq Z_K(x)^0\)</span>, and follow in
general from what we have just shown. ◻</p>
</span></div>
<p>It’s worth illustrating the subtlety here with a “near proof.” Given
an element <span class="math inline">\(x \in K\)</span>, let <span
class="math inline">\(H := \overline{\langle x \rangle}\)</span> denote
the closure of the subgroup that it generates. Then <span
class="math inline">\(H\)</span> is closed in <span
class="math inline">\(K\)</span>, hence compact, and abelian. If we knew
that <span class="math inline">\(H\)</span> were connected, then <span
class="math inline">\(H\)</span> would be a torus, and so we’d be done.
If we even knew merely that <span class="math inline">\(x\)</span>
belonged to the connected component <span
class="math inline">\(H^0\)</span> of <span
class="math inline">\(H\)</span>, then we could conclude similarly. But
in general <span class="math inline">\(x \notin H^0\)</span>. For
instance, take <span class="math inline">\(x = (-1,e^i) \in
\mathop{\mathrm{U}}(1)^2\)</span>. Then <span class="math inline">\(H =
\{\pm 1\} \times \mathop{\mathrm{U}}(1)\)</span> and <span
class="math inline">\(H^0 = \{1\} \times
\mathop{\mathrm{U}}(1)\)</span>, so <span class="math inline">\(x \notin
H^0\)</span>. This illustrates some of the subtlety involved in Theorem
<a href="#thm:exp-onto" data-reference-type="ref"
data-reference="thm:exp-onto">106</a>.</p>
<p>Anyway, continuing with the consequences:</p>
<div id="thm:conj-max-tori" class="theorem">
<p><strong>Theorem 107</strong>. <em>Any two maximal tori <span
class="math inline">\(T, T&#39;\)</span> of <span
class="math inline">\(K\)</span> are conjugate.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(t&#39; \in
T&#39;\)</span> be a generator. We’ve seen that <span
class="math inline">\(t&#39; \in g T g^{-1}\)</span> for some <span
class="math inline">\(g \in K\)</span>. Since <span
class="math inline">\(g T g^{-1}\)</span> is a closed subgroup and <span
class="math inline">\(t&#39;\)</span> is a generator, it follows that
<span class="math inline">\(T&#39; \subseteq g T g^{-1}\)</span>. Since
<span class="math inline">\(T\)</span> is a maximal torus, so is <span
class="math inline">\(g T g^{-1}\)</span>, which forces the equality
<span class="math inline">\(T&#39; = g T g^{-1}\)</span>. ◻</p>
</span></div>
<div class="theorem">
<p><strong>Theorem 108</strong>. <em>The center <span
class="math inline">\(Z(K)\)</span> of <span
class="math inline">\(K\)</span> is given by <span
class="math display">\[Z(K) = \cap _{\text{maximal tori } T}
T.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ul>
<li><p>“<span class="math inline">\(\supseteq\)</span>”: Let <span
class="math inline">\(z \in \cap T\)</span> and <span
class="math inline">\(x \in K\)</span>. By Theorem <a
href="#thm:exp-onto" data-reference-type="ref"
data-reference="thm:exp-onto">106</a>, we may find a maximal torus <span
class="math inline">\(T\)</span> with <span class="math inline">\(x \in
T\)</span>. Then <span class="math inline">\(z \in T\)</span>, so <span
class="math inline">\(x\)</span> and <span
class="math inline">\(z\)</span> commute. Since <span
class="math inline">\(x\)</span> was arbitrary, we conclude that <span
class="math inline">\(z \in Z(K)\)</span>.</p></li>
<li><p>“<span class="math inline">\(\subseteq\)</span>”: Let <span
class="math inline">\(z \in Z(K)\)</span>, and let <span
class="math inline">\(T\)</span> be a maximal torus. Choose <span
class="math inline">\(g \in K\)</span> so that <span
class="math inline">\(z \in g T g ^{-1}\)</span>. Then <span
class="math inline">\(T \ni g^{-1} z g = z\)</span>, because <span
class="math inline">\(z\)</span> is central. Since <span
class="math inline">\(T\)</span> was arbitrary, we conclude that <span
class="math inline">\(z \in \cap T\)</span>.</p></li>
</ul>
<p> ◻</p>
</span></div>
<div class="theorem">
<p><strong>Theorem 109</strong>. <em>Let <span
class="math inline">\(T\)</span> be a maximal torus, with Weyl group
<span class="math inline">\(W = N(T)/T\)</span>. If <span
class="math inline">\(t, t&#39; \in T\)</span> are <span
class="math inline">\(K\)</span>-conjugate, then they have the same
<span class="math inline">\(W\)</span>-orbits. Thus the map <span
class="math display">\[T/W \rightarrow \{\text{conjugacy classes in }
K\}\]</span> is bijective.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(H :=
Z_K(t&#39;)^0\)</span> denote the connected component of the centralizer
of <span class="math inline">\(t&#39; \in T\)</span>. Choose <span
class="math inline">\(g \in K\)</span> so that <span
class="math inline">\(t&#39; = g t g^{-1}\)</span>; in paricular, <span
class="math inline">\(t&#39; \in g T g^{-1}\)</span>. Then the tori
<span class="math inline">\(g T g^{-1}\)</span> and <span
class="math inline">\(T\)</span> are both contained in <span
class="math inline">\(H\)</span> and maximal in <span
class="math inline">\(K\)</span>, hence maximal in <span
class="math inline">\(H\)</span>, so by Theorem <a
href="#thm:conj-max-tori" data-reference-type="ref"
data-reference="thm:conj-max-tori">107</a> applied to the compact
connected Lie group <span class="math inline">\(H\)</span>, we see that
there is some <span class="math inline">\(h \in H\)</span> so that <span
class="math inline">\(T = h g T g^{-1} h^{-1}\)</span>, i.e., so that
<span class="math inline">\(h g \in N_K(T)\)</span>. Let <span
class="math inline">\(w := h g T\)</span> denote the class of <span
class="math inline">\(h g\)</span> in the Weyl group <span
class="math inline">\(W\)</span>. Then <span class="math inline">\(w
\cdot t = h g t g^{-1} h^{-1} = h t&#39; h^{-1} = t&#39;\)</span>, since
<span class="math inline">\(h\)</span> centralizes <span
class="math inline">\(t&#39;\)</span>. ◻</p>
</span></div>
<div class="theorem">
<p><strong>Theorem 110</strong>. <em>Let <span class="math inline">\(S
\subseteq K\)</span> be any torus. Then its centralizer is described by
the formula <span class="math display">\[Z_K(S) = \cup _{\text{maximal
tori } T \supseteq S} T.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We start by noting that if <span
class="math inline">\(g \in Z_K(S)\)</span>, then <span
class="math inline">\(S \subseteq Z_K(g)^0\)</span>. The remainder of
the proof is left as an exercise in applying the ideas introduced
above. ◻</p>
</span></div>
<div class="corollary">
<p><strong>Corollary 111</strong>. <em>For all tori <span
class="math inline">\(S\)</span>, the centralizer <span
class="math inline">\(Z_K(S)\)</span> is connected.</em></p>
</div>
<p>This might sound at first like a very dry and boring result, but
knowing that a subgroup is connected is quite powerful, because it
reduces the determination of that subgroup to that of its Lie
algebra.</p>
<div class="corollary">
<p><strong>Corollary 112</strong>. <em>Let <span
class="math inline">\(T\)</span> be a maximal torus. Then <span
class="math inline">\(Z_K(T) = T\)</span>. Thus the Weyl group <span
class="math inline">\(W = N_K(T)/T = N_K(T)/ Z_K(T)\)</span> acts
faithfully on <span class="math inline">\(T\)</span>, i.e., <span
class="math inline">\(W\)</span> injects into <span
class="math inline">\(\mathop{\mathrm{Aut}}(T)\)</span>.</em></p>
</div>
<div id="cor:Z-k-x-conn" class="corollary">
<p><strong>Corollary 113</strong>. <em>Let <span class="math inline">\(x
\in \mathfrak{k}\)</span>. Then <span class="math inline">\(Z_K(x) :=
\{g \in K : \mathop{\mathrm{Ad}}(g) x = x\}\)</span> is
connected.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Set <span class="math inline">\(S :=
\overline{\exp(\mathbb{R} x)}\)</span>. Then <span
class="math inline">\(S\)</span> is a torus, and <span
class="math inline">\(Z_K(x) = Z_K(S)\)</span>. ◻</p>
</span></div>
<h2 id="sec:basics-weyl-chambers">§7.8. Basics on Weyl chambers</h2>
<p>We continue to assume that <span class="math inline">\(K\)</span> is
a compact connected Lie group. We fix a maximal torus <span
class="math inline">\(T\)</span>. We now define the “Lie algebra
variants” of the sets of regular elements defined at the group level in
§<a href="#sec:weyl-integr-form-general" data-reference-type="ref"
data-reference="sec:weyl-integr-form-general">7.6</a>. To that end, let
us denote by <span class="math display">\[D_0 : \mathfrak{g} \rightarrow
\mathbb{R}\]</span> <span class="math display">\[D_0(x) := \text{
coefficient of } \lambda^{\dim(T)} \text{ in } \det(\lambda -
\mathop{\mathrm{ad}}(x))\]</span> the Lie algebra analogue of the map
<span class="math inline">\(D : G \rightarrow \mathbb{R}\)</span>
defined earlier. We may compute <span class="math inline">\(D_0\)</span>
on a toral element <span class="math inline">\(x \in
\mathfrak{t}\)</span> as follows. The root space decomposition <a
href="#eq:root-space-decomp" data-reference-type="eqref"
data-reference="eq:root-space-decomp">\((43)\)</a> for the
action of <span class="math inline">\(T\)</span> on <span
class="math inline">\(\mathfrak{g}\)</span> differentiates to a
decomposition for the action of <span
class="math inline">\(\mathfrak{t}\)</span> on <span
class="math inline">\(\mathfrak{g}\)</span>, namely if we decompose
<span class="math inline">\(x \in \mathfrak{g}\)</span> as <span id="eq:root-space-decomp-of-x-again" class="math display">\[\label{eq:root-space-decomp-of-x-again}\tag{49}
  x = x_0 + \sum x_\alpha
  \in \mathfrak{t}_{\mathbb{C}} \oplus (\oplus_{\alpha \in \Phi}
  \mathfrak{g}^\alpha),\]</span> then <span id="eq:adjoint-actino-on-root-sapce-decmop" class="math display">\[\label{eq:adjoint-actino-on-root-sapce-decmop}\tag{50}
  [z,x]
  = 0 + \sum \alpha(z) x_\alpha
  \text{ for all }
  z \in \mathfrak{t}.\]</span> Thus <span
class="math inline">\(\det(\lambda - \mathop{\mathrm{ad}}(z)) =
\lambda^{\dim(T)} \prod_{\alpha \in \Phi } (\lambda -
\alpha(z))^{\dim(\mathfrak{g}^\alpha)}\)</span>. Since the roots <span
class="math inline">\(\alpha\)</span> come in pairs <span
class="math inline">\(\{\alpha, - \alpha \}\)</span> with <span
class="math inline">\(\dim(\mathfrak{g}^\alpha) =
\dim(\mathfrak{g}^{-\alpha})\)</span>, we have <span
class="math inline">\(\prod_{\alpha \in \Phi}
(-1)^{\dim(\mathfrak{g}^\alpha)} = 1\)</span>, which gives the simple
formula <span class="math display">\[D_0(z) = \prod_{\alpha \in \Phi}
\alpha(z)^{\dim(\mathfrak{g}^\alpha)} \text{ for } z \in
\mathfrak{t}.\]</span> We note again that we’ll show in a bit that each
root space is one-dimensional, so that the exponents <span
class="math inline">\(\dim(\mathfrak{g}^\alpha)\)</span> may be
omitted.</p>
<div class="definition">
<p><strong>Definition 114</strong>. We say that <span
class="math inline">\(x \in \mathfrak{k}\)</span> is <em>regular</em> if
<span class="math inline">\(D_0(x) \neq 0\)</span>. We write <span
class="math inline">\(\mathfrak{k}^{\mathop{\mathrm{reg}}} \subseteq
\mathfrak{k}\)</span> for the subset of regular elements. We more
generally use a superscripted <span
class="math inline">\(\mathop{\mathrm{reg}}\)</span>, as in <span
class="math inline">\(\mathfrak{t}^{\mathop{\mathrm{reg}}},
\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>, etc., to
denote the subset of regular elements.</p>
<p>A <em>Weyl chamber</em> <span class="math inline">\(C\)</span> is a
connected component of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>.</p>
</div>
<p>We note that <span
class="math inline">\(\mathfrak{k}^{\mathop{\mathrm{reg}}}\)</span> is
closed under <span
class="math inline">\(\mathop{\mathrm{Ad}}(K)\)</span>, since the
characteristic polynomial is invariant by conjugation. We leave it to
the reader to check the instructive identity <span
class="math display">\[\mathfrak{k}^{\mathop{\mathrm{reg}}} = \{ x \in
\mathfrak{k} : \exp(i \varepsilon x) \in K^{\mathop{\mathrm{reg}}}
\text{ for all small } \varepsilon&gt; 0.  \}\]</span> Thus <span
class="math inline">\(\mathfrak{k}^{\mathop{\mathrm{reg}}}\)</span> may
be regarded as a sort of “tangent cone” at the identity to the open
subset <span class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span> of
<span class="math inline">\(K\)</span>. Note however that there are
elements of <span
class="math inline">\(\mathfrak{k}^{\mathop{\mathrm{reg}}}\)</span>
whose exponentials do not lie in <span
class="math inline">\(K^{\mathop{\mathrm{reg}}}\)</span>; for example,
<span class="math inline">\(x = \mathop{\mathrm{diag}}(\pi i, - \pi i )
\in \mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span> is regular,
but <span class="math inline">\(\exp(x) = \mathop{\mathrm{diag}}(-1,-1)
\in \mathop{\mathrm{SU}}(2)\)</span> is not regular.</p>
<p>Let <span class="math inline">\(C\)</span> be a Weyl chamber. Its
image <span class="math inline">\(\alpha(C)\)</span> under any root
<span class="math inline">\(\alpha\)</span> is then a connected subset
of <span class="math inline">\(\mathbb{R}_{ \neq 0} = \mathbb{R}_{&gt;0}
\cup \mathbb{R}_{&lt;0}\)</span>, and is thus contaiend in either the
positive or negative reals. In other words, we may find signs <span
class="math inline">\(\varepsilon_{\alpha} \in \{\pm 1\}\)</span> (<span
class="math inline">\(\alpha \in \Phi\)</span>) so that <span
class="math inline">\(C \subseteq C_\varepsilon:= \{x \in
\mathfrak{t}_{\mathbb{R}} : \varepsilon_\alpha \alpha(x) &gt; 0 \text{
for all } \alpha \in \Phi \}\)</span>. On the other hand, it’s clear
from the definition that <span
class="math inline">\(C_{\varepsilon}\)</span> is a <em>convex
cone</em>, i.e., if <span class="math inline">\(x_1,\dotsc,x_n \in
C_{\varepsilon}\)</span> and <span class="math inline">\(t_1,\dotsc,t_n
&gt; 0\)</span>, then <span class="math inline">\(t_1 x_1 + \dotsb + t_n
x_n\)</span>. In particular, <span
class="math inline">\(C_{\varepsilon}\)</span> is a connected subset of
<span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>.
Since <span class="math inline">\(C\)</span> is by definition a
connected component of the latter set, we deduce that <span
class="math inline">\(C = C_{\varepsilon}\)</span>; that is to say,
every Weyl chamber is described by requiring that each root <span
class="math inline">\(\alpha\)</span> have some prescribed sign <span
class="math inline">\(\varepsilon_{\alpha}\)</span> on all of <span
class="math inline">\(C\)</span>. In particular, <span
class="math inline">\(C\)</span> is a convex cone.</p>
<p>For instance, if <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, then <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> identifies with
the set <span class="math inline">\(\mathbb{R}^n\)</span> of <span
class="math inline">\(n\)</span>-tuples <span class="math inline">\(x =
(x_1,\dotsc,x_n)\)</span> of real numbers, and the subset <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>
with the subset consisting of those <span
class="math inline">\(x\)</span> whose entries are distinct: <span
class="math inline">\(x_i \neq x_j\)</span> for <span
class="math inline">\(i \neq j\)</span>. Since the roots are of the form
<span class="math inline">\(\varepsilon_i - \varepsilon_j\)</span> with
<span class="math inline">\(i \neq j\)</span>, any Weyl chamber <span
class="math inline">\(C\)</span> is described by inequalities of the
form <span class="math inline">\(x_i &gt; x_j\)</span> or <span
class="math inline">\(x_i &lt; x_j\)</span> for all indices <span
class="math inline">\(i &lt; j\)</span>. There is thus a permutation
<span class="math inline">\(\sigma\)</span> of <span
class="math inline">\(\{1..n\}\)</span> so that <span
class="math inline">\(C = \{ x : x_{\sigma(1)} &gt; \dotsb &gt;
x_{\sigma(n)} \}\)</span>. In particular, the symmetric group <span
class="math inline">\(S(n)\)</span> acts simply-transitively on the set
of Weyl chambers. This observation and the fact that <span
class="math inline">\(W \cong S(n)\)</span> are no accident; we’ll soon
see that they are features of general compact connected Lie groups.</p>
<p>Let’s briefly review the various actions at our disposal. We have
actions of <span class="math inline">\(K\)</span> on <span
class="math inline">\(K\)</span> by conjugation, on <span
class="math inline">\(\mathfrak{k}, \mathfrak{g}\)</span> by the adjoint
representation <span
class="math inline">\(\mathop{\mathrm{Ad}}\)</span>, and on <span
class="math inline">\(\mathfrak{k}^*, \mathfrak{g}^*\)</span> by the
coadjoint representation <span
class="math inline">\({\mathop{\mathrm{Ad}}}^*\)</span>; we also have the
differentiated actions <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span> of <span
class="math inline">\(\mathfrak{k}\)</span> on <span
class="math inline">\(\mathfrak{k}, \mathfrak{g}\)</span> (or of <span
class="math inline">\(\mathfrak{g}\)</span> on <span
class="math inline">\(\mathfrak{g}\)</span>) and <span
class="math inline">\({\mathop{\mathrm{ad}}}^*\)</span> of <span
class="math inline">\(\mathfrak{k}\)</span> on <span
class="math inline">\(\mathfrak{k}^*, \mathfrak{g}^*\)</span> (or of
<span class="math inline">\(\mathfrak{g}\)</span> on <span
class="math inline">\(\mathfrak{g}^*\)</span>). These are related as
follows: if <span class="math inline">\(g \in K\)</span> and <span
class="math inline">\(x \in \mathfrak{g}\)</span> and <span
class="math inline">\(\xi \in \mathfrak{g}^*\)</span>, then <span
class="math display">\[\langle x, \xi \rangle = \langle g \cdot x, g
\cdot \xi \rangle;\]</span> here <span class="math inline">\(\langle ,
\rangle\)</span> denotes the canonical pairing <span
class="math inline">\(\mathfrak{g} \otimes \mathfrak{g}^* \rightarrow
\mathbb{C}\)</span> and we abbreviate <span class="math inline">\(g
\cdot x := \mathop{\mathrm{Ad}}(g) x\)</span> and <span
class="math inline">\(g \cdot \xi := {\mathop{\mathrm{Ad}}}^*(g)
\xi\)</span>. In terms of the differentiated actions, this reads: for
<span class="math inline">\(z \in \mathfrak{g}\)</span>, we have <span
class="math display">\[\langle z \cdot x, \xi \rangle + \langle x, z
\cdot \xi \rangle
  = 0,\]</span> where <span class="math inline">\(\cdot\)</span> denotes
the evident action, e.g., <span class="math inline">\(z \cdot x =
\mathop{\mathrm{ad}}(z) x = [z,x]\)</span>.</p>
<p>The Weyl group <span class="math inline">\(W = N(T)/T\)</span> acts
on <span class="math inline">\(T\)</span> by conjugation, hence on <span
class="math inline">\(\mathfrak{t}, \mathfrak{t}_{\mathbb{R}},
\mathfrak{t}_{\mathbb{C}}\)</span>, etc., by the adjoint action
inherited from <span class="math inline">\(G\)</span>, and likewise on
<span class="math inline">\(\mathfrak{t}^*,
\mathfrak{t}_{\mathbb{R}}^*\)</span>, etc., by the coadjoint action. The
action of <span class="math inline">\(W\)</span> on <span
class="math inline">\(T\)</span> induces an action of <span
class="math inline">\(w \in W\)</span> on the cocharacter group <span
class="math inline">\(X^\vee(T)\)</span> and on the character group
<span class="math inline">\(X(T)\)</span>, denoted <span
class="math inline">\(\gamma \mapsto w(\gamma)\)</span> and <span
class="math inline">\(\lambda \mapsto w(\lambda)\)</span>, characterized
in the first case by requiring that <span class="math display">\[z^{w
(\gamma)} = w \cdot z^{\gamma}\]</span> (for <span
class="math inline">\(z \in \mathop{\mathrm{U}}(1)\)</span> and <span
class="math inline">\(\gamma \in X^\vee(T)\)</span>) and in the second
case by requiring that <span class="math display">\[(w \cdot
t)^{w(\lambda)} = t^{\lambda}\]</span> (for <span
class="math inline">\(t \in T\)</span> and <span
class="math inline">\(\lambda \in X(T)\)</span>). The actions of <span
class="math inline">\(W\)</span> on <span
class="math inline">\(X(T)\)</span> and <span
class="math inline">\(X^\vee(T)\)</span> and on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> are compatible
with the identifications <span class="math inline">\(X(T) \cong
\mathfrak{t}_{\mathbb{Z}}^* \subseteq
\mathfrak{t}_{\mathbb{R}}^*\)</span> and <span
class="math inline">\(X^\vee(T) \cong \mathfrak{t}_{\mathbb{Z}}
\subseteq \mathfrak{t}_{\mathbb{R}}\)</span>, thus the actions of <span
class="math inline">\(W\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> and on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> stabilize the
lattices <span class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span>
and <span class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span>.
Moreover:</p>
<div id="sec:weyl-group-acts-on-roots" class="lemma">
<p><strong>Lemma 115</strong>. </p>
<ol type="i">
<li><p><span class="math inline">\(W\)</span> acts on the set <span
class="math inline">\(\Phi\)</span> of roots, i.e., <span
class="math inline">\(w(\alpha) \in \Phi\)</span> for all <span
class="math inline">\(\alpha \in \Phi\)</span>; more precisely, <span id="eq:w-permutes-root-spaces" class="math display">\[\label{eq:w-permutes-root-spaces}\tag{51}
      w \cdot \mathfrak{g}^{\alpha}
      =
      \mathfrak{g}^{w(\alpha)}.\]</span></p></li>
<li><p><span class="math inline">\(W\)</span> acts on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>.</p></li>
<li><p><span class="math inline">\(W\)</span> acts on the set of Weyl
chambers, i.e., if <span class="math inline">\(C\)</span> is a Weyl
chamber, then so is <span class="math inline">\(w(C)\)</span> for each
<span class="math inline">\(w \in W\)</span>.</p></li>
</ol>
</div>
<p>We might pause to convince ourselves that all of these properties are
obvious in the familiar case of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>.</p>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>We check <a href="#eq:w-permutes-root-spaces"
data-reference-type="eqref"
data-reference="eq:w-permutes-root-spaces">\((51)\)</a>.
It suffices to show that <span class="math inline">\(w \cdot
\mathfrak{g}^{\alpha}\)</span>. (The same argument then gives <span
class="math inline">\(w^{-1} \cdot \mathfrak{g}^{w(\alpha)} \subseteq
\mathfrak{g}^{\alpha}\)</span>, whence equality.) Let <span
class="math inline">\(x \in \mathfrak{g}^\alpha\)</span> Then for <span
class="math inline">\(t \in T\)</span>, <span class="math display">\[t
\cdot w \cdot x = \mathop{\mathrm{Ad}}(t) \mathop{\mathrm{Ad}}(w) x =
\mathop{\mathrm{Ad}}(w) \mathop{\mathrm{Ad}}(w^{-1} \cdot t) x = (w^{-1}
\cdot t)^{\alpha} \mathop{\mathrm{Ad}}(w) x = t^{w(\alpha)}
\mathop{\mathrm{Ad}}(w) x.\]</span> Thus <span
class="math inline">\(\mathop{\mathrm{Ad}}(w) x \in
\mathfrak{g}^{w(\alpha)}\)</span>, as required.</p></li>
<li><p>Recall that <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>
consists of <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{R}}\)</span> for which <span
class="math inline">\(\langle x, \alpha \rangle = \alpha(x)\)</span> is
nonzero for all roots <span class="math inline">\(\alpha\)</span>. We
have <span class="math inline">\(\langle w \cdot x, \alpha \rangle =
\langle x, w^{-1}(\alpha) \rangle\)</span>, and we’ve seen that <span
class="math inline">\(w^{-1}\)</span> preserves the set of roots, so we
conclude that <span class="math inline">\(w\)</span> stabilizes <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>.</p></li>
<li><p>We use the previous assertion and the continuity of the action of
<span class="math inline">\(W\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<p>The following result illustrates well the power of knowing that tori
have connected centralizers:</p>
<div id="lem:W-acts-freely-weyl-chambers" class="lemma">
<p><strong>Lemma 116</strong>. The action of <span
class="math inline">\(W\)</span> on the set of Weyl chambers is free,
i.e., if <span class="math inline">\(C\)</span> is a Weyl chamber and
<span class="math inline">\(w \in W\)</span> satisfies <span
class="math inline">\(w(C) = C\)</span>, then <span
class="math inline">\(w = 1\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(W_C := \{w \in W :
w(C) = C\}\)</span>. We must show that <span class="math inline">\(W_C =
\{1\}\)</span>. We’ve seen that <span class="math inline">\(C\)</span>
is a convex cone, and also that <span class="math inline">\(W\)</span>
and hence <span class="math inline">\(W_C\)</span> is finite. Let <span
class="math inline">\(y_0 \in C\)</span>. Then the element <span
class="math inline">\(y := \sum_{w \in W_C} w \cdot y_0\)</span> is a
positive linear combination of elements of <span
class="math inline">\(C\)</span>, hence belongs to <span
class="math inline">\(C\)</span>. Let <span class="math inline">\(w \in
W_C\)</span>. Then <span class="math inline">\(w\)</span> permutes the
summands in the definition of <span class="math inline">\(y\)</span>, so
<span class="math inline">\(w \cdot y = y\)</span>, i.e., <span
class="math inline">\(w T \subseteq Z_K(y)\)</span>. By Corollary <a
href="#cor:Z-k-x-conn" data-reference-type="ref"
data-reference="cor:Z-k-x-conn">113</a>, <span
class="math inline">\(Z_K(y)\)</span> is connected. By general Lie
theory, the Lie algebra of <span class="math inline">\(Z_K(y)\)</span>
is given by <span class="math inline">\(Z_{\mathfrak{k}}(y) = \{x \in
\mathfrak{k} : [y,x] = 0\}\)</span>. Let <span class="math inline">\(x
\in Z_{\mathfrak{k}}(y)\)</span>. Writing <span class="math inline">\(x
= x_0 + \sum x_\alpha\)</span> as in <a
href="#eq:root-space-decomp-of-x-again" data-reference-type="eqref"
data-reference="eq:root-space-decomp-of-x-again">\((49)\)</a>,
we have <span class="math inline">\(0 = [y,x] = 0 + \sum \alpha(y)
x_\alpha\)</span>. Since <span class="math inline">\(\alpha(y)\)</span>
is nonzero and the root space decomposition <a
href="#eq:root-space-decomp" data-reference-type="eqref"
data-reference="eq:root-space-decomp">\((43)\)</a> is a
direct sum decomposition, it follows that <span
class="math inline">\(x_\alpha =0\)</span> for all <span
class="math inline">\(\alpha\)</span>, whence that <span
class="math inline">\(x = x_0 \in \mathfrak{t}_{\mathbb{C}} \cap
\mathfrak{k} = \mathfrak{t}\)</span>. Therefore <span
class="math inline">\(Z_{\mathfrak{k}}(y) = \mathfrak{t}\)</span>. By
the noted connectivity, it follows that <span
class="math inline">\(Z_K(y) = T\)</span>. Thus <span
class="math inline">\(w T \subseteq T\)</span>, i.e., <span
class="math inline">\(w = 1\)</span> in <span
class="math inline">\(W\)</span>. We conclude as required that <span
class="math inline">\(W_C = \{1\}\)</span>. ◻</p>
</span></div>
<p>We’ll see later that the action of <span
class="math inline">\(W\)</span> on the set of Weyl chambers is moreover
<em>transitive</em>; the above lemma will then tell us that it is
simply-transitive, hence that the order <span
class="math inline">\(|W|\)</span> of the Weyl group is equal to the
number of Weyl chambers. So far, we haven’t given any way to
<em>produce</em> nontrivial elements of the Weyl group. (For instance,
why should <span class="math inline">\(W\)</span> be nontrivial when
<span class="math inline">\(K \neq T\)</span>?) That’s our next main
objective. The construction will involve the roots. For each root <span
class="math inline">\(\alpha\)</span> , we’ll cook up a map <span
class="math inline">\(F_\alpha : \mathop{\mathrm{SU}}(2) \rightarrow
K\)</span>. We’ll then use these maps to produce Weyl group elements,
called <em>root reflections</em>, which we’ll eventually show generate
the Weyl group.</p>
<h2 id="notation-and-preliminaries-concerning-mathopmathrmsu2">Notation
and preliminaries concerning <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></h2>
<p>Take <span class="math inline">\(K =
\mathop{\mathrm{SU}}(2)\)</span>, so that <span
class="math inline">\(\mathfrak{k} =
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span>, <span
class="math inline">\(G = {\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>,
<span class="math inline">\(\mathfrak{g} =
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>. Let
<span class="math inline">\(T \leq K\)</span> denote the standard
maximal torus <span
class="math inline">\(\{\mathop{\mathrm{diag}}(t,t^{-1}) : t \in
\mathop{\mathrm{U}}(1)\}\)</span>, so that <span
class="math inline">\(\mathfrak{t} \leq \mathfrak{k}\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}} \leq
\mathfrak{g}\)</span> are the diagonal subalgebras. The map <span
class="math inline">\(\theta : \mathfrak{g} \rightarrow
\mathfrak{g}\)</span> given as usual by <span
class="math inline">\(\theta(x) = - x^* = - \overline{x}^t\)</span> has
the property that <span class="math inline">\(\mathfrak{k}\)</span> is
the <span class="math inline">\(\theta\)</span>-fixed subspace of <span
class="math inline">\(\mathfrak{g}\)</span>. Define <span
class="math inline">\(X,Y,H \in \mathfrak{g}\)</span> by <span id="eq:defn-HXY" class="math display">\[\label{eq:defn-HXY}\tag{52}
  H :=
\begin{pmatrix}
    1 &amp;  \\
    &amp; -1
  \end{pmatrix}
, \quad X :=
\begin{pmatrix}
    0 &amp; 1 \\
    0 &amp; 0
  \end{pmatrix}
, \quad Y :=
\begin{pmatrix}
    0 &amp; 0 \\
    1 &amp; 0
  \end{pmatrix}
.\]</span> Then <span id="eq:relations-X-Y-H" class="math display">\[\label{eq:relations-X-Y-H}\tag{53}
  [X,Y] = H,
  \quad
  [H, X] = 2 X,
  \quad
  [H, Y] = - 2 Y\]</span> and <span id="eq:relations-X-Y-H-theta" class="math display">\[\label{eq:relations-X-Y-H-theta}\tag{54}
  \theta(H) = - H,
  \quad
  \theta(X) = -Y,
  \quad
  \theta(Y) = -X.\]</span> These properties give a “presentation” for
<span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)\)</span>
in that for any pair <span class="math inline">\((\mathfrak{g} &#39;,
\theta&#39;)\)</span> consisting of a three-dimensional Lie algebra
<span class="math inline">\(\mathfrak{g} &#39;\)</span> equipped with an
antilinear involution <span class="math inline">\(\theta&#39;\)</span>
that admits a basis <span class="math inline">\(H&#39;, X&#39;,
Y&#39;\)</span> satisfying the analogue of <a href="#eq:relations-X-Y-H"
data-reference-type="eqref"
data-reference="eq:relations-X-Y-H">\((53)\)</a> and <a
href="#eq:relations-X-Y-H-theta" data-reference-type="eqref"
data-reference="eq:relations-X-Y-H-theta">\((54)\)</a>,
the map <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
\rightarrow \mathfrak{g} &#39;\)</span> given by <span
class="math inline">\(H \mapsto H&#39;, X \mapsto X&#39;, Y \mapsto
Y&#39;\)</span> is an isomorphism of complex Lie algebras that
intertwines <span class="math inline">\(\theta\)</span> with <span
class="math inline">\(\theta &#39;\)</span>, hence induces an
isomorphism of real Lie algebras <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)
\rightarrow \mathfrak{k} &#39; := \{x \in \mathfrak{g} &#39; : \theta
&#39;(x) = x\}\)</span>.</p>
<p>We have <span class="math display">\[\mathfrak{t}_{\mathbb{C}} =
\mathbb{C} H, \quad \mathfrak{t}_{\mathbb{R}} = \mathbb{R} H, \quad
\mathfrak{t}_{\mathbb{Z}} = \mathbb{Z} H.\]</span> (For the last of
these, we note that every one-parameter subgroup <span
class="math inline">\(\mathop{\mathrm{U}}(1) \rightarrow T\)</span> is
given by <span class="math inline">\(z \mapsto
\mathop{\mathrm{diag}}(z^m, z^{-m})\)</span> for some <span
class="math inline">\(m \in \mathbb{Z}\)</span>; we may rewrite this as
<span class="math inline">\(\exp(i \theta) \mapsto \exp(i m H)\)</span>,
whence the claim.) In view of <a href="#eq:relations-X-Y-H"
data-reference-type="eqref"
data-reference="eq:relations-X-Y-H">\((53)\)</a>, the root
space decomposition of <span class="math inline">\(\mathfrak{g}\)</span>
is given by <span class="math display">\[\mathfrak{g} =
  \underbrace{\mathbb{C} H}_{\mathfrak{t}_{\mathbb{C}}}
  \oplus
  \underbrace{\mathbb{C} X}_{\mathfrak{g}^{\alpha}}
  \oplus
  \underbrace{\mathbb{C} Y}_{\mathfrak{g}^{-\alpha}},\]</span> where
<span class="math inline">\(\alpha \in \mathfrak{t} _{\mathbb{R}
}^*\)</span> is characterized by <span class="math display">\[\alpha(H)
= 2.\]</span> The set of roots is thus <span class="math display">\[\Phi
= \{\alpha, - \alpha\}.\]</span> We note that <span
class="math display">\[\mathfrak{t}_{\mathbb{C}}^* = \mathbb{C} \alpha,
  \quad
  \mathfrak{t}_{\mathbb{R}}^* = \mathbb{R} \alpha,
  \quad
  \mathfrak{t}_{\mathbb{Z}}^*
  =  \tfrac{1}{2}\mathbb{Z} \alpha.\]</span> (For the last of these,
note that the characters of <span class="math inline">\(T\)</span> are
given by <span class="math inline">\(\mathop{\mathrm{diag}}(t,t^{-1})
\mapsto t^{l}\)</span> for some <span class="math inline">\(l \in
\mathbb{Z}\)</span>, and that if we write <span
class="math inline">\(\mathop{\mathrm{diag}}(t,t^{-1}) = \exp(i \theta
H)\)</span>, then <span class="math inline">\(t^l = \exp(i \theta l) =
\exp(i \theta l \alpha(H)/2) = \exp(i \theta H)^{l \alpha/2}\)</span>,
whence the characters of <span class="math inline">\(T\)</span> are
uniquely of the form <span class="math inline">\(l \alpha/2\)</span>
with <span class="math inline">\(l \in \mathbb{Z}\)</span>.)</p>
<p>Recall (§<a href="#sec:case-su2" data-reference-type="ref"
data-reference="sec:case-su2">3.8</a> and earlier) that any
finite-dimensional representation <span class="math inline">\(\pi :
\mathop{\mathrm{SU}}(2) \rightarrow \mathop{\mathrm{GL}}(V)\)</span>
decomposes as a sum <span class="math display">\[V = \oplus_{k \in
\mathbb{Z}} V^k\]</span> of weight spaces <span
class="math display">\[V^k := \{v \in V :
\mathop{\mathrm{diag}}(t,t^{-1}) v = t^k v \text{ for all } t \in
\mathop{\mathrm{U}}(1) \}.\]</span> For example, if <span
class="math inline">\((\pi,V) =
(\mathop{\mathrm{Ad}},\mathfrak{g})\)</span>, then <span
class="math inline">\(V^0 = \mathbb{C} H = \mathfrak{t}_{\mathbb{C}},
V^2 = \mathbb{C} X = \mathfrak{g}^{\alpha}, V^{-2} = \mathbb{C} Y =
\mathfrak{g}^{-\alpha}\)</span>. In terms of the differentiated
representation <span class="math inline">\(d \pi :
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2) \rightarrow
\mathop{\mathrm{End}}(V)\)</span> and its complexification <span
class="math inline">\(d \pi :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}) \rightarrow
\mathop{\mathrm{End}}(V)\)</span>, we may write <span
class="math display">\[V^k = \{v \in V : d \pi(H) v = k v \},\]</span>
that is to say, the weight space decomposition of <span
class="math inline">\((\pi,V)\)</span> is simply its decomposition into
eigenspaces for the operator <span class="math inline">\(d
\pi(H)\)</span>. Note in particular that every eigenvalue of <span
class="math inline">\(d \pi(H)\)</span> is an <em>integer</em>.</p>
<p>For simplicity of notation we will often use abbreviations like <span
class="math inline">\(x v := d \pi(x) v\)</span> for <span
class="math inline">\(x \in \mathfrak{g}\)</span> and <span
class="math inline">\(v \in V\)</span> when <span
class="math inline">\(\pi\)</span> is clear from context.</p>
<p>In view of the general identity “<span
class="math inline">\(\mathfrak{g}^\alpha \cdot V^{\lambda} \subseteq
V^{\lambda+\alpha}\)</span>” (Lemma <a
href="#lem:root-spaces-permute-weight-spaces" data-reference-type="ref"
data-reference="lem:root-spaces-permute-weight-spaces">92</a>) and the
fact that <span class="math inline">\(\alpha(H) = 2\)</span>, we see
that <span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> act on the <span
class="math inline">\(H\)</span>-eigenspaces by “raising and lowering
operators,” i.e., <span class="math display">\[d \pi(X) : V^k
\rightarrow V^{k+2}, \quad d \pi(Y) : V^k
  \rightarrow V^{k-2}.\]</span> For instance, this follows in the case
<span class="math inline">\((\pi,V) =
(\mathop{\mathrm{Ad}},\mathfrak{g})\)</span> from the identities <a
href="#eq:relations-X-Y-H" data-reference-type="eqref"
data-reference="eq:relations-X-Y-H">\((53)\)</a>.</p>
<p>We have also seen that the irreducible finite-dimensional
representation of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> are indexed by
nonnegative integers <span class="math inline">\(n\)</span> and given
explicitly by the <span class="math inline">\((n+1)\)</span>-dimensional
space <span class="math inline">\(V_n = \mathbb{C}[x,y]^{(n)}\)</span>
of homogeneous polynomials of degree <span
class="math inline">\(n\)</span> in two variables, with <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> acting by right
translation. Moreover, any finite-dimensional representation <span
class="math inline">\((\pi,V)\)</span> of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> decomposes
uniquely as a finite direct sum <span class="math inline">\(V =
\oplus_{n \geq 0} V_n^{\oplus \mu(n)}\)</span> for some multiplicities
<span class="math inline">\(\mu(n) \geq 0\)</span>,</p>
<p>The weight spaces of the irreducible representations <span
class="math inline">\((\pi_n,V_n)\)</span> are all one-dimensional, and
the weight space decompositions read <span
class="math display">\[\begin{align}
  V_n
  &amp;=
    V_n^{n} \oplus V_n^{n-2} \oplus V_n^{n-2} \oplus \dotsb
    \oplus V_{n}^{-n}
  \\
  &amp;=
    \mathbb{C} x^n
    \oplus \mathbb{C} x^{n-1} y
    \oplus \mathbb{C} x^{n-2} y^2
    \oplus \dotsb \oplus
    \mathbb{C} y^n.
\end{align}\]</span> Using the definition <a href="#eq:defn-HXY"
data-reference-type="eqref"
data-reference="eq:defn-HXY">\((52)\)</a>, we compute that the
action of <span class="math inline">\(\mathfrak{g}\)</span> is given by
<span class="math display">\[d \pi_n(H) = x \partial_x - y \partial _y,
  \quad d \pi_n(X)
  = x \partial_y,
  \quad
  d \pi_n(Y) = y \partial_x.\]</span> It follows readily from this
explicit description that the lowering maps <span
class="math display">\[V_n^n \xrightarrow{Y} V_n^{n-2}
  \xrightarrow{Y} V_n^{n-2} \xrightarrow{Y} \dotsb
  \xrightarrow{Y} V_n^{-n}\]</span> and the raising maps <span id="eq:X-raising-isoms" class="math display">\[\label{eq:X-raising-isoms}\tag{55}
  V_n^{-n} \xrightarrow{X} V_n^{-n+2}
  \xrightarrow{X} V_n^{-n+4} \xrightarrow{X} \dotsb
  \xrightarrow{X} V_n^{n}\]</span> are all isomorphisms of
one-dimensional vector spaces. Indeed, they send each monomial to an
explicit nonzero multiple of another monomial. Of course <span
class="math inline">\(d \pi(X) V_n^n\)</span> and <span
class="math inline">\(d \pi(Y) V_n^{-n}\)</span> are trivial, because
the weight spaces <span class="math inline">\(V_n^{n+2}\)</span> and
<span class="math inline">\(V_n^{-n-2}\)</span> are trivial.</p>
<p>Here’s a typical application of the above explication of the
representation theory of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>; this application
will turn out to be the key for showing that the root spaces of a
general compact Lie group are one-dimensional.</p>
<div id="lem:key-for-root-space-one-dimensional" class="lemma">
<p><strong>Lemma 117</strong>. Let <span
class="math inline">\(V\)</span> be a finite-dimensional representation
of <span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> such
that</p>
<ol type="i">
<li><p>all weights (i.e., eigenvalues of <span
class="math inline">\(H\)</span>) are even, and</p></li>
<li><p>the weight space <span class="math inline">\(V^0\)</span> is
one-dimensional.</p></li>
</ol>
<p>Then <span class="math inline">\(V\)</span> is irreducible, say <span
class="math inline">\(V \cong V_n\)</span>. If moreover there exists a
nonzero vector <span class="math inline">\(v \in V^2\)</span> such that
<span class="math inline">\(X v = 0\)</span>, then <span
class="math inline">\(n = 2\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Since the weights are even, when we decompose <span
class="math inline">\(V = \oplus V_n^{\oplus \mu(n)}\)</span> as a sum
of irreducibles <span class="math inline">\(V_n\)</span>, only those
with <span class="math inline">\(n\)</span> even occur with positive
multiplicity <span class="math inline">\(\mu(n)\)</span>. For <span
class="math inline">\(n\)</span> even, we have <span
class="math inline">\(\dim V_n^0 = 1\)</span>, thus <span
class="math inline">\(1 = \dim V^0 = \sum_n \mu(n)\)</span>. Thus <span
class="math inline">\(\mu(n) = 1\)</span> for some <span
class="math inline">\(n\)</span> and vanishes for all other values, and
so <span class="math inline">\(V \cong V_n\)</span>.</p>
<p>Suppose there exists <span class="math inline">\(v\)</span> with the
stated property. Since <span class="math inline">\(v\)</span> is nonzero
and <span class="math inline">\(X\)</span> annihilates <span
class="math inline">\(v\)</span>, we see (from the assertion following
<a href="#eq:X-raising-isoms" data-reference-type="eqref"
data-reference="eq:X-raising-isoms">\((55)\)</a>) that <span
class="math inline">\(n = 2\)</span>. ◻</p>
</span></div>
<p><a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a></p>
<p>Similarly:</p>
<div id="lem:key-for-rational-multiples-of-roots" class="lemma">
<p><strong>Lemma 118</strong>. Let <span
class="math inline">\(V\)</span> be a finite-dimensional representation
of <span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> that has
some odd weight, i.e., the weight space <span
class="math inline">\(V^n\)</span> is nonzero for some odd integer <span
class="math inline">\(n\)</span>. Then the weight space <span
class="math inline">\(V^1\)</span> is nonzero.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We decompose <span class="math inline">\(V =
\oplus_{n \geq 0} V_n^{\oplus \mu(n)}\)</span> into irreducibles. Since
the weights of <span class="math inline">\(V_n\)</span> all have the
same parity as <span class="math inline">\(n\)</span>, we see that <span
class="math inline">\(\mu(n)\)</span> is positive for some odd <span
class="math inline">\(n\)</span>. But for such <span
class="math inline">\(n\)</span>, the weights of <span
class="math inline">\(V_n\)</span> are <span
class="math inline">\(n,n-2,n-4,\dotsc,3,1,-1,-3,\dotsc,-n\)</span>.
Thus <span class="math inline">\(\dim V_n^1 &gt; 0\)</span> and so <span
class="math inline">\(\dim V^1 \geq \mu(n) \dim V_n^1 &gt; 0\)</span>,
as required. ◻</p>
</span></div>
<h2 id="sec:from-roots-dist">§7.10. From roots to distinguished <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>’s</h2>
<p>We’re now ready to state and prove one of the most important theorems
concerning the structure of compact Lie groups.</p>
<p>Recall the notation <a href="#eq:defn-HXY"
data-reference-type="eqref"
data-reference="eq:defn-HXY">\((52)\)</a> for the standard basis
elements <span class="math inline">\(H,X,Y\)</span> of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>.</p>
<div id="item:image-F-alpha" class="theorem">
<p><strong>Theorem 119</strong>. <em><span id="thm:from-roots-dist-su2"
label="thm:from-roots-dist-su2"></span> Let <span
class="math inline">\(K\)</span> be a compact connected Lie group, <span
class="math inline">\(T \leq K\)</span> a maximal torus, <span
class="math inline">\(\Phi = \Phi(K:T)\)</span> the associated set of
roots, and <span class="math inline">\(\mathfrak{g} =
\mathfrak{k}_{\mathbb{C}}\)</span> the complexified Lie algebra with the
usual root space decomposition. Let <span class="math inline">\(\alpha
\in \Phi \subseteq \mathfrak{t}_{\mathbb{Z}}^*\)</span> be a
root.</em></p>
<ol>
<li><p><em>There is a morphism of Lie groups <span
class="math display">\[F_\alpha : \mathop{\mathrm{SU}}(2) \rightarrow
K\]</span> whose differential <span class="math inline">\(d F_\alpha :
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2) \rightarrow
\mathfrak{k}\)</span> has complexification <span class="math inline">\(d
F_\alpha : {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
\rightarrow \mathfrak{g}\)</span> satisfying <span
class="math display">\[d F_\alpha (X) \in
\mathfrak{g}^\alpha.\]</span></em></p></li>
<li><p><em>There is a cocharacter <span
class="math inline">\(\alpha^\vee \in X^\vee(T) =
\mathop{\mathrm{Hom}}(\mathop{\mathrm{U}}(1),T)\)</span> so that for
each such <span class="math inline">\(F_\alpha\)</span>, we have a
commutative diagram <span id="eq:F-alpha-alpha-vee-commute" class="math display">\[\label{eq:F-alpha-alpha-vee-commute}\tag{56}
      \begin{CD}         
        \mathop{\mathrm{U}}(1) @&gt; \alpha^{\vee} &gt;&gt; T\\
        @V t \mapsto \mathop{\mathrm{diag}}(t, 1/t) VV  @VV V \\
        \mathop{\mathrm{SU}}(2) @&gt;&gt; F_{\alpha} &gt; K.
      \end{CD}\]</span> The cocharacter <span
class="math inline">\(\alpha^\vee\)</span> is independent of the choice
of <span class="math inline">\(F_\alpha\)</span>. More precisely, let
<span class="math display">\[H_\alpha \in \mathfrak{t}_{\mathbb{Z}}
\cong X^\vee(T)\]</span> correspond to <span
class="math inline">\(\alpha^\vee\)</span> in the sense of §<a
href="#sec:notat-relat-torus" data-reference-type="ref"
data-reference="sec:notat-relat-torus">7.1</a>, thus <span
class="math display">\[\alpha^\vee(e^{i \theta}) = \exp(i \theta
H_\alpha)\]</span> for all <span class="math inline">\(\theta \in
\mathbb{R}\)</span>. Then <span class="math inline">\(H_\alpha\)</span>
is the unique element of <span
class="math inline">\([\mathfrak{g}^{\alpha},
\mathfrak{g}^{-\alpha}]\)</span> such that <span
class="math inline">\(\alpha(H_\alpha) = 2\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(\dim(\mathfrak{g}^\alpha) =
1\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(\mathbb{C} \alpha \cap \Phi =
\mathbb{Q} \alpha \cap \Phi = \{\alpha, - \alpha
\}\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(F_\alpha\)</span> is unique up to
conjugation by the image of <span
class="math inline">\(\alpha^\vee\)</span>.</em></p></li>
<li><p><em>Let <span class="math inline">\(T_\alpha \leq T\)</span>
denote the codimension one subtorus defined as the connected component
of the kernel of <span class="math inline">\(\alpha\)</span>, thus <span
class="math display">\[T_\alpha := \ker(\alpha)^0 = \{t \in T : t^\alpha
= 1\}^0, \quad \mathfrak{t}_\alpha := \mathop{\mathrm{Lie}}(T_\alpha) =
\{x \in \mathfrak{t} : \alpha(x) = 0\}.\]</span> Then the image of <span
class="math inline">\(F_\alpha\)</span> is contained in the centralizer
<span class="math inline">\(Z_K(T_\alpha)\)</span>, and the composition
<span class="math display">\[\mathop{\mathrm{SU}}(2)
\xrightarrow{F_\alpha } Z_K(T_\alpha)
      \rightarrow Z_K(T_\alpha)/T_\alpha\]</span> is surjective, and
induces an isomorphism <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)
\cong Z_{\mathfrak{k}}(\mathfrak{t}_\alpha) /
\mathfrak{t}_\alpha\)</span> of Lie algebras.</em></p></li>
</ol>
</div>
<p>The point is that a root <span class="math inline">\(\alpha\)</span>
on its own is fairly useless – there’s not much you can do – but once
you know that it comes from some copy of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>, everything
becomes possible. If we learn anything from this part of the course,
it’s that <em>we should always think of a root of a compact connected
Lie group as coming with an associated copy of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></em> in the above
sense.</p>
<p>Let’s illustrate with the example of <span class="math inline">\(K =
\mathop{\mathrm{U}}(3)\)</span>, with <span class="math inline">\(T =
\mathop{\mathrm{U}}(1)^3\)</span> the standard diagonal maximal torus
and <span class="math inline">\(\alpha = \varepsilon_1 -
\varepsilon_2\)</span>, so that <span
class="math inline">\(\mathfrak{g}^{\alpha} = \mathbb{C} E_{12
}\)</span>. We may then take <span class="math display">\[F_\alpha (
\begin{pmatrix}
    a &amp; b \\
    c &amp; d
  \end{pmatrix}
) =
\begin{pmatrix}
    a &amp; b &amp; 0 \\
    c &amp; d &amp; 0 \\
    0 &amp; 0 &amp; 1
  \end{pmatrix}
,\]</span> so that <span class="math inline">\(d F_\alpha(X) = E_{12}
\in \mathfrak{g}^\alpha\)</span>. The composition of the standard
cocharacter <span class="math inline">\(\mathop{\mathrm{U}}(1)
\xrightarrow{t \mapsto \mathop{\mathrm{diag}}(t,1/t)}
\mathop{\mathrm{SU}}(2)\)</span> with <span
class="math inline">\(F_\alpha\)</span> is the cocharacter <span
class="math display">\[\alpha^\vee : \mathop{\mathrm{U}}(1) \rightarrow
T\]</span> <span class="math display">\[t \mapsto
\begin{pmatrix}
    t &amp;  &amp;  \\
    &amp; 1/t &amp;  \\
    &amp; &amp; 1
  \end{pmatrix}\]</span> of <span class="math inline">\(K\)</span>, and
we have <span class="math inline">\(\alpha^\vee(e^{i \theta}) = \exp(i
\theta H_\alpha)\)</span> with <span class="math display">\[H_\alpha =
\begin{pmatrix}
    1 &amp;  &amp;  \\
    &amp; -1 &amp;  \\
    &amp; &amp; 0
  \end{pmatrix}
  = d F_\alpha(H).\]</span> We have <span class="math inline">\(\Phi =
\{\varepsilon_i - \varepsilon_j : i \neq j\}\)</span>, so it is clear
that <span class="math inline">\(\mathbb{Q} \alpha \cap \Phi = \{\alpha,
- \alpha \}\)</span>. We compute using the Lie algebra that <span
class="math display">\[T_\alpha = \left\{
\begin{pmatrix}
      z &amp;  &amp;  \\
      &amp; z &amp;  \\
      &amp; &amp; t
    \end{pmatrix}
: z, t \in \mathop{\mathrm{U}}(1) \right\},\]</span> <span
class="math display">\[Z_K(T_\alpha) = \left\{
\begin{pmatrix}
      a &amp; b &amp;  \\
      c &amp; d &amp;  \\
      &amp; &amp; t
    \end{pmatrix}
:
\begin{pmatrix}
      a &amp; b \\
      c &amp; d
    \end{pmatrix}
\in \mathop{\mathrm{U}}(2), t \in \mathop{\mathrm{U}}(1)
\right\}.\]</span> We may verify that <span
class="math inline">\(F_\alpha : \mathop{\mathrm{SU}}(2) \rightarrow
Z_K(T_\alpha)/T_\alpha\)</span> is surjective with kernel <span
class="math inline">\(\{\pm 1\}\)</span>, and in any event that <span
class="math inline">\(d F_\alpha\)</span> defines an isomorphism of Lie
algebras (which is simplest to check first for the complexified Lie
algebras).</p>
<p>If we were instead given <span class="math inline">\(\alpha =
\varepsilon_{1} - \varepsilon_3\)</span>, then we’d take <span
class="math display">\[F_\alpha (
\begin{pmatrix}
    a &amp; b \\
    c &amp; d
  \end{pmatrix}
) =
\begin{pmatrix}
    a &amp; 0 &amp; b \\
    0 &amp; 1 &amp; 0 \\
    c &amp; 0 &amp; d
  \end{pmatrix}
.\]</span></p>
<h2 id="classification-of-rank-one-groups">Classification of rank one
groups</h2>
<p>Before proving Theorem <a href="#thm:from-roots-dist-su2"
data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>,
let’s illustrate its power with a typical application.</p>
<div class="definition">
<p><strong>Definition 120</strong>. The <em>rank</em> of a compact
connected Lie group <span class="math inline">\(K\)</span> is defined to
be the dimension of any maximal torus <span
class="math inline">\(T\)</span> (which is well-defined by Theorem <a
href="#thm:conj-max-tori" data-reference-type="ref"
data-reference="thm:conj-max-tori">107</a>, for instance): <span
class="math display">\[\mathop{\mathrm{rank}}(K) :=
\dim(T).\]</span></p>
</div>
<p>For instance, <span
class="math inline">\(\mathop{\mathrm{rank}}(\mathop{\mathrm{U}}(n)) =
n\)</span>, while <span
class="math inline">\(\mathop{\mathrm{rank}}(\mathop{\mathrm{SU}}(n)) =
n-1\)</span>.</p>
<p>It’s clear from Lemma <a href="#lem:maximal-tori-vs-maxl-ab-subalg"
data-reference-type="ref"
data-reference="lem:maximal-tori-vs-maxl-ab-subalg">89</a>
that every connected compact Lie group of rank <span
class="math inline">\(0\)</span> is trivial. The case of rank <span
class="math inline">\(1\)</span> is more interesting:</p>
<div id="cor:classification-compact-lie-gps-rank-1" class="corollary">
<p><strong>Corollary 121</strong>. <em>Every connected compact Lie
groups <span class="math inline">\(K\)</span> of rank <span
class="math inline">\(1\)</span> is isomorphic to exactly one of the
following:</em></p>
<ul>
<li><p><em><span
class="math inline">\(\mathop{\mathrm{U}}(1)\)</span></em></p></li>
<li><p><em><span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span></em></p></li>
<li><p><em><span class="math inline">\(\mathop{\mathrm{SU}}(2) / \{\pm
1\} \cong \mathop{\mathrm{SO}}(3)\)</span></em></p></li>
</ul>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(T \leq K\)</span> be
a maximal torus and <span class="math inline">\(\mathfrak{g} =
\mathfrak{k}_{\mathbb{C}}\)</span>, with <span
class="math inline">\(\Phi\)</span> the set of roots. If <span
class="math inline">\(\Phi\)</span> is empty, then the root space
decomposition implies that <span class="math inline">\(\mathfrak{g} =
\mathfrak{t}_{\mathbb{C}}\)</span>, hence that <span
class="math inline">\(\mathfrak{k} = \mathfrak{t}\)</span>; since <span
class="math inline">\(K\)</span> is connected, this forces <span
class="math inline">\(K = T \cong \mathop{\mathrm{U}}(1)\)</span>.
Suppose otherwise that there exists some <span
class="math inline">\(\alpha \in \Phi\)</span>. Then the codimension
<span class="math inline">\(1\)</span> subtorus <span
class="math inline">\(T_\alpha \leq T\)</span> defined in Theorem <a
href="#thm:from-roots-dist-su2" data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>
has dimension <span class="math inline">\(\dim(T_\alpha) = \dim(T) - 1 =
0\)</span>, and so <span class="math inline">\(T_\alpha =
\{1\}\)</span>. Thus <span class="math inline">\(Z_K(T_\alpha) =
K\)</span> and <span class="math inline">\(Z_K(T_\alpha)/T_\alpha \cong
K\)</span>. Thus any map <span class="math inline">\(F_\alpha :
\mathop{\mathrm{SU}}(2) \rightarrow K\)</span> as in Theorem <a
href="#thm:from-roots-dist-su2" data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>
defines a Lie algebra isomorphism <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)
\rightarrow K\)</span>. Since <span class="math inline">\(K\)</span> is
connected, <span class="math inline">\(F_\alpha\)</span> is surjective.
Since <span class="math inline">\(d F_\alpha\)</span> is injective, the
kernel of <span class="math inline">\(F_\alpha\)</span> is a (discrete)
subgroup of the center <span class="math inline">\(\{\pm 1\}\)</span> of
<span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> (see e.g.
§20 and especially Lemma 154 of my notes on Lie groups, on the course
homepage; the general fact being used here is that if <span
class="math inline">\(f : G \rightarrow H\)</span> is a morphism of Lie
groups with <span class="math inline">\(d f\)</span> injective and <span
class="math inline">\(G\)</span> connected, then <span
class="math inline">\(\ker(f)\)</span> is a discrete subgroup of the
center of <span class="math inline">\(G\)</span>). Thus either <span
class="math inline">\(K \cong \mathop{\mathrm{SU}}(2)\)</span> or <span
class="math inline">\(K \cong \mathop{\mathrm{SU}}(2) / \{\pm
1\}\)</span>; the two cases are distinguished by (for instance) their
centers. ◻</p>
</span></div>
<p>In fact, this application is representative of the power of Theorem
<a href="#thm:from-roots-dist-su2" data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>
in the sense that one could go backwards and derive much of Theorem <a
href="#cor:classification-compact-lie-gps-rank-1"
data-reference-type="ref"
data-reference="cor:classification-compact-lie-gps-rank-1">121</a>
assuming Corollary <a href="#cor:classification-compact-lie-gps-rank-1"
data-reference-type="ref"
data-reference="cor:classification-compact-lie-gps-rank-1">121</a>. We
will not do this here, but it’s done that way in some references, e.g.,
the BTD course reference.</p>
<h2 id="sec:some-invariant-inner">§7.12. Some invariant inner products</h2>
<p>Before turning to the proof of Theorem <a
href="#thm:from-roots-dist-su2" data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>,
we pause to choose some inner products concerning the objects in its
statement. (The formulation of Theorem <a
href="#thm:from-roots-dist-su2" data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>
is independent of this choice, but the proof will not be.) Choose an
embedding <span class="math inline">\(K \hookrightarrow
\mathop{\mathrm{U}}(n)\)</span> with respect to which <span
class="math inline">\(T\)</span> is contained in the diagonal subgroup
(see §<a href="#sec:notat-relat-torus" data-reference-type="ref"
data-reference="sec:notat-relat-torus">7.1</a> for details on this and
what follows). This choice defines an embedding <span
class="math inline">\(\mathfrak{g} \hookrightarrow
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\)</span> with
respect to which <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> is contained in
the subspace of diagonal matricse with real entries. We have the usual
involution <span class="math inline">\(\theta :
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C}) \rightarrow
{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\)</span>,
preserving <span class="math inline">\(\mathfrak{g}\)</span>, and given
by <span class="math inline">\(\theta(x) := - x^*\)</span>, where <span
class="math inline">\(x^* := \overline{x}^t\)</span>. Then:</p>
<ul>
<li><p>The map <span
class="math display">\[{\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})
\times {\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})
\rightarrow \mathbb{R}\]</span> <span class="math display">\[(x,y)
\mapsto - \mathop{\mathrm{trace}}(x \theta(y))\]</span> defines an inner
product. Indeed, <span class="math display">\[-
\mathop{\mathrm{trace}}(x \theta(y)) = \mathop{\mathrm{trace}}(x y^*) =
\sum_{i,j} x_{i j} \overline{y_{i j}}.\]</span> In particular, this map
restricts to an inner product on <span
class="math inline">\(\mathfrak{g}\)</span>.</p></li>
<li><p>The map <span class="math display">\[\mathfrak{t}_{\mathbb{R}}
\times \mathfrak{t}_{\mathbb{R}} \rightarrow \mathbb{R}\]</span> <span
class="math display">\[(x,y) \mapsto \mathop{\mathrm{trace}}( x
y)\]</span> is an inner product. Indeed, for <span
class="math inline">\(y \in \mathfrak{t}_{\mathbb{R}}\)</span>, we have
<span class="math inline">\(y = - \theta(y)\)</span>, so this is just
the restriction of the inner product defined above on <span
class="math inline">\({\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\)</span>;
explicitly, it is just the obvious inner product given in terms of the
diagonal entries by the formula <span
class="math inline">\(\mathop{\mathrm{trace}}(x y) = \sum_{i} x_{i i}
\overline{y_{i i}}\)</span>.</p></li>
<li><p>The inner product just defined on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> defines an
isomorphism <span class="math display">\[\mathfrak{t}_{\mathbb{R}}^*
\rightarrow \mathfrak{t}_{\mathbb{R}}\]</span> <span
class="math display">\[\lambda \mapsto u_\lambda\]</span> characterized
by the identity <span id="eq:characterize-u-lambda" class="math display">\[\label{eq:characterize-u-lambda}\tag{57}
    \lambda(z) = \mathop{\mathrm{trace}}(u_\lambda z)\]</span> for all
<span class="math inline">\(z \in \mathfrak{t}_{\mathbb{R}}\)</span>.
The same identity extends <span
class="math inline">\(\mathbb{C}\)</span>-linearly to all <span
class="math inline">\(z \in \mathfrak{t}_{\mathbb{C}}\)</span>.</p></li>
<li><p>Using the above isomorphism, we may transport the given inner
product on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> to an inner
product on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> that we
denote by <span class="math inline">\((,)\)</span>: for <span
class="math inline">\(\lambda_1, \lambda_2 \in
\mathfrak{t}_{\mathbb{R}}^*\)</span>, <span
class="math display">\[(\lambda_1, \lambda_2) :=
\mathop{\mathrm{trace}}(u_{\lambda_1} u_{\lambda_2}).\]</span> For
example, if <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, then under the identification <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^* \cong
\mathbb{R}^n\)</span> as in §<a href="#sec:notat-relat-torus"
data-reference-type="ref"
data-reference="sec:notat-relat-torus">7.1</a>, this inner product is
the standard one.</p></li>
</ul>
<p>We verify readily that the inner product that we defined on <span
class="math inline">\({\mathop{\mathrm{\mathfrak{g}\mathfrak{l}}}}_n(\mathbb{C})\)</span>
is <span
class="math inline">\(\mathop{\mathrm{Ad}}(\mathop{\mathrm{U}}(n))\)</span>-invariant,
hence that on <span class="math inline">\(\mathfrak{g}\)</span> is <span
class="math inline">\(\mathop{\mathrm{Ad}}(K)\)</span>-invariant and
that on <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span>
is <span class="math inline">\(W\)</span>-invariant.</p>
<h2 id="sec:proofs-conc-pass">§7.13. Proofs concerning the passage from roots
to <span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>’s</h2>
<p>With these preliminaries out of the way, we’re now prepared to give
the:</p>
<div class="proof">
<p><em>Proof of Theorem <a href="#thm:from-roots-dist-su2"
data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>.</em></p>
<ol type="i">
<li><p>We’ll construct <span class="math inline">\(F_\alpha\)</span> in
terms of generators and relations (see <a href="#eq:relations-X-Y-H"
data-reference-type="eqref"
data-reference="eq:relations-X-Y-H">\((53)\)</a> and <a
href="#eq:relations-X-Y-H-theta" data-reference-type="eqref"
data-reference="eq:relations-X-Y-H-theta">\((54)\)</a>).
We start by constructing elements <span class="math inline">\(X_\alpha,
Y_\alpha, H_\alpha \in \mathfrak{g}\)</span> that we eventually intend
to be the images of <span class="math inline">\(X,Y,H \in
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span> under
<span class="math inline">\(d F_\alpha\)</span>.</p>
<p>First, let <span class="math inline">\(c &gt; 0\)</span> denote a
suitable constant to be specified later (in <a
href="#eq:definition-of-c-equals-2-over-alpha-alpha"
data-reference-type="eqref"
data-reference="eq:definition-of-c-equals-2-over-alpha-alpha">\((65)\)</a>),
and choose any <span class="math inline">\(X_\alpha \in
\mathfrak{g}^{\alpha}\)</span> whose norm <span
class="math inline">\(\|X_\alpha \|^2 := -
\mathop{\mathrm{trace}}(X_\alpha \theta(X_\alpha))\)</span> is equal to
<span class="math inline">\(c\)</span>. Set <span
class="math inline">\(Y_\alpha := - \theta(X_\alpha) \in
\mathfrak{g}^{-\alpha}\)</span> and <span class="math inline">\(H_\alpha
:= [X_\alpha, Y_\alpha] \in \mathfrak{t}_{\mathbb{C}}\)</span>. We get a
linear map <span class="math display">\[``d F_\alpha&#39;&#39; :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}) \rightarrow
\mathfrak{g}\]</span> <span class="math display">\[X \mapsto X_\alpha, Y
\mapsto Y_\alpha, H \mapsto H_\alpha.\]</span></p>
<p>We want the above map to define a <span
class="math inline">\(\theta\)</span>-equivariant Lie algebra morphism.
For this to be the case, the non-obvious relations to be verified are
that <span id="eq:HXalpha-2Xalph" class="math display">\[\label{eq:HXalpha-2Xalph}\tag{58}
      [H_\alpha, X_\alpha] = 2 X_\alpha,\]</span> <span id="eq:HYalpha-2Yalph" class="math display">\[\label{eq:HYalpha-2Yalph}\tag{59}
      [H_\alpha, Y_\alpha] = - 2 Y_\alpha,\]</span> <span id="eq:thetaHalphanegAlpha" class="math display">\[\label{eq:thetaHalphanegAlpha}\tag{60}
      \theta(H_\alpha) = - H_\alpha.\]</span> Since <span
class="math inline">\([H_\alpha,X_\alpha] = \alpha(H_\alpha)
X_\alpha\)</span> and <span class="math inline">\([H_\alpha,Y_\alpha] =
- \alpha(H_\alpha) Y_\alpha\)</span>, the two relations <a
href="#eq:HYalpha-2Yalph" data-reference-type="eqref"
data-reference="eq:HYalpha-2Yalph">\((59)\)</a> are
equivalent to the single relation <span id="eq:alpha-H-alpha-equals-2" class="math display">\[\label{eq:alpha-H-alpha-equals-2}\tag{61}
      \alpha(H_\alpha) = 2,\]</span> while the third relation <a
href="#eq:thetaHalphanegAlpha" data-reference-type="eqref"
data-reference="eq:thetaHalphanegAlpha">\((60)\)</a> is
equivalent to requiring that <span id="eq:H-alpha-in-t-R" class="math display">\[\label{eq:H-alpha-in-t-R}\tag{62}
      H_\alpha \in \mathfrak{t}_{\mathbb{R}}.\]</span></p>
<p>Before checking the above relations, we note that for all <span
class="math inline">\(x \in \mathfrak{g}^{\alpha}, y \in
\mathfrak{g}^{-\alpha}\)</span> and <span class="math inline">\(z \in
\mathfrak{t}_{\mathbb{C}}\)</span>, we have <span id="eq:trace-x-y-z-alpha" class="math display">\[\label{eq:trace-x-y-z-alpha}\tag{63}
      \mathop{\mathrm{trace}}([x,y] z) = \alpha(z)
\mathop{\mathrm{trace}}(x y).\]</span> Indeed, since the trace of a
product of two matrices doesn’t change if we swap the two matrices, we
have <span class="math inline">\(\mathop{\mathrm{trace}}([x,y] z) =
\mathop{\mathrm{trace}}(z[x,y]) = \mathop{\mathrm{trace}}(z x y - z y x)
= \mathop{\mathrm{trace}}(z x y - x z y) = \mathop{\mathrm{trace}}([z,x]
y)\)</span>, and since <span class="math inline">\([z,x] =
\alpha(z)\)</span> the required identity follows. By the characterizing
property <a href="#eq:characterize-u-lambda" data-reference-type="eqref"
data-reference="eq:characterize-u-lambda">\((57)\)</a>
of <span class="math inline">\(u_\alpha\)</span>, we may rewrite <a
href="#eq:trace-x-y-z-alpha" data-reference-type="eqref"
data-reference="eq:trace-x-y-z-alpha">\((63)\)</a> as the
identity <span id="eq:x-comm-y-vs-trace-vs-u-alpha" class="math display">\[\label{eq:x-comm-y-vs-trace-vs-u-alpha}\tag{64}
      [x,y] = \mathop{\mathrm{trace}}(x y) u_\alpha\]</span> of elements
of <span class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>.</p>
<p>Applying <a href="#eq:x-comm-y-vs-trace-vs-u-alpha"
data-reference-type="eqref"
data-reference="eq:x-comm-y-vs-trace-vs-u-alpha">\((64)\)</a>
to <span class="math inline">\(X_\alpha\)</span> and <span
class="math inline">\(Y_\alpha\)</span> gives <span
class="math display">\[H_\alpha = [X_\alpha, Y_\alpha ]
      = \mathop{\mathrm{trace}}(X_\alpha Y_\alpha) u_\alpha
      = \|X_\alpha \|^2 u_\alpha
      = c u_\alpha.\]</span> using in the last two steps the definitions
of <span class="math inline">\(\|X_\alpha \|^2\)</span> and of <span
class="math inline">\(Y_\alpha\)</span>. On the other hand, the
definition of <span class="math inline">\(u_\alpha\)</span> gives <span
class="math display">\[\alpha(u_\alpha) =
\mathop{\mathrm{trace}}(u_\alpha u_\alpha)
      = (\alpha,\alpha).\]</span> Combining the above two identites, we
obtain <span class="math inline">\(\alpha(H_\alpha) = c
(\alpha,\alpha)\)</span>. With the choice <span id="eq:definition-of-c-equals-2-over-alpha-alpha" class="math display">\[\label{eq:definition-of-c-equals-2-over-alpha-alpha}\tag{65}
      c := \frac{2}{(\alpha,\alpha)},\]</span> we obtain the required
relation <a href="#eq:alpha-H-alpha-equals-2"
data-reference-type="eqref"
data-reference="eq:alpha-H-alpha-equals-2">\((61)\)</a>.
Moreover, we have <span class="math inline">\(H_\alpha = c u_\alpha \in
\mathbb{R} u_\alpha \subseteq \mathfrak{t}_{\mathbb{R}}\)</span>, so <a
href="#eq:H-alpha-in-t-R" data-reference-type="eqref"
data-reference="eq:H-alpha-in-t-R">\((62)\)</a> holds.</p>
<p>This completes the proof that the linear map “<span
class="math inline">\(d F_\alpha\)</span>” defines a <span
class="math inline">\(\theta\)</span>-equivariant <span
class="math inline">\(\mathbb{C}\)</span>-linear Lie algebra morphism
<span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
\rightarrow \mathfrak{g}\)</span>. By passage to <span
class="math inline">\(\theta\)</span>-fixed subspaces, we obtain a Lie
algebra morphism <span
class="math inline">\(\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2)
\rightarrow \mathfrak{k}\)</span>. Since <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> is
simply-connected, this lifts to a Lie group morphism <span
class="math inline">\(F_\alpha : K \rightarrow
\mathop{\mathrm{SU}}(2)\)</span>, whose differential <span
class="math inline">\(d F_\alpha\)</span> is the map “<span
class="math inline">\(d F_\alpha\)</span>” that we constructed.</p></li>
<li><p>The composition <span class="math display">\[\alpha^\vee :
\mathop{\mathrm{U}}(1) \rightarrow \mathop{\mathrm{SU}}(2)
      \xrightarrow{F_\alpha } K\]</span> is given by <span
class="math display">\[e^{i \theta}
      \mapsto
      \exp (i \theta d F_\alpha(H))
      =
      \exp(i \theta H_\alpha)
      \in T,\]</span> so the diagram <a
href="#eq:F-alpha-alpha-vee-commute" data-reference-type="eqref"
data-reference="eq:F-alpha-alpha-vee-commute">\((56)\)</a>
is defined and commutes. Finally, we see from <a
href="#eq:x-comm-y-vs-trace-vs-u-alpha" data-reference-type="eqref"
data-reference="eq:x-comm-y-vs-trace-vs-u-alpha">\((64)\)</a>
that <span id="eq:commutators-land-in-C-H-alpha" class="math display">\[\label{eq:commutators-land-in-C-H-alpha}\tag{66}
      [\mathfrak{g}^\alpha, \mathfrak{g}^{-\alpha}]
      \subseteq \mathbb{C} u_\alpha
      = \mathbb{C} H_\alpha,\]</span> so that <span
class="math inline">\(H_\alpha = [X_\alpha, Y_\alpha]\)</span> admits
the required characterization as the unique element of <span
class="math inline">\([\mathfrak{g}^\alpha,
\mathfrak{g}^{-\alpha}]\)</span> for which <span
class="math inline">\(\alpha(H_\alpha) = 2\)</span>.</p></li>
<li><p>Define <span id="eq:defn-V-relevant-for-dim-g-alpha-1" class="math display">\[\label{eq:defn-V-relevant-for-dim-g-alpha-1}\tag{67}
      V := \mathbb{C} H_\alpha \oplus (\oplus_{0 \neq n \in
        \mathbb{Z} }
      \mathfrak{g}^{n \alpha}),\]</span> and set <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})_\alpha
:= d
F_\alpha({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}))\)</span>.
We may verify then <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})_\alpha\)</span>
that acts <span class="math inline">\(\mathbb{C}\)</span>-linearly on
<span class="math inline">\(V\)</span> by the restriction of the adjoint
representation <span
class="math inline">\(\mathop{\mathrm{ad}}\)</span>:</p>
<ul>
<li><p><span
class="math inline">\({\mathop{\mathrm{ad}}}_{H_\alpha}\)</span> preserves
each summand in <a href="#eq:defn-V-relevant-for-dim-g-alpha-1"
data-reference-type="eqref"
data-reference="eq:defn-V-relevant-for-dim-g-alpha-1">\((67)\)</a>,
acting on <span class="math inline">\(\mathbb{C} H_\alpha\)</span> by
the eigenvalue <span class="math inline">\(0\)</span> and on each <span
class="math inline">\(\mathfrak{g}^{n \alpha}\)</span> by the eigenvalue
<span class="math inline">\(n \alpha(H_\alpha) = 2 n\)</span>.</p></li>
<li><p><span
class="math inline">\({\mathop{\mathrm{ad}}}_{X_\alpha}(\mathfrak{g}^{n
\alpha}) \subseteq \mathfrak{g}^{(n+1) \alpha}\)</span> for all integers
<span class="math inline">\(n\)</span>. Moreover, <span
class="math inline">\({\mathop{\mathrm{ad}}}_{X_\alpha}(\mathfrak{g}^{-\alpha})
\subseteq \mathbb{C} H_\alpha\)</span> thanks to <a
href="#eq:commutators-land-in-C-H-alpha" data-reference-type="eqref"
data-reference="eq:commutators-land-in-C-H-alpha">\((66)\)</a>.
Thus <span
class="math inline">\({\mathop{\mathrm{ad}}}_{X_\alpha}\)</span> maps
<span class="math inline">\(V\)</span> to <span
class="math inline">\(V\)</span>.</p></li>
<li><p>Similarly, <span
class="math inline">\({\mathop{\mathrm{ad}}}_{Y_\alpha}(\mathfrak{g}^{n
\alpha}) \subseteq \mathfrak{g}^{(n-1) \alpha}\)</span> for all integers
<span class="math inline">\(n\)</span>, and <span
class="math inline">\({\mathop{\mathrm{ad}}}_{Y_\alpha}(\mathfrak{g}^\alpha)
\subseteq \mathbb{C} H_\alpha\)</span>.</p></li>
</ul>
<p>Thus <span class="math inline">\(V\)</span> defines a
finite-dimensional <span
class="math inline">\(\mathbb{C}\)</span>-linear representation of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>,
hence by Theorem <a href="#thm:unitary-trick"
data-reference-type="eqref"
data-reference="thm:unitary-trick">\((86)\)</a> a
finite-dimensional representation of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>. This
representation has the property that all weights (i.e., <span
class="math inline">\(H_\alpha\)</span>-eigenvalues) are even, the
weight zero subspace <span class="math inline">\(\mathbb{C}
H_\alpha\)</span> is one-dimensional, and the weight two subspace <span
class="math inline">\(\mathfrak{g}^{\alpha}\)</span> contains the vector
<span class="math inline">\(X_\alpha\)</span> for which <span
class="math inline">\({\mathop{\mathrm{ad}}}_{X_\alpha} X_\alpha =
0\)</span>. By Lemma <a href="#lem:key-for-root-space-one-dimensional"
data-reference-type="ref"
data-reference="lem:key-for-root-space-one-dimensional">117</a>, we
deduce that <span class="math inline">\(V\)</span> is isomorphic to the
irreducible three-dimensional representation <span
class="math inline">\(V_2\)</span> of <span
class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span>, whose weights
are <span class="math inline">\(\{0,2,-2\}\)</span> each occurring with
multiplicity one. Thus <span class="math display">\[\dim
\mathfrak{g}^{\alpha}
      =
      \dim \mathfrak{g}^{-\alpha}
      = 1\]</span> and <span id="eq:first-exclusion-dimensions-g-n-alpha" class="math display">\[\label{eq:first-exclusion-dimensions-g-n-alpha}\tag{68}
      \dim \mathfrak{g}^{n \alpha} = 0 \text{ for } n \in \mathbb{Z} -
\{0,1,-1\}.\]</span></p></li>
<li><p>We now take instead <span class="math display">\[V = \mathbb{C}
H_\alpha
      \oplus (\oplus_{0 \neq n \in \mathbb{C} \alpha }
      \mathfrak{g}^{n \alpha}).\]</span> (We might note in passing that,
since the set <span class="math inline">\(\Phi\)</span> of roots is
contained in the finite free <span
class="math inline">\(\mathbb{Z}\)</span>-module <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span>, the sum over
<span class="math inline">\(n\)</span> could be restricted from the
start to <span class="math inline">\(\mathbb{Q} \alpha\)</span>.) We
note as before that <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})_\alpha\)</span>
acts on <span class="math inline">\(V\)</span> by the restriction of
<span class="math inline">\(\mathop{\mathrm{ad}}\)</span>. Then <span
class="math inline">\(V\)</span> defines a finite-dimensional
representation of <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>,
and so, as we have seen, all of the weights of <span
class="math inline">\({\mathop{\mathrm{ad}}}_{H_\alpha}\)</span> must be
integers. But the eigenvalue of <span
class="math inline">\({\mathop{\mathrm{ad}}}_{H_\alpha}\)</span> on <span
class="math inline">\(\mathfrak{g}^{n \alpha}\)</span> is <span
class="math inline">\(n \alpha(H_\alpha) = 2 n\)</span>, which is an
integer only if <span class="math inline">\(n \in (1/2)
\mathbb{Z}\)</span>. We’ve seen already in <a
href="#eq:first-exclusion-dimensions-g-n-alpha"
data-reference-type="eqref"
data-reference="eq:first-exclusion-dimensions-g-n-alpha">\((68)\)</a>
that for <span class="math inline">\(n \in \mathbb{Z}\)</span>, we have
<span class="math inline">\(n \alpha \notin \Phi\)</span> unless <span
class="math inline">\(n = \pm 1\)</span>, so it remains only to consider
the case that <span class="math inline">\(n \alpha \in \Phi\)</span> for
some <span class="math inline">\(n \in (1/2) \mathbb{Z} -
\mathbb{Z}\)</span>. But then <span class="math inline">\(2 n\)</span>
is odd, so <span class="math inline">\(\mathfrak{g}^{n \alpha}\)</span>
is a nonzero weight space for <span class="math inline">\(V\)</span>
with odd weight, so by Lemma <a
href="#lem:key-for-rational-multiples-of-roots"
data-reference-type="ref"
data-reference="lem:key-for-rational-multiples-of-roots">118</a>, we see
that the weight one subspace <span class="math inline">\(V^1 =
\mathfrak{g}^{\alpha/2}\)</span> is nonzero, i.e., that <span
class="math inline">\(\alpha/2\)</span> is a root. But then <span
class="math inline">\(\alpha/2\)</span> and <span
class="math inline">\(\alpha = 2 (\alpha/2)\)</span> are both roots,
which contradicts <a href="#eq:first-exclusion-dimensions-g-n-alpha"
data-reference-type="eqref"
data-reference="eq:first-exclusion-dimensions-g-n-alpha">\((68)\)</a>
(applied to <span class="math inline">\(\alpha/2\)</span> in place of
<span class="math inline">\(\alpha\)</span>). The proof that <span
class="math inline">\(\mathbb{C} \alpha \cap \Phi = \mathbb{Q} \alpha
\cap \Phi = \{\alpha, -\alpha \}\)</span> is now complete.<a
href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a></p></li>
<li><p>The uniqueness of <span class="math inline">\(F_\alpha\)</span>
up to conjugation by <span class="math inline">\(\alpha^\vee\)</span>
follows from the recently established one-dimensionality of <span
class="math inline">\(\mathfrak{g}^\alpha\)</span> and the construction
of <span class="math inline">\(F_\alpha\)</span>. Since we required
<span class="math inline">\(\|X_\alpha \|^2 = 2/(\alpha,\alpha)\)</span>
and the choices of <span class="math inline">\(Y_\alpha\)</span> and
<span class="math inline">\(H_\alpha\)</span> were then forced by the
requirement that <span class="math inline">\(d F_\alpha\)</span> be a
<span class="math inline">\(\theta\)</span>-equivariant Lie algebra
morphism, any other map <span class="math inline">\(F_\alpha
&#39;\)</span> satisfying the same conditions as <span
class="math inline">\(F_\alpha\)</span> is obtained by replacing <span
class="math inline">\(X_\alpha\)</span> as in the construction of <span
class="math inline">\(F_\alpha\)</span> with its multiple by some
element <span class="math inline">\(e^{i \theta} \in
\mathop{\mathrm{U}}(1)\)</span>. Since <span
class="math inline">\([H_\alpha, X_\alpha] = 2 X_\alpha\)</span>, we
have <span class="math display">\[\mathop{\mathrm{Ad}}(\alpha^\vee(e^{i
\theta/2}))
      X_\alpha
      =
      \mathop{\mathrm{Ad}}(\exp(i \theta H_\alpha/2))
      X_\alpha
      =
      e^{i \theta} X_\alpha,\]</span> which implies that <span
class="math inline">\(F_\alpha &#39;\)</span> is the conjugate of <span
class="math inline">\(F_\alpha\)</span> by <span
class="math inline">\(\alpha^\vee(e^{i \theta/2})\)</span>, as
required.</p></li>
<li><p>We have <span class="math inline">\(\mathfrak{t}_{\alpha} = \{x
\in \mathfrak{t} : \alpha(x) =0\}\)</span> and and <span
class="math inline">\(\mathop{\mathrm{Lie}}(Z_K(T_\alpha)) =
Z_{\mathfrak{k}}(\mathfrak{t}_\alpha)\)</span> and <span
class="math inline">\((Z_{\mathfrak{k}}(\mathfrak{t}_\alpha))_{\mathbb{C}}
= Z_{\mathfrak{g}}(\mathfrak{t}_\alpha) = \{x \in \mathfrak{g} : [x,z] =
0 \text{ for all } z \in \mathfrak{t} \text{ with } \alpha(z) =
0\}\)</span>. Since <span class="math inline">\([z,X_\alpha] = \alpha(z)
X_\alpha\)</span> and <span class="math inline">\([z,Y_\alpha] =
-\alpha(z) Y_\alpha\)</span> for all <span class="math inline">\(z \in
\mathfrak{t}\)</span>, and since <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> is commutative,
we see that <span class="math inline">\(X_\alpha, Y_\alpha,
H_\alpha\)</span> all belong to <span
class="math inline">\(Z_{\mathfrak{g}}(\mathfrak{t}_\alpha)\)</span>.
Since <span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> is
connected, it follows likewise that the image of <span
class="math inline">\(F_\alpha\)</span> is contained in <span
class="math inline">\(Z_K(T_\alpha)\)</span>. It remains only to check
that the map <span class="math display">\[d F_\alpha :
\mathop{\mathrm{\mathfrak{s}\mathfrak{u}}}(2) \rightarrow
Z_{\mathfrak{k}}(\mathfrak{t}_\alpha)/\mathfrak{t}_\alpha\]</span> is an
isomorphism, or equivalently, that <span id="eq:required-lie-alg-isom-involving-F-alpha" class="math display">\[\label{eq:required-lie-alg-isom-involving-F-alpha}\tag{69}
      d F_\alpha :
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C}) \rightarrow
      Z_{\mathfrak{g}}(\mathfrak{t}_\alpha)
      / (\mathfrak{t}_{\alpha})_{\mathbb{C}}\]</span> is an isomorphism.
We note that <span
class="math inline">\(Z_{\mathfrak{g}}(\mathfrak{t}_\alpha)\)</span> is
a Lie subalgebra of <span class="math inline">\(\mathfrak{g}\)</span>
that contains <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>, hence admits a
root space decomposition <span
class="math display">\[Z_{\mathfrak{g}}(\mathfrak{t}_\alpha)
      = \mathfrak{t}_{\mathbb{C}}
      \oplus (\oplus_{\beta \in B}
      \mathfrak{g}^\beta),\]</span> where <span
class="math inline">\(B\)</span> denotes the set of all roots <span
class="math inline">\(\beta \in \Phi\)</span> for which <span
class="math inline">\(\mathfrak{g}^\beta \subseteq
Z_{\mathfrak{g}}(\mathfrak{t}_\alpha)\)</span>, i.e., for which <span
class="math inline">\(\beta(z) = 0\)</span> for all <span
class="math inline">\(z \in \mathfrak{t}\)</span> with <span
class="math inline">\(\alpha(z) = 0\)</span>. Since <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> are both nonzero functionals, it
follows that <span class="math inline">\(\beta \in B\)</span> iff <span
class="math inline">\(\beta \in \mathbb{C} \alpha\)</span>, which we’ve
seen is equivalent to asking that <span class="math inline">\(\beta =
\pm \alpha\)</span>. Since <span class="math inline">\(\alpha(H_\alpha)
\neq 0\)</span>, we have a decomposition <span id="eq:decompose-t-C-via-H-alpha" class="math display">\[\label{eq:decompose-t-C-via-H-alpha}\tag{70}
      \mathfrak{t}_{\mathbb{C}} =
      (\mathfrak{t}_{\alpha})_{\mathbb{C}}
      \oplus \mathbb{C} H_\alpha.\]</span> Thus <span
class="math display">\[Z_{\mathfrak{g}}(t_\alpha)
      = (\mathfrak{t}_\alpha)_{\mathbb{C}}
      \oplus \mathbb{C} H_\alpha
      \oplus \mathfrak{g}^{\alpha}
      \oplus \mathfrak{g}^{-\alpha}\]</span> and so <span
class="math display">\[Z_{\mathfrak{g}}(\mathfrak{t}_\alpha)
      / (\mathfrak{t}_{\alpha})_{\mathbb{C}}
      \cong
      \mathbb{C} H_\alpha
      \oplus \mathfrak{g}^{\alpha} \oplus
\mathfrak{g}^{-\alpha}.\]</span> The composition <span
class="math display">\[{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})
\xrightarrow{d F_\alpha }
      Z_{\mathfrak{g}}(t_\alpha)
      \twoheadrightarrow Z_{\mathfrak{g}}(t_\alpha)/
      (t_\alpha)_{\mathbb{C}}
      \cong
      \mathbb{C} H_\alpha
      \oplus \mathfrak{g}^{\alpha} \oplus \mathfrak{g}^{-\alpha}
      \cong
{\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\]</span> is the
identity, so we deduce as required that <a
href="#eq:required-lie-alg-isom-involving-F-alpha"
data-reference-type="eqref"
data-reference="eq:required-lie-alg-isom-involving-F-alpha">\((69)\)</a>
is an isomorphism.</p></li>
</ol>
<p> ◻</p>
</div>
<h2 id="construction-of-root-reflections">Construction of root
reflections</h2>
<p>We finally develop a way to produce nontrivial elements of the Weyl
group. Start with <span class="math inline">\(K =
\mathop{\mathrm{SU}}(2)\)</span>, with <span class="math inline">\(T
\cong \mathop{\mathrm{U}}(1)\)</span> the standard diagonal maximal
torus. It follows from our earlier analysis of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> that the Weyl
group <span class="math inline">\(W\)</span> of <span
class="math inline">\(T\)</span> is isomorphic to <span
class="math inline">\(\mathbb{Z}/2\)</span>. One can see this by noting
that <span class="math inline">\(T\)</span> consists of those elements
of <span class="math inline">\(K\)</span> that are diagonalized by the
decomposition <span class="math inline">\(\mathbb{C}^2 = \mathbb{C} e_1
\oplus \mathbb{C} e_2\)</span> of the standard representation into the
lines spanned by its standard basis elements. Hence <span
class="math inline">\(N(T)\)</span> acts faithfully on such lines, with
<span class="math inline">\(T\)</span> acting trivially. Thus <span
class="math inline">\(W\)</span> embeds as a subgroup of the permutation
group of <span class="math inline">\(\{\mathbb{C} e_1, \mathbb{C}
e_2\}\)</span>. The element <span class="math inline">\(w :=
\begin{pmatrix}
  &amp; 1 \\
  -1 &amp;
\end{pmatrix}
\in K\)</span> swaps the two lines, so in fact <span
class="math inline">\(W = \{e T, w T\}\)</span> is the full permutation
group. The same proof shows that the Weyl group of each of <span
class="math inline">\(\mathop{\mathrm{U}}(n), \mathop{\mathrm{SU}}(n),
\PU(n)\)</span> is the symmetric group <span
class="math inline">\(S(n)\)</span>. Anyway, we compute that with <span
class="math inline">\(H =
\begin{pmatrix}
  1 &amp;  \\
  &amp; -1
\end{pmatrix}
\in {\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>,
<span class="math display">\[w \cdot H = -H.\]</span> More generally,
<span class="math inline">\(w\)</span> acts on each of the spaces <span
class="math inline">\(\mathfrak{t}, \mathfrak{t}_{\mathbb{Z}},
\mathfrak{t}_{\mathbb{R}}, \mathfrak{t}_{\mathbb{C}}, \mathfrak{t}^*,
\mathfrak{t}_{\mathbb{Z}}^*, \mathfrak{t}_{\mathbb{R}}^*,
\mathfrak{t}_{\mathbb{C}}^*\)</span> by negation. Moreover, for any
finite-dimensional representation <span class="math inline">\(V\)</span>
of <span class="math inline">\(\mathop{\mathrm{SU}}(2)\)</span> with
weight space decomposition <span class="math inline">\(V =
\oplus_{\lambda \in \mathbb{Z}} V^\lambda\)</span> (here <span
class="math inline">\(V^\lambda = \{v \in V : H v = \lambda v
\}\)</span>, as usual), the action of <span
class="math inline">\(w\)</span> defines an isomorphism <span
class="math display">\[w : V^{\lambda} \xrightarrow{\cong
}V^{-\lambda},\]</span> as follows from a routine computation as in the
proof of Lemma <a href="#sec:weyl-group-acts-on-roots"
data-reference-type="ref"
data-reference="sec:weyl-group-acts-on-roots">115</a>.</p>
<p>Returning now to the general setting:</p>
<div class="theorem">
<p><strong>Theorem 122</strong>. <em>Let <span
class="math inline">\(K\)</span> be a compact connected Lie group, with
maximal torus <span class="math inline">\(T\)</span>. Let <span
class="math inline">\(\Phi = \Phi(K:T)\)</span> denote the set of roots,
and <span class="math inline">\(W = N(T)/T\)</span> the Weyl
group.</em></p>
<p><em>Let <span class="math inline">\(\alpha \in \Phi\)</span>. Let
<span class="math inline">\(F_\alpha : \mathop{\mathrm{SU}}(2)
\rightarrow K\)</span>, as in Theorem <a href="#thm:from-roots-dist-su2"
data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>,
be such that <span class="math inline">\(F_\alpha (
\begin{pmatrix}
    &amp; 1 \\
    &amp;
  \end{pmatrix}
)\)</span> is a nonzero element of <span
class="math inline">\(\mathfrak{g}^{\alpha}\)</span>. Define <span
class="math display">\[w_\alpha := F_\alpha (
  \begin{pmatrix}
    0 &amp; 1 \\
    -1 &amp; 0
  \end{pmatrix}
  ).\]</span> Then:</em></p>
<ol type="i">
<li><p><em><span class="math inline">\(w_\alpha\)</span> belongs to the
normalizer <span class="math inline">\(N(T)\)</span> of <span
class="math inline">\(T\)</span>, hence defines a Weyl group element
that we denote by <span class="math display">\[s_\alpha := w_\alpha T
\in W.\]</span> The element <span
class="math inline">\(s_\alpha\)</span> is independent of the choice of
<span class="math inline">\(F_\alpha\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(s_\alpha^2 =
1\)</span>.</em></p></li>
<li><p><em>For <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{C}}\)</span>, <span
class="math display">\[s_\alpha \cdot x = x - \alpha(x)
H_\alpha\]</span> and for <span class="math inline">\(t \in T\)</span>,
<span class="math display">\[s_\alpha \cdot t = t /
\alpha^\vee(t^\alpha).\]</span></em></p></li>
<li><p><em>For <span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{C}}^*\)</span>, <span
class="math display">\[s_\alpha \cdot \lambda  = \lambda  -
\lambda(H_\alpha) \alpha.\]</span></em></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We check readily that assertions (iii) and (iv) are
equivalent, that either implies (ii), and that the claimed uniqueness of
<span class="math inline">\(s_\alpha\)</span> follows from the
established uniqueness of <span class="math inline">\(F_\alpha\)</span>.
On the other hand, each of the assertions (i) and (iii) will follow if
we can show that <span
class="math display">\[\mathop{\mathrm{Ad}}(w_\alpha) x = x - \alpha(x)
H_\alpha\]</span> for all <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{C}}\)</span>. To that end, we apply the
decomposition <a href="#eq:decompose-t-C-via-H-alpha"
data-reference-type="eqref"
data-reference="eq:decompose-t-C-via-H-alpha">\((70)\)</a>
to write <span class="math inline">\(x = y + z H_\alpha\)</span>, where
<span class="math inline">\(y \in \mathfrak{t}_{\mathbb{C}}\)</span>
with <span class="math inline">\(\alpha(y) = 0\)</span> and <span
class="math inline">\(z \in \mathbb{C}\)</span>, namely <span
class="math inline">\(z = (1/2) \alpha(x)\)</span>. By part (vi) of
Theorem <a href="#thm:from-roots-dist-su2" data-reference-type="ref"
data-reference="thm:from-roots-dist-su2">119</a>,
the image of <span class="math inline">\(F_\alpha\)</span> commutes with
<span class="math inline">\(y\)</span>, hence <span
class="math inline">\(\mathop{\mathrm{Ad}}(w_\alpha) y = y\)</span>. Set
<span class="math inline">\(w :=
\begin{pmatrix}
    &amp; 1 \\
    -1 &amp;
  \end{pmatrix}
\in \mathop{\mathrm{SU}}(2)\)</span>. Then <span
class="math display">\[\mathop{\mathrm{Ad}}(w_\alpha) H_\alpha
   = \mathop{\mathrm{Ad}}(F_\alpha(w)) F_\alpha(H)
   = F_\alpha(\mathop{\mathrm{Ad}}(w) H)
   = F_\alpha(-H) = - H_\alpha,\]</span> so <span
class="math display">\[\mathop{\mathrm{Ad}}(w_\alpha) x = y - z H_\alpha
   = x - 2 z H_\alpha
   = x - \alpha(x) H_\alpha,\]</span> as required. ◻</p>
</span></div>
<p><a href="#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<p>The theorem and its proof imply that the action of <span
class="math inline">\(s_\alpha\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> may be
characterized as the unique linear map that restricts to the identity on
<span class="math inline">\(\ker(\alpha)\)</span> and sends <span
class="math inline">\(H_\alpha\)</span> to <span class="math inline">\(-
H_\alpha\)</span>; similarly, the action on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> is the unique
linear map that is given by the identity on <span
class="math inline">\(\ker(H_\alpha)\)</span> (here <span
class="math inline">\(H_\alpha \in \mathfrak{t}_{\mathbb{R}} =
(\mathfrak{t}_{\mathbb{R}}^*)^*\)</span>) and sends <span
class="math inline">\(\alpha\)</span> to <span
class="math inline">\(-\alpha\)</span>. Suppose now that we choose an
embedding <span class="math inline">\(K \hookrightarrow
\mathop{\mathrm{U}}(n)\)</span>. Then, as discussed in §<a
href="#sec:some-invariant-inner" data-reference-type="ref"
data-reference="sec:some-invariant-inner">7.12</a>, we get an <span
class="math inline">\(\mathop{\mathrm{Ad}}(K)\)</span>-invariant inner
product on <span class="math inline">\(\mathfrak{g}\)</span> given by
<span class="math inline">\((x,y) \mapsto - \mathop{\mathrm{trace}}(x
\theta(y))\)</span> and hence a <span
class="math inline">\(W\)</span>-invariant inner product <span
class="math inline">\(\langle , \rangle\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> given by <span
class="math inline">\(\langle x, y \rangle := \mathop{\mathrm{trace}}(x
y)\)</span>. We may use this inner product to define a duality
isomorphism <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*
\cong \mathfrak{t}_{\mathbb{R}}\)</span>, <span
class="math inline">\(\lambda \mapsto u_\lambda\)</span>, where as
before <span class="math inline">\(\langle u_\lambda, v \rangle =
\lambda(v)\)</span> for <span class="math inline">\(v \in
\mathfrak{t}_{\mathbb{R}}\)</span>, and also an inner product <span
class="math inline">\(\langle , \rangle\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> given by
<span class="math inline">\(\langle \lambda_1, \lambda_2 \rangle :=
\langle u_{\lambda_1}, u_{\lambda_{2}} \rangle\)</span>. Using such
inner products, we may interpret the <span
class="math inline">\(s_\alpha\)</span> geometrically as follows.</p>
<div class="definition">
<p><strong>Definition 123</strong>. Let <span class="math inline">\((V,
\langle , \rangle)\)</span> be a finite-dimensional real inner product
space, and let <span class="math inline">\(0 \neq v \in V\)</span>. The
<em>reflection in <span class="math inline">\(v\)</span></em> is the
linear map <span class="math inline">\(r_v : V \rightarrow V\)</span>
that restricts to the identity on the orthogonal complement <span
class="math inline">\(v^\perp\)</span> of <span
class="math inline">\(v\)</span> and that sends <span
class="math inline">\(v\)</span> to <span
class="math inline">\(-v\)</span>, thus <span
class="math display">\[r_v(u) = u - 2 \frac{\langle u, v
\rangle}{\langle v, v \rangle} v.\]</span></p>
</div>
<div class="lemma">
<p><strong>Lemma 124</strong>. Define inner products on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> as above. Let
<span class="math inline">\(\alpha \in \Phi\)</span>. The action of
<span class="math inline">\(s_\alpha\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> is the
reflection in <span class="math inline">\(H_\alpha\)</span>, while that
of <span class="math inline">\(s_\alpha\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> is the
reflection in <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We recall from §<a href="#sec:proofs-conc-pass"
data-reference-type="ref" data-reference="sec:proofs-conc-pass">7.13</a>
that <span class="math inline">\(H_\alpha = \frac{2}{\langle \alpha,
\alpha \rangle} u_\alpha\)</span>, so that <span
class="math inline">\(H_\alpha\)</span> and <span
class="math inline">\(\alpha\)</span> correspond to positive multiples
of one another under the isomorphism <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}} \cong
\mathfrak{t}_{\mathbb{R}}^*\)</span> defined above. Thus <span
class="math inline">\(\ker(H_\alpha : \mathfrak{t}_{\mathbb{R}}^*
\rightarrow \mathbb{R})\)</span> is the orthogonal complement of <span
class="math inline">\(\alpha\)</span>, while <span
class="math inline">\(\ker(\alpha : \mathfrak{t}_{\mathbb{R}}
\rightarrow \mathbb{R})\)</span> is the orthogonal complement of <span
class="math inline">\(H_\alpha\)</span>. The required conclusion then
follows from the formulas for <span
class="math inline">\(s_\alpha\)</span> noted previously. ◻</p>
</span></div>
<p>We’ve defined the regular subset <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>
in <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> to be
the complement of <span class="math inline">\(\cup_{\alpha \in \Phi}
\ker(\alpha)\)</span>, and we’ve defined a Weyl chamber <span
class="math inline">\(C\)</span> in <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> to be a
connected component of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>.
We may similarly define the regular subset <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{*
\mathop{\mathrm{reg}}}\)</span> in <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> to be the
complement of <span class="math inline">\(\cup_{\alpha \in \Phi}
\ker(H_\alpha)\)</span>, where now <span class="math inline">\(H_\alpha
\in \mathfrak{t}_{\mathbb{R}}\)</span> is viewed as an element of <span
class="math inline">\((\mathfrak{t}_{\mathbb{R}}^*)^*\)</span>, and a
Weyl chamber <span class="math inline">\(C^\vee \subseteq
\mathfrak{t}_{\mathbb{R}}^*\)</span> to be a connected component of
<span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{*\mathop{\mathrm{reg}}}\)</span>.
Since the isometry <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}
\cong \mathfrak{t}_{\mathbb{R}}^*\)</span> defined above identifies
<span class="math inline">\(H_\alpha\)</span> with a positive multiple
of <span class="math inline">\(\alpha\)</span>, we see that it
identifies the kernel of <span class="math inline">\(\alpha\)</span>
with the kernel of <span class="math inline">\(H_\alpha\)</span>, and
hence identifies each Weyl chamber <span
class="math inline">\(C\)</span> of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> with a
corresponding Weyl chamber <span class="math inline">\(C^\vee\)</span>
of <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span>.
This identification is independent of the embedding <span
class="math inline">\(K \hookrightarrow \mathop{\mathrm{U}}(n)\)</span>,
since if <span class="math inline">\(C\)</span> is described as <span
class="math display">\[C = \{t  \in \mathfrak{t}_{\mathbb{R}} :
\varepsilon_\alpha \alpha(t) &gt; 0 \text{ for all } \alpha \in
  \Phi  \}\]</span> for some signs <span
class="math inline">\(\varepsilon_\alpha \in \{\pm 1\}\)</span> (see §<a
href="#sec:basics-weyl-chambers" data-reference-type="ref"
data-reference="sec:basics-weyl-chambers">7.8</a>), then <span
class="math inline">\(C^\vee\)</span> is described analogously as <span
class="math display">\[C^\vee
  = \{\lambda
  \in \mathfrak{t}_{\mathbb{R}}^*
  : \varepsilon_\alpha
  \lambda(H_\alpha) &gt; 0 \text{ for all } \alpha \in
  \Phi  \}.\]</span> In this way all of the facts that we prove below
involving the Weyl group action on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> and Weyl
chambers thereof have immediate counterparts for <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span>.</p>
<div class="example">
<p><strong>Example 125</strong>. Take <span class="math inline">\(K =
\mathop{\mathrm{SU}}(3)\)</span>. Then (with the usual notation) <span
class="math inline">\(\Phi = \{\varepsilon_i - \varepsilon_j : 1 \leq i
&lt; j \leq 3\}\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^* \cong
\mathfrak{t}_{\mathbb{R}} \cong (\mathbb{R}^3)_0\)</span>, the space of
triples <span class="math inline">\(x = (x_1,x_2,x_3) \in
\mathbb{R}^3\)</span> with <span class="math inline">\(\sum x_j =
0\)</span>. Using the standard representation, the inner product on
<span class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> is
given by the restriction of the standard inner product on <span
class="math inline">\(\mathbb{R}^3\)</span>. The elements <span
class="math display">\[\varepsilon_1 - \varepsilon_2 = (1,-1,0), \quad
\varepsilon_2 - \varepsilon_3 = (0,1,-1), \quad \varepsilon_3 -
\varepsilon_1 = (-1,0,1)\]</span> of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> sum to zero,
have the same lengths, and have the same inner products with one another
(up to sign). An isometric embedding of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}^*}\)</span> into <span
class="math inline">\(\mathbb{R}^2\)</span> is thus obtained by sending
these elements to the vertices of an equilateral triangle with center
the origin. The following elements are then sent to the vertices of a
regular hexagon with center the origin, traversed in the order they
appear around the boundary: <span class="math display">\[\varepsilon_1 -
\varepsilon_2, \quad \varepsilon_1 - \varepsilon_3, \quad \varepsilon_2
- \varepsilon_3, \quad \varepsilon_1 - \varepsilon_2, \quad
\varepsilon_3 - \varepsilon_1, \quad \varepsilon_3 -
\varepsilon_2.\]</span> In lecture we drew a picture and described the
root reflections, noting that they preserve the set of roots. For each
root <span class="math inline">\(\alpha\)</span>, we drew the hyperplane
perpendicular to <span class="math inline">\(\alpha\)</span>, which we
denoted by <span class="math inline">\(H_{\alpha}\)</span>. (The
notation is not so terrible, because the hyperplane <span
class="math inline">\(H_\alpha \subseteq
\mathfrak{t}_{\mathbb{R}}^*\)</span> is also the kernel of the
functional on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> defined by
the element <span class="math inline">\(H_{\alpha} \in
\mathfrak{t}_{\mathbb{R}}\)</span>.) There are six such hyperplanes. The
connected components of their complements are the six Weyl chambers.
Each Weyl chamber is a <span class="math inline">\(60\)</span> degree
open “pizza slice” in <span class="math inline">\(\mathbb{R}^2\)</span>.
Each Weyl chamber contains exactly one root, which is positioned along
the central ray of that Weyl chamber, <span
class="math inline">\(30\)</span> degrees from each of its walls. (TODO:
replace this text with a picture.)</p>
</div>
<h2 id="using-root-reflections-to-elucidate-the-weyl-group">Using root
reflections to elucidate the Weyl group</h2>
<div id="lem:key-root-reflections" class="lemma">
<p><strong>Lemma 126</strong>. Let <span class="math inline">\(C,
C&#39;\)</span> be Weyl chambers in <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span>. Then there
exist Weyl chambers <span class="math inline">\(C = C_0, C_1, C_2,
\dotsc, C_{n-1}, C_n = C&#39;\)</span> and roots <span
class="math inline">\(\alpha_1,\dotsc,\alpha_n \in \Phi\)</span> with
the following properties:</p>
<ol type="i">
<li><p>For <span class="math inline">\(j=1..n\)</span>, we have <span
class="math inline">\(\alpha_j &gt; 0\)</span> on <span
class="math inline">\(C_0, \dotsc, C_{j-1}\)</span> and <span
class="math inline">\(\alpha_j &lt; 0\)</span> on <span
class="math inline">\(C_j, \dotsc, C_{n}\)</span>.</p></li>
<li><p>Each <span class="math inline">\(\beta \in \Phi - \{\pm \alpha_1,
\dotsc, \pm \alpha_n\}\)</span> takes the same sign on <span
class="math inline">\(C_0,\dotsc,C_n\)</span>.</p></li>
<li><p>For <span class="math inline">\(j=1..n\)</span>, we have <span
class="math inline">\(s_{\alpha_j} C_{j-1} = C_j\)</span>. In
particular, <span class="math display">\[C&#39;
      = s_{\alpha_n} \dotsb s_{\alpha_1} C.\]</span></p></li>
</ol>
<p>Analogous conclusions hold for any pair of Weyl chambers in <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span>.</p>
</div>
<p>The idea of the proof was illustrated in class on the picture of the
Weyl chambers for <span
class="math inline">\(\mathop{\mathrm{SU}}(3)\)</span>. Consider the
straight line path from some <span class="math inline">\(t \in
C\)</span> to some <span class="math inline">\(t&#39; \in
C&#39;\)</span>. If <span class="math inline">\(t, t&#39;\)</span> are
chosen generically, then this path will hit each root hyperplane <span
class="math inline">\(\alpha^{\perp} := \{x \in
\mathfrak{t}_{\mathbb{R}} : \alpha(x) = 0\}\)</span> one at a time. We
take <span class="math inline">\(\alpha_1,\dotsc,\alpha_n\)</span> to
correspond to the root hyperplanes encountered along the way from <span
class="math inline">\(t\)</span> to <span
class="math inline">\(t&#39;\)</span> and <span
class="math inline">\(C_0,\dotsc,C_n\)</span> the Weyl chambers, so that
the path starts in the Weyl chamber <span
class="math inline">\(C_0\)</span>, then passes through the root
hyperplane <span class="math inline">\(\alpha_1^{\perp}\)</span>, then
spends some time in the Weyl chamber <span
class="math inline">\(C_1\)</span>, then passes through the root
hyperplane <span class="math inline">\(\alpha_2^{\perp}\)</span>, and so
on. We’ll give the actual proof next time. For now, let’s illustrate
with some motivating applications.</p>
<div class="corollary">
<p><strong>Corollary 127</strong>. <em>The Weyl group <span
class="math inline">\(W = N(T)/T\)</span> of a maximal torus <span
class="math inline">\(T\)</span> in a compact connected Lie group <span
class="math inline">\(K\)</span> is generated by the root reflections
<span class="math inline">\(s_\alpha\)</span> (<span
class="math inline">\(\alpha \in \Phi = \Phi(K:T)\)</span>).</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Recall from Lemma <a
href="#lem:W-acts-freely-weyl-chambers" data-reference-type="ref"
data-reference="lem:W-acts-freely-weyl-chambers">116</a> that <span
class="math inline">\(W\)</span> acts freely on the set of Weyl
chambers. Let <span class="math inline">\(C\)</span> be any Weyl
chamber, and let <span class="math inline">\(w \in W\)</span>. Then
<span class="math inline">\(C&#39; := w(C)\)</span> is a Weyl chamber.
By Lemma <a href="#lem:key-root-reflections" data-reference-type="ref"
data-reference="lem:key-root-reflections">126</a>, we may write <span
class="math inline">\(C&#39; = s_{\alpha_n} \dotsb s_{\alpha_1}
C\)</span> for some <span class="math inline">\(\alpha_1,\dotsc,\alpha_n
\in \Phi\)</span>. Since the action of <span
class="math inline">\(W\)</span> on the set of Weyl chambers is free, we
obtain <span class="math inline">\(w = \alpha_n \dotsb
\alpha_1\)</span>. ◻</p>
</span></div>
<div class="corollary">
<p><strong>Corollary 128</strong>. <em>With notation as assumptions as
above, <span class="math inline">\(W\)</span> acts simply-transitively
on the set of Weyl chambers.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We’ve seen (Lemma <a
href="#lem:W-acts-freely-weyl-chambers" data-reference-type="ref"
data-reference="lem:W-acts-freely-weyl-chambers">116</a>) that the
action is defined and free; the final assertion in Lemma <a
href="#lem:key-root-reflections" data-reference-type="ref"
data-reference="lem:key-root-reflections">126</a> implies that it is
transitive. ◻</p>
</span></div>
<p><a href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a></p>
<div class="proof">
<p><em>Proof of Lemma <a href="#lem:key-root-reflections"
data-reference-type="ref"
data-reference="lem:key-root-reflections">126</a>.</em> We implement the
proof sketch given above. Fix <span class="math inline">\(t&#39; \in
C&#39;\)</span>. Set <span class="math inline">\(\Sigma := \{\alpha \in
\Phi : \alpha(C) &gt; 0, \alpha(C&#39;) &lt; 0\}\)</span>. Note that for
each <span class="math inline">\(t \in C\)</span> and <span
class="math inline">\(\alpha \in \Phi\)</span>, we have <span
class="math inline">\(\alpha(t) &gt; 0 &gt; \alpha(t&#39;)\)</span>, so
the line segment <span class="math inline">\(\{(1 - \tau) t + \tau t
&#39; : \tau \in [0,1]\}\)</span> connecting <span
class="math inline">\(t\)</span> to <span
class="math inline">\(t&#39;\)</span> intersects <span
class="math inline">\(\alpha^\perp\)</span> in a unique point that we
denote by <span class="math inline">\(p_\alpha(t)\)</span>. This defines
a map <span class="math display">\[p_\alpha : C \rightarrow
\alpha^\perp.\]</span> This map is continuous and open. Moreover, for
each <span class="math inline">\(\alpha \in \Phi\)</span>, the
hyperplane <span class="math inline">\(\alpha^\perp\)</span> is distinct
from <span class="math inline">\(\beta^\perp\)</span> for all <span
class="math inline">\(\beta \in \Phi - \{\pm \alpha \} = \Phi -
\mathbb{C} \alpha\)</span>, so the set <span
class="math display">\[\alpha^\perp - \cup_{\beta \in \Phi - \{\pm
\alpha \}} \alpha^\perp \cup \beta^{\perp}\]</span> is dense and open in
<span class="math inline">\(\alpha^\perp\)</span>. By an exercise in
topology, it follows that for each <span class="math inline">\(\alpha
\in \Sigma\)</span>, the set <span class="math display">\[A_\alpha :=
\{t \in C : p_\alpha(t) \in \beta^\perp \text{ for all } \beta \in \Phi
- \mathbb{C} \alpha \}\]</span> is dense and open in <span
class="math inline">\(C\)</span>. Hence likewise <span
class="math inline">\(A := \cap_{\alpha \in \Sigma} A_\alpha\)</span> is
dense and open in <span class="math inline">\(C\)</span>. Choose any
<span class="math inline">\(t \in A\)</span>. Let <span
class="math inline">\(\gamma : [0,1] \rightarrow
\mathfrak{t}_{\mathbb{R}}\)</span> denote the linear path connecting
<span class="math inline">\(t\)</span> to <span
class="math inline">\(t&#39;\)</span>, thus <span
class="math inline">\(\gamma(\tau) := (1 - \tau) t + \tau
t&#39;\)</span>. For each <span class="math inline">\(\alpha \in
\Sigma\)</span>, abbreviate <span class="math inline">\(p_\alpha :=
p_\alpha(t)\)</span>, and let <span class="math inline">\(\tau_{\alpha}
\in (0,1)\)</span> be such that <span
class="math inline">\(\gamma(\tau_\alpha) = p_\alpha\)</span>. By the
construction of <span class="math inline">\(t\)</span>, we have <span
class="math inline">\(\tau_\alpha \neq \tau_{\alpha &#39;}\)</span>
whenever <span class="math inline">\(\alpha \neq \alpha &#39;\)</span>.
We may thus order <span class="math inline">\(\Sigma = \{\alpha_1,
\dotsc, \alpha_n\}\)</span> in such a way that <span
class="math inline">\(\tau_{\alpha_1} &lt; \dotsb &lt;
\tau_{\alpha_n}\)</span>. Abbreviate <span class="math inline">\(\tau_j
:= \tau_{\alpha_j}\)</span> and set <span class="math inline">\(\tau_0
:= 0, \tau_{n+1} := 1\)</span>. Note if <span
class="math inline">\(\beta \in \Phi - (\Sigma \cup (-
\Sigma))\)</span>, then <span class="math inline">\(\beta\)</span> takes
the same sign on <span class="math inline">\(t\)</span> and <span
class="math inline">\(t&#39;\)</span>, hence also on the path <span
class="math inline">\(\gamma\)</span> connecting them. It follows that
for <span class="math inline">\(j=0..n\)</span>, the set <span
class="math inline">\(\{\gamma(\tau) : \tau_{j} &lt; \tau &lt;
\tau_{j+1}\}\)</span> belongs to some Weyl chamber <span
class="math inline">\(C_j\)</span> of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span>, with <span
class="math inline">\(C_0 = C\)</span> and <span
class="math inline">\(C_n = C&#39;\)</span>. Moreover, for <span
class="math inline">\(j=1..n\)</span>, there is a neighborhood <span
class="math inline">\(U_j\)</span> of <span
class="math inline">\(p_{\alpha_j}\)</span> that doesn’t intersect <span
class="math inline">\(\beta^\perp\)</span> for any <span
class="math inline">\(\beta \in \Phi - \mathbb{C} \alpha_j\)</span>,
thus <span class="math inline">\(U_j = (U_j \cap C_{j-1}) \sqcup (U_j
\cap \alpha_j^\perp) \sqcup (U_j \cap C_j)\)</span>. The root reflection
<span class="math inline">\(s_{\alpha_j}\)</span> satisfies <span
class="math inline">\(s_{\alpha_j}|_{\alpha_j^\perp} =
\mathop{\mathrm{id}}\)</span>, thus <span
class="math inline">\(s_{\alpha_j} U_j \cap U_j \neq \emptyset\)</span>,
thus <span class="math inline">\(s_{\alpha_j} (U_j \cap C_{j-1}) \cap
(U_j \cap C_{j-1}) \neq \emptyset\)</span>, hence <span
class="math inline">\(s_{\alpha_j} C_{j-1} = C_j\)</span>. The remaining
assertions follow from what we have already shown. ◻</p>
</div>
<div class="corollary">
<p><strong>Corollary 129</strong>. <em>Let <span
class="math inline">\(C\)</span> be a Weyl chamber. Any <span
class="math inline">\(x \in
\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span> is <span
class="math inline">\(W\)</span>-conjugate to a unique element of <span
class="math inline">\(C\)</span>. The <span
class="math inline">\(W\)</span>-stabilizer of <span
class="math inline">\(x\)</span> is trivial.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We use that <span class="math inline">\(x\)</span>
belongs to some Weyl chamber and that <span
class="math inline">\(W\)</span> acts transitively on the set of Weyl
chambers. ◻</p>
</span></div>
<div id="cor:W-conj-to-unique-dominant-element" class="corollary">
<p><strong>Corollary 130</strong>. <em>Let <span
class="math inline">\(C\)</span> be a Weyl chamber. Then any <span
class="math inline">\(x \in \mathfrak{t}_{\mathbb{R}}\)</span> is <span
class="math inline">\(W\)</span>-conjugate to a unique element of the
closure <span class="math inline">\(\overline{C}\)</span> of <span
class="math inline">\(C\)</span>.</em></p>
<p><em>The <span class="math inline">\(W\)</span>-stabilizer of <span
class="math inline">\(x\)</span> is generated by <span
class="math inline">\(\{s_\alpha : \alpha(x) = 0\}\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We observe first that <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>
is dense in <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span>. Indeed, if
<span class="math inline">\(x \in \mathfrak{t}_{\mathbb{R}}\)</span> and
<span class="math inline">\(y\)</span> is any element of <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>,
then <span class="math inline">\(x + \varepsilon y \in
\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span> for all small
enough <span class="math inline">\(\varepsilon&gt; 0\)</span>, and <span
class="math inline">\(x = \lim_{\varepsilon\rightarrow 0} (x +
\varepsilon y)\)</span>. Since <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>
is the union of the <span class="math inline">\(W\)</span>-conjugates of
<span class="math inline">\(C\)</span>, it follows that <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>
is the union of the <span class="math inline">\(W\)</span>-conjugates of
<span class="math inline">\(\overline{C}\)</span>. This gives the
existence of a <span class="math inline">\(W\)</span>-conjugate of <span
class="math inline">\(x\)</span> in <span
class="math inline">\(\overline{C}\)</span>. For verifying the
uniqueness, we may assume that <span class="math inline">\(x\)</span>
belongs to <span class="math inline">\(\overline{C}\)</span>, and must
show that if <span class="math inline">\(w \in W\)</span> satisfies
<span class="math inline">\(w(x) \in \overline{C}\)</span>, then <span
class="math inline">\(w(x) = x\)</span>. To see this, we apply Lemma <a
href="#lem:key-root-reflections" data-reference-type="ref"
data-reference="lem:key-root-reflections">126</a> to <span
class="math inline">\(C\)</span> and <span class="math inline">\(C&#39;
:= w^{-1}(C)\)</span>, giving us some chambers <span
class="math inline">\(C_0,\dotsc,C_n\)</span> and roots <span
class="math inline">\(\alpha_1,\dotsc,\alpha_n\)</span>. Our hypothesis
implies that <span class="math inline">\(x \in \overline{C} \cap
\overline{C&#39;}\)</span>. For <span class="math inline">\(j =
1..n\)</span>, we have <span class="math inline">\(\alpha_j &gt;
0\)</span> on <span class="math inline">\(C\)</span> and <span
class="math inline">\(\alpha_j &lt; 0\)</span> on <span
class="math inline">\(C&#39;\)</span>, thus <span
class="math inline">\(\alpha_j(x) = 0\)</span>, and so <span
class="math inline">\(s_{\alpha_j}(x) = x\)</span>. On the other hand,
<span class="math inline">\(w^{-1} = s_{\alpha_n} \dotsb
s_{\alpha_1}\)</span>, so <span class="math inline">\(w = s_{\alpha_1}
\dotsb s_{\alpha_n}\)</span>. Thus <span class="math inline">\(w(x) =
x\)</span>.</p>
<p>The final assertion follows from the argument just given; we note
that it doesn’t depend upon the choice of <span
class="math inline">\(C\)</span>. ◻</p>
</span></div>
<h2 id="basics-on-dominance-positivity-and-simple-roots">Basics on
dominance, positivity and simple roots</h2>
<div class="definition">
<p><strong>Definition 131</strong>. Choose a Weyl chamber <span
class="math inline">\(C \subseteq
\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>, hence a
corresponding dual Weyl chamber <span class="math inline">\(C^\vee
\subseteq \mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>. We
say that <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{R}}\)</span> (resp. <span
class="math inline">\(\lambda \in \mathfrak{t}_{\mathbb{R}}^*\)</span>)
is <em>dominant</em> if <span class="math inline">\(x \in
\overline{C}\)</span> (resp. if <span class="math inline">\(\lambda \in
\overline{C^\vee}\)</span>), and <em>strictly dominant</em> if <span
class="math inline">\(x \in {C}\)</span> (resp. if <span
class="math inline">\(\lambda \in {C^\vee}\)</span>).</p>
<p>We say that <span class="math inline">\(\alpha \in \Phi\)</span> is
<em>positive</em> if <span class="math inline">\(\alpha(C) &gt;
0\)</span>; we abbreviate this condition simply to <span
class="math inline">\(\alpha &gt; 0\)</span> when <span
class="math inline">\(C\)</span> is clear by context. We denote by <span
class="math inline">\(\Phi^+ := \Phi^+(C) \subseteq \Phi\)</span> the
subset of positive roots. We say that a positive root <span
class="math inline">\(\alpha \in \Phi^+\)</span> is <em>simple</em> if
it cannot be written in the form <span class="math inline">\(\alpha_1 +
\alpha_2\)</span> for some <span class="math inline">\(\alpha_1,
\alpha_2 \in \Phi^+\)</span>. We denote by <span
class="math inline">\(\Delta := \Delta(C) \subseteq \Phi^+\)</span> the
set of simple roots.</p>
<p>For <span class="math inline">\(x,y \in
\mathfrak{t}_{\mathbb{R}}\)</span> we say that <span
class="math inline">\(x\)</span> is <em>higher than</em> <span
class="math inline">\(y\)</span>, and write <span
class="math inline">\(x \geq y\)</span>, if <span
class="math inline">\(\lambda(x-y) \geq 0\)</span> for all <span
class="math inline">\(\lambda \in C^\vee\)</span>. Similarly, for <span
class="math inline">\(\lambda,\mu \mathfrak{t}_{\mathbb{R}}^*\)</span>,
we say that <span class="math inline">\(\lambda\)</span> is <em>higher
than</em> <span class="math inline">\(\mu\)</span>, and write <span
class="math inline">\(\lambda \geq \mu\)</span>, if <span
class="math inline">\((\lambda - \mu)(x) \geq 0\)</span> for all <span
class="math inline">\(x \in C\)</span>. We use “strictly higher than” to
mean “higher than and not equal to.”</p>
</div>
<p>We note that, for reasons explained earlier, all of these notions are
compatible with the isometry <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}} \cong
\mathfrak{t}_{\mathbb{R}}^*\)</span> defined by the inner product given
by the trace pairing with respect to any embedding <span
class="math inline">\(K \hookrightarrow
\mathop{\mathrm{U}}(n)\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 132</strong>. (Not proved in lecture, but useful facts
to mention at this point.)</p>
<ol type="i">
<li><p><span class="math inline">\(\Phi = \Phi^+ \sqcup
(-\Phi^+)\)</span>.</p></li>
<li><p><span class="math inline">\(C = \{x \in \mathfrak{t}_{\mathbb{R}}
: \alpha(x) &gt; 0 \text{ for all } \alpha &gt; 0\}\)</span> and <span
class="math inline">\(C^\vee = \{\lambda \in \mathfrak{t}_{\mathbb{R}}^*
: \lambda(H_\alpha) &gt; 0 \text{ for all } \alpha &gt;
0\}\)</span>.</p></li>
<li><p><span class="math inline">\(\{ x \in \mathfrak{t}_{\mathbb{R}} :
x \geq 0 \} = \sum_{\alpha &gt; 0} \mathbb{R}_{\geq 0}
H_{\alpha}\)</span> and <span class="math inline">\(\{ \lambda \in
\mathfrak{t}_{\mathbb{R}}^* : \lambda \geq 0 \} = \sum_{\alpha &gt; 0}
\mathbb{R}_{\geq 0} \alpha\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We’ve seen that we may write <span
class="math inline">\(C = \{x : \varepsilon_\alpha \alpha(x) &gt; 0
\text{ for all } \alpha \in \Phi \}\)</span> for some signs <span
class="math inline">\(\varepsilon_\alpha \in \{\pm 1\}\)</span>. Then
<span class="math inline">\(C^\vee = \{\lambda : \varepsilon_\alpha
\lambda(H_\alpha) &gt; 0 \text{ for all } \alpha \in \Phi \}\)</span>.
Since <span class="math inline">\(\varepsilon_{-\alpha} = -
\varepsilon_{\alpha}\)</span> and <span class="math inline">\(\Phi^+ =
\{\alpha : \varepsilon_\alpha = 1\}\)</span>, we deduce assertions (i)
and (ii). The final assertion (iii) boils down, as follows, to a general
duality principle for convex cones. Let <span
class="math inline">\(M_1\)</span> and <span
class="math inline">\(M_2\)</span> denote the LHS and RHS of the claimed
identity. Then <span class="math inline">\(M_1\)</span> and <span
class="math inline">\(M_2\)</span> are closed convex cones containing
the origin. Clearly <span class="math inline">\(M_2 \subseteq
M_1\)</span>. To prove the reverse containment <span
class="math inline">\(M_1 \subseteq M_2\)</span>, it suffices (by the
separating hyperplane theorem, the finite-dimensional case of
Hahn–Banach) to show that for each <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{R}}\)</span> with <span
class="math inline">\(M_2(x) \geq 0\)</span>, we have <span
class="math inline">\(M_1(x) \geq 0\)</span>. Indeed, if <span
class="math inline">\(M_2(x) \geq 0\)</span>, then <span
class="math inline">\(\alpha(x) \geq 0\)</span> for all <span
class="math inline">\(\alpha &gt; 0\)</span>; since <span
class="math inline">\(\lambda \geq 0\)</span> for all <span
class="math inline">\(\lambda \in M_1\)</span>, the required implication
follows. ◻</p>
</span></div>
<p>For instance, take <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, with <span
class="math inline">\(T\)</span> as usual and coordinates as before. We
might take <span class="math display">\[C = \{x \in
\mathfrak{t}_{\mathbb{R}} \cong \mathbb{R}^n : x_1
  &gt; \dotsb &gt; x_n\}.\]</span> Then <span
class="math display">\[C^\vee = \{\lambda \in
\mathfrak{t}_{\mathbb{R}}^* \cong
  \mathbb{R}^n:
  \lambda_1 &gt; \dotsb &gt; \lambda_n\}\]</span> and <span
class="math display">\[\Phi^+ = \{\varepsilon_i - \varepsilon_j : i &lt;
j\} = \{\varepsilon_1 - \varepsilon_2,
  \varepsilon_1 - \varepsilon_3, \dotsc\}\]</span> and <span
class="math display">\[\Delta = \{\varepsilon_1 - \varepsilon_2,
\varepsilon_2 - \varepsilon_3, \dotsc, \varepsilon_{n-1} -
\varepsilon_n\}.\]</span></p>
<div class="corollary">
<p><strong>Corollary 133</strong>. <em>If <span
class="math inline">\(\lambda \in \mathfrak{t}_{\mathbb{R}}^*\)</span>
is dominant, then <span class="math inline">\(\lambda \geq
w(\lambda)\)</span> for all <span class="math inline">\(w \in
W\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We apply Lemma <a href="#lem:key-root-reflections"
data-reference-type="ref"
data-reference="lem:key-root-reflections">126</a> in its dual form to
<span class="math inline">\(C^\vee\)</span> and <span
class="math inline">\(w C^\vee\)</span>. This gives us a sequence of
dual Weyl chambers <span class="math inline">\(C_0^\vee = C^\vee,
C_1^\vee, \dotsc, C_n^\vee = w C^\vee\)</span> and roots <span
class="math inline">\(\alpha_1,\dotsc,\alpha_n\)</span> satisfying
(among other properties) <span class="math inline">\(H_{\alpha_j} &gt;
0\)</span> on <span class="math inline">\(C_0^{\vee}, \dotsc,
C_{j-1}^{\vee}\)</span> and <span class="math inline">\(H_{\alpha_j}
&lt; 0\)</span> on <span class="math inline">\(C_j^{\vee}, \dotsc,
C_{n}^{\vee}\)</span>. Set <span class="math inline">\(\lambda_j :=
s_{\alpha_j} \dotsb s_{\alpha_1} \lambda\)</span>. Then <span
class="math inline">\(\lambda = \lambda_0\)</span> and <span
class="math inline">\(w(\lambda) = \lambda_n\)</span>, so <span
class="math display">\[\lambda - w(\lambda) = (\lambda_0 - \lambda_1) +
(\lambda_1 - \lambda_2) + \dotsb + (\lambda_{n-1} - \lambda_n).\]</span>
For <span class="math inline">\(j=1..n\)</span>, the formulas defining
<span class="math inline">\(\lambda_j\)</span> and <span
class="math inline">\(s_{\alpha_j}\)</span> give <span
class="math display">\[\lambda_{j-1} - \lambda_j = \lambda_{j-1} -
s_{\alpha_j} \lambda_{j-1} = \lambda_{j-1}(H_{\alpha_j})
\alpha_j.\]</span> We have <span class="math inline">\(\alpha_j &gt;
0\)</span> (because <span class="math inline">\(H_{\alpha_j} &gt;
0\)</span> on <span class="math inline">\(C^\vee\)</span>) and <span
class="math inline">\(\lambda_{j-1}(H_{\alpha_j}) \geq 0\)</span>
(because <span class="math inline">\(H_{\alpha_j} \geq0\)</span> on
<span class="math inline">\(C_{j-1}\)</span>), hence <span
class="math inline">\(\lambda_{j-1} - \lambda_j \geq 0\)</span>. It
follows that <span class="math inline">\(\lambda - w(\lambda) \geq
0\)</span>. ◻</p>
</span></div>
<div id="thm:simple-system-is-linearly-indep" class="theorem">
<p><strong>Theorem 134</strong>. <em><span
class="math inline">\(\Delta\)</span> is linearly independent over <span
class="math inline">\(\mathbb{R}\)</span>, and the <span
class="math inline">\(\mathbb{Z}\)</span>-module <span
class="math inline">\(\mathbb{Z} \Phi\)</span> spanned by <span
class="math inline">\(\Phi\)</span> admits the <span
class="math inline">\(\mathbb{Z}\)</span>-module basis <span
class="math inline">\(\Delta\)</span>.</em></p>
</div>
<p>We’ll give the proof after a few lemmas.</p>
<div id="lem:pos-roots-via-simple-roots" class="lemma">
<p><strong>Lemma 135</strong>. Every <span class="math inline">\(\beta
\in \Phi^+\)</span> may be written in the form <span
class="math inline">\(\beta = \sum_{\alpha \in \Delta} n_\alpha
\alpha\)</span> with <span class="math inline">\(n_\alpha \in
\mathbb{Z}_{\geq 0}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Fix <span class="math inline">\(t \in C\)</span>. As
<span class="math inline">\(\beta\)</span> varies over <span
class="math inline">\(\Phi^+\)</span>, the quantities <span
class="math inline">\(\beta(t)\)</span> vary over a finite subset of
<span class="math inline">\(\mathbb{R}_{&gt;0}\)</span>. We argue by
induction on <span class="math inline">\(\beta(t)\)</span>. If <span
class="math inline">\(\beta \in \Delta\)</span>, then we are done.
Otherwise <span class="math inline">\(\beta = \beta_1 + \beta_2\)</span>
with <span class="math inline">\(\beta_1, \beta_2 \in \Delta\)</span>.
Then <span class="math inline">\(\beta_1(t), \beta_2(t) &lt;
\beta(t)\)</span>, so we may conclude by our inductive hypothesis. ◻</p>
</span></div>
<p>Let <span class="math inline">\(\alpha,\beta \in \Phi\)</span> be
roots. Recall that, if we choose an embedding <span
class="math inline">\(K \hookrightarrow \mathop{\mathrm{U}}(n)\)</span>
and hence an inner product <span class="math inline">\(\langle x,y
\rangle = \mathop{\mathrm{trace}}( x y)\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> and hence an
isometry <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}^* \ni
\lambda \mapsto u_\lambda \in \mathfrak{t}_{\mathbb{R}}\)</span>, then
<span class="math inline">\(H_\alpha = \frac{2}{( \alpha, \alpha )}
u_\alpha\)</span>. Thus <span id="eq:identity-alpha-beta-inner-prod-vs-H-stuff" class="math display">\[\label{eq:identity-alpha-beta-inner-prod-vs-H-stuff}\tag{73}
  \langle \alpha, \beta  \rangle
  =
  \beta(u_\alpha)
  =
  \alpha(u_\beta)
  =
  \frac{\langle\alpha,\alpha\rangle}{2}
  \beta(H_\alpha)
  =
  \frac{\langle\beta,\beta\rangle}{2}
  \alpha(H_\beta).\]</span> In particular, the quantities <span
class="math display">\[(\alpha,\beta),
  \quad
  \alpha(H_\beta),
  \quad
  \beta(H_\alpha)\]</span> all have the same sign. We say that the roots
<span class="math inline">\(\alpha,\beta\)</span></p>
<ul>
<li><p>are <em>orthogonal</em> if these quantities are zero,</p></li>
<li><p>form an <em>acute</em> angle if these quantities are positive,
and</p></li>
<li><p>form an <em>obtuse</em> angle if they are negative.</p></li>
</ul>
<p>These notions are evidently independent of the choice of embedding
<span class="math inline">\(K \hookrightarrow
\mathop{\mathrm{U}}(n)\)</span>.</p>
<div id="lem:non-proportional-roots-inner-products-etc" class="lemma">
<p><strong>Lemma 136</strong>. Let <span
class="math inline">\(\alpha,\beta \in \Phi\)</span> be roots that are
non-proportional (thus <span class="math inline">\(\alpha \neq \pm
\beta\)</span>).</p>
<ul>
<li><p>If <span class="math inline">\(\alpha,\beta\)</span> are
orthogonal, then <span class="math inline">\(\alpha(H_\beta) =
\beta(H_\alpha) = 0\)</span>.</p></li>
<li><p>Suppose <span class="math inline">\(\alpha,\beta\)</span> form an
acute angle. Then the pair <span class="math inline">\((\alpha(H_\beta),
\beta(H_\alpha))\)</span> is one of the following: <span
class="math display">\[(1,1), (1,2), (2, 1), (1, 3), (3, 1).\]</span>
Moreover, <span class="math inline">\(\alpha - \beta\)</span> is a
root.</p></li>
<li><p>Suppose <span class="math inline">\(\alpha,\beta\)</span> form an
obtuse angle. Then the pair <span
class="math inline">\((\alpha(H_\beta), \beta(H_\alpha))\)</span> is one
of the following: <span class="math display">\[(-1,-1), (-1,-2), (-2,
-1), (-1, -3), (-3, -1).\]</span> Moreover, <span
class="math inline">\(\alpha + \beta\)</span> is a root.</p></li>
</ul>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Suppose for instance that <span
class="math inline">\(\alpha,\beta\)</span> form an acute angle. Since
<span class="math inline">\(\alpha,\beta \in
\mathfrak{t}_{\mathbb{Z}}^*\)</span> and <span
class="math inline">\(H_\alpha, H_\beta \in
\mathfrak{t}_{\mathbb{Z}}\)</span>, we then have <span
class="math inline">\(\alpha(H_\beta), \beta(H_\alpha) \in
\mathbb{Z}_{\geq 1}\)</span>. Since <span
class="math inline">\(\alpha\)</span>,<span
class="math inline">\(\beta\)</span> are non-proportional, we may apply
the Cauchy–Schwartz inequality in its strict form and the identity <a
href="#eq:identity-alpha-beta-inner-prod-vs-H-stuff"
data-reference-type="eqref"
data-reference="eq:identity-alpha-beta-inner-prod-vs-H-stuff">\((73)\)</a>
to see that <span class="math display">\[\alpha(H_\beta) \beta(H_\alpha)
= 4 \frac { \left\lvert \langle \alpha, \beta \rangle \right\rvert^2 } {
\langle \alpha, \alpha \rangle \langle \beta, \beta \rangle } &lt;
4.\]</span> Thus <span class="math inline">\(\alpha(H_\beta)
\beta(H_\alpha) \in \{1,2,3\}\)</span>, which leads to the possibilities
indicated. In particular, either <span
class="math inline">\(\alpha(H_\beta)\)</span> or <span
class="math inline">\(\beta(H_\alpha)\)</span> is equal to <span
class="math inline">\(1\)</span>. Suppose for instance that <span
class="math inline">\(\beta(H_\alpha) = 1\)</span>. Then <span
class="math display">\[s_{\alpha}(\beta) = \beta - \beta(H_\alpha)
\alpha = \beta - \alpha,\]</span> so <span class="math inline">\(\beta -
\alpha\)</span> is a root, thus <span class="math inline">\(\alpha -
\beta = - (\beta - \alpha)\)</span> is a root, as required. The case
that <span class="math inline">\(\alpha(H_\beta) = 1\)</span> is treated
similarly. The obtuse case is treated similarly. ◻</p>
</span></div>
<div id="cor:simple-roots-obtuse-angles" class="corollary">
<p><strong>Corollary 137</strong>. <em>If <span
class="math inline">\(\alpha, \beta\)</span> are distinct elements of
<span class="math inline">\(\Delta\)</span>, then <span
class="math inline">\(\langle \alpha, \beta \rangle \leq
0\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We’ve seen that otherwise <span
class="math inline">\(\gamma := \alpha - \beta\)</span> is a root. If
<span class="math inline">\(\gamma \in \Phi^+\)</span>, then the
identity <span class="math inline">\(\alpha = \beta + \gamma\)</span>
implies that <span class="math inline">\(\alpha \notin \Delta\)</span>,
while if <span class="math inline">\(-\gamma \in \Phi^+\)</span>, then
the identity <span class="math inline">\(\beta = \alpha +
(-\gamma)\)</span> implies that <span class="math inline">\(\beta \notin
\Delta\)</span>. In either case we obtain the required
contradiction. ◻</p>
</span></div>
<div class="proof">
<p><em>Proof of Theorem <a href="#thm:simple-system-is-linearly-indep"
data-reference-type="ref"
data-reference="thm:simple-system-is-linearly-indep">134</a>.</em>
Suppose there are distinct elements <span
class="math inline">\(\alpha_1,\dotsc,\alpha_m, \beta_1, \dotsc, \beta_n
\in \Delta\)</span> and positive reals <span
class="math inline">\(a_1,\dotsc,a_m,b_1,\dotsc,b_n\)</span> so that
<span class="math display">\[x := \sum a_i \alpha_i = \sum b_j \beta_j
=: y.\]</span> Corollary <a href="#cor:simple-roots-obtuse-angles"
data-reference-type="ref"
data-reference="cor:simple-roots-obtuse-angles">137</a> then implies
that <span class="math inline">\(\langle \alpha_i, \beta_j \rangle \leq
0\)</span>, so <span class="math display">\[0 \leq \langle x, x \rangle
= \langle x, y \rangle = \sum_{i,j} \underbrace{a_i b_j}_{&gt;0}
\underbrace{\langle \alpha_i, \beta_j \rangle}_{\leq 0} \leq 0,\]</span>
so equality holds, and thus <span class="math inline">\(x = y =
0\)</span>. Choose any <span class="math inline">\(t \in C\)</span>.
Then <span class="math inline">\(a_i(t) &gt; 0\)</span>, so <span
class="math inline">\(0 = x(t) = \sum_{i} a_i \alpha_i(t)\)</span> and
<span class="math inline">\(0 = y(t) = \sum_{j} b_j \beta_j(t)\)</span>
with each summand positive. Thus <span class="math inline">\(m = n =
0\)</span>. ◻</p>
</div>
<div class="theorem">
<p><strong>Theorem 138</strong>. <em>The Weyl group is generated by the
simple reflections, i.e., <span class="math inline">\(W = \langle
s_\alpha : \alpha \in \Delta \rangle\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We’ll leave this to the homework. It can be proved
using Lemma <a href="#lem:key-root-reflections"
data-reference-type="ref"
data-reference="lem:key-root-reflections">126</a>; the main point is
that <span class="math inline">\(\alpha_1 \in \Delta(C)\)</span> for any
<span class="math inline">\(\alpha_1\)</span> in the conclusion of that
lemma. ◻</p>
</span></div>
<h2 id="cartan-matrices">Cartan matrices</h2>
<p>Let <span class="math inline">\(K\)</span> be a compact connected Lie
group, with maximal torus <span class="math inline">\(T\)</span>, Weyl
chamber <span class="math inline">\(C\)</span> and accompanying notation
as above.</p>
<div class="definition">
<p><strong>Definition 139</strong>. The Cartan matrix is <span
class="math inline">\((N_{\alpha \beta})_{\alpha, \beta \in
\Delta}\)</span> where <span class="math inline">\(N_{\alpha \beta} :=
\alpha(H_\beta)\)</span>.</p>
</div>
<p>We’ll note that the Cartan matrix, as we’ve defined it here, depends
only upon the isomorphism class of the compact Lie group <span
class="math inline">\(K\)</span>. (Use that any two maximal tori are
<span class="math inline">\(G\)</span>-conjugate and that any two Weyl
chambers are <span class="math inline">\(W\)</span>-conjugate.)</p>
<div class="lemma">
<p><strong>Lemma 140</strong>. We have <span
class="math inline">\(N_{\alpha \alpha} = 2\)</span>. For <span
class="math inline">\(\alpha \neq \beta\)</span>, the pair <span
class="math inline">\((N_{\alpha \beta},N_{\beta \alpha})\)</span> is
one of <span class="math display">\[(0,0), \quad (-1,-1), \quad (-1,-2),
\quad (-2,-1), \quad (-1,-3), \quad (-3,-1).\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> By Lemma <a
href="#lem:non-proportional-roots-inner-products-etc"
data-reference-type="ref"
data-reference="lem:non-proportional-roots-inner-products-etc">136</a>
and Corollary <a href="#cor:simple-roots-obtuse-angles"
data-reference-type="ref"
data-reference="cor:simple-roots-obtuse-angles">137</a>. ◻</p>
</span></div>
<p>We’ll prove the following (and some variants) after the break:</p>
<div id="thm:cartan-matrix-determines-K" class="theorem">
<p><strong>Theorem 141</strong>. <em>The tuple <span
class="math inline">\((T, \Delta, \Delta^\vee)\)</span> determines <span
class="math inline">\(K\)</span> up to isomorphism, in the following
sense:</em></p>
<p><em>Suppose given two compact connected Lie groups <span
class="math inline">\(K&#39;, K&#39;&#39;\)</span> equipped with maximal
tori <span class="math inline">\(T&#39;, T&#39;&#39;\)</span>, Weyl
chambers <span class="math inline">\(C&#39;, C&#39;&#39;\)</span>. Let
<span class="math inline">\(\Delta &#39; = \{\gamma_1 &#39;, \dotsc,
\gamma_n&#39;\}\)</span> and <span class="math inline">\(\Delta
&#39;&#39; = \{\gamma_1 &#39;&#39;, \dotsc,
\gamma_n&#39;&#39;\}\)</span> denote the associated sets of simple
roots, and <span class="math inline">\(H_i&#39; :=
H_{\gamma_i&#39;}\)</span>, <span class="math inline">\(H_i&#39;&#39; :=
H_{\gamma_i&#39;&#39;}\)</span> the simple coroots. Suppose given an
isomorphism <span class="math inline">\(\kappa : T&#39; \rightarrow
T&#39;&#39;\)</span> such that <span class="math inline">\(\kappa^*
\gamma_i&#39;&#39; = \gamma_i&#39;\)</span> and <span
class="math inline">\(\kappa_* H_i&#39; = H_i&#39;&#39;\)</span>. Then
<span class="math inline">\(\kappa\)</span> extends to an isomorphism
<span class="math inline">\(K&#39; \rightarrow
K&#39;&#39;\)</span>.</em></p>
<p><em>More precisely, suppose given maps <span
class="math inline">\(F_i&#39; : \mathop{\mathrm{SU}}(2) \rightarrow
K&#39;\)</span> and <span class="math inline">\(F_i&#39;&#39; :
\mathop{\mathrm{SU}}(2) \rightarrow K&#39;&#39;\)</span> attached to the
roots <span class="math inline">\(\gamma_i&#39;\)</span> and <span
class="math inline">\(\gamma_i&#39;&#39;\)</span>. Let <span
class="math inline">\(X_i&#39;, Y_i&#39;, H_i&#39;\)</span> and <span
class="math inline">\(X_i&#39;&#39;, Y_i&#39;&#39;,
H_i&#39;&#39;\)</span> be defined accordingly. Then there exists a
unique extension of <span class="math inline">\(\kappa\)</span> whose
differential maps <span class="math inline">\(X_i&#39;\)</span> to <span
class="math inline">\(X_i&#39;&#39;\)</span> for each <span
class="math inline">\(i\)</span>.</em></p>
</div>
<p>This has the following consequence:</p>
<div class="corollary">
<p><strong>Corollary 142</strong>. <em>Suppose that <span
class="math inline">\(K\)</span> has finite center, or equivalently,
that <span class="math inline">\(\mathfrak{k}\)</span> has trivial
center. Then the pair <span class="math inline">\((T, (N_{\alpha
\beta})_{\alpha,\beta \in \Delta})\)</span> determines <span
class="math inline">\(K\)</span> up to isomorphism in the following
sense:</em></p>
<p><em>Let <span class="math inline">\(K&#39;, K&#39;&#39;\)</span> be
two compact connected Lie groups having finite center, with maximal tori
<span class="math inline">\(T&#39;, T&#39;&#39;\)</span> and Weyl
chambers <span class="math inline">\(C&#39;, C&#39;&#39;\)</span> and
sets of simple roots <span class="math inline">\(\Delta &#39;, \Delta
&#39;&#39;\)</span> so that there is an isomorphism <span
class="math inline">\(T&#39; \xrightarrow{\simeq } T&#39;&#39;\)</span>
for which the induced isomorphism <span
class="math inline">\(X(T&#39;&#39;) \xrightarrow{\simeq }
X(T&#39;)\)</span> defines a bijection <span
class="math inline">\(\Delta &#39;&#39; \xrightarrow{\simeq } \Delta
&#39;\)</span> with respect to which the Cartan matrices coincide, i.e.,
<span class="math inline">\(\alpha &#39;&#39;(H_{\beta &#39;&#39;}) =
\alpha &#39;(H_{\beta &#39;})\)</span> whenever <span
class="math inline">\(\alpha &#39;, \beta &#39; \in \Delta
&#39;\)</span> correspond to <span class="math inline">\(\alpha
&#39;&#39;, \beta &#39;&#39; \in \Delta &#39;&#39;\)</span>. Then the
isomorphism <span class="math inline">\(T&#39; \xrightarrow{\simeq }
T&#39;&#39;\)</span> extends to an isomorphism <span
class="math inline">\(K&#39; \xrightarrow{\simeq } K&#39;&#39;\)</span>.
The set of possible isomorphisms may be described as in theorem <a
href="#thm:cartan-matrix-determines-K" data-reference-type="ref"
data-reference="thm:cartan-matrix-determines-K">141</a>.</em></p>
</div>
<p><a href="#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a> The proof will be given in §???
after some preliminaries.</p>
<h2 id="strings-of-roots">Strings of roots</h2>
<p>Let <span class="math inline">\(K,T,\Phi\)</span> be as usual: a
compact connected Lie group, a maximal torus, and the set of roots. Let
<span class="math inline">\(\alpha, \beta \in \Phi\)</span>.</p>
<div id="lem:strings-roots" class="lemma">
<p><strong>Lemma 143</strong>. </p>
<ol type="i">
<li><p>If <span class="math inline">\(\alpha+\beta \in \Phi\)</span>,
then <span class="math inline">\([\mathfrak{g}^\alpha,
\mathfrak{g}^{\beta}] = \mathfrak{g}^{\alpha+\beta}\)</span>.</p></li>
<li><p>Suppose that <span class="math inline">\(\alpha,\beta\)</span>
are non-proportional, i.e., <span class="math inline">\(\mathbb{Q}
\alpha \neq \mathbb{Q} \beta\)</span>. The set <span
class="math display">\[E := \{k \in \mathbb{Z} : \beta + k \alpha \in
\Phi \}\]</span> contains <span class="math inline">\(0\)</span> and is
finite, hence has a minimal element of the form <span
class="math inline">\(-p\in \mathbb{Z}_{ \leq 0}\)</span> and a maximal
element of the form <span class="math inline">\(q \in \mathbb{Z}_{\geq
0}\)</span>. We have <span id="eq:E-equals-Z-cap-interval" class="math display">\[\label{eq:E-equals-Z-cap-interval}\tag{74}
      E = \mathbb{Z} \cap [-p,q].\]</span> Moreover, for any nonzero
elements <span class="math inline">\(X_\alpha \in \mathfrak{g}^{\alpha},
Y_\alpha \in \mathfrak{g}^{-\alpha}\)</span>, each of the maps <span
class="math display">\[\mathfrak{g}^{\beta - p \alpha}
\xrightarrow{{\mathop{\mathrm{ad}}}_{X_\alpha}} \mathfrak{g}^{\beta -
(p-1) \alpha} \xrightarrow{{\mathop{\mathrm{ad}}}_{X_\alpha}} \dotsb
\xrightarrow{{\mathop{\mathrm{ad}}}_{X_\alpha}} \mathfrak{g}^{\beta +
(q-1) \alpha} \xrightarrow{{\mathop{\mathrm{ad}}}_{X_\alpha}}
\mathfrak{g}^{\beta + q \alpha},\]</span> <span
class="math display">\[\mathfrak{g}^{\beta - p \alpha}
\xleftarrow{{\mathop{\mathrm{ad}}}_{Y_\alpha}} \mathfrak{g}^{\beta - (p-1)
\alpha} \xleftarrow{{\mathop{\mathrm{ad}}}_{Y_\alpha}} \dotsb
\xleftarrow{{\mathop{\mathrm{ad}}}_{Y_\alpha}} \mathfrak{g}^{\beta + (q-1)
\alpha} \xleftarrow{{\mathop{\mathrm{ad}}}_{Y_\alpha}} \mathfrak{g}^{\beta
+ q \alpha},\]</span> is an isomorphism. Moreover, <span id="eq:beta-H-alpha-diff-p-q" class="math display">\[\label{eq:beta-H-alpha-diff-p-q}\tag{75}
      \beta(H_\alpha) = p - q.\]</span></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Note first that (ii) implies (i): if <span
class="math inline">\(\alpha+\beta \in \Phi\)</span>, then (since <span
class="math inline">\(\mathbb{Q} \alpha \cap \Phi = \{\pm \alpha
\}\)</span>) <span class="math inline">\(\alpha,\beta\)</span> are
non-proportional, the set <span class="math inline">\(E\)</span> as
defined in (ii) contains the elements <span
class="math inline">\(0,1\)</span>, and <span
class="math inline">\(\mathop{\mathrm{ad}}(X_\alpha) :
\mathfrak{g}^{\beta} \rightarrow \mathfrak{g}^{\beta+\alpha}\)</span> is
an isomorphism of one-dimensional vector spaces, which implies that
<span class="math inline">\([\mathfrak{g}^\alpha,\mathfrak{g}^{\beta}] =
\mathfrak{g}^{\alpha+\beta}\)</span>.</p>
<p>We turn to the proof of (ii). Since <span
class="math inline">\(\beta, \alpha\)</span> are non-proportional, we
have <span class="math inline">\(\beta + k \alpha \neq 0\)</span> for
all <span class="math inline">\(k \in \mathbb{Z}\)</span>. Thus <span
class="math display">\[V := \oplus_{k \in \mathbb{Z}}
\mathfrak{g}^{\beta + k
      \alpha}
    =
    \oplus _{k \in E}
    \mathfrak{g}^{\beta + k \alpha}.\]</span> We check easily that <span
class="math inline">\(V\)</span> is an <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})_\alpha\)</span>-module
whose weight spaces, i.e., <span
class="math inline">\(\mathop{\mathrm{ad}}(H_\alpha)\)</span>-eigenspaces,
are the summands <span class="math inline">\(\mathfrak{g}^{\beta+k
\alpha}\)</span>, with correspond eigenvalues <span
class="math inline">\((\beta+k \alpha)(H_\alpha) = \beta(H_\alpha) + 2
k\)</span>. The weight spaces are thus one-dimensional and the weights
all have the same parity, so by the structure theory for <span
class="math inline">\({\mathop{\mathrm{\mathfrak{s}\mathfrak{l}}}}_2(\mathbb{C})\)</span>-modules,
we deduce that <span class="math inline">\(V\)</span> is irreducible,
that the weights of <span class="math inline">\(V\)</span> are of the
form <span class="math inline">\(\{-n, -n+2, \dotsc, n-2, n\}\)</span>
for some nonnegative integer <span class="math inline">\(n\)</span>,
that <a href="#eq:E-equals-Z-cap-interval" data-reference-type="eqref"
data-reference="eq:E-equals-Z-cap-interval">\((74)\)</a>
holds, and that the connecting maps between adjacent weight spaces
defined by <span
class="math inline">\(\mathop{\mathrm{ad}}(X_\alpha)\)</span> and <span
class="math inline">\(\mathop{\mathrm{ad}}(Y_\alpha)\)</span> are
isomorphisms. Moreover, <span class="math inline">\(n = \beta(H_\alpha)
+ 2 q\)</span> and <span class="math inline">\(-n = \beta(H_\alpha) - 2
p\)</span>, which gives <a href="#eq:beta-H-alpha-diff-p-q"
data-reference-type="eqref"
data-reference="eq:beta-H-alpha-diff-p-q">\((75)\)</a>. ◻</p>
</span></div>
<h2 id="sec:gener-lie-algebra">§7.19. Generating the Lie algebra using simple
root vectors</h2>
<p>For the next few results, let <span
class="math inline">\(K,T,C,\Phi,\Phi^+,\Delta\)</span> be as usual.
Write <span class="math display">\[\Delta =
\{\gamma_1,\dotsc,\gamma_n\}.\]</span> Fix <span
class="math inline">\(F_{\gamma_j} : \mathop{\mathrm{SU}}(2) \rightarrow
K\)</span> as in §<a href="#sec:from-roots-dist"
data-reference-type="ref" data-reference="sec:from-roots-dist">7.10</a>
and associated elements <span class="math inline">\(X_j :=
X_{\gamma_j}\)</span>, <span class="math inline">\(Y_j :=
Y_{\gamma_j}\)</span>, <span class="math inline">\(H_j :=
H_{\gamma_j}\)</span>.</p>
<div id="lem:roots-partial-sums" class="lemma">
<p><strong>Lemma 144</strong>. Let <span class="math inline">\(\beta \in
\Phi^+\)</span>. Then there exist <span
class="math inline">\(\alpha_1,\dotsc,\alpha_r \in \Delta\)</span> so
that</p>
<ul>
<li><p><span class="math inline">\(\beta = \alpha_1 + \dotsb +
\alpha_r\)</span>, and</p></li>
<li><p><span class="math inline">\(\alpha_1 + \dotsb + \alpha_s \in
\Phi\)</span> for <span class="math inline">\(s=1..r\)</span>.</p></li>
</ul>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The proof is an adaptation of that of Lemma <a
href="#lem:pos-roots-via-simple-roots" data-reference-type="ref"
data-reference="lem:pos-roots-via-simple-roots">135</a>. Fix <span
class="math inline">\(t \in C\)</span>. Induct on <span
class="math inline">\(\beta(t) \in \mathbb{R}_{&gt;0}\)</span>. If <span
class="math inline">\(\beta \in \Delta\)</span>, then the required
conclusion holds with <span class="math inline">\(r = 1\)</span> and
<span class="math inline">\(\alpha_1 = \beta\)</span>, so suppose <span
class="math inline">\(\beta \notin \Delta\)</span>.</p>
<p>We claim that there exists <span class="math inline">\(j \in
\{1..n\}\)</span> so that <span class="math inline">\(\beta\)</span> and
<span class="math inline">\(\gamma_j\)</span> form an acute angle.
Otherwise, arguing as in the proof of Theorem <a
href="#thm:simple-system-is-linearly-indep" data-reference-type="ref"
data-reference="thm:simple-system-is-linearly-indep">134</a>, we see
that the set <span class="math inline">\(\{\beta, \gamma_1, \dotsc,
\gamma_n\}\)</span> is linearly independent over <span
class="math inline">\(\mathbb{R}\)</span>. Since <span
class="math inline">\(\beta \in \oplus_{j=1..n} \mathbb{Z}_{\geq 0}
\gamma_j\)</span>, we obtain the required contradiction.</p>
<p>Fix one such <span class="math inline">\(j\)</span>. Since <span
class="math inline">\(\beta \in \Phi^+ - \Delta\)</span>, the roots
<span class="math inline">\(\beta\)</span> and <span
class="math inline">\(\gamma_j\)</span> are non-proportional, so by
Lemma <a href="#lem:non-proportional-roots-inner-products-etc"
data-reference-type="ref"
data-reference="lem:non-proportional-roots-inner-products-etc">136</a>,
the difference <span class="math inline">\(\beta - \gamma_j\)</span> is
a root. We claim that <span class="math inline">\(\beta -
\gamma_j\)</span> is positive. If not, then <span
class="math inline">\(\gamma_j - \beta\)</span> is positive. Writing
<span class="math inline">\(\beta = \sum_i c_i \gamma_i\)</span> with
<span class="math inline">\(c_i \in \mathbb{Z}_{\geq 0}\)</span>, the
decomposition <span class="math inline">\(\gamma _j - \beta = \sum_i
(\delta_{i j} - c_i) \gamma_i\)</span> then has nonnegative
coefficients, so <span class="math inline">\(c_j \leq 1\)</span> and
<span class="math inline">\(c_i \leq 0\)</span> for <span
class="math inline">\(i \neq j\)</span>. These conditions force either
<span class="math inline">\(\beta = 0\)</span> (which is impossible
because <span class="math inline">\(\beta\)</span> is a root) or <span
class="math inline">\(\beta = \gamma_j\)</span> (which is impossible
because <span class="math inline">\(\beta \notin \Delta\)</span>).</p>
<p>We now apply our inductive hypothesis to <span
class="math inline">\(\beta - \gamma_j\)</span>, writing it as <span
class="math inline">\(\alpha_1 + \dotsb + \alpha_r\)</span> for some
simple roots satisfying the required conclusion of the lemma, and take
<span class="math inline">\(\alpha_{r+1} := \gamma_j\)</span>. Then
<span class="math inline">\(\beta = \alpha_1 + \dotsb +
\alpha_{r+1}\)</span> gives the required decomposition. ◻</p>
</span></div>
<div id="cor:g-gen-via-simple-stuff" class="corollary">
<p><strong>Corollary 145</strong>. <em><span
class="math inline">\(\mathfrak{g}\)</span> is generated (as a complex
Lie algebra) by <span class="math inline">\(\mathfrak{t}_{\mathbb{C}}
\cup \{X_i\} \cup \{Y_j\}\)</span>. More precisely, <span id="eqn:decomposition-frak-g-via-simple-root-vecs" class="math display">\[\label{eqn:decomposition-frak-g-via-simple-root-vecs}\tag{77}
    \mathfrak{g} =
    \mathfrak{t}_{\mathbb{C}}
    \oplus
    (
    \sum _{ \substack{
        r \geq 1 \\
        i = (i_1,\dotsc,i_r) \in \mathbb{Z}_{\geq 1}^r
      }
    }
    \mathbb{C} e_i
    )
    \oplus
    (
    \sum _{ \substack{
        r \geq 1 \\
        i = (i_1,\dotsc,i_r) \in \mathbb{Z}_{\geq 1}^r
      }
    }
    \mathbb{C} f_i
    ),\]</span> where <span id="eqn:defn-e-i" class="math display">\[\label{eqn:defn-e-i}\tag{78}
    e_i := [X_{i_1},\dotsc,[X_{i_{r-1}}, X_{i_r}]\dotsb]
    \in \mathfrak{g}^{\gamma_{i_1} + \dotsb + \gamma_{i_r}},\]</span>
<span id="eqn:defn-f-i" class="math display">\[\label{eqn:defn-f-i}\tag{79}
    f_i := [Y_{i_1},\dotsc,[Y_{i_{r-1}}, Y_{i_r}]\dotsb]
    \in \mathfrak{g}^{-\gamma_{i_1} - \dotsb - \gamma_{i_r}}.\]</span>
The action of the indicated generators for <span
class="math inline">\(\mathfrak{g}\)</span> on the above decomposition
is described as follows: For <span class="math inline">\(H \in
\mathfrak{t}_{\mathbb{C}}\)</span>, we have <span
class="math display">\[{\mathop{\mathrm{ad}}}_{X_j}
    H = -\gamma_j(H) X_j,\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{Y_j}
    H = -\gamma_j(H) X_j,\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{X_j}
    e_i
    =
    [X_j, [X_{i_1},\dotsc,[X_{i_{r-1}}, X_{i_r}]\dotsb]]\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{H}
    e_i
    =
    \langle H, \gamma_{i_1} + \dotsb + \gamma_{i_r} \rangle
    e_i\]</span> <span class="math display">\[{\mathop{\mathrm{ad}}}_{Y_j}
    f_i
    =
    [Y_j, [Y_{i_1},\dotsc,[Y_{i_{r-1}}, Y_{i_r}]\dotsb]]\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{H}
    f_i
    =
    -\langle H, \gamma_{i_1} + \dotsb + \gamma_{i_r} \rangle
    f_i\]</span> <span class="math display">\[{\mathop{\mathrm{ad}}}_{Y_j}
X_i
    =
    \begin{cases}
      - H_i &amp; \text{ if }i = j \\
      0 &amp; \text{ if } i \neq j,
    \end{cases}\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{Y_j} e_i
    =
    [{\mathop{\mathrm{ad}}}_{Y_j} X_{i_1},\dotsc,[X_{i_{r-1}},
X_{i_r}]\dotsb]
    + \dotsb
    +
    [ X_{i_1},\dotsc,[X_{i_{r-1}}, {\mathop{\mathrm{ad}}}_{Y_j}
X_{i_r}]\dotsb],\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{X_j} Y_i
    =
    \begin{cases}
      H_i &amp; \text{ if }i = j \\
      0 &amp; \text{ if } i \neq j,
    \end{cases}\]</span> <span
class="math display">\[{\mathop{\mathrm{ad}}}_{X_j} f_i
    =
    [{\mathop{\mathrm{ad}}}_{X_j} Y_{i_1},\dotsc,[Y_{i_{r-1}},
Y_{i_r}]\dotsb]
    + \dotsb
    +
    [ Y_{i_1},\dotsc,[Y_{i_{r-1}}, {\mathop{\mathrm{ad}}}_{X_j}
Y_{i_r}]\dotsb].\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(\mathfrak{h}\)</span>
denote the subalgebra of <span
class="math inline">\(\mathfrak{g}\)</span> generated by the indicated
set. In particular, <span class="math inline">\(\mathfrak{h}\)</span> is
a <span class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>-module
containing <span class="math inline">\(\mathfrak{g}^{\pm
\gamma_j}\)</span> for <span class="math inline">\(j=1..n\)</span>, so
we may write <span class="math display">\[\mathfrak{h} =
\mathfrak{t}_{\mathbb{C}} \oplus (\oplus_{\alpha \in E}
\mathfrak{g}^{\alpha})\]</span> for some subset <span
class="math inline">\(E \subseteq \Phi\)</span> containing <span
class="math inline">\(\{\pm \gamma_1, \dotsc, \pm \gamma_n\}\)</span>.
We must show that in fact <span class="math inline">\(E = \Phi\)</span>.
So let <span class="math inline">\(\beta \in \Phi\)</span>; we must show
that <span class="math inline">\(\beta \in E\)</span>. We assume that
<span class="math inline">\(\beta \in \Phi^+\)</span>; a similar proof
applies if <span class="math inline">\(- \beta \in \Phi^+\)</span>. By
Lemma <a href="#lem:roots-partial-sums" data-reference-type="ref"
data-reference="lem:roots-partial-sums">144</a>, we may write <span
class="math inline">\(\beta = \alpha_1 + \dotsb + \alpha_r\)</span> with
each partial sum <span class="math inline">\(\alpha_1 + \dotsb +
\alpha_s\)</span> also a root. We show by induction on <span
class="math inline">\(r\)</span> that <span class="math inline">\(\beta
\in E\)</span>. If <span class="math inline">\(r = 1\)</span>, then
<span class="math inline">\(\beta \in \Delta \subseteq E\)</span>, so
suppose <span class="math inline">\(r \geq 2\)</span>. By our inductive
hypothesis, <span class="math inline">\(\delta := \alpha_1 + \dotsb +
\alpha_{r-1} \in E\)</span>. We have <span class="math inline">\(\beta =
\delta + \alpha_r\)</span>, with each term a root, so by Lemma <a
href="#lem:strings-roots" data-reference-type="ref"
data-reference="lem:strings-roots">143</a>, <span
class="math inline">\(\mathfrak{g}^{\beta} = [\mathfrak{g}^\delta,
\mathfrak{g}^{\alpha_r}]\)</span>. Our inductive hypothesis gives <span
class="math inline">\(\mathfrak{g}^\delta, \mathfrak{g}^{\alpha_r}
\subseteq \mathfrak{h}\)</span>. Since <span
class="math inline">\(\mathfrak{h}\)</span> is a subalgebra, it follows
that <span class="math inline">\(\mathfrak{g}^{\beta} \subseteq
\mathfrak{h}\)</span>, whence as required that <span
class="math inline">\(\beta \in E\)</span>.</p>
<p>This establishes that the indicated set is indeed a generating set
for <span class="math inline">\(\mathfrak{g}\)</span>. The remaining
assertions follow from the argument just given together and some routine
calculation. ◻</p>
</span></div>
<div id="cor:nonzero-ideals-detected-via-t" class="corollary">
<p><strong>Corollary 146</strong>. <em>Any nonzero ideal <span
class="math inline">\(\mathfrak{a}\)</span> of <span
class="math inline">\(\mathfrak{g}\)</span> contains a nonzero element
of <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> The proof is similar to that of the previous
corollary (and could even be deduced from its conclusion by considering
orthogonal complements). Since <span
class="math inline">\(\mathfrak{a}\)</span> is in particular a <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>-module, we may
write <span class="math inline">\(\mathfrak{a} = \mathfrak{b} \oplus
(\oplus_{\alpha \in E} \mathfrak{g}^{\alpha})\)</span> for some subspace
<span class="math inline">\(\mathfrak{b} \subseteq
\mathfrak{t}_{\mathbb{C}}\)</span> and some subset <span
class="math inline">\(E \subseteq \Phi\)</span>. We want to show that
<span class="math inline">\(\mathfrak{b}\)</span> is nonzero. Suppose
otherwise that <span class="math inline">\(\mathfrak{b}\)</span> is
zero. Then <span class="math inline">\(E\)</span> is nonempty. Let <span
class="math inline">\(\beta \in E\)</span>. Write <span
class="math inline">\(\beta = \alpha_1 + \dotsb + \alpha_r\)</span> as
in Lemma <a href="#lem:roots-partial-sums" data-reference-type="ref"
data-reference="lem:roots-partial-sums">144</a>. Set <span
class="math inline">\(Z := [Y_{\alpha_1}, \dotsb, [Y_{\alpha_{r-1}},
[Y_{\alpha_r}, X_{\beta}]] \dotsb ]\)</span>. Then <span
class="math inline">\(Z \in \mathfrak{t}_{\mathbb{C}} \cap \mathfrak{b}
= \mathfrak{b} = \{0\}\)</span>, but several applications of Lemma <a
href="#lem:strings-roots" data-reference-type="ref"
data-reference="lem:strings-roots">143</a> (and <a
href="#eq:commutators-land-in-C-H-alpha" data-reference-type="eqref"
data-reference="eq:commutators-land-in-C-H-alpha">\((66)\)</a>)
implies that <span class="math inline">\(Z \neq 0\)</span>, giving the
required contradiction. ◻</p>
</span></div>
<h2 id="proof-of-theorem-thmcartan-matrix-determines-k">Proof of Theorem
<a href="#thm:cartan-matrix-determines-K" data-reference-type="ref"
data-reference="thm:cartan-matrix-determines-K">141</a></h2>
<p>We need one final miscellaneous lemma:</p>
<div id="lem:pi-1-T-onto-pi-1-K" class="lemma">
<p><strong>Lemma 147</strong>. Let <span
class="math inline">\(K\)</span> be a compact connected Lie group with
maximal torus <span class="math inline">\(T\)</span>. Then the map <span
class="math inline">\(\pi_1(T) \rightarrow \pi_1(K)\)</span> induced by
the inclusion <span class="math inline">\(T \rightarrow K\)</span> is
surjective.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> (Omitted in lecture; see for instance Section 36.4 of
my Fall 2016 notes on Lie groups, linked on the course homepage.) ◻</p>
</span></div>
<p>We now give the proof of Theorem <a
href="#thm:cartan-matrix-determines-K" data-reference-type="ref"
data-reference="thm:cartan-matrix-determines-K">141</a>. Let notation be
as in its statement. We may write <span class="math inline">\(\Delta
&#39; = \{\gamma_1 &#39;, \dotsc, \gamma_n&#39; \}\)</span> and <span
class="math inline">\(\Delta &#39;&#39; = \{\gamma_1&#39;&#39;, \dotsc,
\gamma_n&#39;&#39;\}\)</span> so that <span
class="math inline">\(\gamma_i&#39;\)</span> corresponds to <span
class="math inline">\(\gamma_i&#39;&#39;\)</span>. We define <span
class="math inline">\(\mathfrak{g} &#39;, \mathfrak{g}
&#39;&#39;\)</span> in the obvious way and define <span
class="math inline">\(X_i&#39;, Y_j&#39; \in \mathfrak{g} &#39;\)</span>
and <span class="math inline">\(X_i&#39;&#39;, Y_j&#39;&#39; \in
\mathfrak{g} &#39;&#39;\)</span> as in §<a href="#sec:gener-lie-algebra"
data-reference-type="ref"
data-reference="sec:gener-lie-algebra">7.19</a>. We will show more
precisely that there exists a unique isomorphism <span
class="math inline">\(K&#39; \xrightarrow{\cong } K&#39;&#39;\)</span>
extending the given isomorphism <span class="math inline">\(\kappa :
T&#39; \xrightarrow{\cong } T&#39;&#39;\)</span> with the additional
property that the induced isomorphism <span
class="math inline">\(\mathfrak{g} &#39; \xrightarrow{\cong }
\mathfrak{g} &#39;&#39;\)</span> maps <span
class="math inline">\(X_i&#39;\)</span> to <span
class="math inline">\(X_i&#39;&#39;\)</span> for <span
class="math inline">\(i=1..n\)</span>.</p>
<p>To that end, we fix linear embeddings of <span
class="math inline">\(K&#39;\)</span> and <span
class="math inline">\(K&#39;&#39;\)</span>, hence involutions <span
class="math inline">\(\theta\)</span> of <span
class="math inline">\(\mathfrak{g} &#39;\)</span> and <span
class="math inline">\(\mathfrak{g} &#39;&#39;\)</span> with fixed
subspaces <span class="math inline">\(\mathfrak{k} &#39;\)</span> and
<span class="math inline">\(\mathfrak{k} &#39;&#39;\)</span>. It
suffices to show that there exists a unique <span
class="math inline">\(\theta\)</span>-equivariant isomorphism <span
class="math inline">\(\mathfrak{g} &#39; \xrightarrow{\cong }
\mathfrak{g} &#39;&#39;\)</span> given on <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}} &#39;\)</span> by <span
class="math inline">\(d \kappa\)</span> and which maps <span
class="math inline">\(X_i&#39;\)</span> to <span
class="math inline">\(X_i&#39;&#39;\)</span>. Indeed, such an
isomorphism of complexified Lie algebras induces an isomorphism <span
class="math inline">\(\tau : \mathfrak{k} &#39; \xrightarrow{\cong }
\mathfrak{k} &#39;&#39;\)</span> of their <span
class="math inline">\(\theta\)</span>-fixed subspaces. What remains to
be checked is just that any such isomorphism arises from a Lie group
morphism <span class="math inline">\(K&#39; \rightarrow
K&#39;&#39;\)</span>, and similarly for the inverse isomorphism. From
basic Lie theory (see e.g. Theorem 155 of the Fall 2016 notes linked on
the course webpage), the Lie group <span
class="math inline">\(K&#39;\)</span> admits a universal connected
covering group <span class="math inline">\(\widetilde{K&#39;}\)</span>,
which fits into a short exact sequence <span class="math inline">\(1
\rightarrow \pi_1(K) \rightarrow \widetilde{K&#39;} \rightarrow K&#39;
\rightarrow 1\)</span>, where <span
class="math inline">\(\pi_1(K)\)</span> identifies with a discrete
central subgroup of <span
class="math inline">\(\widetilde{K&#39;}\)</span>. The given Lie algebra
map <span class="math inline">\(\mathfrak{k} &#39; \rightarrow
\mathfrak{k} &#39;&#39;\)</span> extends to a Lie group map <span
class="math inline">\(\widetilde{K&#39;} \rightarrow
K&#39;&#39;\)</span> (see e.g. Theorem 146 of the aforementioned notes);
we just need to check that <span
class="math inline">\(\pi_1(K&#39;)\)</span> lies in the kernel of the
latter. But by Lemma <a href="#lem:pi-1-T-onto-pi-1-K"
data-reference-type="ref"
data-reference="lem:pi-1-T-onto-pi-1-K">147</a>, it suffices to show
that <span class="math inline">\(\pi_1(T&#39;)\)</span> lies in the
indicated kernel, which follows from the fact that the given map <span
class="math inline">\(T&#39; \rightarrow T&#39;&#39;\)</span> is a
well-defined Lie group map. The completes the proof of the required
reduction.</p>
<p>It remains to produce the required <span
class="math inline">\(\theta\)</span>-equivariant map <span
class="math inline">\(\mathfrak{g} &#39; \rightarrow \mathfrak{g}
&#39;&#39;\)</span>. We will do so by constructing its graph. Let <span
class="math inline">\(\mathfrak{g}\)</span> denote the subalgebra of
<span class="math inline">\(\mathfrak{g} &#39; \oplus \mathfrak{g}
&#39;&#39;\)</span> generated by <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}} \cup \{X_i\} \cup
\{Y_i\}\)</span>, where <span
class="math display">\[\mathfrak{t}_{\mathbb{C}} := \{(x&#39;,
x&#39;&#39; ) \in \mathfrak{t}_{\mathbb{C}} &#39; \oplus
\mathfrak{t}_{\mathbb{C}} &#39;&#39; : d \kappa(x&#39;) = x&#39;&#39;
\}\]</span> and <span class="math inline">\(X_i := (X_i&#39;,
X_i&#39;&#39;)\)</span> and <span class="math inline">\(Y_i :=
(Y_i&#39;, Y_i&#39;&#39;)\)</span> with <span
class="math inline">\(Y_i&#39; := -\theta(X_i&#39;), Y_i&#39;&#39; :=
-\theta(X_i&#39;&#39;)\)</span>. <a href="#fn19" class="footnote-ref"
id="fnref19" role="doc-noteref"><sup>19</sup></a> It is enough to check
that <span class="math inline">\(\mathfrak{g}\)</span> is the graph of a
<span class="math inline">\(\theta\)</span>-equivariant isomorphism of
Lie algebras; note that if such a morphism exists, then it is uniquely
defined and restricts on <span
class="math inline">\(\mathfrak{t}_{\mathbb{C} }&#39;\)</span> to <span
class="math inline">\(d \kappa\)</span>. The <span
class="math inline">\(\theta\)</span>-equivariance will follow from the
construction of <span class="math inline">\(\mathfrak{g}\)</span>. By
applying the same argument with the roles of <span
class="math inline">\(\mathfrak{g} &#39;\)</span> and <span
class="math inline">\(\mathfrak{g} &#39;&#39;\)</span> reversed, we
reduce to showing that <span class="math inline">\(\mathfrak{g}\)</span>
is the graph of a morphism of Lie algebras. Let <span
class="math inline">\(\pi &#39; : \mathfrak{g} \rightarrow \mathfrak{g}
&#39;\)</span> and <span class="math inline">\(\pi &#39;&#39; :
\mathfrak{g} \rightarrow \mathfrak{g} &#39;&#39;\)</span> denote the
projections. By Corollary <a href="#cor:g-gen-via-simple-stuff"
data-reference-type="ref"
data-reference="cor:g-gen-via-simple-stuff">145</a>, we see that <span
class="math inline">\(\pi &#39;\)</span> and <span
class="math inline">\(\pi &#39;&#39;\)</span> are surjective. We might
thus hope to define a morphism <span class="math inline">\(f :
\mathfrak{g} &#39; \rightarrow \mathfrak{g} &#39;&#39;\)</span> by
requiring that <span class="math inline">\(f(x) := y\)</span> whenever
<span class="math inline">\((x,y) \in \mathfrak{g}\)</span>. Since <span
class="math inline">\(\mathfrak{g}\)</span> is a subalgebra, we know
that <span class="math inline">\(f\)</span> is a morphism provided that
it is well-defined as a set-theoretic map. We thus need only check that
if <span class="math inline">\((x,y_1)\)</span> and <span
class="math inline">\((x,y_2)\)</span> both belong to <span
class="math inline">\(\mathfrak{g}\)</span>, then <span
class="math inline">\(y_1 = y_2\)</span>. Equivalently, we need to check
that if <span class="math inline">\((0,y)\)</span> belongs to <span
class="math inline">\(\mathfrak{g}\)</span>, then <span
class="math inline">\(y = 0\)</span>; in other words, we must show that
<span class="math inline">\(\ker(\pi &#39;&#39;)\)</span> is
trivial.</p>
<p>We claim that <span id="eq:key-claim-for-proof-of-that-Cartan-determines-K" class="math display">\[\label{eq:key-claim-for-proof-of-that-Cartan-determines-K}\tag{80}
  \mathfrak{g} \cap (\mathfrak{t}_{\mathbb{C}}&#39; \oplus
  \mathfrak{t}_{\mathbb{C} }&#39;&#39;)
  =
  \mathfrak{t}_{\mathbb{C}}.\]</span> Before proving the claim, we
explain why it suffices. Suppose for the sake of contradiction that
<span class="math inline">\(\ker(\pi &#39;&#39;)\)</span> is nonzero.
Then <span class="math inline">\(\mathfrak{a} &#39; := \pi
&#39;(\ker(\pi &#39;&#39;))\)</span> is a nonzero ideal of <span
class="math inline">\(\mathfrak{g}&#39;\)</span>. By Corollary <a
href="#cor:nonzero-ideals-detected-via-t" data-reference-type="ref"
data-reference="cor:nonzero-ideals-detected-via-t">146</a>, we have
<span class="math inline">\(\mathfrak{a} &#39; \cap
\mathfrak{t}_{\mathbb{C}}&#39; \neq \{0\}\)</span>. We may thus find
<span class="math inline">\(0 \neq x&#39; \in \mathfrak{t}_{\mathbb{C}
}&#39;\)</span> so that <span class="math inline">\((x&#39;, 0) \in
\ker(\pi &#39;&#39;)\)</span>. Clearly <span
class="math display">\[(x&#39;,0) \in \mathfrak{g} \cap
(\mathfrak{t}_{\mathbb{C}}&#39; \oplus
  \mathfrak{t}_{\mathbb{C} }&#39;&#39;).\]</span> From the claim <a
href="#eq:key-claim-for-proof-of-that-Cartan-determines-K"
data-reference-type="eqref"
data-reference="eq:key-claim-for-proof-of-that-Cartan-determines-K">\((80)\)</a>,
it follows that <span class="math inline">\((x&#39;, 0) \in
\mathfrak{t}_{\mathbb{C}}\)</span>, whence that <span
class="math inline">\(0 = d \kappa(x&#39;)\)</span>. Since <span
class="math inline">\(d \kappa\)</span> is an isomorphism, this forces
<span class="math inline">\(x&#39; = 0\)</span>, giving the required
contradiction.</p>
<p>We turn finally to the proof of the claim <a
href="#eq:key-claim-for-proof-of-that-Cartan-determines-K"
data-reference-type="eqref"
data-reference="eq:key-claim-for-proof-of-that-Cartan-determines-K">\((80)\)</a>.
Let <span class="math inline">\(\mathfrak{h} \subseteq \mathfrak{g}
&#39; \oplus \mathfrak{g} &#39;&#39;\)</span> denote the set defined as
on the RHS of <a href="#eqn:decomposition-frak-g-via-simple-root-vecs"
data-reference-type="eqref"
data-reference="eqn:decomposition-frak-g-via-simple-root-vecs">\((77)\)</a>,
with <span class="math inline">\(e_i, f_i\)</span> defined in terms of
<span class="math inline">\(X_i, Y_i \in \mathfrak{g}\)</span> as in <a
href="#eqn:defn-e-i" data-reference-type="eqref"
data-reference="eqn:defn-e-i">\((78)\)</a>, <a
href="#eqn:defn-f-i" data-reference-type="eqref"
data-reference="eqn:defn-f-i">\((79)\)</a>. Then <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}} \subseteq
\mathfrak{h}\)</span>; moreover, <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> is
self-centralizing in <span class="math inline">\(\mathfrak{h}\)</span>,
since the <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span>-weights of
<span class="math inline">\(\oplus \mathbb{C} e_i\)</span> (resp. of
<span class="math inline">\(\oplus \mathbb{C} f_i\)</span>) are positive
(resp. negative). In particular, <span
class="math inline">\((\mathfrak{t}_{\mathbb{C}}&#39; \oplus
\mathfrak{t}_{\mathbb{C}} &#39;&#39;) \cap \mathfrak{h} =
\mathfrak{t}_{\mathbb{C}}\)</span>, so to establish <a
href="#eq:key-claim-for-proof-of-that-Cartan-determines-K"
data-reference-type="eqref"
data-reference="eq:key-claim-for-proof-of-that-Cartan-determines-K">\((80)\)</a>,
we reduce to showing that <span class="math inline">\(\mathfrak{g} =
\mathfrak{h}\)</span>. To that end, observe first that <span
class="math inline">\(\mathfrak{h}\)</span> is contained in <span
class="math inline">\(\mathfrak{g}\)</span> and contains the generating
set <span class="math inline">\(S := \mathfrak{t}_{\mathbb{C}} \cup
\{X_i\} \cup \{Y_i\}\)</span> for <span
class="math inline">\(\mathfrak{g}\)</span>. We thereby reduce to
verifying that <span class="math inline">\(\mathfrak{h}\)</span> is a
subalgebra. Since <span class="math inline">\(\mathfrak{h} \subseteq
\mathfrak{g}\)</span>, we may reduce further to showing that <span
class="math inline">\(\mathfrak{h}\)</span> is closed under <span
class="math inline">\({\mathop{\mathrm{ad}}}_{Z}\)</span> for each <span
class="math inline">\(Z \in S\)</span>. For this we appeal to the
relations noted in Corollary <a href="#cor:g-gen-via-simple-stuff"
data-reference-type="ref"
data-reference="cor:g-gen-via-simple-stuff">145</a>, applied to each
component <span class="math inline">\(\mathfrak{g} &#39;, \mathfrak{g}
&#39;&#39;\)</span> of <span class="math inline">\(\mathfrak{g} &#39;
\oplus \mathfrak{g} &#39;&#39;\)</span>, together with the assumed
compatibility between <span class="math inline">\(\gamma_i&#39;\)</span>
and <span class="math inline">\(\gamma_i&#39;&#39;\)</span>.</p>
<p>This completes the proof.</p>
<h2 id="dynkin-diagrams">Dynkin diagrams</h2>
<p>They provide a convenient pictorial representation of the Cartan
matrix. Here we just summarize what was discussed in class; look at
Wikipedia or any of the course references for a detailed discussion.</p>
<p>The vertices of the Dynkin diagram correspond to the simple roots.
For any pair <span class="math inline">\((\alpha,\beta)\)</span> of
<em>distinct</em> simple roots, we have seen that there are at most
seven possibilities for the pair <span class="math inline">\((N_{\alpha
\beta}, N_{\beta \alpha})\)</span> of integers appearing in the Cartan
matrix:</p>
<ul>
<li><p><span class="math inline">\((0,0)\)</span>: we draw no edge
between <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span></p></li>
<li><p><span class="math inline">\((-1,-1)\)</span>: we draw a simple
undirected edge between <span class="math inline">\(\alpha\)</span> and
<span class="math inline">\(\beta\)</span></p></li>
<li><p><span class="math inline">\((-1,-2)\)</span>: we draw a double
oriented edge from <span class="math inline">\(\alpha\)</span> to <span
class="math inline">\(\beta\)</span></p></li>
<li><p><span class="math inline">\((-2,-1)\)</span>: we draw a double
oriented edge from <span class="math inline">\(\beta\)</span> to <span
class="math inline">\(\alpha\)</span></p></li>
<li><p><span class="math inline">\((-1,-3)\)</span>: we draw a triple
oriented edge from <span class="math inline">\(\alpha\)</span> to <span
class="math inline">\(\beta\)</span></p></li>
<li><p><span class="math inline">\((-3,-1)\)</span>: we draw a triple
oriented edge from <span class="math inline">\(\beta\)</span> to <span
class="math inline">\(\alpha\)</span></p></li>
</ul>
<p>We illustrated with <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span> or <span
class="math inline">\(\mathop{\mathrm{SU}}(n)\)</span> or <span
class="math inline">\(\PU(n)\)</span>, where the Cartan matrix looks
like (for <span class="math inline">\(n=5\)</span>) <span
class="math display">\[\begin{pmatrix}
    2 &amp; -1 &amp; 0 &amp; 0 &amp; 0  \\
    -1 &amp; 2 &amp; -1 &amp; 0 &amp; 0 \\
    0 &amp; -1  &amp; 2 &amp; -1 &amp; 0 \\
    0 &amp; 0 &amp; -1  &amp; 2 &amp; -1 \\
    0 &amp; 0 &amp; 0 &amp; -1 &amp; 2
  \end{pmatrix}
,\]</span> so the Dynkin diagram looks like a series of vertices
connected by simple edges.</p>
<p>We’ve focused in this class on Lie groups rather than Lie algebras. A
variant of Theorem <a href="#thm:cartan-matrix-determines-K"
data-reference-type="ref"
data-reference="thm:cartan-matrix-determines-K">141</a> (with similar
proof) is that if <span class="math inline">\(K&#39;,
K&#39;&#39;\)</span> are connected compact Lie groups with maximal tori
<span class="math inline">\(T&#39;, T&#39;&#39;\)</span> of the same
dimension, then <span class="math inline">\(\mathfrak{k} &#39; \cong
\mathfrak{k} &#39;&#39;\)</span> iff the Cartan matrices are the same
(up to relabeling indices) iff the Dynkin diagrams are the same.</p>
<h2 id="sec:root-data">§7.22. Root data</h2>
<div class="definition">
<p><strong>Definition 148</strong>. A <em>root datum</em> is a quadruple
<span class="math inline">\(\Psi = (X, \Phi, X^\vee, \Phi^\vee)\)</span>
consisting of</p>
<ol type="i">
<li><p>finitely-generated free abelian groups <span
class="math inline">\(X, X^\vee\)</span> of the same rank <span
class="math inline">\(n\)</span>, thus <span class="math inline">\(X
\cong \mathbb{Z}^n, X^\vee \cong \mathbb{Z}^n\)</span>,</p></li>
<li><p>a perfect <span class="math inline">\(\mathbb{Z}\)</span>-linear
pairing <span class="math inline">\(X \otimes_{\mathbb{Z}} X^\vee
\xrightarrow{(,)} \mathbb{Z}\)</span>,</p></li>
<li><p>finite subsets <span class="math inline">\(\Phi \subseteq X,
\Phi^\vee \subseteq X\)</span>, and</p></li>
<li><p>a bijection <span class="math inline">\(\Phi \leftrightarrow
\Phi^\vee\)</span> denoted <span class="math inline">\(\alpha
\leftrightarrow \alpha^\vee\)</span> such that</p></li>
<li><p><span class="math inline">\((\alpha,\alpha^\vee) = 2\)</span> for
all <span class="math inline">\(\alpha \in \Phi\)</span>,</p></li>
<li><p><span class="math inline">\(s_\alpha(\lambda) := \lambda -
(\lambda,\alpha^\vee) \alpha\)</span> defines a linear automorphism
<span class="math inline">\(s_\alpha : X \rightarrow X\)</span> such
that <span class="math inline">\(s_\alpha(\Phi) = \Phi\)</span>,
and</p></li>
<li><p><span class="math inline">\(s_{\alpha^\vee}(\lambda^\vee) :=
\lambda^\vee - (\alpha,\lambda^\vee) \alpha^\vee\)</span> defines a
linear automorphism <span class="math inline">\(s_{\alpha^\vee} : X^\vee
\rightarrow X^\vee\)</span> such that <span
class="math inline">\(s_{\alpha^\vee}(\Phi^\vee) =
\Phi^\vee\)</span>.</p></li>
</ol>
<p>We say that <span class="math inline">\(\Psi\)</span> is
<em>reduced</em> if <span class="math inline">\(\mathbb{Q} \alpha \cap
\Phi = \{\alpha, - \alpha \}\)</span> for all <span
class="math inline">\(\alpha \in \Phi\)</span>.</p>
<p>There is an obvious notion of an isomorphism of root data.</p>
</div>
<p>For example, if <span class="math inline">\(K\)</span> is a compact
connected Lie group with maximal torus <span
class="math inline">\(T\)</span>, then <span
class="math display">\[\Psi(K:T) :=(X(T), \Phi(K:T),X^\vee(T),
\Phi^\vee(K:T))\]</span> is a root datum; here <span
class="math inline">\(\Phi^\vee(K:T) := \{\alpha^\vee : \alpha \in
\Phi(K:T)\}\)</span>. Using the conjugacy of maximal tori, we see that
the isomorphism class of <span class="math inline">\(\Psi(K:T)\)</span>
is independent of <span class="math inline">\(T\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 149</strong>. <em>The map <span
class="math display">\[\{\text{compact connected Lie groups } K\}/\sim
\, \longrightarrow \, \{\text{reduced root data } \Psi \} /
\sim,\]</span> given by sending <span class="math inline">\(K\)</span>
to <span class="math inline">\(\Psi(K:T)\)</span> for some maximal torus
<span class="math inline">\(T\)</span>, is a bijection.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Sketch of proof." data-folded-text="Sketch of proof. (...)">Sketch of proof.</em></a>
<span class="proof-content"> Injectivity follows readily from Theorem <a
href="#thm:cartan-matrix-determines-K" data-reference-type="ref"
data-reference="thm:cartan-matrix-determines-K">141</a> (exercise). We
omit the proof of surjectivity; one way to proceed would be to argue as
in the proof of Theorem <a href="#thm:cartan-matrix-determines-K"
data-reference-type="ref"
data-reference="thm:cartan-matrix-determines-K">141</a>, but
incorporating the Serre relations <span
class="math inline">\({\mathop{\mathrm{ad}}}_{X_i}^{-N_{i j}+1} X_j =
{\mathop{\mathrm{ad}}}_{Y_i}^{-N_{ij}+1} Y_j = 0\)</span>. ◻</p>
</span></div>
<p><a href="#fn20" class="footnote-ref" id="fnref20"
role="doc-noteref"><sup>20</sup></a></p>
<h1 id="sec:repr-comp-lie">§8. Representations of compact Lie groups</h1>
<p>Let <span class="math inline">\(K\)</span> be a compact connected Lie
group. Our aim in this section is to generalize the results established
in §<a href="#sec:char-theory-comp" data-reference-type="ref"
data-reference="sec:char-theory-comp">3</a> when <span
class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span>.</p>
<h2 id="setup-and-preliminaries">Setup and preliminaries</h2>
<p>Choose a maximal torus <span class="math inline">\(T\)</span> and
then a Weyl chamber <span class="math inline">\(C \subseteq
\mathfrak{t}_{\mathbb{R}}^{\mathop{\mathrm{reg}}}\)</span>. These
choices define a Weyl group <span class="math inline">\(W\)</span> and
sets <span class="math inline">\(\Phi \supseteq \Phi^+ \supseteq
\Delta\)</span> of roots, positive roots and simple roots, respectively.
Recall that <span class="math inline">\(C\)</span> defines a notion of
<span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{R}}^*\)</span> being <em>dominant</em>, which
means that it belongs to the closure <span
class="math inline">\(\overline{C^\vee } = \{\lambda : \lambda(H_\alpha)
\geq 0 \text{ for all } \alpha \in \Phi^+\}\)</span> of the Weyl chamber
<span class="math inline">\(C^\vee = \{\lambda : \lambda(H_\alpha) &gt;
0 \text{ for all } \alpha \in \Phi^+\}\)</span>, and <em>strictly
dominant</em> if in fact <span class="math inline">\(\lambda \in
C^\vee\)</span>. Recall that <span class="math inline">\(C\)</span>
defines a partial on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}^*}\)</span>, where we say
that <span class="math inline">\(\lambda_1 \geq \lambda_2\)</span> if
<span class="math inline">\((\lambda_1 - \lambda_2)(C) \geq 0\)</span>,
or equivalently, if <span class="math inline">\(\lambda_1 - \lambda_2
\in \sum_{\alpha \in \Phi^+} \mathbb{R}_{\geq 0} \alpha\)</span>; we say
also that <span class="math inline">\(\lambda\)</span> is
<em>positive</em> if <span class="math inline">\(\lambda \geq
0\)</span>.</p>
<p>We remark that one can characterize the subsets <span
class="math inline">\(\Phi^+ \subseteq \Phi\)</span> arising in the
above way as those for which</p>
<ul>
<li><p><span class="math inline">\(\alpha, \beta \in \Phi^+, \alpha +
\beta \in \Phi \implies \alpha+\beta \in \Phi^+\)</span> and</p></li>
<li><p><span class="math inline">\(\Phi\)</span> is the disjoint union
of <span class="math inline">\(\Phi^+\)</span> and <span
class="math inline">\(- \Phi^+\)</span>.</p></li>
</ul>
<p>(See any of the main course references.) The choice of <span
class="math inline">\(\Phi^+\)</span> determines <span
class="math inline">\(C = \{x : \alpha(x) &gt; 0 \text{ for all } \alpha
\in \Phi^+ \}\)</span> and <span class="math inline">\(C^\vee\)</span>.
A convenient way to choose <span class="math inline">\(\Phi^+\)</span>
is via a <em>lexicographical ordering</em>: choose a faithful embedding
<span class="math inline">\(K \hookrightarrow
\mathop{\mathrm{U}}(n)\)</span>, hence an embedding <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}} \hookrightarrow
\mathbb{R}^n\)</span>, identify <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> with <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span> in the usual
way via the pairing <span class="math inline">\((x,y) \mapsto
\mathop{\mathrm{trace}}(x y)\)</span> (the restriction of the standard
Euclidean norm on <span class="math inline">\(\mathbb{R}^n\)</span>),
and equip <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span> with the
lexicographical order coming from <span
class="math inline">\(\mathbb{R}^n\)</span>. This is what we did earlier
(implicitly) in the case <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>.</p>
<p>We recall some additional facts established in the preceeding
section:</p>
<ol type="i">
<li><p><span class="math inline">\(W\)</span> acts simply-transitively
on the set of Weyl chambers.</p></li>
<li><p>(dual form of Corollary <a
href="#cor:W-conj-to-unique-dominant-element" data-reference-type="ref"
data-reference="cor:W-conj-to-unique-dominant-element">130</a>) Any
<span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{R}}^*\)</span> is <span
class="math inline">\(W\)</span>-conjugate to a unique dominant
element.</p></li>
<li><p>Any dominant <span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{R}}^*\)</span> satisfies <span
class="math inline">\(\lambda \geq w(\lambda)\)</span> for all <span
class="math inline">\(w \in W\)</span>.</p></li>
</ol>
<p>Recall finally the Weyl integral formula (§<a
href="#sec:weyl-integr-form-general" data-reference-type="ref"
data-reference="sec:weyl-integr-form-general">7.6</a>) <span id="eqn:WIF-recall-for-reps" class="math display">\[\label{eqn:WIF-recall-for-reps}\tag{81}
  \int_K f
  = \frac{1}{|W|}
  \int_{g \in K/T}
  \int_{t \in T}
  D(t) f (g t g^{-1}),\]</span> where we integrate with respect to
probability Haar measures and where the Jacobian factor <span
class="math inline">\(D\)</span> is given explicitly by <span
class="math display">\[D(t) = |\det( t - 1  |
  \mathfrak{g}/\mathfrak{t}_{\mathbb{C}})|
  =
  \prod_{\alpha \in   \Phi}
  |t^{\alpha}-1|.\]</span></p>
<p>Our first aim is to factor <span class="math inline">\(D= \Delta
\overline{\Delta } = |\Delta|^2\)</span> as in the case <span
class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span>. Such a
factorization holds formally with <span class="math display">\[\Delta(t)
:=
  \prod_{\alpha &gt; 0}
  (t^{\alpha/2} - t^{-\alpha/2}).\]</span> Unfortunately, <span
class="math inline">\(\Delta\)</span> is not in general well-defined as
a function on <span class="math inline">\(T\)</span>; the source of this
issue is that the expressions <span
class="math inline">\(t^{\alpha/2}\)</span> themselves are not
well-defined, since it may happen that <span
class="math inline">\(\alpha \in \mathfrak{t}_{\mathbb{Z}}^*\)</span>
but <span class="math inline">\((1/2) \alpha \notin
\mathfrak{t}_{\mathbb{Z}}^*\)</span>. To circumvent this issue, we pass
to a covering torus <span class="math inline">\(\tilde{T}\)</span> of
<span class="math inline">\(T\)</span>. Recall that the normalized
exponential map <span class="math inline">\(e(x) := \exp(2 \pi i
x)\)</span> induces an isomorphism <span class="math inline">\(e :
\mathfrak{t}_{\mathbb{R}} / \mathfrak{t}_{\mathbb{Z}} \xrightarrow{\sim}
T\)</span>. We denote by <span class="math inline">\(\tilde{T}\)</span>
the covering torus of <span class="math inline">\(T\)</span>
corresponding to the sublattice <span class="math inline">\(2
\mathfrak{t}_{\mathbb{Z}}\)</span> of <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span>; it comes with
an isomorphism <span class="math inline">\(e : \mathfrak{t}_{\mathbb{R}}
/ 2 \mathfrak{t}_{\mathbb{Z}} \xrightarrow{\sim} \tilde{T}\)</span> and
a canonical surjection <span class="math inline">\(\tilde{T} \rightarrow
T\)</span>. In other words, choosing a basis for <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span>, we may
identify <span class="math inline">\(T\)</span> with <span
class="math inline">\(\mathbb{R}^n/\mathbb{Z}^n\)</span> and <span
class="math inline">\(\tilde{T}\)</span> with <span
class="math inline">\(\mathbb{R}^n/2 \mathbb{Z}^n\)</span>. In any
event, for <span class="math inline">\(\lambda \in (1/2)
\mathfrak{t}_{\mathbb{Z}}^*\)</span>, we have <span
class="math inline">\(\lambda(2 \mathfrak{t}_{\mathbb{Z}}) \subseteq
\mathbb{Z}\)</span>, and so the character <span
class="math inline">\(e^{\lambda} : \tilde{T} \rightarrow
\mathop{\mathrm{U}}(1)\)</span> given by <span
class="math inline">\(\exp(x) \mapsto \exp(\lambda(x))\)</span> is
well-defined. In particular, the above formula defines <span
class="math inline">\(\Delta : \tilde{T} \rightarrow
\mathbb{C}\)</span>. We identify <span class="math inline">\(D : T
\rightarrow \mathbb{C}\)</span> with a function <span
class="math inline">\(D : \tilde{T} \rightarrow \mathbb{C}\)</span> via
pullback. The identity <span class="math inline">\(|\Delta|^2 =
D\)</span> then holds. For a class function <span
class="math inline">\(f\)</span> on <span
class="math inline">\(K\)</span>, the Weyl integral formula <a
href="#eqn:WIF-recall-for-reps" data-reference-type="eqref"
data-reference="eqn:WIF-recall-for-reps">\((81)\)</a>
implies that <span class="math display">\[\langle f, f \rangle_K
  =
  \frac{1}{W}
  \langle \Delta f, \Delta f \rangle_{\tilde{T}},\]</span> where we
identify <span class="math inline">\(f\)</span> with a function on <span
class="math inline">\(\tilde{T}\)</span> by restricting to <span
class="math inline">\(T\)</span> and then pulling back to <span
class="math inline">\(\tilde{T}\)</span>, and where we integrate with
respect to the probability Haar on <span
class="math inline">\(\tilde{T}\)</span>.</p>
<p>Set <span class="math display">\[\rho := \frac{1}{2} \sum_{\alpha \in
\Phi^+} \alpha.\]</span> It defines an element of <span
class="math inline">\((1/2) \mathfrak{t}_{\mathbb{Z}}^*\)</span>, hence
a character of <span class="math inline">\(\tilde{T}\)</span>. We may
rewrite <span class="math display">\[\Delta(t) =
  t^{\rho}
  \prod_{\alpha &gt; 0}
  (1 - t^{-\alpha})\]</span> We pause to record some basic properties of
<span class="math inline">\(\rho\)</span>.</p>
<div id="lem:rho-basic-props" class="lemma">
<p><strong>Lemma 150</strong>. </p>
<ol type="i">
<li><p><span class="math inline">\(\rho\)</span> is strictly dominant.
Its <span class="math inline">\(W\)</span>-stabilizer is
trivial.</p></li>
<li><p>For all <span class="math inline">\(w \in W\)</span>, we have
<span id="eqn:formula-for-rho-minus-w-rho" class="math display">\[\label{eqn:formula-for-rho-minus-w-rho}\tag{82}
      \rho - w(\rho)
      = \sum_{
        \substack{
          \alpha \in \Phi : \\
          \alpha &gt; 0, \\
          w^{-1}(\alpha) &lt; 0
        }
      }
      \alpha.\]</span> In particular, <span class="math inline">\(\rho -
w(\rho)\)</span> defines a positive element of <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> We first establish the formula <a
href="#eqn:formula-for-rho-minus-w-rho" data-reference-type="eqref"
data-reference="eqn:formula-for-rho-minus-w-rho">\((82)\)</a>.
We have <span class="math display">\[w(\rho) = \frac{1}{2} \sum_{\alpha
&gt; 0} w(\alpha) = \sum_{\alpha: w^{-1}(\alpha) &gt; 0} \alpha =
\sum_{\alpha &gt; 0} \varepsilon_\alpha \alpha,\]</span> where <span
class="math display">\[\varepsilon_\alpha =
    \begin{cases}
      1 &amp; \text{ if }
      w^{-1}(\alpha) &gt; 0, \\
      -1 &amp; \text{ if } w^{-1}(\alpha) &lt; 0.
    \end{cases}\]</span> Thus <span class="math display">\[\rho -
w(\rho) = \sum _{\alpha &gt; 0} \frac{1 - \varepsilon_\alpha }{2}
\alpha.\]</span> We have <span class="math display">\[\frac{1 -
\varepsilon_\alpha }{2} =
    \begin{cases}
      1 &amp; \text{ if } w^{-1}(\alpha) &lt; 0, \\
      0 &amp; \text{ otherwise},
    \end{cases}\]</span> which leads to the required formula. It follows
immediately that <span class="math inline">\(\rho - w(\rho)\)</span>
defines a positive element of <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span>.</p>
<p>Suppose now that <span class="math inline">\(w \in W\)</span> fixes
<span class="math inline">\(\rho\)</span>. Then <span
class="math inline">\(w\)</span> stabilizes <span
class="math inline">\(\Phi^+\)</span>, hence <span
class="math inline">\(w\)</span> stabilizes <span
class="math inline">\(C\)</span>. Since we have seen (in Lemma <a
href="#lem:W-acts-freely-weyl-chambers" data-reference-type="ref"
data-reference="lem:W-acts-freely-weyl-chambers">116</a>) that <span
class="math inline">\(W\)</span> acts freely on the set of Weyl
chambers, it follows that <span class="math inline">\(w = 1\)</span>.
Thus <span class="math inline">\(\rho\)</span> has trivial <span
class="math inline">\(W\)</span>-stabilizer.</p>
<p>It remains only to verify that <span
class="math inline">\(\rho\)</span> is strictly dominant, i.e., that for
each <span class="math inline">\(\alpha \in \Phi^+\)</span>, we have
<span class="math inline">\(\rho(H_\alpha) &gt; 0\)</span> . To that
end, note first that since <span class="math inline">\(\rho\)</span> has
trivial <span class="math inline">\(W\)</span>-stabilizer, it is not
fixed by the root reflection <span
class="math inline">\(s_\alpha\)</span>, and so <span
class="math inline">\(\rho(H_\alpha) \neq 0\)</span>. Suppose for the
sake of contradiction that <span class="math inline">\(\rho(H_\alpha)
&lt; 0\)</span>. Then <span class="math inline">\(s_\alpha(\rho) - \rho
= - \rho(H_\alpha) \alpha &gt; 0\)</span>. But we have seen already
using the formula <a href="#eqn:formula-for-rho-minus-w-rho"
data-reference-type="eqref"
data-reference="eqn:formula-for-rho-minus-w-rho">\((82)\)</a>
that <span class="math inline">\(s_\alpha(\rho) - \rho &lt; 0\)</span>,
giving the required contradiction. ◻</p>
</span></div>
<p>Let <span class="math inline">\(L\)</span> denote the ring of Laurent
polynomials on <span class="math inline">\(\tilde{T}\)</span>, thus
<span class="math display">\[L = \oplus_{\lambda \in (1/2)
\mathfrak{t}_{\mathbb{Z}}^*} \mathbb{C} e^{\lambda},\]</span> where as
usual <span class="math inline">\(e^\lambda = [t \mapsto
t^{\lambda}]\)</span>. The Weyl group <span
class="math inline">\(W\)</span> acts on <span
class="math inline">\(L\)</span>. We set <span
class="math display">\[L^{\mathop{\mathrm{sym}}} := \{f \in L : w(f) = f
\text{ for all } w \in W\}.\]</span> For <span class="math inline">\(w
\in W\)</span>, we denote by <span class="math inline">\((-1)^w\)</span>
the determinant of the action of <span class="math inline">\(w\)</span>
on <span class="math inline">\(\mathfrak{t}_{\mathbb{R}}\)</span>. For
instance, for the root reflections <span
class="math inline">\(s_\alpha\)</span>, we have <span
class="math inline">\((-1)^{s_\alpha} = -1\)</span>, because reflections
have determinant <span class="math inline">\(-1\)</span>. More
generally, if <span class="math inline">\(w \in W\)</span> may be
written as a product of exactly <span class="math inline">\(k \geq
0\)</span> root reflections, then <span class="math inline">\((-1)^w =
(-1)^k\)</span>. This observation justifies the notation. We set <span
class="math display">\[L^{\mathop{\mathrm{alt}}} := \{f \in L : w(f) =
(-1)^w f \text{ for all } w \in W\}.\]</span> Since the (simple) root
reflections generate <span class="math inline">\(W\)</span>, we may also
write <span class="math display">\[L^{\mathop{\mathrm{alt}}} = \{f \in L
: s_\alpha(f) = - f \text{ for all } \alpha \in \Delta\}.\]</span> For
<span class="math inline">\(\lambda \in (1/2)
\mathfrak{t}_{\mathbb{Z}}^*\)</span>, define <span
class="math display">\[A(\lambda)
  :=
  \sum_{w \in W}
  (-1)^w
  e^{w(\lambda)}.\]</span></p>
<div class="lemma">
<p><strong>Lemma 151</strong>. </p>
<ol type="i">
<li><p><span class="math inline">\(A(\lambda) \in
L^{\mathop{\mathrm{alt}}}\)</span> for all <span
class="math inline">\(\lambda \in (1/2)
\mathfrak{t}_{\mathbb{Z}}^*\)</span>.</p></li>
<li><p><span class="math inline">\(L^{\mathop{\mathrm{alt}}} =
\oplus_{\lambda \in (1/2) \mathfrak{t}_{\mathbb{Z}}^* \cap C^\vee}
\mathbb{C} A(\lambda)\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>Direct calculation.</p></li>
<li><p>Let <span class="math inline">\(f \in
L^{\mathop{\mathrm{alt}}}\)</span>. Then <span class="math inline">\(f =
\sum_{\lambda \in (1/2) \mathfrak{t}_{\mathbb{Z}}^*} c(\lambda)
e^{\lambda}\)</span>, where <span class="math inline">\(c(w(\lambda)) =
(-1)^w c(\lambda)\)</span> for all <span class="math inline">\(w \in
W\)</span>. If <span class="math inline">\(\lambda\)</span> is
irregular, i.e., if <span class="math inline">\(\lambda(H_\alpha) =
0\)</span> for some root <span class="math inline">\(\alpha\)</span>,
then <span class="math inline">\(s_\alpha(\lambda) = \lambda\)</span>,
while <span class="math inline">\((-1)^{s_\alpha} = -1\)</span>, and so
<span class="math inline">\(c(\lambda) = 0\)</span>. If <span
class="math inline">\(\lambda\)</span> is regular, then its unique
dominant <span class="math inline">\(W\)</span>-conjugate <span
class="math inline">\(w(\lambda)\)</span> belongs to <span
class="math inline">\(C^\vee\)</span>, and we have <span
class="math inline">\(c(\lambda) = (-1)^w c(w(\lambda))\)</span>. It
follows that <span class="math inline">\(f = \sum_{\lambda \in (1/2)
\mathfrak{t}_{\mathbb{Z}}^* \cap C^\vee} c(\lambda) A(\lambda)\)</span>.
The uniqueness of this decomposition follows from the fact that if <span
class="math inline">\(\lambda \in (1/2) \mathfrak{t}_{\mathbb{Z}}^* \cap
C^\vee\)</span>, then <span class="math inline">\(w(\lambda) \notin
C^\vee\)</span> for all nontrivial <span class="math inline">\(w \in
W\)</span>.</p></li>
</ol>
<p> ◻</p>
</span></div>
<p>Let <span class="math inline">\(\pi\)</span> be a finite-dimensional
representation of <span class="math inline">\(G\)</span>. Recall that
the <em>weights</em> of <span class="math inline">\(\pi\)</span> are
those <span class="math inline">\(\mu \in X(T)\)</span> for which the
weight space <span class="math inline">\(\pi[\mu] := \{v \in \pi : t v =
t^{\mu} v \text{ for all } t \in T\}\)</span> is nonzero. The character
<span class="math inline">\(\chi_\pi\)</span> of <span
class="math inline">\(\pi\)</span> is a class function on <span
class="math inline">\(G\)</span>, which we may identify with a <span
class="math inline">\(W\)</span>-invariant function on <span
class="math inline">\(T\)</span>, and in fact an element <span
class="math inline">\(\chi_\pi \in L^{\mathop{\mathrm{sym}}}\)</span>,
given by <span class="math inline">\(\chi_\pi = \sum_{\mu \in X(T)}
m_\pi(\mu) e^{\mu}\)</span>. For any element <span
class="math inline">\(f \in L\)</span>, we may speak more generally of
the <em>weights</em> of <span class="math inline">\(f\)</span> (i.e.,
those <span class="math inline">\(\mu \in X(\tilde{T})\)</span> for
which the coefficient of <span class="math inline">\(e^{\mu}\)</span> in
<span class="math inline">\(f\)</span> is nonzero), and we say that
<span class="math inline">\(\lambda\)</span> is</p>
<ul>
<li><p>a <em>maximal weight</em> of <span
class="math inline">\(f\)</span> if there does not exist a weight <span
class="math inline">\(\mu\)</span> of <span
class="math inline">\(f\)</span> with <span class="math inline">\(\mu
&gt; \lambda\)</span>, and</p></li>
<li><p>the <em>highest weight</em> of <span
class="math inline">\(f\)</span> if every weight <span
class="math inline">\(\mu\)</span> of <span
class="math inline">\(f\)</span> satisfies <span
class="math inline">\(\mu \leq \lambda\)</span>.</p></li>
</ul>
<p>Note that <span class="math inline">\(f\)</span> has (in general,
many) maximal weights, and that <span class="math inline">\(f\)</span>
has a highest weight iff it has a unique maximal weight. This
terminology applies also to <span class="math inline">\(\pi\)</span> in
place of <span class="math inline">\(f\)</span> by considering the
character <span class="math inline">\(\chi_\pi\)</span>. For instance,
<span class="math inline">\(\Delta = \prod_{\alpha &gt; 0} (e^{\alpha/2}
- e^{-\alpha/2})\in L^{\mathop{\mathrm{alt}}}\)</span> and <span
class="math inline">\(A(\rho) = \sum_{w \in W} (-1)^w e^{w(\rho)} =
A(\rho)\)</span> are each of the form <span
class="math inline">\(e^{\rho} + \dotsb\)</span> where <span
class="math inline">\(\dotsb\)</span> denotes the contributions of
weights <span class="math inline">\(w(\rho)\)</span> strictly less than
<span class="math inline">\(\rho\)</span>, and so <span
class="math inline">\(\Delta\)</span> and <span
class="math inline">\(A(\rho)\)</span> both have highest weight <span
class="math inline">\(\rho\)</span>.</p>
<div id="lem:props-of-delta-vs-L" class="lemma">
<p><strong>Lemma 152</strong>. </p>
<ol type="i">
<li><p><span class="math inline">\(\Delta \in
L^{\mathop{\mathrm{alt}}}\)</span>.</p></li>
<li><p>For all <span class="math inline">\(f \in
L^{\mathop{\mathrm{alt}}}\)</span>, we have <span
class="math inline">\(f/\Delta \in
L^{\mathop{\mathrm{sym}}}\)</span>.</p></li>
<li><p><span class="math inline">\(\Delta = A(\rho)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\lambda\)</span> be a dominant
element of <span class="math inline">\((1/2)
\mathfrak{t}_{\mathbb{Z}}^*\)</span>. Then <span
class="math inline">\(\lambda + \rho\)</span> is a strictly dominant
element <span class="math inline">\((1/2)
\mathfrak{t}_{\mathbb{Z}}^*\)</span>, and <span id="eq:evaluate-schur-poly-at-1-general-group" class="math display">\[\label{eq:evaluate-schur-poly-at-1-general-group}\tag{83}
      \frac{A(\lambda+\rho)}{A(\rho)}(1)
      = \prod _{\alpha &gt; 0}
      \frac{\langle \lambda + \rho, H_\alpha  \rangle
      }{
        \langle \rho, H_\alpha  \rangle}.\]</span></p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"></p>
<ol type="i">
<li><p>It is enough to check for each simple root <span
class="math inline">\(\beta\)</span> that <span
class="math display">\[\Delta(s_\beta(t)) = - \Delta(t).\]</span> Using
that <span class="math inline">\(s_\beta^2 =1\)</span>, we compute that
<span class="math display">\[\Delta(s_\beta(t))
      =
      \prod_{\alpha&gt;0}
      (t^{s_\beta(\alpha)/2}
      - t^{-s_\beta(\alpha)/2}).\]</span> Since <span
class="math inline">\(s_\beta(\beta) = -\beta\)</span>, we have <span
class="math display">\[(t^{s_\beta(\beta)/2}
      - t^{-s_\beta(\beta)/2})
      =
      -(t^{\beta/2} - t^{-\beta/2}).\]</span> Let <span
class="math inline">\(\alpha \in \Phi^+ - \{\beta\}\)</span>. Then (see
the homework for details concerning the following terminology and facts)
the Weyl chambers <span class="math inline">\(C\)</span> and <span
class="math inline">\(s_\beta(C)\)</span> are adjacent, separated by the
wall <span class="math inline">\(\beta^\perp\)</span> and no other wall.
In particular, <span class="math inline">\(\alpha\)</span> takes the
same sign on <span class="math inline">\(C\)</span> and <span
class="math inline">\(s_\beta(C)\)</span>, hence <span
class="math inline">\(\alpha\)</span> is positive on <span
class="math inline">\(s_\beta(C)\)</span>; equivalently, <span
class="math inline">\(s_\beta(\alpha)\)</span> is positive on <span
class="math inline">\(C\)</span>, i.e., <span
class="math inline">\(s_\beta(\alpha) &gt; 0\)</span>. Thus <span
class="math inline">\(s_\beta\)</span> acts on <span
class="math inline">\(\Phi^+ - \{\beta\}\)</span>, and so <span
class="math display">\[\prod_{\alpha&gt;0, \alpha \neq \beta }
      (t^{s_\beta(\alpha)/2}
      - t^{-s_\beta(\alpha)/2})
      =
      \prod_{\alpha&gt;0, \alpha \neq \beta }
      (t^{\alpha/2}
      - t^{-\alpha/2}).\]</span> The required identity follows.</p></li>
<li><p>It is enough to show that <span class="math inline">\(f\)</span>
is divisible by <span class="math inline">\(\Delta\)</span> in <span
class="math inline">\(L\)</span>. We record two proofs (the second of
which was given in lecture, the first of which I find a bit more
natural). Both proofs use the fact that for distinct positive roots
<span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>, <span id="eq:C-alpha-not-C-beta" class="math display">\[\label{eq:C-alpha-not-C-beta}\tag{84}
      \mathbb{C} \alpha \cap \mathbb{C} \beta = \{0\}.\]</span> (To see
this, it suffices to check that <span class="math inline">\(\beta \notin
\mathbb{C} \alpha\)</span>, which follows from the identity <span
class="math inline">\(\mathbb{C} \alpha \cap \Phi = \{\alpha, - \alpha
\}\)</span> and our assumptions.)</p>
<ol>
<li><p>(First proof) Set <span class="math inline">\(Z := \{z \in
(\mathbb{C}^\times)^n : \Delta(z) = 0 \}\)</span>. Then <span
class="math inline">\(z \in Z\)</span> iff <span
class="math inline">\(z^\alpha = 1\)</span> for some positive root <span
class="math inline">\(\alpha\)</span>. The identity <span
class="math inline">\(z^\alpha = 1\)</span> is equivalent to <span
class="math inline">\(s_\alpha(z) = z\)</span>. Let <span
class="math inline">\(f \in L^{\mathop{\mathrm{alt}}}\)</span> and <span
class="math inline">\(z \in Z\)</span>. Then, choosing <span
class="math inline">\(\alpha\)</span> so that <span
class="math inline">\(s_\alpha(z) = z\)</span>, we have <span
class="math inline">\(f(z) = f(s_\alpha(z)) = - f(z)\)</span>, hence
<span class="math inline">\(f(z) = 0\)</span>. Thus <span
class="math inline">\(f\)</span> vanishes on <span
class="math inline">\(Z\)</span>. By the Nullstellensatz, it follows
that <span class="math inline">\(f\)</span> belongs to the radical of
the ideal in <span class="math inline">\(\Delta\)</span> generated by
<span class="math inline">\(\Delta\)</span>. Note that <span
class="math inline">\(L\)</span> is a UFD (being a localization of the
UFD <span class="math inline">\(\mathbb{C}[t_1,\dotsc,t_n]\)</span>). To
conclude, it suffices to show that <span
class="math inline">\(\Delta\)</span> defines a squarefree element of
<span class="math inline">\(L\)</span>, i.e., that no prime factor of
<span class="math inline">\(\Delta\)</span> occurs with multiplicity
<span class="math inline">\(&gt; 1\)</span>.</p>
<p>We first compute the prime factorization of <span
class="math inline">\(t^\alpha - 1\)</span> for each nontrivial
character <span class="math inline">\(\alpha\)</span> of <span
class="math inline">\(\tilde{T}\)</span>. The character group <span
class="math inline">\(X(\tilde{T})\)</span> is isomorphic to <span
class="math inline">\(\mathbb{Z}^n\)</span>, where <span
class="math inline">\(n = \dim(\tilde{T})\)</span>. Suppose that <span
class="math inline">\(\alpha\)</span> is of the form <span
class="math inline">\(d \beta\)</span> for some natural number <span
class="math inline">\(d\)</span> and some character <span
class="math inline">\(\beta\)</span> of <span
class="math inline">\(\tilde{T}\)</span>, with <span
class="math inline">\(d\)</span> chosen maximally. Then <span id="eq:prime-factorization-t-alpha-minus-one" class="math display">\[\label{eq:prime-factorization-t-alpha-minus-one}\tag{85}
        t^\alpha - 1 = \prod (t^\beta - \zeta),\]</span> with the
product taken over all <span class="math inline">\(d\)</span>th roots of
unity <span class="math inline">\(\zeta\)</span>. We claim that each
factor <span class="math inline">\(t^\beta - \zeta\)</span> is
irreducible. For this it suffices to show more generally that if <span
class="math inline">\(\alpha\)</span> is a <em>primitive</em> nontrivial
character of <span class="math inline">\(\tilde{T}\)</span> (thus <span
class="math inline">\(\alpha\)</span> corresponds to a nonzero element
of <span class="math inline">\(\mathbb{Z}^n\)</span> whose coordinates
are relatively prime) and <span class="math inline">\(\zeta \in
\mathbb{C}^\times\)</span>, then <span class="math inline">\(t^\alpha -
\zeta\)</span> is irreducible. Indeed, since <span
class="math inline">\(\alpha\)</span> is primitive, we may apply a
linear change of variables on <span
class="math inline">\(\mathbb{Z}^n\)</span> to reduce to the case that
<span class="math inline">\(\alpha = (1,0,\dotsc,0)\)</span>, so that
<span class="math inline">\(t^\alpha - \zeta = t_1 - \zeta\)</span>,
which is clearly irreducible. (The existence of such a change of
variables is a simple exercise in linear algebra, closely related to the
fact that finitely-generated torsion-free modules over <span
class="math inline">\(\mathbb{Z}\)</span> are free; indeed, the latter
fact implies that the quotient <span
class="math inline">\(X(\tilde{T})/\mathbb{Z} \alpha\)</span> is free,
hence that the surjection to that quotient from <span
class="math inline">\(X(\tilde{T})\)</span> splits, leading to a direct
sum decomposition <span class="math inline">\(X(\tilde{T}) = \mathbb{Z}
\alpha \oplus (\dotsb)\)</span> and hence the required change of
variables.)</p>
<p>Since no prime factor in <a
href="#eq:prime-factorization-t-alpha-minus-one"
data-reference-type="eqref"
data-reference="eq:prime-factorization-t-alpha-minus-one">\((85)\)</a>
occurs twice, we see in particular that <span
class="math inline">\(t^\alpha - 1\)</span> is squarefree. To establish
the same for <span class="math inline">\(\Delta\)</span>, we need to
check that no prime factor of <span class="math inline">\(t^\alpha -
1\)</span> divides <span class="math inline">\(t^\beta - 1\)</span>
whenever <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> are distinct positive roots. This
follows from <a href="#eq:prime-factorization-t-alpha-minus-one"
data-reference-type="eqref"
data-reference="eq:prime-factorization-t-alpha-minus-one">\((85)\)</a>
and <a href="#eq:C-alpha-not-C-beta" data-reference-type="eqref"
data-reference="eq:C-alpha-not-C-beta">\((84)\)</a>.</p></li>
<li><p>(Second proof) We show first that if <span
class="math inline">\(f \in L\)</span> vanishes on <span
class="math inline">\(\{z : z^\alpha = 1\}\)</span>, then <span
class="math inline">\(f / (t^\alpha - 1) \in L\)</span>. Choosing
coordinates <span class="math inline">\(t_1,\dotsc,t_n\)</span> on <span
class="math inline">\(\tilde{T}\)</span>, we may represent <span
class="math inline">\(\alpha\)</span> as <span
class="math inline">\((\alpha_1,\dotsc,\alpha_n)\)</span> for some
integers <span class="math inline">\(\alpha_j\)</span>. We may assume
for convenience, by inverting the coordinate <span
class="math inline">\(t_n\)</span> if necessary, that <span
class="math inline">\(\alpha_n \geq 0\)</span>. Setting <span
class="math inline">\(R := \mathbb{Z}[t_1^{\pm 1}, \dotsc, t_{n-1}^{\pm
1}]\)</span>, we then have <span class="math inline">\(t^{\alpha} - 1
\in R[t_n]\)</span>. We may assume, after multiplying <span
class="math inline">\(f\)</span> by a sufficiently large power of <span
class="math inline">\(t_n\)</span>, then <span class="math inline">\(f
\in R[t_n]\)</span>. By division with remainder in the polynomial <span
class="math inline">\(t_n\)</span>, we then have <span
class="math inline">\(f = (t_n^{\alpha_n} - \prod_{j &lt; n}
t_j^{-\alpha_j}) q + r\)</span> for some <span class="math inline">\(q,
r \in R[t_n]\)</span> for which the degree in <span
class="math inline">\(t_n\)</span> of <span
class="math inline">\(r\)</span> is strictly less than <span
class="math inline">\(\alpha_n\)</span>. This identity implies that
<span class="math inline">\(r\)</span> vanishes on the solution set to
the equation <span class="math inline">\(t^\alpha = 1\)</span>. For any
given values <span class="math inline">\(t_1,\dotsc,t_{n-1} \in
\mathbb{C}^\times\)</span> of the first <span
class="math inline">\(n-1\)</span> coordinates, that equation has
exactly <span class="math inline">\(\alpha_n\)</span> solutions in the
variable <span class="math inline">\(t_n\)</span>. The noted degree
bound on <span class="math inline">\(r\)</span> thus implies that <span
class="math inline">\(r=0\)</span>. It follows as required that <span
class="math inline">\(f\)</span> is divisible by <span
class="math inline">\(t^\alpha - 1\)</span>.</p>
<p>From <a href="#eq:C-alpha-not-C-beta" data-reference-type="eqref"
data-reference="eq:C-alpha-not-C-beta">\((84)\)</a> we
see that for distinct positive roots <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>, the tangent planes to the
hypersurfaces <span class="math inline">\(\{t : t^\alpha = 1\}\)</span>
and <span class="math inline">\(\{t : t^\beta = 1\}\)</span> are
traverse at any point of the intersection <span
class="math inline">\(\{t : t^\alpha = t^\beta = 1\}\)</span>. Thus if
<span class="math inline">\(f\)</span> vanishes on <span
class="math inline">\(\{z : z^\beta = 1\}\)</span> and is divisible by
<span class="math inline">\(t^\alpha -1\)</span>, then <span
class="math inline">\(f / (t^\alpha - 1)\)</span> likewise vanishes on
<span class="math inline">\(\{z : z^\beta = 1\}\)</span>. We may thus
iteratively apply the argument of the preceeding paragraph to obtain the
required conclusion.</p></li>
</ol></li>
<li><p>By the previous item, we have <span
class="math inline">\(A(\rho)/\Delta \in
L^{\mathop{\mathrm{sym}}}\)</span>. We’ve noted already that <span
class="math inline">\(\Delta\)</span> and <span
class="math inline">\(A(\rho)\)</span> each have <span
class="math inline">\(\rho\)</span> as highest weight. If <span
class="math inline">\(\lambda\)</span> is any maximal weight of <span
class="math inline">\(A(\rho)/\Delta\)</span>, then <span
class="math inline">\(\lambda + \rho = \rho\)</span>, whence <span
class="math inline">\(\lambda = 0\)</span>. Thus <span
class="math inline">\(A(\rho)/\Delta\)</span> is a complex scalar; since
<span class="math inline">\(A(\rho)\)</span> and <span
class="math inline">\(\Delta\)</span> are each of the form <span
class="math inline">\(e^{\rho} + (\dotsb)\)</span>, we conclude that
<span class="math inline">\(A(\rho)/\Delta = 1\)</span>.</p></li>
<li><p>We have seen that <span class="math inline">\(\rho\)</span> is
strictly dominant. Since <span class="math inline">\(\lambda\)</span> is
dominant, it follows that <span class="math inline">\(\lambda +
\rho\)</span> is strictly dominant. It remains to check the formula <a
href="#eq:evaluate-schur-poly-at-1-general-group"
data-reference-type="eqref"
data-reference="eq:evaluate-schur-poly-at-1-general-group">\((83)\)</a>.
This requires taking a limit as in the proof of the analogous result for
<span class="math inline">\(\mathop{\mathrm{U}}(n)\)</span> (Lemma <a
href="#lem:schur-evalu-at-1-U-n" data-reference-type="ref"
data-reference="lem:schur-evalu-at-1-U-n">42</a>). Let us first rewrite
the identity <span class="math inline">\(\Delta = A(\rho)\)</span>
established above in the form: for <span class="math inline">\(x \in
\mathfrak{t}_{\mathbb{C}}\)</span>, <span
class="math display">\[\sum_{W}
      (-1)^w
      e^{\langle w(x), \rho \rangle}
      =
      \prod_{\alpha &gt; 0}
      (
      e^{\alpha(x)/2} - e^{-\alpha(x)/2}
      ).\]</span> A similar argument (applied with the roles of <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}^*\)</span> reversed)
gives for <span class="math inline">\(\lambda \in
\mathfrak{t}_{\mathbb{C}}^*\)</span> that <span
class="math display">\[\sum_{W}
      (-1)^w
      e^{\langle w(\lambda),  H_\rho \rangle}
      =
      \prod_{\alpha &gt; 0}
      (
      e^{\lambda(H_\alpha)/2} - e^{-\lambda(H_\alpha)/2}
      ).\]</span> It follows that for <span class="math inline">\(t =
\exp(\varepsilon H_\rho)\)</span> with <span
class="math inline">\(\varepsilon&gt; 0\)</span> small, we have <span
class="math display">\[\sum_{W} (-1)^w t^{w(\lambda)} = \prod_{\alpha
&gt; 0} ( e^{\varepsilon\lambda(H_\alpha)/2} -
e^{-\varepsilon\lambda(H_\alpha)/2} ) \sim \varepsilon^{|\Phi_+|}
\prod_{\alpha &gt; 0} \langle \lambda, H_\alpha \rangle.\]</span> Thus
<span class="math display">\[\frac{ \sum_{W} (-1)^w t^{w(\lambda + \rho
)} } { \sum_{W} (-1)^w t^{w(\rho )} } |_{t=1} = \prod_{\alpha &gt; 0}
\frac{ \langle \lambda + \rho , H_\alpha \rangle }{ \langle \rho,
H_\alpha \rangle },\]</span> as required.</p></li>
</ol>
<p> ◻</p>
</span></div>
<h2 id="classification-of-irreducibles">Classification of
irreducibles</h2>
<div id="thm:highest-weight-general-gp" class="theorem">
<p><strong>Theorem 153</strong>. <em>Let <span
class="math inline">\(K\)</span> be a compact connected Lie group with
maximal torus <span class="math inline">\(T\)</span>, hence root set
<span class="math inline">\(\Phi\)</span> and Weyl group <span
class="math inline">\(W\)</span>. Choose a Weyl chamber <span
class="math inline">\(C\)</span>, hence sets <span
class="math inline">\(\Phi^+\)</span> and <span
class="math inline">\(\Delta\)</span> of positive and simple roots,
respectively, as well as a partial order <span
class="math inline">\(\geq\)</span> on <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}}^*\)</span>.</em></p>
<p><em>Each <span class="math inline">\(\pi \in
\mathop{\mathrm{Irr}}(K)\)</span> has a highest weight <span
class="math inline">\(\lambda \in X(T) =
\mathfrak{t}_{\mathbb{Z}}^*\)</span>; this is a dominant element for
which the Weyl character formula <span class="math display">\[\chi_{\pi}
= \frac{A_{\lambda+\rho}}{A_\rho }\]</span> holds, with <span
class="math display">\[A_{\mu} := \sum_{w \in W} (-1)^w e^{w(\mu)} \in
X(\tilde{T}) = \frac{1}{2} \mathfrak{t}_{\mathbb{Z}}^*, \quad \rho :=
\frac{1}{2} \sum_{\alpha &gt; 0} \alpha.\]</span> The map <span
class="math inline">\(\pi \mapsto \lambda\)</span> defines a bijection
<span class="math display">\[\mathop{\mathrm{Irr}}(K)
    \leftrightarrow \{\text{dominant }
    \lambda \in X(T)\}
    \leftrightarrow
    X(T)/W.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(\pi \in
\mathop{\mathrm{Irr}}(K)\)</span>. Let <span
class="math inline">\(\lambda \in X(T)\)</span> be any maximal weight of
<span class="math inline">\(\pi\)</span>. Since <span
class="math inline">\(\chi_\pi\)</span> is <span
class="math inline">\(W\)</span>-invariant, and since every element
<span class="math inline">\(\mu\)</span> of <span
class="math inline">\(X(T)\)</span> is <span
class="math inline">\(W\)</span>-conjugate to a unique dominant element
which is then <span class="math inline">\(\geq \mu\)</span>, we know
that <span class="math inline">\(\lambda\)</span> is dominant. Since
<span class="math inline">\(\Delta\)</span> has highest weight <span
class="math inline">\(\rho\)</span> with <span
class="math inline">\(\Delta = e^\rho + \dotsb\)</span>, we know that
<span class="math inline">\(\Delta \chi_\pi \in
L^{\mathop{\mathrm{alt}}}\)</span> has <span
class="math inline">\(\lambda + \rho\)</span> as a maximal weight, with
<span class="math inline">\(\Delta \chi_\pi = m_\pi(\lambda)
e^{\lambda+\rho} + \dotsb\)</span>. Regrouping terms into monomial
alternating functions gives <span id="eq:WCF-Delta-chi-pi" class="math display">\[\label{eq:WCF-Delta-chi-pi}\tag{88}
    \Delta \chi_\pi
    = m_\pi(\lambda) A_{\lambda+\rho} + \dotsb,\]</span> where <span
class="math inline">\(\dotsb\)</span> denotes a linear combination of
<span class="math inline">\(A_{\mu+\rho}\)</span> taken over <span
class="math inline">\(\mu\)</span> with <span
class="math inline">\(\mu+\rho\)</span> strictly dominant and <span
class="math inline">\(\mu\)</span> not greater than <span
class="math inline">\(\lambda\)</span>. By the Weyl integral formula and
Schur orthogonality, we have (as in the case of <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>) <span id="eqn:WCF-general-long" class="math display">\[\label{eqn:WCF-general-long}\tag{89}
    1 = \langle \chi_\pi, \chi_\pi  \rangle_G
    =
    \frac{\langle D \chi_\pi, \chi_\pi  \rangle_T}{|W|}
    =
    \frac{\langle \Delta \chi_\pi, \Delta \chi_\pi
      \rangle_{\tilde{T}}}  {|W|}
    =
    \frac{\|m_\pi(\lambda) A_{\lambda+\rho} + \dotsb \|^2}{|W|}
    \geq |m_\pi(\lambda)|^2.\]</span> Here we used that <span
class="math inline">\(\lambda+\rho\)</span> is strictly dominant and
that for strictly dominant <span class="math inline">\(\lambda_1,
\lambda_2\)</span>, <span class="math display">\[\langle A_{\lambda_1},
A_{\lambda_2} \rangle =
\begin{cases}
      |W| &amp; \text{ if } \lambda_1 = \lambda_2, \\
      0 &amp; \text{ otherwise}
    \end{cases}
.\]</span> Since <span class="math inline">\(m_\pi(\lambda) \in
\mathbb{Z}_{\geq 1}\)</span>, we deduce from <a
href="#eqn:WCF-general-long" data-reference-type="eqref"
data-reference="eqn:WCF-general-long">\((89)\)</a> that
<span class="math inline">\(m_\pi(\lambda) = 1\)</span> and hence that
equality holds in each step, i.e., that the <span
class="math inline">\(\dotsb\)</span> in <a href="#eq:WCF-Delta-chi-pi"
data-reference-type="eqref"
data-reference="eq:WCF-Delta-chi-pi">\((88)\)</a> vanishes.
This gives the required formula for <span
class="math inline">\(\chi_\pi\)</span> in terms of <span
class="math inline">\(\lambda\)</span>. The proof shows also that <span
class="math inline">\(\lambda\)</span> is uniquely determined, hence is
the unique maximal weight, i.e., the highest weight of <span
class="math inline">\(\pi\)</span>. We thus obtain an injective map
<span class="math inline">\(\mathop{\mathrm{Irr}}(K) \rightarrow
\{\text{dominant } \lambda \in X(T)\}\)</span> as in the statement of
the theorem; to complete the proof, it remains only to show that this
map is surjective. We imitate the first proof given earlier for <span
class="math inline">\(\mathop{\mathrm{U}}(n)\)</span>. Suppose <span
class="math inline">\(\lambda\)</span> is a dominant element of <span
class="math inline">\(X(T)\)</span> not arising as the highest weight of
any element of <span
class="math inline">\(\mathop{\mathrm{Irr}}(K)\)</span>. By Lemma <a
href="#lem:props-of-delta-vs-L" data-reference-type="ref"
data-reference="lem:props-of-delta-vs-L">152</a>, the ratio <span
class="math inline">\(A_{\lambda+\rho}/A_{\rho}\)</span> defines an
element of <span
class="math inline">\(L^{\mathop{\mathrm{sym}}}\)</span>, hence in
particular a function <span class="math inline">\(\tilde{T} \rightarrow
\mathbb{C}\)</span>. We claim that this function factors through <span
class="math inline">\(T\)</span>. To see this, we write <span
class="math display">\[\frac{A_{\lambda+\rho}}{A_{\rho}} = \frac {
\sum_{w \in W} (-1)^w e^{w(\lambda+\rho) - \rho } } { e^{\rho}
\prod_{\alpha &gt; 0} (1 - e^{-\alpha}) },\]</span> and observe that
having rewritten the ratio in this way, both the numerator and
denominator factor through <span class="math inline">\(T\)</span>: for
the denominator, this is clear, while for the numerator, we use that
<span class="math inline">\(w(\lambda+\rho) - \rho = w(\lambda) - (\rho
- w(\rho))\)</span>, which belongs to <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}^*\)</span> thanks to
Lemma <a href="#lem:rho-basic-props" data-reference-type="ref"
data-reference="lem:rho-basic-props">150</a>. This completes the
verification of the claim. Thus <span
class="math inline">\(A_{\lambda+\rho}/A_\rho\)</span> defines a <span
class="math inline">\(W\)</span>-invariant function <span
class="math inline">\(T \rightarrow \mathbb{C}\)</span>, hence a class
function <span class="math inline">\(K \rightarrow \mathbb{C}\)</span>.
For each <span class="math inline">\(\pi \in
\mathop{\mathrm{Irr}}(K)\)</span>, say with highest weight <span
class="math inline">\(\mu\)</span>, then the Weyl integral formula gives
<span class="math display">\[\langle A_{\lambda+\rho}/A_\rho, \chi_\pi
\rangle_K = \langle A_{\lambda+\rho}, \Delta \chi_\pi
\rangle_{\tilde{T}} = \langle A_{\lambda+\rho}, A_{\mu+\rho}
\rangle_{\tilde{T}}= 0,\]</span> using in the last step that <span
class="math inline">\(\lambda, \mu\)</span> are dominant and distinct.
The Peter–Weyl theorem then implies that <span
class="math inline">\(A_{\lambda+\rho}/A_\rho = 0\)</span>, which is
absurd. This completes the proof of the required contradiction. ◻</p>
</span></div>
<div class="remark">
<p><strong>Remark 154</strong>. We indicate a way to formulate the
conclusion of Theorem <a href="#thm:highest-weight-general-gp"
data-reference-type="ref"
data-reference="thm:highest-weight-general-gp">153</a> without explicit
reference to a maximal torus. Recall from §<a href="#sec:root-data"
data-reference-type="ref" data-reference="sec:root-data">7.22</a> that
there is a bijection <span class="math display">\[\{\text{compact
connected } K\}/\sim \quad \leftrightarrow \quad \{\text{reduced root
data } \Psi = (X, \Phi, X^\vee, \Phi^\vee)\}\]</span> <span
class="math display">\[K \mapsto \Psi(K) := (X(T), \Phi(K:T), X^\vee(T),
\Phi^\vee).\]</span> There is a “duality” <span
class="math inline">\(\Psi \mapsto \Psi^\vee\)</span> on the set of
(reduced) root data given by <span class="math display">\[\Psi^\vee :=
(X^\vee, \Phi^\vee, X, \Phi).\]</span> We may define the dual group
<span class="math inline">\(K^\vee\)</span> of <span
class="math inline">\(K\)</span> to be the connected compact Lie group
(up to isomorphism) having the dual root datum, i.e., <span
class="math inline">\(\Psi(K^\vee) = \Psi(K)^\vee\)</span>; it comes
with a maximal torus <span class="math inline">\(T^\vee \subseteq
K^\vee\)</span> having natural identifications <span
class="math inline">\(X(T^\vee) = X^\vee(T)\)</span> and <span
class="math inline">\(X^\vee(T^\vee) = X(T)\)</span>, and we may
furthermore identify the Weyl group <span
class="math inline">\(W\)</span> of <span
class="math inline">\(T\)</span> with the Weyl group of <span
class="math inline">\(T^\vee\)</span>. We then have natural bijections
<span class="math display">\[\begin{align}
    \mathop{\mathrm{Irr}}(K)
    &amp;\cong
      \{\text{dominant } \lambda \in X^\vee(T)\}
    \\
    &amp;\cong
      X(T) / W
    \\
    &amp;\cong
      X^\vee(T^\vee) / W
    \\
    &amp;\cong
      \mathop{\mathrm{Hom}}(\mathop{\mathrm{U}}(1), K^\vee)/\sim,
  
\end{align}\]</span> where the equivalence relation <span
class="math inline">\(\sim\)</span> in the last expression is given by
conjugation.</p>
</div>
<h2 id="sec:borel-weil">§8.3. Borel–Weil</h2>
<p>Recall the usual notation: <span class="math inline">\(K\)</span> is
a compact connected Lie group with Lie algebra <span
class="math inline">\(\mathfrak{k}\)</span>, complexification <span
class="math inline">\(G\)</span>, and complexified Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span>. Recall that <span
class="math inline">\(\mathop{\mathrm{Irr}}(K)\)</span> is in natural
bijection with the set of isomorphism classes of holomorphic
(equivalently, algebraic) finite-dimensional irreducible representation
of <span class="math inline">\(G\)</span>. We fix a maximal torus <span
class="math inline">\(T \leq K\)</span>, with Lie algebra denoted <span
class="math inline">\(\mathfrak{t}\)</span>, and set <span
class="math inline">\(\mathfrak{t}_{\mathbb{R}} := i \mathfrak{t}
\subseteq \mathfrak{t} _{\mathbb{C}}\)</span>, as usual. We denote by
<span class="math inline">\(A \leq G\)</span> the connected (complex)
Lie subgroup with Lie algebra <span
class="math inline">\(\mathop{\mathrm{Lie}}(A) =
\mathfrak{t}_{\mathbb{C}}\)</span>. For example, if <span
class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span>, so that <span
class="math inline">\(G = {\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>,
then with the choice <span class="math display">\[T =
\begin{pmatrix}
    \mathop{\mathrm{U}}(1) &amp;  &amp;  \\
    &amp; \ddots &amp;  \\
    &amp; &amp; \mathop{\mathrm{U}}(1)
  \end{pmatrix}\]</span> we have <span class="math display">\[A =
\begin{pmatrix}
    \mathbb{C}^\times &amp;  &amp;  \\
    &amp; \ddots &amp;  \\
    &amp; &amp; \mathbb{C}^\times
  \end{pmatrix}
.\]</span> Fix a Weyl chamber <span class="math inline">\(C \subseteq
\mathfrak{t}_{\mathbb{R}}\)</span> and hence choices of positive roots
<span class="math inline">\(\Phi^+\)</span> and simple roots <span
class="math inline">\(\Delta\)</span>, as usual. Set <span
class="math display">\[\mathfrak{n} := \oplus_{\alpha \in
\Phi^+}\]</span> and <span class="math display">\[\mathfrak{b} :=
\mathfrak{n} \oplus \mathfrak{t}_{\mathbb{C}} \leq
\mathfrak{g}.\]</span> (The directness of the sum follows immediately
from the root space decomposition of <span
class="math inline">\(\mathfrak{g}\)</span>.) For example, if we take
<span class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span>, <span
class="math inline">\(T\)</span> as above, and for <span
class="math inline">\(C\)</span> the “standard” Weyl chamber <span
class="math inline">\(\{(x_1,\dotsc,x_n) : x_i &gt; x_j \text{ for } i
&lt; j \}\)</span>, then <span class="math inline">\(\Phi^+ =
\{\varepsilon_i - \varepsilon_j : i &lt; j\}\)</span>, and (for <span
class="math inline">\(n=3\)</span>, say) <span
class="math display">\[\mathfrak{n} = \oplus_{i &lt; j} \mathbb{C} E_{i
j } =
\begin{pmatrix}
    0 &amp; \ast &amp; \ast \\
    &amp; 0 &amp; \ast \\
    &amp; &amp; 0
  \end{pmatrix}
,\]</span> <span class="math display">\[\mathfrak{b} =
\begin{pmatrix}
    \ast &amp; \ast &amp; \ast \\
    &amp; \ast &amp; \ast \\
    &amp; &amp; \ast
  \end{pmatrix}
,\]</span> <span class="math display">\[N =
\begin{pmatrix}
    1 &amp; \ast &amp; \ast \\
    &amp; 1 &amp; \ast \\
    &amp; &amp; 1
  \end{pmatrix}
,\]</span> <span class="math display">\[B =
\begin{pmatrix}
    \ast &amp; \ast &amp; \ast \\
    &amp; \ast &amp; \ast \\
    &amp; &amp; \ast
  \end{pmatrix}
.\]</span> Using that the sum of two positive roots, if it is a root, is
positive, we see that <span class="math inline">\(\mathfrak{n}\)</span>
and <span class="math inline">\(\mathfrak{b}\)</span> are Lie
subalgebras of <span class="math inline">\(\mathfrak{g}\)</span>, with
<span class="math inline">\(\mathfrak{n}\)</span> an ideal of <span
class="math inline">\(\mathfrak{b}\)</span>. Hence they correspond to
some connected (complex) Lie subgroups <span
class="math inline">\(N\)</span> and <span
class="math inline">\(B\)</span> of <span
class="math inline">\(G\)</span>, with <span
class="math inline">\(N\)</span> a normal Lie subgroup of <span
class="math inline">\(B\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 155</strong>. </p>
<ol type="i">
<li><p>The Lie subgroups <span class="math inline">\(N, A\)</span> and
<span class="math inline">\(B\)</span> of <span
class="math inline">\(G\)</span> are closed.</p></li>
<li><p><span class="math inline">\(N \cap A = \{1\}\)</span>.</p></li>
<li><p><span class="math inline">\(B = N A\)</span>; more precisely,
<span class="math inline">\(B\)</span> is the semidirect product of
<span class="math inline">\(N\)</span> and <span
class="math inline">\(A\)</span>.</p></li>
</ol>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> In the special case <span class="math inline">\(K =
\mathop{\mathrm{U}}(n)\)</span>, these conclusions are clear by
inspection of the explicit descriptions given above (which depended upon
the choice of <span class="math inline">\(C\)</span>, but the choice
doesn’t matter, because any two choices are <span
class="math inline">\(W\)</span>-conjugate). In general, choose a
faithful representation <span class="math inline">\((\pi,V)\)</span> of
<span class="math inline">\(K\)</span> and a basis <span
class="math inline">\(e_1,\dotsc,e_n\)</span> of <span
class="math inline">\(V\)</span> consisting of weight vectors for <span
class="math inline">\(T\)</span>, thus <span class="math inline">\(t e_j
= t^{\lambda_j} e_j\)</span> for some <span
class="math inline">\(\lambda_j \in X(T)\)</span>. We may assume that
this basis has been ordered in such a way that if <span
class="math inline">\(\lambda_i &lt; \lambda_j\)</span> (with respect to
the partial order defined by <span class="math inline">\(C\)</span>),
then <span class="math inline">\(i &lt; j\)</span>. Since for <span
class="math inline">\(x \in \mathfrak{g}^\alpha\)</span> with <span
class="math inline">\(\alpha &gt; 0\)</span> we have <span
class="math inline">\(d \pi(x) : V^{\lambda} \rightarrow
V^{\lambda+\alpha}\)</span> and <span class="math inline">\(\lambda +
\alpha &gt; \lambda\)</span>, we see that <span class="math inline">\(d
\pi(x) \in
\begin{pmatrix}
    0 &amp; \ast &amp; \ast \\
    &amp; 0 &amp; \ast \\
    &amp; &amp; 0
  \end{pmatrix}\)</span>. On the other hand, <span
class="math inline">\(d \pi(\mathfrak{t}_{\mathbb{C}}) \subseteq
\begin{pmatrix}
    \ast &amp; \ast &amp; \ast \\
    &amp; \ast &amp; \ast \\
    &amp; &amp; \ast
  \end{pmatrix}\)</span>. Exponentiating, it follows that <span
class="math inline">\(\pi(N) \subseteq
\begin{pmatrix}
    1 &amp; \ast &amp; \ast \\
    &amp; 1 &amp; \ast \\
    &amp; &amp; 1
  \end{pmatrix}\)</span> and <span class="math inline">\(\pi(A)
\subseteq
\begin{pmatrix}
    \ast &amp;  &amp;  \\
    &amp; \ast &amp;  \\
    &amp; &amp; \ast
  \end{pmatrix}\)</span>. In particular, <span class="math inline">\(A
\cap N = \{1\}\)</span>.</p>
<p>We claim now that <span class="math inline">\(A\)</span> and <span
class="math inline">\(N\)</span> are closed. (The remaining assertions
then follow readily.) We identify <span class="math inline">\(G\)</span>
with its image under <span class="math inline">\(\pi\)</span>.
(Apologies in advance if these proofs are sloppy. The customary way to
develop this material is in the language of algebraic groups. I don’t
know offhand of a reference for the approach taken here.)</p>
<p>Start with <span class="math inline">\(N\)</span>. Recall that, by
definition, <span class="math inline">\(N\)</span> is generated by the
image under <span class="math inline">\(\exp\)</span> of small elements
of <span class="math inline">\(\mathfrak{n}\)</span>. Let <span
class="math inline">\(\mathfrak{n}_1 :=
\begin{pmatrix}
    0 &amp; \ast &amp; \ast \\
    &amp; 0 &amp; \ast \\
    &amp; &amp; 0
  \end{pmatrix}
\geq \mathfrak{n}\)</span> denote the Lie algebra consisting of strictly
upper-triangular matrices, and <span class="math inline">\(N_1 :=
\begin{pmatrix}
    1 &amp; \ast &amp; \ast \\
    &amp; 1 &amp; \ast \\
    &amp; &amp; 1
  \end{pmatrix}
  \geq N\)</span> the corresponding Lie gruop. Then we have mutually
inverse diffeomorphisms <span class="math inline">\(\exp :
\mathfrak{n}_1 \rightarrow N_1\)</span> and <span
class="math inline">\(\log : N_1 \rightarrow \mathfrak{n}_1\)</span>
given by finite Taylor series. In particular, the exponential map is
defined on all of <span class="math inline">\(\mathfrak{n}\)</span>.
Using the BCH formula, we see that in fact <span class="math inline">\(N
= \exp(\mathfrak{n})\)</span>. Since <span
class="math inline">\(\mathfrak{n}\)</span> is closed in <span
class="math inline">\(\mathfrak{n}_1\)</span>, it follows that <span
class="math inline">\(N\)</span> is closed in <span
class="math inline">\(N_1\)</span>. Since <span
class="math inline">\(N_1 \cap G\)</span> is closed in <span
class="math inline">\(G\)</span>, we conclude that <span
class="math inline">\(N\)</span> is closed in <span
class="math inline">\(G\)</span>.</p>
<p>We turn to <span class="math inline">\(A\)</span>. Let <span
class="math inline">\(A_1 :=
  \begin{pmatrix}
    \mathbb{C}^\times  &amp;  &amp;  \\
    &amp; \mathbb{C}^\times  &amp;  \\
    &amp; &amp; \mathbb{C}^\times
  \end{pmatrix}
  \geq A\)</span> denote the diagonal subgroup of <span
class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, and
<span class="math inline">\(T_1 :=
\begin{pmatrix}
    \mathop{\mathrm{U}}(1) &amp;  &amp;  \\
    &amp; \mathop{\mathrm{U}}(1) &amp;  \\
    &amp; &amp; \mathop{\mathrm{U}}(1)
  \end{pmatrix}\)</span> its standard maximal torus, so that <span
class="math inline">\(A_1 \geq T_1 \geq T\)</span>. We get <span
class="math inline">\(\mathfrak{t}_{1,\mathbb{R}} \geq
\mathfrak{t}_{\mathbb{R}}\)</span> and <span
class="math inline">\(\mathfrak{t}_{1,\mathbb{Z}} \geq
\mathfrak{t}_{\mathbb{Z}}\)</span>. Since <span
class="math inline">\(T_1 \hookrightarrow T\)</span>, we have <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}} =
\mathfrak{t}_{1,\mathbb{Z}} \cap \mathfrak{t}_{\mathbb{R}}\)</span>.
Thus we can find a lattice <span class="math inline">\(L \subseteq
\mathfrak{t}_{1,\mathbb{Z}}\)</span> complementary to <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span>, i.e., so that
<span class="math inline">\(\mathfrak{t}_{1,\mathbb{Z}} =
\mathfrak{t}_{\mathbb{Z}} \oplus L\)</span>. Choosing bases for these
lattices, we can identify <span
class="math inline">\(\mathfrak{t}_{1,\mathbb{Z}}\)</span> with <span
class="math inline">\(\mathbb{Z}^n\)</span> and <span
class="math inline">\(\mathfrak{t}_{\mathbb{Z}}\)</span> with <span
class="math inline">\(\mathbb{Z}^m\)</span> for some <span
class="math inline">\(0 \leq m \leq n\)</span> in such a way that the
inclusion <span class="math inline">\(\mathfrak{t}_{\mathbb{Z}}
\hookrightarrow \mathfrak{t}_{1,\mathbb{Z}}\)</span> is the standard
one. In the coordinates defined by these bases, the inclusions <span
class="math inline">\(T = \mathop{\mathrm{U}}(1)^m \hookrightarrow T_1 =
\mathop{\mathrm{U}}(1)^n\)</span> and <span class="math inline">\(A =
(\mathbb{C}^\times)^m \hookrightarrow (\mathbb{C}^\times)^n =
A_1\)</span> are then likewise the standard ones; in particular, the
latter has closed image. ◻</p>
</span></div>
<p>In particular, <span class="math inline">\(B/N \cong A\)</span>. We
may and shall thus extend each homomorphism <span
class="math inline">\(\chi : A \rightarrow \mathbb{C}^\times\)</span> to
a homomorphism <span class="math inline">\(\chi : B \rightarrow
\mathbb{C}^\times\)</span> that is trivial on <span
class="math inline">\(N\)</span>, thus <span
class="math inline">\(\chi(n a) = \chi(a)\)</span>. We’ll often write
<span class="math inline">\(b^{\chi} := \chi(b)\)</span>.</p>
<div id="thm:highest-weight-borel-weil" class="theorem">
<p><strong>Theorem 156</strong>. <em>Let <span
class="math inline">\(\pi\)</span> be an irreducible holomorphic
finite-dimensional representation of <span
class="math inline">\(G\)</span>. There is a unique holomorphic
character <span class="math inline">\(\lambda : A \rightarrow
\mathbb{C}^\times\)</span> and a unique-up-to-scalars nonzero vector
<span class="math inline">\(v \in \pi\)</span> so that <span id="eqn:v-is-a-B-eigenvector" class="math display">\[\label{eqn:v-is-a-B-eigenvector}\tag{90}
    \pi(b) v = b^{\lambda} v
    \text{ for all }
    b \in B.\]</span> Moreover, <span
class="math inline">\(\lambda\)</span> is the highest weight of <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(v\)</span> is a highest weight vector.</em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Existence: Let <span class="math inline">\(\lambda
\in X(T)\)</span> be the highest weight of <span
class="math inline">\(\pi\)</span> (via Theorem <a
href="#thm:highest-weight-general-gp" data-reference-type="ref"
data-reference="thm:highest-weight-general-gp">153</a>, and using
Theorem <a href="#thm:alg-rep" data-reference-type="ref"
data-reference="thm:alg-rep">83</a> to regard <span
class="math inline">\(\pi\)</span> as an irreducible representation of
<span class="math inline">\(K\)</span>), and <span
class="math inline">\(v \in \pi[\lambda]\)</span> a highest weight
vector. We extend <span class="math inline">\(\lambda\)</span> to a
holomorphic character <span class="math inline">\(A \rightarrow
\mathbb{C}^\times\)</span>. The vector <span
class="math inline">\(v\)</span> is an eigenvector of <span
class="math inline">\(T\)</span> with eigenvalue <span
class="math inline">\(\lambda\)</span>, hence also of <span
class="math inline">\(A\)</span> with eigenvalue <span
class="math inline">\(\lambda\)</span>. A short calculation as in the
proof of Lemma <a href="#lem:root-spaces-permute-weight-spaces"
data-reference-type="ref"
data-reference="lem:root-spaces-permute-weight-spaces">92</a> shows that
<span class="math inline">\(d \pi(X_\alpha) : \pi[\lambda] \rightarrow
\pi[\lambda+\alpha]\)</span>. Since <span
class="math inline">\(\lambda\)</span> is the highest weight of <span
class="math inline">\(\pi\)</span>, we have <span
class="math inline">\(\pi[\lambda+\alpha] = \{0\}\)</span>. Thus <span
class="math inline">\(X_\alpha v = 0\)</span>. Since <span
class="math inline">\(\alpha\)</span> was arbitrary, <span
class="math inline">\(v\)</span> is annihilated by <span
class="math inline">\(\mathfrak{n}\)</span>. Since <span
class="math inline">\(N\)</span> is connected (by construction), it
follows that <span class="math inline">\(v\)</span> is fixed by <span
class="math inline">\(N\)</span>. Thus <span
class="math inline">\(v\)</span> is a <span
class="math inline">\(B\)</span>-eigenvector, as required.</p>
<p>Uniqueness: Suppose given a pair <span
class="math inline">\((v,\lambda)\)</span> as in the conclusion of the
theorem. Our task is to show that <span
class="math inline">\(\lambda\)</span> is in fact the highest weight
<span class="math inline">\(\pi\)</span>. For each finite ordered tuple
<span class="math inline">\((\alpha_1,\dotsc,\alpha_n)\)</span> of
positive roots, the vector <span class="math display">\[X_{-\alpha_1}
\dotsb X_{-\alpha_n} v
    :=
    d \pi(X_{-\alpha_1}) \dotsb d \pi(X_{-\alpha_n}) v\]</span> is a
<span class="math inline">\(T\)</span>-eigenvector of weight <span
class="math inline">\(\lambda - \alpha_1 - \dotsb - \alpha_n\)</span>,
which is strictly lower than <span
class="math inline">\(\lambda\)</span> when <span
class="math inline">\(n \geq 1\)</span>. Call the span of the indicated
vectors <span class="math inline">\(V\)</span>. It suffices to show that
<span class="math inline">\(V = \pi\)</span>. Since <span
class="math inline">\(v \in V\)</span> and <span
class="math inline">\(\pi\)</span> is irreducible, it suffices to show
that <span class="math inline">\(V\)</span> is <span
class="math inline">\(K\)</span>-invariant. Since <span
class="math inline">\(K\)</span> is connected, it is enough to show that
<span class="math inline">\(V\)</span> is <span
class="math inline">\(\mathfrak{g}\)</span>-invariant. To that end,
recall that <span class="math inline">\(\mathfrak{g} =
\mathfrak{t}_{\mathbb{C}} \oplus (\oplus_{\alpha &gt;0} \mathbb{C}
X_\alpha) \oplus (\oplus_{\alpha &gt; 0} \mathbb{C}
X_{-\alpha})\)</span>. It’s clear that <span
class="math inline">\(V\)</span> is invariant by <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> and by <span
class="math inline">\(X_{-\alpha}\)</span> for <span
class="math inline">\(\alpha &gt; 0\)</span>, so it remains only to show
for <span class="math inline">\(\alpha &gt; 0\)</span> that <span
class="math inline">\(V\)</span> is <span
class="math inline">\(X_{\alpha}\)</span>-invariant. Differentiating the
condition <a href="#eqn:v-is-a-B-eigenvector"
data-reference-type="eqref"
data-reference="eqn:v-is-a-B-eigenvector">\((90)\)</a>,
we see that <span class="math inline">\(v\)</span> is annihilated by
<span class="math inline">\(X_{\alpha}\)</span>. It remains to check for
<span class="math inline">\(n \geq 1\)</span> that <span
class="math inline">\(X_{\alpha} X_{-\alpha_1} \dotsb X_{-\alpha_n}
v\)</span> belongs to <span class="math inline">\(V\)</span>. Set <span
class="math inline">\(u := X_{-\alpha_2} \dotsb X_{-\alpha_n}
v\)</span>. Then <span class="math inline">\(X_{\alpha} X_{-\alpha_1} u
= X_{-\alpha_1} X_\alpha u + [X_{\alpha}, X_{-\alpha_1}] u\)</span>. By
induction on <span class="math inline">\(n\)</span>, both <span
class="math inline">\(X_{-\alpha} u\)</span> and <span
class="math inline">\([X_{\alpha}, X_{-\alpha_1}] u\)</span> belong to
<span class="math inline">\(V\)</span>. Since <span
class="math inline">\(X_{-\alpha_1}\)</span> stabilizes <span
class="math inline">\(V\)</span>, the required conclusion follows. ◻</p>
</span></div>
<p>Now let <span class="math inline">\(\lambda \in X(T)\)</span> be a
dominant weight, and consider the vector space <span
class="math display">\[F_\lambda := \{f : G \rightarrow \mathbb{C} :
  \text{holomorphic},
  f(b g) = b^{-\lambda} f(g) \text{ for } b \in B, g \in G
  \}.\]</span> The group <span class="math inline">\(G\)</span> (and
hence also its subgroup <span class="math inline">\(K\)</span>) acts on
<span class="math inline">\(F_\lambda\)</span> by right translation. We
will show the following:</p>
<div id="thm:borel-weil-construction" class="theorem">
<p><strong>Theorem 157</strong>. <em>Let <span
class="math inline">\(\pi_\lambda\)</span> denote the irreducible
representation of <span class="math inline">\(K\)</span> of highest
weight <span class="math inline">\(\lambda\)</span>. Then <span
class="math inline">\(\pi_\lambda \cong F_\lambda^*\)</span>. Here <span
class="math inline">\(F_\lambda^*\)</span> denotes the dual
representation of <span class="math inline">\(F_\lambda\)</span>,
regarded as a representation of <span class="math inline">\(K\)</span>;
alternatively, we may use Theorem <a href="#thm:alg-rep"
data-reference-type="ref" data-reference="thm:alg-rep">83</a> to extend
<span class="math inline">\(\pi_\lambda\)</span> to an algebraic
representation of <span class="math inline">\(G\)</span>, and the
isomorphism is then of algebraic representations of <span
class="math inline">\(G\)</span>.</em></p>
</div>
<p>We compute in passing the dual of <span
class="math inline">\(\pi_\lambda\)</span>. Note that if <span
class="math inline">\(C\)</span> is a Weyl chamber, then so is <span
class="math inline">\(-C\)</span>; since the Weyl group acts
simply-transitively on the chambers, there is thus a unique <span
class="math inline">\(w_0 \in W\)</span> for which <span
class="math inline">\(w_0(C) = - C\)</span>. (It is often called the
<em>longest Weyl element</em>, with the notion of “longest”
corresponding to <span class="math inline">\(C\)</span>). For instance,
if <span class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span> and
<span class="math inline">\(C\)</span> is chosen in the usual way, then
<span class="math inline">\(w_0 =
\begin{pmatrix}
  &amp;  &amp; 1 \\
  &amp; \dotsb &amp;  \\
  1 &amp; &amp;
\end{pmatrix}\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 158</strong>. <span class="math inline">\(\pi_\lambda^*
\cong \pi_{-w_0(\lambda)}\)</span>.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> It’s clear that <span
class="math inline">\(\pi_\lambda^*\)</span> is an irreducible, hence is
isomorphic to <span class="math inline">\(\pi_{\mu}\)</span> for some
dominant weight <span class="math inline">\(\mu\)</span>. We must verify
that <span class="math inline">\(\mu = - w_0 (\lambda)\)</span>, or
equivalently, that <span class="math inline">\(\lambda = -
w_0(\mu)\)</span>. We check first that <span
class="math inline">\(-\mu\)</span> is the lowest weight of <span
class="math inline">\(\pi_\lambda\)</span>. From this it follows that
<span class="math inline">\(- w_0 (\mu)\)</span> is the highest weight
of <span class="math inline">\(\pi_\lambda\)</span>, and so <span
class="math inline">\(\lambda = - w_0(\mu)\)</span>, as required. ◻</p>
</span></div>
<p>Thus Theorem <a href="#thm:borel-weil-construction"
data-reference-type="ref"
data-reference="thm:borel-weil-construction">157</a> tells us that <span
class="math display">\[\pi_{\lambda}
  \cong F_{-w_0(\lambda)}.\]</span></p>
<div class="proof">
<p><em>Proof of Theorem <a href="#thm:borel-weil-construction"
data-reference-type="ref"
data-reference="thm:borel-weil-construction">157</a>.</em> Let <span
class="math inline">\(F\)</span> denote the space of all holomorphic
functions <span class="math inline">\(f : G \rightarrow
\mathbb{C}\)</span>, and let <span class="math inline">\(f \in
F\)</span>. Using the identity principle for holomorphic functions on
<span class="math inline">\(G \cong K \times \mathfrak{p}\)</span>, we
may identify <span class="math inline">\(f\)</span> with its restriction
to <span class="math inline">\(K\)</span>, and then further with an
element of the space <span class="math inline">\(L^2(K)\)</span>, on
which the group <span class="math inline">\(K \times K\)</span> acts by
the regular representation <span class="math inline">\((k_1,k_2) \cdot
f(x) = f(k_1^{-1} x k)\)</span>. We accordingly have an <span
class="math inline">\(L^2(K)\)</span>-decomposition <span
class="math inline">\(f = \sum_{\mu} f_\mu\)</span>, where <span
class="math inline">\(\mu \in X(T)\)</span> runs over the dominant
weights and <span class="math inline">\(f_\mu\)</span> belongs to the
space <span class="math inline">\(\mathcal{A}(\pi_\mu)\)</span> of
matrix coefficients of the representation <span
class="math inline">\(\pi_\mu\)</span>. Let <span
class="math inline">\(L\)</span> and <span
class="math inline">\(R\)</span> denote respectively the left and right
regular representations of <span class="math inline">\(K\)</span> on
<span class="math inline">\(L^2(K)\)</span>. Since <span
class="math inline">\(\mathcal{A}(\pi_\mu) \cong \pi_\mu^* \otimes
\pi_\mu\)</span> is the <span
class="math inline">\(\pi_\mu\)</span>-isotypic component (see §<a
href="#sec:isotyp-decomp" data-reference-type="ref"
data-reference="sec:isotyp-decomp">5.10</a>) of <span
class="math inline">\(L^2(K)\)</span> under <span
class="math inline">\(R\)</span>, we have <span
class="math inline">\(f_\mu = \dim(\pi_\mu) R(\overline{\chi_{\mu}})
f\)</span>. Suppose now that <span class="math inline">\(f \in
F_\lambda\)</span>, i.e., that <span class="math inline">\(L(b) f =
b^{\lambda} f\)</span> for all <span class="math inline">\(b \in
B\)</span>. Since <span class="math inline">\(R\)</span> and <span
class="math inline">\(L\)</span> commute, it follows that <span
class="math inline">\(L(b) f_\mu = b^{\lambda} f_\mu\)</span>, i.e.,
that <span class="math inline">\(f_\mu\)</span> belongs to <span
class="math inline">\(F_\lambda\)</span>. If <span
class="math inline">\(f_\mu\)</span> is nonzero, then we may find a
nonzero vector <span class="math inline">\(v \in \pi_\mu^*\)</span> so
that <span class="math inline">\(b v = b^{\lambda} v\)</span> for all
<span class="math inline">\(b \in B\)</span>. Then Theorem <a
href="#thm:highest-weight-borel-weil" data-reference-type="ref"
data-reference="thm:highest-weight-borel-weil">156</a> implies that
<span class="math inline">\(\pi_\mu^* \cong \pi_\lambda\)</span> and
that <span class="math inline">\(v \in \pi_\lambda\)</span> is a highest
weight vector. Thus <span class="math display">\[f \in (\pi_\lambda
\otimes \pi_\lambda^*) \cap F_\lambda
    = \mathbb{C} v \otimes \pi_\lambda^*.\]</span> Thus <span
class="math inline">\(F_\lambda = \mathbb{C} v \otimes
\pi_\lambda^*\)</span>, hence <span class="math inline">\(F_\lambda
\cong \pi_\lambda^*\)</span>. ◻</p>
</div>
<h1 id="plancherel-formula-for-complex-reductive-groups">Plancherel
formula for complex reductive groups</h1>
<p>With the remaining fewl ectures in the course, we aim to treat some
of the simplest aspects of the representation theory of non-compact
groups. We focus on the case of complex reductive groups, which are
simpler than real reductive groups for reasons to be explained
later.</p>
<p>Let <span class="math inline">\(G\)</span> be a unimodular group
equipped with a Haar measure <span class="math inline">\(d g\)</span>,
and let <span class="math inline">\(f : G \rightarrow
\mathbb{C}\)</span> be nice enough (e.g., smooth and compactly-supported
in the case of a Lie group). We’ve seen in §<a
href="#sec:four-analys-comp" data-reference-type="ref"
data-reference="sec:four-analys-comp">5.9</a> that for <span
class="math inline">\(G\)</span> compact, one has the Fourier inversion
formula <span class="math display">\[f(1)
  =
  \sum_{\pi \in \mathop{\mathrm{Irr}}(G)}
  \frac{\dim(\pi)}{\mathop{\mathrm{vol}}(G)}
  \mathop{\mathrm{trace}}(\pi(f)).\]</span> (We showed this when <span
class="math inline">\(\mathop{\mathrm{vol}}(G) = 1\)</span>, but the
general case follows because <span class="math inline">\(\pi(f)\)</span>
and <span class="math inline">\(\mathop{\mathrm{vol}}(G)\)</span> scale
in the same way when one scales <span class="math inline">\(d
g\)</span>.) In the non-compact case, one seeks a formula of the shape
<span id="eqn:general-plancherel" class="math display">\[\label{eqn:general-plancherel}\tag{91}
  f(1)
  = \int_{\pi \in \hat{G}}
  \mathop{\mathrm{trace}}(\pi(f))
  \, d \mu_P(\pi),\]</span> where now <span
class="math inline">\(\hat{G}\)</span> denotes the set of isomorphism
classes of irreducible unitary representations of <span
class="math inline">\(G\)</span> and <span class="math inline">\(d
\mu_P\)</span> denotes a measure on <span
class="math inline">\(\hat{G}\)</span>, called <em>Plancherel
measure</em>, which scales inversely to <span class="math inline">\(d
g\)</span>. For instance, the Fourier inversion formulas on the circle
<span class="math display">\[f(0)
  = \sum_{n \in \mathbb{Z}}
  \hat{f}(n),
  \quad
  \hat{f}(n) := \int_{x \in \mathbb{R}/\mathbb{Z}}
  f(x) e^{2 \pi i n x} \, d x,
  \quad
  f \in C^\infty(\mathbb{R}/\mathbb{Z})\]</span> and on the real line
<span class="math display">\[f(0)
  = \sum_{\xi \in \mathbb{R}}
  \hat{f}(\xi)
  \, d \xi,
  \quad
  \hat{f}(\xi) := \int_{x \in \mathbb{R}/\mathbb{Z}}
  f(x) e^{2 \pi i n x} \, d x,
  \quad
  f \in C_c^\infty(\mathbb{R})\]</span> may be interpreted in this way;
for instance, in the second example, <span
class="math inline">\(\hat{f}(\xi)\)</span> is the trace of <span
class="math inline">\(\pi_\xi(f)\)</span>, where <span
class="math inline">\(\pi_\xi\)</span> denotes the one-dimensional
representation of <span class="math inline">\(\mathbb{R}\)</span>,
spanned by the function <span class="math inline">\(\mathbb{R} \ni x
\mapsto e^{2 \pi i \xi x}\)</span>, and with <span
class="math inline">\(\mathbb{R}\)</span> acting by right
translation.</p>
<p>In a course emphasizing the functional analytic aspects of
representation theory one might study general conditions under which
such formulas <a href="#eqn:general-plancherel"
data-reference-type="eqref"
data-reference="eqn:general-plancherel">\((91)\)</a>
exist (e.g., look up the definition of a “Type I” group). Here we will
focus instead on the problem of determining <span
class="math inline">\(\mu_P\)</span> explicitly for a more restricted
class of groups, namely the connected complex reductive groups.</p>
<p>We will use much of the same notation as above. We start with a
compact connected Lie group <span class="math inline">\(K\)</span>. We
denote by <span class="math inline">\(G\)</span> its complexification.
We fix a maximal torus <span class="math inline">\(T\)</span> and Weyl
chamber <span class="math inline">\(C\)</span>. We use these to define
subgroups <span class="math inline">\(N\)</span>, <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> of <span
class="math inline">\(G\)</span>, as in §<a href="#sec:borel-weil"
data-reference-type="ref" data-reference="sec:borel-weil">8.3</a>. The
example <span class="math inline">\(K = \mathop{\mathrm{U}}(n)\)</span>
depicted earlier is worth keeping in mind.</p>
<p>We note that <span class="math inline">\(G\)</span> is unimodular. To
see this, we must show that <span
class="math inline">\(|\det(\mathop{\mathrm{Ad}}(g))| = 1\)</span> for
all <span class="math inline">\(g \in G\)</span>. It suffices to verify
the stronger identity <span id="eqn:det-circ-Ad-equals-1" class="math display">\[\label{eqn:det-circ-Ad-equals-1}\tag{92}
  \det(\mathop{\mathrm{Ad}}(g)) = 1\]</span> By the identity principle
for holomorphic functions applied to <span class="math inline">\(\det
\circ \mathop{\mathrm{Ad}}: G \rightarrow \mathbb{C}^\times\)</span>, we
need only verify <a href="#eqn:det-circ-Ad-equals-1"
data-reference-type="eqref"
data-reference="eqn:det-circ-Ad-equals-1">\((92)\)</a>
holds for <span class="math inline">\(g \in K\)</span>. Since <span
class="math inline">\(\det \circ \mathop{\mathrm{Ad}}\)</span> is a
class function, we reduce further to verifying <a
href="#eqn:det-circ-Ad-equals-1" data-reference-type="eqref"
data-reference="eqn:det-circ-Ad-equals-1">\((92)\)</a>
when <span class="math inline">\(g = t \in T\)</span>, and indeed, <span
class="math inline">\(\det(\mathop{\mathrm{Ad}}(t)) = \prod_{\alpha \in
\Phi} t^\alpha = \prod_{\alpha &gt; 0} t^{\alpha} t^{-\alpha} =
1\)</span>.</p>
<h2 id="sec:iwas-decomp">§9.1. Iwasawa decomposition</h2>
<p>In its most basic form it asserts that <span class="math display">\[G
= B  K.\]</span> Moreover, <span class="math display">\[B \cap K =
T.\]</span> In the case <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, this amounts to the
Gram–Schmidt procedure (explanation given in class). We record the proof
for general <span class="math inline">\(G\)</span>. We consider first
the analogous Lie algebra question. To start, we might write any element
of <span class="math inline">\(\mathfrak{g}\)</span> as <span
class="math inline">\(x + y + z\)</span> using the decomposition <span
class="math display">\[\mathfrak{g} = \mathfrak{t}_{\mathbb{C}} \oplus
\mathfrak{n} \oplus \overline{\mathfrak{n}},\]</span> where <span
class="math inline">\(\mathfrak{n} = \oplus_{\alpha &gt; 0}
\mathfrak{g}^\alpha\)</span> and <span class="math inline">\(\overline{
\mathfrak{n} } = \oplus_{\alpha &lt; 0} \mathfrak{g}^\alpha\)</span>. We
may write <span class="math inline">\(x = x_0 + x_1\)</span> with <span
class="math inline">\(x_0 \in \mathfrak{t}_{\mathbb{R}}, x_1 \in i
\mathfrak{t}_{\mathbb{R}}\)</span>, say. Then the element <span
class="math inline">\(w := x_1 + z + \theta (z)\)</span> is <span
class="math inline">\(\theta\)</span>-invariant, hence belongs to <span
class="math inline">\(\mathfrak{k}\)</span>. On the other hand, <span
class="math inline">\(y - \theta(z)\)</span> belongs to <span
class="math inline">\(\mathfrak{n}\)</span>. Thus <span
class="math display">\[x + y + z = w + x_0 + (y - \theta(z)) \in
\mathfrak{k} + \mathfrak{t}_{\mathbb{R}} + \mathfrak{n} .\]</span> In
particular, <span id="eqn:Lie-alg-iwasawa" class="math display">\[\label{eqn:Lie-alg-iwasawa}\tag{93}
  \mathfrak{g} =
  \mathfrak{b} + \mathfrak{k}.\]</span> Using that <span
class="math inline">\(\mathfrak{k} = \{x \in \mathfrak{g} : \theta(x) =
x\}\)</span> and that <span class="math inline">\(\theta\)</span> swaps
<span class="math inline">\(\mathfrak{n}\)</span> and <span
class="math inline">\(\overline{\mathfrak{n}}\)</span> and acts on <span
class="math inline">\(\mathfrak{t}_{\mathbb{C}}\)</span> with fixed
subspace <span class="math inline">\(I
\mathfrak{t}_{\mathbb{R}}\)</span>, we see that <span
class="math display">\[\mathfrak{b} \cap \mathfrak{k} = i
\mathfrak{t}_{\mathbb{R}}.\]</span></p>
<p>We now turn to the groups. We’ve seen that <span
class="math inline">\(B\)</span> is a closed subgroup of <span
class="math inline">\(G\)</span>. Since <span
class="math inline">\(K\)</span> is compact, it follows that <span
class="math inline">\(B K\)</span> is closed. Using <a
href="#eqn:Lie-alg-iwasawa" data-reference-type="eqref"
data-reference="eqn:Lie-alg-iwasawa">\((93)\)</a> and
computing the derivative of the map <span class="math inline">\(B \times
K \xrightarrow{(b,g) \mapsto b g } G\)</span> as in the proof of the
Weyl integral formula, we see moreover that <span
class="math inline">\(B K\)</span> is open (see for instance Knapp,
Lemma 5.11). Since <span class="math inline">\(G\)</span> is connected,
we conclude that <span class="math inline">\(G = B K\)</span>.</p>
<h2 id="sec:integr-b-backsl">§9.2. Integration on <span
class="math inline">\(B \backslash G\)</span></h2>
<p>We fix a Haar measure <span class="math inline">\(d g\)</span> on
<span class="math inline">\(G\)</span> and a left Haar measure <span
class="math inline">\(d b\)</span> on <span
class="math inline">\(B\)</span>. Using these choices we will define a
notion of integration over <span class="math inline">\(B \backslash
G\)</span>.</p>
<p>Let <span class="math inline">\(\mathcal{F}\)</span> denote the space
of measurable functions <span class="math inline">\(f : G \rightarrow
\mathbb{C}\)</span> such that <span class="math display">\[f(b g) =
\delta(b) f(g)\]</span> for all <span class="math inline">\(b \in B, g
\in G\)</span> and <span class="math inline">\(\int_K |f| &lt;
\infty\)</span>, the latter integral taken with respect to any Haar
measure on <span class="math inline">\(K\)</span>.</p>
<div class="lemma">
<p><strong>Lemma 159</strong>. Each <span class="math inline">\(f \in
\mathcal{F}\)</span> is of the form <span class="math inline">\(f(g) =
\int_{B} \tilde{f}(b g) \, d b\)</span> for some <span
class="math inline">\(\tilde{f} : G \rightarrow \mathbb{C}\)</span>. The
map <span class="math inline">\(\mathcal{F} \ni f \mapsto \int_G
\tilde{f}(g) \, d g\)</span> is a well-defined linear functional on
<span class="math inline">\(\mathcal{F}\)</span> that is invariant under
right translation by <span class="math inline">\(G\)</span>. We denote
this linear functional by <span class="math inline">\(f \mapsto \int_{B
\backslash G} f\)</span>. We have <span class="math inline">\(\int_{B
\backslash G} f = c \int_K f\)</span> for some constant <span
class="math inline">\(c &gt; 0\)</span>, depending only upon the various
choices of Haar measure.</p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Left to the reader; this or some variant was treated
in “Lie groups I”. ◻</p>
</span></div>
<h2 id="principal-series-representations">Principal series
representations</h2>
<p>We denote by <span class="math inline">\(A^\wedge\)</span> the group
of unitary characters of <span class="math inline">\(A\)</span>, thus
<span class="math inline">\(A^\wedge\)</span> consists of continuous
homomorphisms <span class="math inline">\(\chi : A \rightarrow
\mathop{\mathrm{U}}(1)\)</span>. We similarly define the group <span
class="math inline">\(\mathfrak{a}^\wedge\)</span> of unitary characters
of <span class="math inline">\(A\)</span>. Using the surjective quotient
map <span class="math inline">\(\mathfrak{a} \rightarrow A\)</span>
given by exponentiation, we may identify <span
class="math inline">\(A^\wedge\)</span> with a subgroup of <span
class="math inline">\(\mathfrak{a}^\wedge\)</span>. On the other hand,
by differentiating at the origin, we may identify <span
class="math inline">\(\mathfrak{a}^\wedge\)</span> with the <span
class="math inline">\(\mathbb{R}\)</span>-vector space consisting of
linear functionals <span class="math inline">\(\mathfrak{a} \rightarrow
i\mathbb{R}\)</span>. Concretely, suppose <span
class="math inline">\(A\)</span> is the group of diagonal matrices in
<span class="math inline">\({\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>.
Write <span class="math inline">\(a \in A\)</span> in coordinates as
<span class="math inline">\(a = (a_1,\dotsc,a_n)\)</span> with <span
class="math inline">\(a_j \in \mathbb{C}^\times\)</span>. Then every
<span class="math inline">\(\chi \in A^\wedge\)</span> is of the form
<span class="math inline">\(\chi(a) = \prod_j a_j^{s_j}
(a_j/|a_j|)^{k_j}\)</span> for some <span class="math inline">\(s_j \in
i \mathbb{R}\)</span> and <span class="math inline">\(k_j \in
\mathbb{Z}\)</span>, and this defines an isomorphism <span
class="math inline">\(A^\wedge \cong (i \mathbb{R})^n \times
\mathbb{Z}^n\)</span>. Similarly, we may identify <span
class="math inline">\(\mathfrak{a}\)</span> with the group <span
class="math inline">\(\mathbb{C}^n\)</span> of diagonal matrices <span
class="math inline">\(x = (x_1,\dotsc,x_n)\)</span> in <span
class="math inline">\(M_n(\mathbb{C})\)</span> and <span
class="math inline">\(\mathfrak{a}^\wedge\)</span> with the group <span
class="math inline">\((i \mathbb{R})^n \times \mathbb{R}^n\)</span>.</p>
<p>To each <span class="math inline">\(\lambda \in
\mathop{\mathrm{Hom}}(A,\mathbb{C}^\times)\)</span> we attach a
“principal series representation” <span
class="math inline">\(\pi_\lambda\)</span>, consisting of measurable
functions <span class="math inline">\(v : G \rightarrow
\mathbb{C}\)</span> satisfying <span class="math display">\[v(b x)
  =
  \delta^{1/2}(b) b^{\lambda} v(x)\]</span> for all <span
class="math inline">\(b \in B, x \in G\)</span> and <span
class="math display">\[\int_{K} |v|^2 &lt; \infty.\]</span> Thanks to
the Iwasawa decomposition, we may regard <span
class="math inline">\(\pi_{\lambda}\)</span> as a closed subspace of the
Hilbert space <span class="math inline">\(L^2(K)\)</span>. The group
<span class="math inline">\(G\)</span> acts on <span
class="math inline">\(\pi_\lambda\)</span> by right translation. We note
that if <span class="math inline">\(f_1 \in \pi_{\lambda}\)</span> and
<span class="math inline">\(f_2 \in \pi_{-\lambda}\)</span>, then <span
class="math inline">\(f_1 f_2\)</span> belongs to the space <span
class="math inline">\(\mathcal{F}\)</span> considered in §<a
href="#sec:integr-b-backsl" data-reference-type="ref"
data-reference="sec:integr-b-backsl">9.2</a>, and so we obtain a <span
class="math inline">\(G\)</span>-invariant pairing <span
class="math display">\[\pi_{\lambda} \otimes \pi_{-\lambda} \rightarrow
\mathbb{C}\]</span> <span class="math display">\[f_1 \otimes f_2 \mapsto
\int_{B \backslash G} f_1 f _2.\]</span> Also, <span
class="math inline">\(\overline{\pi_{\lambda}} = \pi_{-
\overline{\lambda }}\)</span>. Thus if <span
class="math inline">\(\lambda\)</span> belongs to <span
class="math inline">\(A^\wedge =
\mathop{\mathrm{Hom}}(A,\mathop{\mathrm{U}}(1))\)</span>, so that <span
class="math inline">\(\lambda = - \overline{\lambda }\)</span>, then
integration over <span class="math inline">\(B \backslash G\)</span>
defines a <span class="math inline">\(G\)</span>-invariant inner product
on <span class="math inline">\(\pi_{\lambda}\)</span>, hence <span
class="math inline">\(\pi_{\lambda}\)</span> is a unitary representation
of <span class="math inline">\(G\)</span>.</p>
<h2 id="characters-of-principal-series-representations">Characters of
principal series representations</h2>
<p>Recall that we equip <span class="math inline">\(G\)</span> with a
Haar measure <span class="math inline">\(d g\)</span> and <span
class="math inline">\(B\)</span> with a left Haar measure <span
class="math inline">\(d b\)</span>; this normalizes an integral over
<span class="math inline">\(B \backslash G\)</span> in the sense
described above. To each <span class="math inline">\(f \in
C_c(G)\)</span> we attach an integral operator <span
class="math inline">\(\pi(f) \in \mathop{\mathrm{End}}(\pi)\)</span>, as
in §<a href="#sec:integral-operators" data-reference-type="ref"
data-reference="sec:integral-operators">5</a>, by the formula <span
class="math inline">\(\pi(f) := \int_{g \in G} f(g) \pi(g) \, d
g\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 160</strong>. <em>For each <span
class="math inline">\(f \in C_c^\infty(G)\)</span>, the operator <span
class="math inline">\(\pi_\lambda(f)\)</span> is trace class. We have
<span id="eq:preliminary-formula-character-ps" class="math display">\[\label{eq:preliminary-formula-character-ps}\tag{94}
    \mathop{\mathrm{trace}}(\pi_\lambda(f))
    = \int_{g \in B \backslash G}
    \int_{b \in B}
    f(g^{-1} b g) \delta^{1/2}(b) b^{\lambda}.\]</span></em></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Let <span class="math inline">\(v \in
\pi_\lambda\)</span>. By definition, <span class="math display">\[\pi(f)
v(x)
    = \int _{g \in G} f(g) v(x g),\]</span> where here and henceforth we
the omit Haar measures for notational simplicity. We apply the
substitutinon <span class="math inline">\(g \mapsto x^{-1} g\)</span> to
rewrite the above as <span class="math display">\[\int_{g \in G}
f(x^{-1} g) v(g).\]</span> We next use the defining property of <span
class="math inline">\(\int_{B \backslash G}\)</span> to rewrite the
above as <span class="math display">\[\int _{y \in B \backslash G} \int
_{b \in B} f (x ^{-1} b y) v (b y).\]</span> Since <span
class="math inline">\(v(b y) = \delta^{1/2}(b) b^{\lambda}
v(y)\)</span>, it follows that <span id="eq:pi-of-f-via-k" class="math display">\[\label{eq:pi-of-f-via-k}\tag{95}
    \pi(f) v(x)
    = \int _{y \in B \backslash G}
    v(y) k(x,y)\]</span> with <span class="math display">\[k(x,y) :=
\int _{b \in B} \delta^{1/2}(b) b^{\lambda} f(x^{-1} b y).\]</span>
Since <span class="math inline">\(B\)</span> is closed and <span
class="math inline">\(f \in C_c^\infty(G)\)</span>, we have <span
class="math inline">\(k \in C^\infty(G \times G)\)</span>. It follows
readily from the definition that <span id="eq:functional-eqn-for-k-kernel-ps" class="math display">\[\label{eq:functional-eqn-for-k-kernel-ps}\tag{96}
    k(b_1 x, b_2 y) = \delta^{1/2} (b_1) b_1^{\lambda}
    \delta^{1/2} (b_2) b_2^{-\lambda} k(x,y)
    \text{ for } b_1, b_2 \in B.\]</span> Note that the diagonal kernel
integral <span id="eq:diagonal-kernel-integral" class="math display">\[\label{eq:diagonal-kernel-integral}\tag{97}
    \int_{x \in B \backslash G} k(x,x)\]</span> is the RHS of <a
href="#eq:preliminary-formula-character-ps" data-reference-type="eqref"
data-reference="eq:preliminary-formula-character-ps">\((94)\)</a>.</p>
<p>The remainder of the argument is a bit of standard functional
analysis. It suffice to show more generally that if <span
class="math inline">\(T\)</span> is any operator on <span
class="math inline">\(\pi\)</span> defined as in <a
href="#eq:pi-of-f-via-k" data-reference-type="eqref"
data-reference="eq:pi-of-f-via-k">\((95)\)</a> by a smooth
kernel <span class="math inline">\(k \in C^\infty(G \times G)\)</span>
satisfying <a href="#eq:functional-eqn-for-k-kernel-ps"
data-reference-type="eqref"
data-reference="eq:functional-eqn-for-k-kernel-ps">\((96)\)</a>,
then <span class="math inline">\(T\)</span> defines a trace class
operator with trace given by <a href="#eq:diagonal-kernel-integral"
data-reference-type="eqref"
data-reference="eq:diagonal-kernel-integral">\((97)\)</a>.
This can be proved in the same way as the following statement, which may
have come up in a functional analysis course:</p>
<div class="center">
<p>Let <span class="math inline">\((M,\mu)\)</span> be a compact
manifold equipped with a smooth finite measure, and let <span
class="math inline">\(k \in C^\infty(M \times M)\)</span>. Then the
operator <span class="math inline">\(T\)</span> on <span
class="math inline">\(L^2(M,\mu)\)</span> defined by <span
class="math inline">\(T v(x) := \int v(y) k(x,y) \, d \mu(y)\)</span> is
trace class, with <span class="math inline">\(\mathop{\mathrm{trace}}(T)
= \int k(x,x) \, d \mu(x)\)</span>.</p>
</div>
<p>One can prove this by reducing first to the case that <span
class="math inline">\(M\)</span> is a compact torus and then appealing
to Fourier series. ◻</p>
</span></div>
<h2 id="some-basics-concerning-conjugacy-classes-in-g">Some basics
concerning conjugacy classes in <span
class="math inline">\(G\)</span></h2>
<p>Every such class intersects <span class="math inline">\(B\)</span>,
that is to say, <span class="math inline">\(G = \cup_{x \in B \backslash
G} x^{-1} B x\)</span>. For instance, if <span class="math inline">\(G =
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>, then this follows from the
Jordan normal form. To sketch a proof in general, it suffices to show
for each <span class="math inline">\(g \in G\)</span> that the map <span
class="math display">\[g : B \backslash G \rightarrow B \backslash
G\]</span> <span class="math display">\[B x \mapsto B x g\]</span> has a
fixed point (because if <span class="math inline">\(B x = B x
g\)</span>, then <span class="math inline">\(g \in x^{-1} B x\)</span>).
One way to see this is to use that <span class="math inline">\(B
\backslash G \cong T \backslash K\)</span> (a consequence of the Iwasawa
decomposition) and then to show as in one of the standard proofs of the
conjugacy of maximal tori (not the one presented in this course) that
any map <span class="math inline">\(T \backslash K \rightarrow T
\backslash K\)</span> homotopic to the identity has a fixed point. One
can also argue algebraically using the Borel fixed point theorem.</p>
<h2 id="a-change-of-variables">A change of variables</h2>
<p>The groups <span class="math inline">\(N\)</span> and <span
class="math inline">\(A\)</span> are unimodular (indeed, their adjoint
representations are unimodular, hence have trivial determinant). We may
thus equip them with Haar measures, compatibly with the chosen left Haar
measure on <span class="math inline">\(B\)</span> in the sense that
<span class="math display">\[\int_B h
  = \int_{n \in N, a \in A} h(a n)
  = \int_{n \in N, a \in A}
  h(n a) \delta^{-1}(a).\]</span> For instance, if <span
class="math inline">\(G = {\mathop{\mathrm{SL}}}_2(\mathbb{C})\)</span>,
then a left Haar on <span class="math inline">\(B\)</span> is given by
<span class="math display">\[\int_B h
  = \int_{x \in \mathbb{C}, y \in \mathbb{C}^\times}
  h (
  \begin{pmatrix}
    1 &amp; x \\
      &amp; 1
  \end{pmatrix}
  \begin{pmatrix}
    y &amp;  \\
      &amp; y^{-1}
  \end{pmatrix}
  )
  \, \frac{d x \, d ^\times y}{|y|_{\mathbb{C}}^2},\]</span> where <span
class="math inline">\(d x\)</span> and <span
class="math inline">\(d^\times y\)</span> denote Haar measures on <span
class="math inline">\(\mathbb{C}\)</span> and <span
class="math inline">\(\mathbb{C}^\times\)</span> respectively and where
<span class="math display">\[|y|_{\mathbb{C}} := |y|^2\]</span> denotes
the complex modulus, given by the square of the usual complex absolute
value, so that <span class="math inline">\(\int_{x \in \mathbb{C}} h(x)
\, d x = |y|_{\mathbb{C}} \int_{x \in \mathbb{C}} h(y x) \, d x\)</span>
for any <span class="math inline">\(h \in C_c(\mathbb{C})\)</span>, and
so that <span class="math inline">\(d^\times y = d y /
|y|_{\mathbb{C}}\)</span> defines a Haar measure on <span
class="math inline">\(\mathbb{C}^\times\)</span> for each Haar measure
<span class="math inline">\(d y\)</span> on <span
class="math inline">\(\mathbb{C}\)</span>.</p>
<p>We want to rewrite this integral formula for <span
class="math inline">\(B\)</span> so that it interacts better with
conjugacy classes. To start, note that <span
class="math display">\[\begin{pmatrix}
    1 &amp; x \\
      &amp; 1
  \end{pmatrix}
  \begin{pmatrix}
    y &amp;  \\
      &amp; y^{-1}
  \end{pmatrix}
  =
  \begin{pmatrix}
    y &amp; x y^{-1} \\
      &amp; y^{-1}
  \end{pmatrix}
  .\]</span> Now observe that “generically” (i.e., for <span
class="math inline">\(y \neq 1\)</span>), the above matrix has distinct
eigenvalues, hence is conjugate to the diagonal matrix with the same
entries. More explicitly, we have <span
class="math display">\[\begin{pmatrix}
    1 &amp; z \\
      &amp; 1
  \end{pmatrix}
  \begin{pmatrix}
    y &amp;  \\
      &amp; y^{-1}
  \end{pmatrix}
  \begin{pmatrix}
    1 &amp; z \\
      &amp; 1
  \end{pmatrix}
  ^{-1} =
  \begin{pmatrix}
    y &amp; (y^{-1} - y ) z \\
      &amp; y^{-1}
  \end{pmatrix}
  ,\]</span> which equals <span class="math inline">\(\begin{pmatrix}
  y &amp; x y^{-1} \\
  &amp; y^{-1}
\end{pmatrix}\)</span> when <span class="math inline">\(z = x y^{-1} /
(y^{-1} - y)\)</span>. Thus <span id="eqn:sl2-change-of-var" class="math display">\[\label{eqn:sl2-change-of-var}\tag{98}
  \int_{x \in \mathbb{C}}
  h (
\begin{pmatrix}
    1 &amp; x \\
    &amp; 1
  \end{pmatrix}
\begin{pmatrix}
    y &amp;  \\
    &amp; y ^{-1}
  \end{pmatrix}
  ) = \frac {|y^{-1} - y|_{\mathbb{C}}}{|y^{-1}|_{\mathbb{C}}} \int_{z
\in \mathbb{C}} h (
\begin{pmatrix}
    1 &amp; z \\
    &amp; 1
  \end{pmatrix}
\begin{pmatrix}
    y &amp;  \\
    &amp; y^{-1}
  \end{pmatrix}
  \begin{pmatrix}
    1 &amp; z \\
    &amp; 1
  \end{pmatrix}
  ^{-1} )\]</span> and so <span class="math display">\[\int_B h
  =
  \frac {|y^{-1} - y|_{\mathbb{C}}}{|y|_{\mathbb{C}}}
  \int_{x \in \mathbb{C}}
  h (
  \begin{pmatrix}
    1 &amp; x \\
      &amp; 1
  \end{pmatrix}
  \begin{pmatrix}
    y &amp;  \\
      &amp; y^{-1}
  \end{pmatrix}
  \begin{pmatrix}
    1 &amp; x \\
      &amp; 1
  \end{pmatrix}
  ^{-1} ) \, d x \, d^\times y.\]</span> Here it is understood that we
integrate away from the measure zero set of <span
class="math inline">\(y\)</span> for which <span
class="math inline">\(y^2 = 1\)</span>.</p>
<p>A similar argument applied “one root at a time” gives the following
more general identity:</p>
<div id="lem:change-variables-N-A" class="lemma">
<p><strong>Lemma 161</strong>. With Haar measures on <span
class="math inline">\(B,N,A\)</span> compatibly normalized as above, we
have for <span class="math inline">\(h \in C_c(B)\)</span> <span
class="math display">\[\int_B
    h
    =
    \int_{a \in A^{\mathop{\mathrm{reg}}}}
    \frac{\prod _{\alpha &gt; 0}  | a^{\alpha/2} -  a^{-\alpha/2}
      |_{\mathbb{C}}}
    {
      \delta^{1/2}(a)
    }
    \int_{n \in N}
    h (n a n^{-1}),\]</span> with the integral taken over the full
measure subset <span
class="math display">\[A^{\mathop{\mathrm{reg}}}  := \{a \in A :
a^\alpha \neq 1 \text{ for all }
    \alpha \in \Phi\}.\]</span></p>
</div>
<div class="proof"><p>
<a href="#" class="toggle-proof"><em data-default-text="Proof." data-folded-text="Proof. (...)">Proof.</em></a>
<span class="proof-content"> Compare with Knapp, Lemma 10.16. The key point is to
verify the following general form of <a href="#eqn:sl2-change-of-var"
data-reference-type="eqref"
data-reference="eqn:sl2-change-of-var">\((98)\)</a>,
valid for any <span class="math inline">\(a \in
A^{\mathop{\mathrm{reg}}}\)</span>: <span id="eqn:general-change-of-var" class="math display">\[\label{eqn:general-change-of-var}\tag{99}
    \int_{n \in N}
    h (n a)
    =
    \frac {
      \prod_{\alpha &gt; 0}
      |a^{\alpha/2} - a^{-\alpha/2}|_{\mathbb{C}}
    }
    {
      \delta^{-1/2}(a)
    }
    \int_{n \in N}
    h (n a n^{-1}).\]</span> ◻</p>
</span></div>
<p>As a consequence, we can rewrite the formula given above for <span
class="math inline">\(\chi_\lambda\)</span>, as follows. We first define
<span class="math inline">\(F : A^{\mathop{\mathrm{reg}}} \rightarrow
\mathbb{C}\)</span> by the formula <span id="eqn:formula-for-F-on-regular-a" class="math display">\[\label{eqn:formula-for-F-on-regular-a}\tag{100}
  F(a) :=
  (\prod_{\alpha &gt; 0}
  |a^{\alpha/2} - a^{-\alpha/2}|_{\mathbb{C}})
  \int_{g \in A \backslash G}
  f(g^{-1} a g).\]</span> By working backwards through the above
calculations, we see that <span class="math inline">\(F\)</span> extends
to an element of <span class="math inline">\(C_c^\infty(A)\)</span>;
indeed, by <a href="#eqn:general-change-of-var"
data-reference-type="eqref"
data-reference="eqn:general-change-of-var">\((99)\)</a>,
we have for <span class="math inline">\(a \in
A^{\mathop{\mathrm{reg}}}\)</span> <span
class="math display">\[\begin{align}
  F(a)
  &amp;=
    (\prod_{\alpha &gt; 0}
    |a^{\alpha/2} - a^{-\alpha/2}|_{\mathbb{C}})
    \int_{g \in B \backslash G}
    \int_{n \in N}
    f(g^{-1} n a n^{-1} g)
  \\
  &amp;=
    \delta^{-1/2}(a)
    \int_{g \in B \backslash G}
    \int_{n \in N}
    f(g^{-1} n a g)
  \\
  &amp;=
    \delta^{-1/2}(a)
    \int_{k \in K}
    \int_{n \in N}
    f(k^{-1} n a g)
\end{align}\]</span> for a suitable Haar measure on <span
class="math inline">\(K\)</span>, but this last expression defines for
<span class="math inline">\(a \in A\)</span> an element of <span
class="math inline">\(C_c^\infty(A)\)</span>, using here that <span
class="math inline">\(K\)</span> is compact. We define the Fourier
transform <span class="math inline">\(F^\wedge : A^\wedge \rightarrow
\mathbb{C}\)</span> by <span class="math display">\[F^\wedge(\lambda) :=
\int_{a \in A} a^{\lambda} F(a).\]</span> We then obtain <span
class="math display">\[\chi_\lambda(f) = F^\wedge(\lambda).\]</span> We
equip <span class="math inline">\(A^\wedge\)</span> with the Haar
measure dual to that on <span class="math inline">\(A\)</span>, so that
the Fourier inversion formula <span class="math inline">\(F(1) =
\int_{\lambda \in A^\wedge} F^\wedge(\lambda)\)</span> holds.</p>
<h2 id="passage-to-the-lie-algebra">Passage to the Lie algebra</h2>
<p>Suppose now that <span class="math inline">\(f \in
C_c^\infty(G)\)</span> as above is supported in a “small
conjugation-invariant neighborhood” <span
class="math inline">\(U\)</span> of the identity element <span
class="math inline">\(1\)</span> of the Lie group <span
class="math inline">\(G\)</span>. For example, in the case <span
class="math inline">\(G = {\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span>,
we might define <span class="math inline">\(U\)</span> to be the set of
all <span class="math inline">\(g \in G\)</span> each of whose
eigenvalues <span class="math inline">\(c\)</span> satisfies <span
class="math inline">\(|c - 1 | &lt; \varepsilon\)</span> for some small
<span class="math inline">\(\varepsilon&gt; 0\)</span>; alternatively,
we might ask that the subleading coefficients of the characteristic
polynomial of <span class="math inline">\(g\)</span> be bounded by <span
class="math inline">\(\varepsilon\)</span>. We may then find a small
<span class="math inline">\(\mathop{\mathrm{Ad}}(G)\)</span>-invariant
neighborhood <span class="math inline">\(Y\)</span> of the origin <span
class="math inline">\(0\)</span> of the Lie algebra <span
class="math inline">\(\mathfrak{g}\)</span> such that <span
class="math inline">\(\exp : Y \rightarrow U\)</span> is a
diffeomorphism onto its image. We may define an element <span
class="math inline">\(f_0 \in C_c^\infty(Y)\)</span> by requiring that
<span class="math inline">\(f_0(x) = f(\exp(x))\)</span>. We define
<span class="math inline">\(F_0 \in C_c^\infty(\mathfrak{a})\)</span> to
vanish off elements <span class="math inline">\(x \in \mathfrak{a} \cap
Y\)</span>, for which we set <span class="math inline">\(F_0(x) :=
F(\exp(x))\)</span>, with <span class="math inline">\(F\)</span>
attached to <span class="math inline">\(f\)</span> as above. We equip
<span class="math inline">\(\mathfrak{a}\)</span> with the Haar measure
matching up near the origin under the exponential map with the Haar
measure on <span class="math inline">\(A\)</span> near the identity. For
<span class="math inline">\(\lambda \in \mathfrak{a}^\wedge\)</span>
(hence, in particular, for <span class="math inline">\(\lambda \in
A^\wedge)\)</span>, we may define the Fourier transform <span
class="math inline">\(F_0^\wedge(\lambda)\)</span>; we have <span
class="math inline">\(F_0^\wedge(\lambda) = F^\wedge(\lambda)\)</span>
when <span class="math inline">\(\lambda \in A^\wedge\)</span>. (Recall
from before that <span class="math inline">\(\mathfrak{a}^\wedge \cong
(\mathbb{R} \times \mathbb{R})^n\)</span> while <span
class="math inline">\(A^\wedge \cong (\mathbb{R} \times
\mathbb{Z})^n\)</span>.) We equip <span
class="math inline">\(\mathfrak{a}^\wedge\)</span> with the dual Haar
measure, so that the Fourier inversion formula <span
class="math inline">\(F_0(0) = \int_{\lambda \in \mathfrak{a}^\wedge}
F_0^\wedge(\lambda)\)</span> holds.</p>
<p>Recall that we’ve fixed a Haar measure <span class="math inline">\(d
g\)</span> on <span class="math inline">\(G\)</span>. We equip <span
class="math inline">\(\mathfrak{g}\)</span> with the Haar measure <span
class="math inline">\(d x\)</span> so that for small <span
class="math inline">\(x \in \mathfrak{g}\)</span>, writing <span
class="math inline">\(g = \exp(x)\)</span>, we have <span
class="math inline">\(d g = j(x) \, d x\)</span>, with <span
class="math inline">\(j(0) = 1\)</span>. Using Lemma <a
href="#lem:deriv-of-expo" data-reference-type="ref"
data-reference="lem:deriv-of-expo">80</a>, one may check then that the
inverse square root of <span class="math inline">\(j\)</span> admits the
following formula for small enough regular elements <span
class="math inline">\(x \in \mathfrak{a}\)</span>: <span
class="math display">\[j^{-1/2}(x)
  = \prod_{\alpha &gt; 0}
  \left\lvert
    \frac
    {
      e^{\alpha(a)/2}
      -
      e^{-\alpha(a)/2}
    }
    {
      \alpha(x)
    }
  \right\rvert.\]</span></p>
<h2 id="main-result">Main result</h2>
<p>We define a polynomial function <span class="math inline">\(P :
\mathfrak{a}^\wedge \rightarrow \mathbb{R}\)</span> by the formula <span
class="math inline">\(P(\lambda) := \prod_{\alpha &gt; 0} |
\lambda(H_\alpha)|_{\mathbb{C}}\)</span>. We aim to show the
following:</p>
<div class="theorem">
<p><strong>Theorem 162</strong>. <em>For <span class="math inline">\(f
\in C_c^\infty(G)\)</span>, and with measures as normalized above, <span
class="math display">\[f(1)
    = \int_{\lambda \in A^\wedge}
    \frac{P(\lambda)}{|W|}
    \chi_\lambda(f).\]</span></em></p>
</div>
<p>This is a theorem of Gelfand–Naimark. We’ll loosely follow
Harish-Chandra’s proof technique, as exposed in the textbook of
Varadarajan. It is a fact that we will not have time to prove that the
<span class="math inline">\(\pi_\lambda\)</span> are
<em>irreducible</em> unitary representations of <span
class="math inline">\(G\)</span>, so this theorem gives the desired
Plancherel formula.</p>
<p>Let’s suppose first that <span class="math inline">\(f\)</span> is
supported in a small conjugation-invariant neighborhood of <span
class="math inline">\(1\)</span>, in the sense described above, so that
we may define <span class="math inline">\(F, f_0, F_0\)</span>. The
formula <a href="#eqn:formula-for-F-on-regular-a"
data-reference-type="eqref"
data-reference="eqn:formula-for-F-on-regular-a">\((100)\)</a>
implies that for small regular <span class="math inline">\(x \in
\mathfrak{a}\)</span>, we have <span class="math display">\[F_0(x)
  =
  (
  \prod _{\alpha &gt; 0 }
  e ^{\alpha(x)/2}
  - e^{-\alpha(x)/2}
  )
  \int_{g \in G/B}
  \int_{n \in N}
  f_0(\mathop{\mathrm{Ad}}(g n) x).\]</span> The exponential map
restricts to a polynomial diffeomorphism <span
class="math inline">\(\exp : \mathfrak{n} \rightarrow N\)</span> with
polynomial inverse <span class="math inline">\(\log : N \rightarrow
\mathfrak{n}\)</span>. We may normalize the Haar measure on <span
class="math inline">\(\mathfrak{n}\)</span> to be compatible with <span
class="math inline">\(\exp\)</span>. With the abbreivation <span
class="math inline">\(f_0^g(y) := f_0(\mathop{\mathrm{Ad}}(g)
y)\)</span>, we then obtain <span class="math display">\[F_0(x)
  =
  (
  \prod _{\alpha &gt; 0 }
  e ^{\alpha(x)/2}
  - e^{-\alpha(x)/2}
  )
  \int_{g \in G/B}
  \int_{y \in \mathfrak{n}}
  f_0^g(\mathop{\mathrm{Ad}}(e^y) x).\]</span> By the Lie algebra
analogue of Lemma <a href="#lem:change-variables-N-A"
data-reference-type="ref"
data-reference="lem:change-variables-N-A">161</a>, we have <span id="eqn:lie-algebra-change-of-var" class="math display">\[\label{eqn:lie-algebra-change-of-var}\tag{101}
  \int_{y \in \mathfrak{n}}
  f_0^g(\mathop{\mathrm{Ad}}(e^y) x)
  =
  (
  \prod_{\alpha&gt;0} |\alpha(x)|_{\mathbb{C}}^{-1}
  )
  \int_{y \in \mathfrak{n}}
  f_0^g(y + x).\]</span> Thus <span class="math display">\[F_0(x)
  = j^{-1/2}(x)
  \int_{g \in G/B, y \in \mathfrak{n}}
  f_0^g(x+y).\]</span> The function <span
class="math inline">\(j^{-1/2}\)</span> extends to an <span
class="math inline">\(\mathop{\mathrm{Ad}}(G)\)</span>-invariant
function on <span class="math inline">\(\mathfrak{g}\)</span>. Setting
<span class="math inline">\(\phi := j^{-1/2} f_0\)</span>, we may
rewrite the above formula as <span class="math display">\[F_0(x)
  = \int_{g \in G/B, y \in \mathfrak{n}}
  \phi^g(x+y).\]</span> Recall the decomposition <span
class="math inline">\(\mathfrak{g} = \mathfrak{n} \oplus \mathfrak{a}
\oplus \overline{\mathfrak{n} }\)</span>. Fix <span
class="math inline">\(K \hookrightarrow \mathop{\mathrm{U}}(n)\)</span>
and hence <span class="math inline">\(G \hookrightarrow
{\mathop{\mathrm{GL}}}_n(\mathbb{C})\)</span> as usual. We then get a
perfect <span
class="math inline">\(\mathop{\mathrm{Ad}}(G)\)</span>-equivariant
pairing <span class="math inline">\(\mathfrak{g} \otimes \mathfrak{g}
\rightarrow \mathbb{C}\)</span> given by <span
class="math inline">\((x,y) \mapsto \mathop{\mathrm{trace}}(x
y)\)</span>. Using this we may identify <span
class="math inline">\(\mathfrak{g}^\wedge\)</span> with <span
class="math inline">\(\mathfrak{g}\)</span>. Under this identification,
<span class="math inline">\(\mathfrak{n}\)</span> and <span
class="math inline">\(\overline{\mathfrak{n}}\)</span> are dual to one
another, while <span class="math inline">\(\mathfrak{a}\)</span> is dual
to itself. Integrating the above formula for <span
class="math inline">\(F_0\)</span> over regular <span
class="math inline">\(x \in \mathfrak{a}\)</span> thus gives for all
<span class="math inline">\(\lambda \in \mathfrak{a}^\wedge\)</span>
that <span class="math display">\[F_0^\wedge(\lambda)
  = \int_{g \in G/B}
  \int_{\eta \in \mathfrak{b}^\perp \subseteq
    \mathfrak{g}^\wedge}
  \hat{\phi}^g(\lambda+\eta).\]</span> Here <span
class="math inline">\(\hat{\phi}\)</span> denotes the Fourier transform
and <span class="math inline">\(\mathfrak{b}^\perp\)</span> the subspace
of <span class="math inline">\(\mathfrak{g}^\wedge\)</span> that
annihilates <span class="math inline">\(\mathfrak{b}\)</span>; by the
above discussion, it identifies with <span
class="math inline">\(\mathfrak{n}\)</span>.</p>
<p>We say that <span class="math inline">\(\lambda \in
\mathfrak{a}^\wedge\)</span> is <em>regular</em> if <span
class="math inline">\(\lambda(H_\alpha) \neq 0\)</span> for all roots
<span class="math inline">\(\alpha\)</span>. By the analogue of <a
href="#eqn:lie-algebra-change-of-var" data-reference-type="eqref"
data-reference="eqn:lie-algebra-change-of-var">\((101)\)</a>
for <span class="math inline">\(\mathfrak{g}^\wedge\)</span>, we see
that for regular <span class="math inline">\(\lambda \in
\mathfrak{a}^\wedge\)</span>, <span
class="math display">\[F_0^\wedge(\lambda)
  = (\prod_{\alpha &gt; 0}
  |\lambda(H_\alpha)|_{\mathbb{C}})
  \int_{g \in G/A}
  \hat{\phi}(\mathop{\mathrm{Ad}}(g) \lambda).\]</span> Let’s denote the
latter expression by <span
class="math inline">\(\int_{\mathcal{O}_\lambda} \hat{\phi}\)</span>;
it’s a normalized integral over the <span
class="math inline">\(G\)</span>-orbit <span
class="math inline">\(\mathcal{O}_\lambda\)</span> of <span
class="math inline">\(\lambda\)</span>. Then we have the following
analogue of the Weyl integral formula for <span class="math inline">\(h
\in C_c(\mathfrak{g}^\wedge)\)</span>: <span
class="math display">\[\int_{\mathfrak{g}^\wedge}
  h
  = \frac{1}{|W|}
  \int_{\lambda \in \mathfrak{a}^\wedge,\text{regular}}
  P(\lambda)
  \int_{\mathcal{O}_\lambda} h.\]</span> (The key point here is that the
union of the orbits <span
class="math inline">\(\mathcal{O}_\lambda\)</span> is open and dense in
<span class="math inline">\(G\)</span>; we may thus reduce to the usual
Jacobian calculation.)</p>
<p>We’re now ready to prove the theorem. We denote by <span
class="math inline">\(\partial_P\)</span> the translation-invariant
differential operator on <span
class="math inline">\(C_c^\infty(A)\)</span> or on <span
class="math inline">\(C_c^\infty(\mathfrak{a})\)</span> with symbol
<span class="math inline">\(P\)</span>, so that <span
class="math inline">\((\partial_P h)^\wedge = P \cdot \hat{h}\)</span>.
Let <span class="math inline">\(f \in C_c^\infty(G)\)</span>. Define
<span class="math inline">\(F\)</span> as above. Then <span
class="math display">\[\int_{\lambda \in \mathfrak{a}^\wedge}
  \frac{P(\lambda)}{|W|}
  \underbrace{\chi_\lambda(f)}_{=F^\wedge(\lambda)}
  =
  \frac{(\partial_P F)(1)}{|W|}.\]</span> We want to show that this last
expression equals <span class="math inline">\(f(1)\)</span>. By smoothly
and <span
class="math inline">\(\mathop{\mathrm{Ad}}(G)\)</span>-invariantly
truncating, we may assume that <span class="math inline">\(f\)</span> is
supported in a small conjugation-invariant neighborhood of the identity,
so that we may define <span class="math inline">\(f_0,F_0,\phi\)</span>
as above. Then, combining everything we’ve shown thus far, we conclude
that <span class="math display">\[\begin{align}
  \frac{(\partial_P F)(1)}{|W|}
  &amp;=
    \frac{\partial_P F_0(0)}{|W|}
  \\
  &amp;=
    \int_{\lambda \in \mathfrak{a}^\wedge}
    \frac{P(\lambda)}{|W|}
    \int_{\mathcal{O}_\lambda}
    \hat{\phi}
  \\
  &amp;= \int_{\mathfrak{g}^\wedge}
    \hat{\phi}
  \\
  &amp;=
    \phi(0)
  \\
  &amp;= f_0(0)
  \\
  &amp;= f(1),
\end{align}\]</span> as required.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The continuity and related conditions follow from the
positivity, see, e.g., the Wikipedia entries on “Radon measure” and
“Riesz-Kakutani representation theorem”<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>End of lecture #1, Tuesday, 19 Feb 2019<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>End of lecture #2, Thursday, 21 Feb 2019<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>End of lecture #3, Tuesday, 26 Feb 2019<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>End of lecture #4, Thursday, 28 Feb 2019<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>End of lecture #5, Tuesday, 5 March<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>End of lecture #6, Thursday, 7 March<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>End of lecture #7, Tuesday, 12 March<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>End of half-lecture #8, Thursday, 14 March<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><em>End of half-lecture #9, Tuesday, 19 March</em><a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>End of lecture #10, Tuesday, 26 March<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>End of lecture #11, Thursday, 28 March<a
href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>End of lecture #12, Tuesday, 2 Apr<a href="#fnref13"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>End of lecture #13, Thursday, 4 Apr<a href="#fnref14"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>End of lecture #14, Tuesday, 9 Apr<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>End of half-lecture #15, Thursday, 11 Apr<a
href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>End of half-lecture #16, Tuesday, 16 Apr<a
href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>End of lecture #17, Thursday, 18 Apr<a href="#fnref18"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>End of lecture #18, Tuesday, 30 Apr 2019<a
href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>End of lecture #???<a href="#fnref20"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<script>
document.querySelectorAll(".toggle-proof").forEach(function(toggle) {
  toggle.addEventListener("click", function(e) {
    e.preventDefault();
    const content = this.nextElementSibling;
    const em = this.querySelector('em');
    if (window.getComputedStyle(content).display === "none") {
      content.style.display = "inline";
      em.textContent = em.dataset.defaultText;
    } else {
      content.style.display = "none";
      em.textContent = em.dataset.foldedText;
    }
  });
});
</script>
<script>
document.querySelector("#toggle-all-proofs").addEventListener("click", function(e) {
  e.preventDefault();
  const proofs = document.querySelectorAll(".proof-content");
  proofs.forEach(function(proof) {
    const proofToggle = proof.previousElementSibling;
    if (window.getComputedStyle(proof).display === "none") {
      proof.style.display = "inline";
      proofToggle.innerHTML = `<em>${proofToggle.dataset.defaultText}</em>`;
    } else {
      proof.style.display = "none";
      proofToggle.innerHTML = `<em>${proofToggle.dataset.foldedText}</em>`;
    }
  });
});
</script>

<script src="https://giscus.app/client.js"
        data-repo="Ultronozm/math"
        data-repo-id="R_kgDOJlhjqQ"
        data-category="Announcements"
        data-category-id="DIC_kwDOJlhjqc4CWo21"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</body>
</html>
